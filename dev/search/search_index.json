{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"sleap-io","text":"<p>Standalone utilities for working with animal pose tracking data.</p> <p>This is intended to be a complement to the core SLEAP package that aims to provide functionality for interacting with pose tracking-related data structures and file formats with minimal dependencies. This package does not have any functionality related to labeling, training, or inference.</p>"},{"location":"#features","title":"Features","text":"<p>The main purpose of this library is to provide utilities to load/save from different formats for pose data and standardize them into our common Data Model.</p> <ul> <li>Read/write labels in SLP, NWB, AlphaTracker, DeepLabCut, JABS, LabelStudio, LEAP and Ultralytics YOLO formats.</li> <li>Support for LabelsSet to manage multiple dataset splits (train/val/test) and export to different formats.</li> <li>Read videos in any format, work them in a numpy-like interface whether the video files are accessible or not, and easily save them out.</li> </ul> <p>This enables ease-of-use through format-agnostic operations that make it easy to work with pose data, including utilities for common tasks. Some of these include:</p> <ul> <li>Create labels from a custom format</li> <li>Convert labels to numpy arrays for analysis</li> <li>Fix video paths in the labels</li> <li>Make training/validation/test splits</li> <li>Work with dataset splits using LabelsSet</li> <li>Replace a skeleton</li> </ul> <p>See Examples for more usage examples and recipes.</p>"},{"location":"#installation","title":"Installation","text":""},{"location":"#from-pypi","title":"From PyPI","text":"<pre><code>pip install sleap-io\n</code></pre> <p>or</p> <pre><code>conda install -c conda-forge sleap-io\n</code></pre>"},{"location":"#from-source-latest-version","title":"From source (latest version)","text":"<pre><code>pip install git+https://github.com/talmolab/sleap-io.git@main\n</code></pre>"},{"location":"#optional-dependencies","title":"Optional Dependencies","text":"<p>For video backend support, install with extras: <pre><code>pip install sleap-io[opencv]  # For OpenCV backend\npip install sleap-io[av]       # For PyAV backend\npip install sleap-io[mat]      # For LEAP .mat file support\npip install sleap-io[all]      # For all backends and formats\n</code></pre></p>"},{"location":"#development-installation","title":"Development Installation","text":"<p>For development, use one of the following: <pre><code>uv sync --all-extras           # Recommended: install with uv\n</code></pre> <pre><code>conda env create -f environment.yml\n</code></pre> <pre><code>pip install -e .[dev,all]      # Install with all extras for development\n</code></pre></p>"},{"location":"#support","title":"Support","text":"<p>For technical inquiries specific to this package, please open an Issue with a description of your problem or request.</p> <p>For general SLEAP usage, see the main website.</p> <p>Other questions? Reach out to <code>talmo@salk.edu</code>.</p>"},{"location":"#license","title":"License","text":"<p>This package is distributed under a BSD 3-Clause License and can be used without restrictions. See <code>LICENSE</code> for details.</p>"},{"location":"changelog/","title":"Changelog","text":""},{"location":"changelog/#v052","title":"v0.5.2\ud83c\udfaf Summary\u2728 New Features\ud83d\udc1b Bug Fixes\ud83d\udca1 Why These Changes Matter\ud83d\udccb Changelog","text":"<p>This release significantly expands sleap-io's format compatibility with three major new pose tracking format readers and important bug fixes. The v0.5.2 release adds support for LEAP MATLAB files, AlphaTracker JSON annotations, and introduces a comprehensive NWB training data I/O system with a simplified API. These additions further establish sleap-io as the universal utility for pose tracking data conversion and interoperability.</p> LEAP .mat Format Reader (#224) <p>Added comprehensive support for reading LEAP (LEAP Estimates Animal Pose) MATLAB <code>.mat</code> files, enabling integration with the LEAP deep learning framework.</p> <p>Key capabilities:</p> <ul> <li>Automatic skeleton detection from <code>nodes</code>/<code>joints</code> fields</li> <li>Flexible position data parsing (handles multiple array shapes and field names)</li> <li>Video path inference when missing from metadata</li> <li>Custom skeleton override support</li> <li>MATLAB 1-based to Python 0-based index conversion</li> </ul> <pre>import sleap_io as sio\n\n# Basic loading\nlabels = sio.load_leap(\"path/to/leap_data.mat\")\n\n# Auto-detection via load_file\nlabels = sio.load_file(\"path/to/leap_data.mat\")\n\n# Custom skeleton override\ncustom_skeleton = sio.Skeleton(\n    nodes=[\"head\", \"tail\"], \n    edges=[(\"head\", \"tail\")]\n)\nlabels = sio.load_leap(\"path/to/leap_data.mat\", skeleton=custom_skeleton)</pre> <p>Installation: Requires the <code>pymatreader</code> package:</p> <pre># Install with LEAP support\npip install sleap-io[mat]\n# or with all extras\nuv sync --all-extras</pre> AlphaTracker Format Reader (#227) <p>Implemented reading support for AlphaTracker JSON annotation format, a multi-animal pose tracking system that exports annotations with bounding boxes and keypoints.</p> <p>Key features:</p> <ul> <li>Dynamic skeleton detection by scanning all annotations</li> <li>Robust annotation grouping (Face markers + sequential keypoints)</li> <li>Handles variable numbers of keypoints per animal</li> <li>Graceful handling of extra annotation types</li> <li>Automatic ImageVideo construction from referenced images</li> </ul> <pre>from sleap_io import load_file\n\n# Auto-detect format\nlabels = load_file(\"path/to/alphatracker.json\")\n\n# Or specify explicitly\nlabels = load_file(\"path/to/alphatracker.json\", format=\"alphatracker\")\n\n# Access the data\nfor lf in labels.labeled_frames:\n    for instance in lf.instances:\n        points = instance.points[\"xy\"]  # Shape: (n_nodes, 2)</pre> Comprehensive NWB Training Data I/O (#228) <p>Introduced a major enhancement to NWB (Neurodata Without Borders) support with a harmonization layer that unifies reading and writing of both annotations and predictions. See <code>ndx-pose</code> for more information on the specification.</p> <p>Harmonization Layer:</p> <ul> <li>Unified API: Single <code>load_nwb()</code> and <code>save_nwb()</code> functions with auto-detection</li> <li>Format flexibility: Supports multiple NWB output formats via <code>NwbFormat</code> enum</li> <li>Auto-detection: Intelligently routes to appropriate backends based on data type</li> </ul> <p>Training Data I/O:</p> <ul> <li>Full roundtrip conversion with complex skeleton hierarchies</li> <li>Multi-skeleton support and frame provenance tracking</li> <li>Video export with embedded frames using optimized MJPEG writer</li> <li>Custom NWB metadata support</li> </ul> <pre>from sleap_io import load_nwb, save_nwb\n\n# Universal loading (auto-detects format)\nlabels = load_nwb(\"pose_data.nwb\")\n\n# Save with auto-detection\nsave_nwb(labels, \"output.nwb\")  # Auto-detects annotation vs prediction\n\n# Force specific format\nsave_nwb(labels, \"annotations.nwb\", nwb_format=\"annotations\")\nsave_nwb(labels, \"predictions.nwb\", nwb_format=\"predictions\")\n\n# Export with embedded video frames\nfrom sleap_io.io.nwb_annotations import export_labels\n\nexport_labels(\n    labels,\n    output_dir=\"export/\",\n    nwb_filename=\"training_with_video.nwb\",\n    as_training=True,\n    include_videos=True\n)</pre> Fixed SLP Skeleton Format Compatibility (#222) <ul> <li>Resolved loading issues with newer SLEAP v1.3.2+ files that use the new \"nx_graph\" skeleton wrapper format</li> <li>Maintains backward compatibility with legacy skeleton format</li> <li>Added comprehensive test coverage with new format fixtures</li> </ul> <p>Impact: Projects created with SLEAP v1.3.2 and later can now be loaded correctly without skeleton parsing errors.</p> <p>The v0.5.2 release significantly strengthens sleap-io's position as a universal pose tracking data utility:</p> <ul> <li>Ecosystem Integration: Support for LEAP and AlphaTracker expands compatibility with popular pose estimation frameworks</li> <li>HITL Workflows: Enhanced NWB training data I/O enables sophisticated human-in-the-loop annotation workflows</li> <li>Data Provenance: Frame mapping and metadata preservation ensure traceability in complex analysis pipelines</li> <li>Research Flexibility: Researchers can now seamlessly move data between SLEAP, LEAP, AlphaTracker, and NWB ecosystems</li> <li>Future-Proofing: Updated format support ensures compatibility with evolving versions of partner tools</li> </ul> <ul> <li>#222: Fix for SLP skeleton format variant (@talmo)</li> <li>#223: Bump version to 0.5.2 (@talmo)</li> <li>#224: Add LEAP .mat format reader (@talmo)</li> <li>#227: Add AlphaTracker format reader (@talmo)</li> <li>#228: Add NWB training data I/O with simplified API (@talmo)</li> </ul> <p>Full Changelog: v0.5.1...v0.5.2</p>"},{"location":"changelog/#v051","title":"v0.5.1\ud83c\udfaf Summary\u2728 New Features\ud83d\udc1b Bug Fixes\ud83d\udd27 Improvements\ud83d\udcda Documentation\ud83d\udca1 Why These Changes Matter\ud83d\udccb Changelog","text":"<p>This release introduces powerful merging capabilities for annotation workflows, enhanced image sequence handling, and improved developer tooling. The highlight is the new comprehensive merging system that enables human-in-the-loop (HITL) workflows and smart combination of multiple annotation sources.</p> Comprehensive Merging System (#216) <ul> <li>New <code>Labels.merge()</code> method with configurable strategies for combining annotations from multiple sources</li> <li>Smart merge strategies that preserve user labels over predictions</li> <li>Instance matching with spatial, identity, and IoU-based methods</li> <li>Skeleton harmonization for consistent structure across merged data</li> <li>Video path resolution with automatic path repair</li> <li>Progress tracking and provenance metadata for merge operations</li> </ul> <pre># Merge annotations with smart conflict resolution\nmerged = labels1.merge(labels2, strategy=\"smart\")\n\n# Custom merge with specific matchers\nmerged = labels1.merge(\n    labels2,\n    video_matcher=\"shape\",  # Match videos by dimensions\n    instance_matcher=\"iou\",  # Match instances by overlap\n    conflict_strategy=\"user\"  # Prefer user annotations\n)</pre> <p>See the new Merging guide for more information.</p> Enhanced <code>ImageVideo</code> support for merging (#219) <ul> <li>Image deduplication with new <code>IMAGE_DEDUP</code> matcher</li> <li>Shape-based matching for merging videos with same dimensions</li> <li>CVAT format support with automatic track preservation</li> <li>New Video methods: <ul> <li><code>has_overlapping_images()</code> - Check for duplicate frames</li> <li><code>matches_shape()</code> - Compare video dimensions</li> <li><code>deduplicate_with()</code> - Remove duplicate frames</li> <li><code>merge_with()</code> - Combine image sequences</li> </ul> </li> </ul> <pre># Remove duplicate images from a video\nvideo_dedup = video.deduplicate_with(other_video)\n\n# Check if videos have the same shape\nif video1.matches_shape(video2):\n    merged = video1.merge_with(video2)</pre> Fixed Duplicate Skeleton Symmetries (#217) <ul> <li>Resolved issue where legacy SLEAP files could create duplicate symmetry relationships</li> <li>Ensures clean YAML exports without redundant symmetry definitions</li> </ul> Developer Tooling (#218) <ul> <li>New coverage analysis script (<code>scripts/cov_summary.py</code>) for PR-aware coverage reporting</li> <li>GitHub CLI integration for targeted coverage analysis of changed files</li> <li>Simplified coverage command with line-by-line annotations</li> </ul> <pre># Quick coverage check with annotations\nuv run pytest -q --maxfail=1 --cov --cov-branch &amp;&amp; uv run coverage annotate\n\n# Get coverage for PR changes only\nuv run python scripts/cov_summary.py</pre> Improved Documentation Structure (#220) <ul> <li>Restructured merging documentation with detailed algorithm explanations</li> <li>Enhanced examples with visual improvements using MkDocs Material</li> <li>Added mermaid flowcharts and behavior matrices for better understanding</li> <li>Improved organization with progressive disclosure of complex topics</li> </ul> <p>The v0.5.1 release significantly enhances sleap-io's capabilities for real-world annotation workflows:</p> <ul> <li>HITL Workflows: The new merging system enables seamless integration of manual corrections with model predictions</li> <li>Data Consolidation: Easily combine annotations from multiple annotators or sessions</li> <li>Video Management: Better handling of image sequences with automatic deduplication</li> <li>Developer Experience: Improved tooling for maintaining code quality and test coverage</li> </ul> <ul> <li>#216: Implement comprehensive merging system for annotation files (@talmo)</li> <li>#217: Fix duplicate skeleton symmetries from legacy SLEAP files (@talmo)</li> <li>#218: Add coverage summary script and update coverage command (@talmo)</li> <li>#219: Deduplicate merging for <code>ImageVideo</code> and add better CVAT support (@talmo)</li> <li>#220: Documentation improvements for merging capabilities (@talmo)</li> </ul> <p>Full Changelog: v0.5.0...v0.5.1</p>"},{"location":"changelog/#v050","title":"v0.5.0SummaryChangelog","text":"Overview <p>The v0.5.0 release of sleap-io represents a major leap forward in format compatibility, development tooling, and data management capabilities. This release introduces support for five new pose tracking formats (COCO, DeepLabCut, TIFF stacks, and enhanced Ultralytics), adds powerful multi-dataset management with <code>LabelsSet</code>, and modernizes the development workflow with UV package manager. The release also includes critical bug fixes, performance improvements, and comprehensive documentation updates.</p> \ud83d\ude80 New Features Multi-Dataset Management with LabelsSet (#197) <p>sleap-io now provides a powerful <code>LabelsSet</code> container for managing multiple <code>Labels</code> objects, enabling seamless handling of train/val/test splits and dataset collections.</p> <p>This feature includes:</p> <ul> <li>Hybrid dictionary/tuple interface for flexible access patterns</li> <li>Automatic split creation from existing datasets</li> <li>Batch I/O operations for entire dataset collections</li> <li>Backward-compatible API that doesn't break existing code</li> </ul> <p>Usage:</p> <pre>import sleap_io as sio\n\n# Create train/val/test splits\nsplits = labels.make_training_splits(n_train=0.8, n_test=0.1)\n\n# Access as dictionary\ntrain = splits[\"train\"]\nval = splits[\"val\"]\ntest = splits[\"test\"]\n\n# Or unpack as tuple (backward compatible)\ntrain, val, test = splits\n\n# Save all splits at once\nsplits.save(\"splits/\", embed=True)  # Creates train.pkg.slp, val.pkg.slp, test.pkg.slp\n\n# Load multi-split datasets\nlabels_set = sio.load_labels_set(\"path/to/splits/\")</pre> COCO-Style Dataset Support (#199) <p>Added comprehensive support for reading COCO pose format, enabling integration with the broader computer vision ecosystem.</p> <p>Features:</p> <ul> <li>Automatic skeleton creation from COCO categories</li> <li>Multi-species support with different skeletons per category</li> <li>Flexible directory structure handling (flat, nested, categorized)</li> <li>Binary and ternary visibility encodings</li> <li>Memory-efficient shared video objects for images</li> </ul> <p>Usage:</p> <pre>import sleap_io as sio\n\n# Load COCO annotations\nlabels = sio.load_file(\"annotations.json\", format=\"coco\")\n\n# Load with custom image root\nlabels = sio.load_file(\"coco_data.json\", dataset_root=\"/path/to/images\")\n\n# Load multi-split COCO dataset\nlabels_set = sio.load_labels_set(\"dataset/\", format=\"coco\")</pre> DeepLabCut Training Data Support (#201) <p>Implemented complete support for reading DeepLabCut CSV files, supporting all DLC format variations.</p> <p>Capabilities:</p> <ul> <li>Single-animal tracking (SADLC)</li> <li>Multi-animal tracking (MADLC)</li> <li>Multi-animal with identity tracking (MAUDLC)</li> <li>Automatic format detection from CSV headers</li> <li>Proper video grouping from image directories</li> </ul> <p>Usage:</p> <pre>import sleap_io as sio\n\n# Load DLC annotations\nlabels = sio.load_file(\"CollectedData_scorer.csv\")\n\n# Access the data\nprint(f\"Found {len(labels.labeled_frames)} labeled frames\")\nfor lf in labels.labeled_frames:\n    for instance in lf.instances:\n        if instance.track:\n            print(f\"Individual '{instance.track.name}': {instance.numpy()}\")</pre> TIFF Stack Support (#195) <p>Added native support for multi-page TIFF files through a new <code>TiffVideo</code> backend.</p> <p>Features:</p> <ul> <li>Automatic detection of single vs multi-page TIFFs</li> <li>Frame-by-frame access for TIFF stacks</li> <li>Full SLP serialization support</li> <li>Backward compatibility with older SLEAP versions</li> </ul> <p>Usage:</p> <pre>import sleap_io as sio\n\n# Load multi-page TIFF\nvideo = sio.Video.from_filename(\"multipage_stack.tif\")\nprint(f\"Stack has {video.shape[0]} frames\")\n\n# Use in labels\nlabels = sio.Labels()\nlabels.videos.append(video)\nlabels.save(\"project.slp\")  # TiffVideo metadata preserved</pre> Video Plugin Management (#202) <p>Introduced comprehensive control over video backend selection to handle platform-specific codec issues.</p> <p>New capabilities:</p> <ul> <li>Global default plugin setting</li> <li>Flexible plugin name aliases (case-insensitive)</li> <li>Runtime plugin switching on existing videos</li> <li>Batch plugin changes for entire projects</li> </ul> <p>Usage:</p> <pre>import sleap_io as sio\n\n# Set global default\nsio.set_default_video_plugin(\"opencv\")  # or \"cv2\", \"cv\", \"ocv\"\n\n# Load with specific plugin\nvideo = sio.load_video(\"video.mp4\", plugin=\"FFMPEG\")\n\n# Switch plugin on existing video\nvideo.set_video_plugin(\"pyav\")  # or \"av\", \"PyAV\"\n\n# Batch change for all videos in project\nlabels = sio.load_slp(\"project.slp\")\nlabels.set_video_plugin(\"opencv\")</pre> \ud83d\udc1b Bug Fixes Fixed Skeleton Node Order Decoding (#208) <ul> <li>Fixed incorrect node ordering when loading skeletons from training configs with non-sequential py/ids</li> <li>Resolved edge connection errors that occurred with complex skeletons</li> <li>Added comprehensive tests for node and edge order preservation</li> </ul> <p>Impact: Skeletons loaded from training configs now correctly preserve their structure and edge connections.</p> \ud83d\udd27 Improvements Performance: Labels.replace_filenames Control (#213) <p>Added <code>open_videos</code> parameter to <code>Labels.replace_filenames()</code> for better performance when working with network storage:</p> <pre># Replace paths without opening videos (faster on network storage)\nlabels.replace_filenames(\n    prefix_map={\"/old/network/path\": \"/new/network/path\"},\n    open_videos=False  # Avoid costly file checks\n)</pre> <p>Impact: Significantly faster filename replacement operations when dealing with many files on network storage.</p> Development Workflow: UV Migration (#214) <p>Migrated CI/CD and development tooling from conda to UV for dramatic performance improvements:</p> <ul> <li>10-100x faster dependency resolution and installation</li> <li>CI runtime reduced from ~12 minutes to ~2 minutes</li> <li>Single tool for all Python/package management tasks</li> <li>PyPI trusted publisher for improved security</li> </ul> <p>Developer experience:</p> <pre># One-line setup\nuv sync --all-extras\n\n# All commands now use uv run prefix\nuv run pytest tests/\nuv run ruff check sleap_io tests\nuv build</pre> Tooling: Unified Linting with Ruff (#194) <p>Replaced black and pydocstyle with ruff for unified, faster code quality checks:</p> <ul> <li>Single tool for both formatting and linting</li> <li>Significantly faster CI runs</li> <li>Fixed 50+ code quality issues during migration</li> <li>Consistent configuration and error reporting</li> </ul> Documentation Enhancements (#203, #215) <p>Comprehensive documentation improvements for both AI assistants and human contributors:</p> <ul> <li>Added Claude Code integration with <code>.claude/commands</code> directory</li> <li>Visual data model diagram with relationships</li> <li>Modernized CONTRIBUTING.md with Quick Start section</li> <li>Updated all examples to use UV commands</li> <li>Streamlined testing and coverage workflows</li> </ul> \ud83d\udce6 Dependencies <ul> <li>Added <code>pyyaml</code> for YAML skeleton support (from v0.4.0)</li> <li>Made OpenCV and PyAV optional dependencies with modular installation</li> <li>Removed hard conda dependencies in favor of pip/UV</li> </ul> \ud83d\udd04 Migration Notes Optional Video Backend Dependencies <p>Video backends are now optional to reduce installation size:</p> <pre># Basic installation (no video backends)\npip install sleap-io\n\n# With specific backends\npip install sleap-io[opencv]  # OpenCV only\npip install sleap-io[av]      # PyAV only\npip install sleap-io[all]     # All backends</pre> Development Setup <p>For developers, UV is now the recommended tool:</p> <pre># Install UV\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n\n# Setup development environment\nuv sync --all-extras\n\n# Run commands with uv run prefix\nuv run pytest tests/</pre> <p>Conda environments still work but use pip under the hood for simplicity.</p> No Breaking API Changes <p>All existing APIs remain compatible. New features are additive and do not affect existing functionality.</p> \ud83c\udfaf Why These Changes Matter <ol> <li>Format Ecosystem: Support for COCO and DeepLabCut enables integration with the broader pose tracking community</li> <li>Dataset Management: <code>LabelsSet</code> provides professional-grade tools for managing train/val/test splits</li> <li>Performance: UV migration and video control features dramatically improve development and runtime speed</li> <li>Media Flexibility: TIFF support and plugin management handle diverse video formats and platform requirements</li> <li>Developer Experience: Modern tooling and documentation reduce friction for contributors</li> <li>Code Quality: Ruff migration ensures consistent, high-quality code across the project</li> </ol> <p>This release significantly expands sleap-io's capabilities as a universal pose tracking data utility, improving compatibility with external tools, performance for large-scale operations, and the overall development experience.</p> <ul> <li>Replace black/pydocstyle with ruff in CI by @talmo in #194</li> <li>Add TIFF support for multi-page stacks by @talmo in #195</li> <li>Add LabelsSet for multi-label and split handling by @talmo in #197</li> <li>Add COCO-style dataset support by @talmo in #199</li> <li>Add DLC training data support by @talmo in #201</li> <li>Video plugin conveniences by @talmo in #202</li> <li>Fix skeleton node order decoding by @talmo in #208</li> <li>Migrate CI from conda to UV by @talmo in #214</li> <li>Update to 0.5.0 and refresh docs by @talmo in #203</li> <li>Add <code>open_videos</code> parameter to <code>Labels.replace_filenames</code> method by @talmo in #213</li> <li>Documentation improvements for Claude Code and contributors by @talmo in #215</li> </ul> <p>Full Changelog: v0.4.1...v0.5.0</p>"},{"location":"changelog/#v041","title":"v0.4.1SummaryChangelog","text":"Overview <p>The v0.4.1 release of sleap-io introduces experimental Ultralytics YOLO pose format support, enhances skeleton loading capabilities, and provides important improvements to video reference handling in saved files. This release focuses on expanding format compatibility and giving users more control over their workflow when working with package files and predictions.</p> <p>\u26a0\ufe0f Important: This release includes a critical fix (#185) for skeleton decoding that affected v0.4.0. Users working with skeletons should upgrade immediately.</p> \ud83d\ude80 New Features Ultralytics YOLO Pose Format Support (#183) [Experimental] <p>sleap-io now provides experimental support for reading and writing pose annotations in the Ultralytics YOLO pose format, enabling seamless integration with YOLO-based pose estimation workflows.</p> <p>Note: This is an initial implementation that has not yet been battle-tested in production environments. Please report any issues or edge cases you encounter.</p> <p>This feature includes:</p> <ul> <li>Full support for YOLO's normalized coordinate system</li> <li>Multi-instance pose annotations</li> <li>Automatic skeleton configuration from <code>data.yaml</code> files</li> <li>Integration with train/val/test splits</li> </ul> <p>Usage:</p> <pre>import sleap_io as sio\n\n# Load YOLO pose annotations\nlabels = sio.load_ultralytics(\n    labels_dir=\"path/to/labels\",\n    image_dir=\"path/to/images\", \n    data_yaml=\"path/to/data.yaml\"\n)\n\n# Save in YOLO format with train/val/test splits\nsio.save_ultralytics(\n    labels,\n    save_dir=\"yolo_dataset\",\n    split_fractions=(0.8, 0.1, 0.1)  # 80% train, 10% val, 10% test\n)\n\n# Also works via the generic API\nlabels = sio.load_file(\"path/to/labels/*.txt\")  # Auto-detects YOLO format\nlabels.save(\"output_dir\", format=\"ultralytics\")</pre> Video Reference Restoration Control (#192) <p>Added fine-grained control over video references when saving SLEAP files. This is particularly useful when working with predictions made on <code>.pkg.slp</code> files, allowing you to maintain references to the specific package files used for inference.</p> <p>Usage:</p> <pre>import sleap_io as sio\n\n# Load a package file used for training/inference\nlabels = sio.load_file(\"train.pkg.slp\")\n\n# Run inference...\n\n# Save predictions while preserving reference to train.pkg.slp\nlabels.save(\"predictions.slp\", embed=False, restore_original_videos=False)\n\n# Default behavior still restores original video references\nlabels.save(\"predictions_default.slp\")  # Links to original video files</pre> <p>Benefits:</p> <ul> <li>Track which exact dataset split was used for predictions</li> <li>Compare inference results across different models</li> <li>Maintain data lineage for reproducible workflows</li> </ul> \ud83d\udc1b Bug Fixes Critical Fix: Skeleton Decoding for Complex Skeletons (#185) \ud83d\udea8 <ul> <li>Fixed a critical bug introduced in v0.4.0 where skeletons with 32+ nodes or non-sequential py/id assignments would fail to decode</li> <li>Removed hardcoded assumptions about py/id patterns that only worked for simple skeletons</li> <li>Now correctly handles arbitrary py/id assignments in skeleton data</li> </ul> <p>Impact: This bug affected v0.4.0 and prevented users with complex skeletons (e.g., full fly body models with 32 nodes) from loading their data. If you use complex skeletons and are on v0.4.0, upgrading to v0.4.1 is strongly recommended.</p> \ud83d\udd27 Improvements Enhanced Skeleton Loading API (#187) <p>The <code>load_skeleton()</code> function now intelligently loads skeletons from multiple sources:</p> <ul> <li><code>.slp</code> files: Extract skeletons directly from SLEAP project files</li> <li>Training config JSON: Automatically detect and extract embedded skeletons</li> <li>Existing formats: Continue to support standalone skeleton JSON/YAML files</li> </ul> <p>Usage:</p> <pre>import sleap_io as sio\n\n# Load from various sources\nskeleton = sio.load_skeleton(\"project.slp\")           # From SLEAP project\nskeleton = sio.load_skeleton(\"training_config.json\")  # From training config\nskeleton = sio.load_skeleton(\"skeleton.yaml\")         # Standalone YAML\nskeleton = sio.load_skeleton(\"skeleton.json\")         # Standalone JSON</pre> Strengthened Test Coverage (#190) <ul> <li>Enhanced skeleton test assertions with specific expected values</li> <li>Improved test clarity and regression detection</li> <li>Ensures skeleton loading behavior is consistent and reliable</li> </ul> \ud83d\udce6 Dependencies <p>No new dependencies added in this release.</p> \ud83d\udd04 Migration Notes Video Reference Behavior <p>The new <code>restore_original_videos</code> parameter defaults to <code>True</code>, maintaining existing behavior:</p> <pre># These are equivalent (default behavior preserved)\nlabels.save(\"output.slp\")\nlabels.save(\"output.slp\", restore_original_videos=True)\n\n# New option to preserve package file references\nlabels.save(\"output.slp\", restore_original_videos=False)</pre> No Breaking API Changes <p>All existing APIs remain compatible. New features are additive and do not affect existing functionality.</p> \ud83c\udfaf Why These Changes Matter <ol> <li>Format Interoperability: YOLO pose format support enables integration with a wider ecosystem of pose estimation tools</li> <li>Workflow Control: Video reference preservation gives users control over their data lineage and prediction tracking</li> <li>Reliability: Bug fixes for complex skeletons ensure sleap-io works with diverse anatomical models</li> <li>Developer Experience: Enhanced skeleton loading API reduces code complexity when working with different file formats</li> <li>Quality Assurance: Improved test coverage ensures long-term stability and catches regressions early</li> </ol> <p>This release strengthens sleap-io's position as a versatile tool for pose tracking data management, improving both compatibility with external tools and control over complex workflows.</p> <ul> <li>Add Ultralytics YOLO pose format support by @talmo in #183</li> <li>Fix skeleton decoding for non-sequential py/id assignments by @talmo in #185</li> <li>Skeleton API enhancements by @talmo in #187</li> <li>Strengthen skeleton test assertions by @talmo in #190</li> <li>Add video reference restoration control by @talmo in #192</li> <li>Bump to v0.4.1 by @talmo in #193</li> </ul> <p>Full Changelog: v0.4.0...v0.4.1</p>"},{"location":"changelog/#v040","title":"v0.4.0SummaryChangelog","text":"Overview <p>The v0.4.0 release of sleap-io introduces significant improvements to skeleton file handling, enhances the package file (.pkg.slp) saving performance, and fixes several important bugs. This release focuses on making skeleton data more accessible and improving the user experience when working with large datasets.</p> \ud83d\ude80 New Features Standalone Skeleton Serialization (#178) <p>sleap-io now supports reading and writing skeleton files independently from label files. This feature enables:</p> <ul> <li>Loading skeleton definitions from <code>.json</code> files in SLEAP's jsonpickle format</li> <li>Saving skeletons for reuse across projects</li> <li>Working with multiple skeletons in a single file</li> </ul> <p>Usage:</p> <pre>import sleap_io as sio\n\n# Load a skeleton\nskeleton = sio.load_skeleton(\"skeleton.json\")\n\n# Save a skeleton  \nsio.save_skeleton(skeleton, \"output.json\")\n\n# Also works with lists of skeletons\nskeletons = sio.load_skeleton(\"multiple_skeletons.json\")\nsio.save_skeleton(skeletons, \"output.json\")</pre> YAML Skeleton Format Support (#179) <p>Added support for human-readable YAML format for skeleton files, making it easier to:</p> <ul> <li>Manually create and edit skeleton definitions</li> <li>Version control skeleton configurations</li> <li>Share skeleton templates between projects</li> </ul> <p>Usage:</p> <pre>import sleap_io as sio\n\n# Load from YAML\nskeleton = sio.load_skeleton(\"skeleton.yaml\")\n\n# Save to YAML  \nsio.save_skeleton(skeleton, \"output.yml\")</pre> <p>Example YAML format:</p> <pre>Skeleton-0:\n  nodes:\n  - name: head\n  - name: thorax\n  - name: abdomen\n  edges:\n  - source:\n      name: head\n    destination:\n      name: thorax\n  symmetries:\n  - - name: eyeL\n    - name: eyeR</pre> Frame Embedding Progress Bar (#174) <p>Added a progress bar when embedding frames into <code>.pkg.slp</code> files, providing:</p> <ul> <li>Visual feedback during long embedding operations</li> <li>Better user experience when working with large datasets</li> <li>Estimate of remaining time for completion</li> </ul> \ud83d\udc1b Bug Fixes Fixed Package File Saving with Embedded Videos (#177) <ul> <li>Changed default behavior: <code>embed=False</code> is now the default for fast-saving</li> <li>Prevented data loss: Added detection for self-referential paths</li> <li>Fixed video referencing: Correctly handles external video references</li> </ul> <p>Impact: Users can now quickly save <code>.pkg.slp</code> files without re-embedding frames, significantly improving save performance for large projects.</p> <p>Usage:</p> <pre># Fast save (default behavior)\nlabels.save(\"file.slp\")  # embed=False by default\n\n# Explicitly re-embed frames\nlabels.save(\"file.slp\", embed=True)</pre> Fixed ImageVideo Backend Metadata Serialization (#173) <ul> <li>Fixed compatibility issue with core SLEAP when using <code>ImageVideo</code> backend</li> <li>Resolved <code>cattrs</code> class inference errors</li> <li>Maintained backward compatibility with existing files</li> </ul> <p>Impact: Users working with image sequences no longer encounter errors when loading files in core SLEAP.</p> \ud83d\udd27 Improvements SLP Format v1.3 Support (#176) <ul> <li>Added explicit support for SLEAP label format version 1.3</li> <li>Enhanced tracking score support on <code>Instance</code> objects</li> <li>Added comprehensive tests for format compatibility</li> </ul> <p>Impact: Full compatibility with the latest SLEAP format features, including improved tracking metrics.</p> \ud83d\udce6 Dependencies <ul> <li>Added <code>pyyaml</code> dependency for YAML skeleton format support</li> </ul> \ud83d\udd04 Migration Notes Default Embedding Behavior Change <p>The default behavior for saving <code>.pkg.slp</code> files has changed:</p> <ul> <li>Before v0.4.0: <code>embed=True</code> (re-embeds all frames)</li> <li>After v0.4.0: <code>embed=False</code> (references existing files)</li> </ul> <p>To maintain previous behavior, explicitly set <code>embed=True</code>:</p> <pre>labels.save(\"output.pkg.slp\", embed=True)</pre> No Breaking API Changes <p>All existing APIs remain compatible. New features are additive and do not affect existing functionality.</p> \ud83c\udfaf Why These Changes Matter <ol> <li>Skeleton Management: Standalone skeleton files enable better project organization and reusability</li> <li>Performance: Fast-saving package files dramatically reduces save times for large datasets</li> <li>User Experience: Progress bars and better error messages improve workflow transparency</li> <li>Compatibility: Bug fixes ensure smooth interoperability with core SLEAP</li> <li>Flexibility: YAML format provides a human-friendly alternative for skeleton configuration</li> </ol> <p>This release enhances sleap-io's capabilities as a standalone utility for pose tracking data management while maintaining full compatibility with the SLEAP ecosystem.</p> <ul> <li>Fix the backend metadata being serialized to SLP for ImageVideo backends by @talmo in #173</li> <li>Frame embedding progress bar by @talmo in #174</li> <li>Implement SLP format v1.3 by @talmo in #176</li> <li>Fix saving package files with embedded videos by @talmo in #177</li> <li>Standalone Skeleton serialization/deserialization by @talmo in #178</li> <li>Add YAML support for skeleton serialization by @talmo in #179</li> <li>Bump to v0.4.0 by @talmo in #180</li> </ul> <p>Full Changelog: v0.3.0...v0.4.0</p>"},{"location":"changelog/#v030","title":"v0.3.0What's ChangedNew Contributors","text":"<ul> <li>Add skeleton symmetry QOL enhancements by @talmo in #144</li> <li>Add support for writing to nwb with ndx-pose &gt; 0.2.0 by @h-mayorquin in #143</li> <li>Check for existence of source video when creating from pkg.slp by @talmo in #148</li> <li>Add <code>Camera</code> class by @roomrys in #145</li> <li>Add CameraGroup class by @roomrys in #146</li> <li>Minimize NWB testing time by @talmo in #155</li> <li>Implement points array backend by @talmo in #154</li> <li>Fix saving .pkg.slp with empty videos by @talmo in #156</li> <li>Add all MV data structures by @roomrys in #151</li> <li>Integrate recording session with labels by @roomrys in #153</li> <li>Remove geometric functionality by @roomrys in #158</li> <li>Refactor data handling and implement setitem for Instances by @talmo in #161</li> <li>Support user instances in <code>Labels.numpy()</code> by @talmo in #162</li> <li>Implement <code>update_from_numpy</code> method for instance updating from tracks array by @talmo in #163</li> <li>Add <code>Labels.from_numpy</code> constructor by @talmo in #166</li> <li>Add repr for mv classes by @roomrys in #167</li> <li>Add codespell support (config, workflow to detect/not fix) and make it fix some typos by @yarikoptic in #168</li> <li>Update ndx-pose dependency to version &gt;=0.2.1 in environment.yml by @lochhh in #169</li> <li>Remove OpenCV dependency for Rodrigues transformation by @talmo in #170</li> <li>Bump to v0.3.0 by @talmo in #171</li> </ul> <ul> <li>@yarikoptic made their first contribution in #168</li> </ul> <p>Full Changelog: v0.2.0...v0.3.0</p>"},{"location":"changelog/#v020","title":"v0.2.0What's Changed","text":"<ul> <li>Update backend filename when backend isn't created on replace by @talmo in #127</li> <li>Update labels videos list on replace by @talmo in #128</li> <li>Add video writing by @talmo in #129 <ul> <li>Add <code>sio.VideoWriter</code>: basic <code>imageio-ffmpeg</code> video writer with sensible H264 presets. This can be used as a context manager: <pre>with sio.VideoWriter(\"video.mp4\") as vw:\n    for frame in video:\n        vw(frame)</pre> </li> <li>Add <code>sio.save_video</code>: high-level video writing. This can be used to quickly write a set of frames or even a whole <code>Video</code> for easy (if inefficient) re-encoding: <pre>bad_video = sio.load_video(\"unseekable.avi\")\nsio.save_video(bad_video, \"seekable.mp4\")</pre> </li> <li>Added <code>IndexError</code> in <code>VideoBackend</code> to enable sequence protocol for iteration over <code>Video</code>s: <pre>for frame in video:\n    pass</pre> </li> <li>Refactored <code>sio.io.video</code> to <code>sio.io.video_reading</code>.</li> </ul> </li> <li>Fixes to get JABS export to work with new data by @talmo in #132</li> <li>Make skeleton nodes mutable by @talmo in #135</li> <li>Add skeleton manipulation utilities by @talmo in #136 <ul> <li><code>Skeleton</code> <ul> <li><code>__contains__(node: NodeOrIndex)</code>: Returns <code>True</code> if a node exists in the skeleton.</li> <li><code>rebuild_cache()</code>: Method allowing explicit regeneration of the caching attributes from the nodes.</li> <li>Caching attributes are now named <code>_name_to_node_cache</code> and <code>_node_to_ind_cache</code>, better reflecting the mapping directionality.</li> <li><code>require_node(node: NodeOrIndex, add_missing: bool = True)</code>: Returns a <code>Node</code> given a <code>Node</code>, <code>int</code> or <code>str</code>. If <code>add_missing</code> is <code>True</code>, the node is added or created, otherwise an <code>IndexError</code> is raised. This is helpful for flexibly converting between node representations with convenient existence handling.</li> <li><code>add_nodes(list[Node | str])</code>: Convenience method to add a list of nodes.</li> <li><code>add_edges(edges: list[Edge | tuple[NodeOrIndex, NodeOrIndex]])</code>: Convenience method to add a list of edges.</li> <li><code>rename_nodes(name_map: dict[NodeOrIndex, str] | list[str])</code>: Method to rename nodes either by specifying a potentially partial mapping from node(s) to new name(s), or a list of new names. Handles updating both the <code>Node.name</code> attributes and the cache.</li> <li><code>rename_node(old_name: NodeOrIndex, new_name: str)</code>: Shorter syntax for renaming a single node.</li> <li><code>remove_nodes(nodes: list[NodeOrIndex])</code>: Method for removing nodes from the skeleton and updating caches. Does NOT update corresponding instances.</li> <li><code>remove_node(node: NodeOrIndex)</code>: Shorter syntax for removing a single node.</li> <li><code>reorder_nodes(new_order: list[NodeOrIndex])</code>: Method for setting the order of the nodes within the skeleton with cache updating. Does NOT update corresponding instances.</li> </ul> </li> <li><code>Instance</code>/<code>PredictedInstance</code> <ul> <li><code>update_skeleton()</code>: Updates the <code>points</code> attribute on the instance to reflect changes in the associated skeleton (removed nodes and reordering). This is called internally after updating the skeleton from the <code>Labels</code> level, but also exposed for more complex data manipulation workflows.</li> <li><code>replace_skeleton(new_skeleton: Skeleton, node_map: dict[NodeOrIndex, NodeOrIndex] | None = None, rev_node_map: dict[NodeOrIndex, NodeOrIndex] | None = None)</code>: Method to replace the skeleton on the instance with optional capability to specify a node mapping so that data stored in the <code>points</code> attribute is retained and associated with the right nodes in the new skeleton. Mapping is specified in <code>node_map</code> from old to new nodes and defaults to mapping between node objects with the same name. <code>rev_node_map</code> maps new nodes to old nodes and is used internally when calling from the <code>Labels</code> level as it bypasses validation.</li> </ul> </li> <li><code>Labels</code> <ul> <li><code>instances</code>: Convenience property that returns a generator that loops over all labeled frames and returns all instances. This can be lazily iterated over without having to construct a huge list of all the instances.</li> <li><code>rename_nodes(name_map: dict[NodeOrIndex, str] | list[str], skeleton: Skeleton | None = None)</code>: Method to rename nodes in a specified skeleton within the labels.</li> <li><code>remove_nodes(nodes: list[NodeOrIndex], skeleton: Skeleton | None = None)</code>: Method to remove nodes in a specified skeleton within the labels. This also updates all instances associated with the skeleton, removing point data for the removed nodes.</li> <li><code>reorder_nodes(new_order: list[NodeOrIndex], skeleton: Skeleton | None = None)</code>: Method to reorder nodes in a specified skeleton within the labels. This also updates all instances associated with the skeleton, reordering point data for the nodes.</li> <li><code>replace_skeleton(new_skeleton: Skeleton, old_skeleton: Skeleton | None = None, node_map: dict[NodeOrIndex, NodeOrIndex] | None = None)</code>: Method to replace a skeleton entirely within the labels, updating all instances associated with the old skeleton to use the new skeleton, optionally with node remapping to retain previous point data.</li> </ul> </li> </ul> </li> <li>Add more checks for video seeking/reading failure by @talmo in #138</li> <li>Fix <code>HDF5Video</code> edge cases by @talmo in #137</li> <li>Docs changelog generation by @talmo in #130</li> <li>Add <code>Labels.extract</code>, <code>Labels.trim</code> and <code>Video.save</code> by @talmo in #140 <ul> <li><code>LabeledFrame.frame_idx</code>: Now always converted to <code>int</code> type.</li> <li><code>Video.close()</code>: Now caches backend metadata to <code>Video.backend_metadata</code> to persist metadata on close.</li> <li><code>copy.deepcopy()</code> now works on <code>Video</code> objects even if backend is open.</li> <li><code>Video.save(save_path: str | Path, frame_inds: list[int] | np.ndarray | None = None, video_kwargs: dict[str, Any] | None = None)</code>: Method to save a video file to an MP4 using <code>VideoWriter</code> with an optional subset of frames.</li> <li><code>Labels.extract(inds: list[int] | list[tuple[Video, int]] | np.ndarray, copy: bool = True)</code>: Add method to extract a subset of frames from the labels, optionally making a copy, and return a new <code>Labels</code> object.</li> <li><code>Labels.trim(save_path: str | Path, frame_inds: list[int] | np.ndarray, video: Video | int | None = None, video_kwargs: dict[str, Any] | None = None)</code>: Add method to extract a subset of the labels, write a video clip with the extracted friends, and adjust frame indices to match the clip.</li> </ul> </li> <li>Docs automation by @talmo in #141</li> <li>Add more examples to docs by @talmo in #142</li> </ul> <p>Full Changelog: v0.1.10...v0.2.0</p>"},{"location":"changelog/#v0110","title":"v0.1.10What's Changed","text":"<ul> <li>Fix embedded video lookup by @talmo in #122</li> <li>Add better support for exporting and loading RGB videos from .pkg.slp files by @talmo in #125</li> <li>Fix video indexing when embedding from labels that already have embedded data by @talmo in #126</li> </ul> <p>Full Changelog: v0.1.9...v0.1.10</p>"},{"location":"changelog/#v019","title":"v0.1.9What's Changed","text":"<ul> <li>Dependency management by @talmo in #118 <ul> <li>Drop <code>av</code> as a dependency since it's still a little buggy and doesn't have broad enough platform compatibility.</li> <li>Pin <code>ndx-pose</code> &lt; 0.2.0 until #104 is merged in.</li> <li>Remove livecov dev tool as it was interfering with VSCode debugging.</li> </ul> </li> <li>Safer video loading from SLP by @talmo in #119 <ul> <li>Added <code>sio.io.utils.is_file_accessible</code> to check for readability by actually reading a byte. This catches permission and other esoteric filesystem errors (addresses #116).</li> <li>Explicit control over whether video files should be opened when loading labels with:<code>sio.load_slp(..., open_videos=False)</code></li> <li>Explicit control over whether backend is auto-initialized when creating or using <code>Video</code> objects with <code>Video(..., open_backend=False)</code>.</li> <li>More sanitization of filenames to posix/forward-slash safe forms when reading and writing SLP files.</li> </ul> </li> <li>Fix split calculation and allow for not embedding by @talmo in #120 <ul> <li>Fix: The function now correctly splits the labels into training, validation, and test sets based on the specified proportions (fixes #117). Previously, the validation fraction was being computed incorrectly in cases where its relative fraction was <code>1.0</code> after taking out the train split.</li> <li>Enhancement: <code>Labels.make_training_splits(..., embed=False)</code>. Previously, the function would always embed the images, which could be slow for large projects. With this change, the <code>embed</code> parameter is introduced, allowing the user to choose whether to embed the images or save the labels with references to the source video files.</li> </ul> </li> </ul> <p>Full Changelog: v0.1.8...v0.1.9</p>"},{"location":"changelog/#v018","title":"v0.1.8What's ChangedNew Contributors","text":"<ul> <li>Fix docs by @talmo in #108</li> <li>Support NumPy &gt; 2.0 and Python 3.12 by @lochhh in #115</li> </ul> <ul> <li>@lochhh made their first contribution in #115</li> </ul> <p>Full Changelog: v0.1.7...v0.1.8</p>"},{"location":"changelog/#v017","title":"v0.1.7What's Changed","text":"<ul> <li>Path sanitization hotfix by @talmo in #107</li> </ul> <p>Full Changelog: v0.1.6...v0.1.7</p>"},{"location":"changelog/#v016","title":"v0.1.6What's Changed","text":"<ul> <li>Grayscale property passthrough by @talmo in #99</li> </ul> <p>Full Changelog: v0.1.5...v0.1.6</p>"},{"location":"changelog/#v015","title":"v0.1.5What's Changed","text":"<ul> <li><code>Labels.split</code> and <code>Labels.make_training_splits</code> by @talmo in #98</li> </ul> <p>Full Changelog: v0.1.4...v0.1.5</p>"},{"location":"changelog/#v014","title":"v0.1.4What's Changed","text":"<ul> <li>Add support for embedding images in .pkg.slp by @talmo in #91 <ul> <li>Saving SLP files with embedded images will re-save the embedded images.</li> <li>Embed images into SLP files with: <ul> <li><code>labels.save(\"labels.pkg.slp\", embed=\"user\")</code> to embed frames with user-labeled instances (<code>Instance</code>)</li> <li><code>labels.save(\"labels.pkg.slp\", embed=\"user+suggestion\")</code> to embed frames with user-labeled instances and suggestion frames (useful for inference after training)</li> <li><code>labels.save(\"labels.pkg.slp\", embed=\"source\")</code> to restore the source video (\"unembed\")</li> </ul> </li> </ul> </li> <li>Better reprs and QOL by @talmo in #96 <ul> <li>Better <code>__repr__</code>s for <code>Skeleton</code>, <code>LabeledFrame</code>, <code>Labels</code>, <code>Instance</code>, <code>PredictedInstance</code></li> <li><code>Labels.append()</code> and <code>Labels.extend()</code> to add <code>LabeledFrame</code>s now will update <code>Labels.tracks</code>, <code>Labels.skeletons</code> and <code>Labels.videos</code> with contents.</li> <li><code>Labels.update()</code> to manually update <code>Labels.tracks</code>, <code>Labels.skeletons</code> and <code>Labels.videos</code> with contents of <code>Labels.labeled_frames</code> and <code>Labels.suggestions</code>.</li> <li><code>Labels.replace_filenames()</code>: multiple methods for replacing all video filenames across the project (#85).</li> <li><code>Skeleton.edge_names</code> to return list of edges as tuples of string names</li> <li>Added docstrings to <code>sio.load_video</code> and related high level <code>Video</code> APIs to clarify supported file formats.</li> <li>Syntactic sugar: try to initialize video backend with <code>Video(filename)</code> construction (#94)</li> </ul> </li> </ul> <p>Note: This is a re-release of v0.1.3 which had a borked deployment.</p> <p>Full Changelog: v0.1.2...v0.1.4</p>"},{"location":"changelog/#v013","title":"v0.1.3What's Changed","text":"<ul> <li>Add support for embedding images in .pkg.slp by @talmo in #91 <ul> <li>Saving SLP files with embedded images will re-save the embedded images.</li> <li>Embed images into SLP files with: <ul> <li><code>labels.save(\"labels.pkg.slp\", embed=\"user\")</code> to embed frames with user-labeled instances (<code>Instance</code>)</li> <li><code>labels.save(\"labels.pkg.slp\", embed=\"user+suggestion\")</code> to embed frames with user-labeled instances and suggestion frames (useful for inference after training)</li> <li><code>labels.save(\"labels.pkg.slp\", embed=\"source\")</code> to restore the source video (\"unembed\")</li> </ul> </li> </ul> </li> <li>Better reprs and QOL by @talmo in #96 <ul> <li>Better <code>__repr__</code>s for <code>Skeleton</code>, <code>LabeledFrame</code>, <code>Labels</code>, <code>Instance</code>, <code>PredictedInstance</code></li> <li><code>Labels.append()</code> and <code>Labels.extend()</code> to add <code>LabeledFrame</code>s now will update <code>Labels.tracks</code>, <code>Labels.skeletons</code> and <code>Labels.videos</code> with contents.</li> <li><code>Labels.update()</code> to manually update <code>Labels.tracks</code>, <code>Labels.skeletons</code> and <code>Labels.videos</code> with contents of <code>Labels.labeled_frames</code> and <code>Labels.suggestions</code>.</li> <li><code>Labels.replace_filenames()</code>: multiple methods for replacing all video filenames across the project (#85).</li> <li><code>Skeleton.edge_names</code> to return list of edges as tuples of string names</li> <li>Added docstrings to <code>sio.load_video</code> and related high level <code>Video</code> APIs to clarify supported file formats.</li> <li>Syntactic sugar: try to initialize video backend with <code>Video(filename)</code> construction (#94)</li> </ul> </li> </ul> <p>Full Changelog: v0.1.2...v0.1.3</p>"},{"location":"changelog/#v012","title":"v0.1.2What's Changed","text":"<ul> <li>Fix suggestions deserialization by @talmo in #95</li> </ul> <p>Full Changelog: v0.1.1...v0.1.2</p>"},{"location":"changelog/#v011","title":"v0.1.1What's Changed","text":"<ul> <li>Create docs pages by @talmo in #87</li> <li>Add <code>ImageVideo</code> backend by @talmo in #88</li> <li>Add <code>SuggestionFrame</code> by @talmo in #89</li> <li>Implement <code>ImageVideo</code> support in SLP by @talmo in #90</li> <li>Bump to v0.1.1 by @talmo in #93</li> </ul> <p>Full Changelog: v0.1.0...v0.1.1</p>"},{"location":"changelog/#v010","title":"v0.1.0What's ChangedNotes on dependency pins","text":"<ul> <li> <p>Add skeleton utilities by @talmo in #76</p> <ul> <li><code>Skeleton.add_node</code>: Add a node by name or object.</li> <li><code>Skeleton.add_edge</code>: Add an edge by lists of names or objects.</li> <li><code>Skeleton.add_symmetry</code>: Add a symmetry edge by lists of names or objects.</li> </ul> </li> <li> <p>Update CI and versions by @talmo in #77</p> <ul> <li>Update dependency ranges (see below)</li> <li>Update action workflow versions</li> <li>Enable M1 mac runners</li> <li>Expand python version range to 3.7-3.12 <ul> <li>Note: Python 3.7 is no longer tested in CI due to lack of conda-forge compatability.</li> </ul> </li> <li>Enable pure conda-forge dependency setup</li> </ul> </li> <li> <p>Bump to v0.1.0 by @talmo in #78</p> </li> <li> <p>Fix multi-skeleton loading by @talmo in #79</p> <ul> <li>Fixes #71.</li> </ul> </li> <li> <p>Add high level APIs by @talmo in #80</p> <ul> <li>Add <code>load_video</code> and <code>load_file</code> high level APIs (#48)</li> </ul> </li> <li> <p>Labels QOL enhancements by @talmo in #81</p> <ul> <li><code>LabeledFrame.remove_predictions</code>: Remove predicted instances from a labeled frame.</li> <li><code>LabeledFrame.remove_empty_instances</code>: Remove instances with no visible points from a labeled frame.</li> <li><code>Labels.save</code>: Instance-level convenience wrapper for <code>sio.save_file</code>.</li> <li><code>Labels.clean</code>: Remove unused or empty frames, instances, videos, skeletons and tracks.</li> <li><code>Labels.remove_predictions</code>: Remove predicted instances from all labeled frames (#69).</li> <li><code>Labels.__getitem__</code>: Now supports lists, slices, numpy arrays, tuples of <code>(Video, frame_idx)</code> and <code>Video</code>.</li> </ul> </li> <li> <p>Video QOL enhancements by @talmo in #82</p> <ul> <li><code>Video.is_open</code>: Checks if the video exists and the backend is set.</li> <li><code>Video.open</code>: Opens or restarts the backend for reading.</li> <li><code>Video.close</code>: Closes the backend for reading.</li> <li><code>Video.exists</code>: Check if the filename for the video exists.</li> <li><code>Video.replace_filename</code>: Replace the filename and restart the backend.</li> </ul> </li> </ul> <ul> <li><code>ffmpeg &lt; 6.1</code> due to imageio/imageio-ffmpeg#99</li> <li><code>h5py &gt;= 3.8.0</code> due to h5py/h5py#2118</li> <li><code>python &gt;= 3.8</code> due to <code>h5py &gt;= 3.8.0</code> (we still support <code>python==3.7</code> via pip but this is not longer in CI)</li> </ul> <p>Full Changelog: v0.0.14...v0.1.0</p>"},{"location":"changelog/#v0014","title":"v0.0.14What's Changed","text":"<ul> <li>Fix importing in Python 3.7 by @talmo in #75</li> </ul> <p>Full Changelog: v0.0.13...v0.0.14</p>"},{"location":"changelog/#v0013","title":"v0.0.13What's Changed","text":"<ul> <li>Add sdist build by @talmo in #74</li> </ul> <p>Full Changelog: v0.0.12...v0.0.13</p>"},{"location":"changelog/#v0012","title":"v0.0.12What's ChangedNew Contributors","text":"<ul> <li>Add support for the Kumar Lab's JABS format by @SkepticRaven in #63</li> <li>Fix multi-video serialization in SLP by @talmo in #72</li> </ul> <ul> <li>@SkepticRaven made their first contribution in #63</li> </ul> <p>Full Changelog: v0.0.11...v0.0.12</p>"},{"location":"changelog/#v0011","title":"v0.0.11What's Changed","text":"<ul> <li>Video handle persistence by @talmo in #64</li> <li>Bump to 0.0.11 by @talmo in #66</li> </ul> <p>Full Changelog: v0.0.10...v0.0.11</p>"},{"location":"changelog/#v0010","title":"v0.0.10What's Changed","text":"<p>This is a hotfix to get around installing in older environments with numpy &lt;1.20.</p> <ul> <li>Fallback on import newer numpy.testing module by @talmo in #65</li> </ul> <p>Full Changelog: v0.0.9...v0.0.10</p>"},{"location":"changelog/#v009","title":"v0.0.9What's Changed","text":"<ul> <li>Fix serialization for negative anchors metadata field in SLP files by @talmo in #59</li> <li>Fix edge unpacking by @talmo in #60</li> <li>Bump to v0.0.9 and update usage docs by @talmo in #61</li> </ul> <p>Full Changelog: v0.0.8...v0.0.9</p>"},{"location":"changelog/#v008","title":"v0.0.8What's Changed","text":"<ul> <li>Fix docstring for LabeledFrame.predicted_instances by @talmo in #43</li> <li>Parse skeleton symmetries from SLP files by @talmo in #53</li> <li>Add Labels.skeleton convenience attribute by @talmo in #54</li> <li>Write SLP files by @talmo in #55</li> <li>Create video backend automatically if filename exists. by @talmo in #56</li> </ul> <p>Full Changelog: v0.0.7...v0.0.8</p>"},{"location":"changelog/#v007","title":"v0.0.7What's Changed","text":"<ul> <li>Pin imageio version by @talmo in #39</li> <li>Fix detection of embedded images when loading SLP files by @talmo in #40</li> </ul> <p>Full Changelog: v0.0.6...v0.0.7</p>"},{"location":"changelog/#v006","title":"v0.0.6What's Changed","text":"<ul> <li>Add from predicted parsing by @talmo in #37</li> </ul> <p>Full Changelog: v0.0.5...v0.0.6</p>"},{"location":"changelog/#v005","title":"v0.0.5What's Changed","text":"<ul> <li>Basic path resolution by @talmo in #36</li> </ul> <p>Full Changelog: v0.0.4...v0.0.5</p>"},{"location":"changelog/#v004","title":"v0.0.4What's Changed","text":"<ul> <li>Fix build by including readme correctly in pyproject.toml by @talmo in #34</li> <li>Add Labels.find and Labels.video by @talmo in #35</li> </ul> <p>Full Changelog: v0.0.3...v0.0.4</p>"},{"location":"changelog/#v003","title":"v0.0.3What's Changed","text":"<ul> <li>Update CI by @talmo in #32 <ul> <li>Switch to using <code>pyproject.toml</code> alone instead of <code>setup.cfg</code>.</li> <li>Remove <code>mypy</code> type enforcement -- this is too strict for a library intended to be this flexible.</li> <li>Use micromamba in GitHub Actions workflow instead of miniconda</li> </ul> </li> <li>Video backends by @talmo in #31 <ul> <li>This PR implements the core video backends for media files, HDF5 and embedded images.</li> </ul> </li> <li>Bump version by @talmo in #33</li> </ul> <p>Full Changelog: v0.0.2...v0.0.3</p>"},{"location":"examples/","title":"Examples","text":"<p>This page provides practical examples for common tasks with sleap-io. Each example includes working code that you can copy and adapt for your needs.</p> <p>Prerequisites</p> <p>All examples assume you have sleap-io installed: <pre><code>pip install sleap-io\n</code></pre></p> <p>Or run any example script directly with <code>uv</code>: <pre><code># Save any example to a file (e.g., example.py)\nuv run --with sleap-io example.py\n</code></pre></p> <p>This automatically handles dependencies without needing to manage environments.</p> <p>Most examples use <code>import sleap_io as sio</code> for brevity.</p>"},{"location":"examples/#basic-io-operations","title":"Basic I/O operations","text":""},{"location":"examples/#load-and-save-in-different-formats","title":"Load and save in different formats","text":"<p>Convert between supported formats with automatic format detection.</p> format_conversion.py<pre><code>import sleap_io as sio\n\n# Load from SLEAP file\nlabels = sio.load_file(\"predictions.slp\")\n\n# Save to NWB file\nlabels.save(\"predictions.nwb\")\n</code></pre> <p>Tip</p> <p>sleap-io automatically detects the format from the file extension. Supported formats include <code>.slp</code>, <code>.nwb</code>, <code>.labelstudio.json</code>, <code>.h5</code> (JABS), and <code>.mat</code> (LEAP).</p> <p>See also</p> <ul> <li><code>Labels.save</code>: Save method with format options</li> <li>Formats: Complete list of supported formats</li> </ul>"},{"location":"examples/#convert-labels-to-raw-arrays","title":"Convert labels to raw arrays","text":"<p>Extract pose data as NumPy arrays for analysis or visualization.</p> labels_to_numpy.py<pre><code>import sleap_io as sio\n\nlabels = sio.load_slp(\"tests/data/slp/centered_pair_predictions.slp\")\n\n# Convert predictions to point coordinates in a single array\ntrx = labels.numpy()\nn_frames, n_tracks, n_nodes, xy = trx.shape\nassert xy == 2  # x and y coordinates\n\n# Convert to array with confidence scores appended\ntrx_with_scores = labels.numpy(return_confidence=True)\nn_frames, n_tracks, n_nodes, xy_score = trx_with_scores.shape \nassert xy_score == 3  # x, y, and confidence score\n</code></pre> Expected output shapes <p>For a dataset with 100 frames, 2 tracks, and 3 nodes:</p> <ul> <li>Without scores: <code>(100, 2, 3, 2)</code> </li> <li>With scores: <code>(100, 2, 3, 3)</code></li> </ul> <p>See also</p> <p><code>Labels.numpy</code>: Full documentation of array conversion options</p>"},{"location":"examples/#video-operations","title":"Video operations","text":""},{"location":"examples/#read-video-data","title":"Read video data","text":"<p>Load and access video frames directly.</p> read_video.py<pre><code>import sleap_io as sio\n\nvideo = sio.load_video(\"test.mp4\")\nn_frames, height, width, channels = video.shape\n\nframe = video[0]  # Get first frame\nheight, width, channels = frame.shape\n\n# Access specific frames\nmiddle_frame = video[n_frames // 2]\nlast_frame = video[-1]\n</code></pre> <p>Info</p> <p>Video loading uses <code>imageio-ffmpeg</code> by default. For alternative backends, install optional dependencies:</p> <pre><code>pip install sleap-io[opencv]  # OpenCV backend\npip install sleap-io[pyav]    # PyAV backend  \npip install sleap-io[all]     # All backends\n</code></pre> <p>See also</p> <ul> <li><code>sio.load_video</code>: Video loading function</li> <li><code>Video</code>: Video class documentation</li> </ul>"},{"location":"examples/#re-encode-video","title":"Re-encode video","text":"<p>Fix video seeking issues by re-encoding with optimal settings.</p> reencode_video.py<pre><code>import sleap_io as sio\n\nsio.save_video(sio.load_video(\"input.mp4\"), \"output.mp4\")\n</code></pre> <p>Why re-encode?</p> <p>Some video formats are not readily seekable at frame-level accuracy. Re-encoding with default settings ensures reliable seeking with minimal quality loss.</p> <p>See also</p> <p><code>save_video</code>: Video saving options and codec settings</p>"},{"location":"examples/#trim-labels-and-video","title":"Trim labels and video","text":"<p>Extract a subset of frames with corresponding labels.</p> trim_video.py<pre><code>import sleap_io as sio\n\n# Load existing data\nlabels = sio.load_file(\"labels.slp\")\n\n# Create a new labels file with frames 1000-2000 from video 0\nclip = labels.trim(\"clip.slp\", list(range(1_000, 2_000)), video=0)\n\n# The new file contains:\n# - A trimmed video saved as \"clip.mp4\"\n# - Labels with adjusted frame indices\n</code></pre> <p>Tip</p> <p>The <code>trim</code> method automatically:</p> <ul> <li>Creates a new video file with only the specified frames</li> <li>Adjusts frame indices in the labels to match the new video</li> <li>Preserves all instance data and tracks</li> </ul> <p>See also</p> <p><code>Labels.trim</code>: Full trim method documentation</p>"},{"location":"examples/#data-creation","title":"Data creation","text":""},{"location":"examples/#create-labels-from-raw-data","title":"Create labels from raw data","text":"<p>Build a complete labels dataset programmatically.</p> create_labels.py<pre><code>import sleap_io as sio\nimport numpy as np\n\n# Create skeleton\nskeleton = sio.Skeleton(\n    nodes=[\"head\", \"thorax\", \"abdomen\"],\n    edges=[(\"head\", \"thorax\"), (\"thorax\", \"abdomen\")]\n)\n\n# Create video\nvideo = sio.load_video(\"test.mp4\")\n\n# Create instance from numpy array\ninstance = sio.Instance.from_numpy(\n    points=np.array([\n        [10.2, 20.4],  # head\n        [5.8, 15.1],   # thorax\n        [0.3, 10.6],   # abdomen\n    ]),\n    skeleton=skeleton\n)\n\n# Create labeled frame\nlf = sio.LabeledFrame(video=video, frame_idx=0, instances=[instance])\n\n# Create labels\nlabels = sio.Labels(videos=[video], skeletons=[skeleton], labeled_frames=[lf])\n\n# Save\nlabels.save(\"labels.slp\")\n</code></pre> Creating predicted instances <p>To create predictions with confidence scores: <pre><code>predicted_instance = sio.PredictedInstance.from_numpy(\n    points=points_array,\n    confidence=confidence_array,  # Shape: (n_nodes,)\n    skeleton=skeleton\n)\n</code></pre></p> <p>See also</p> <ul> <li>Model: Complete data model documentation</li> <li><code>Labels</code>: Labels container class</li> <li><code>Instance</code>: Instance class for manual annotations</li> <li><code>PredictedInstance</code>: Instance class for predictions</li> </ul>"},{"location":"examples/#dataset-management","title":"Dataset management","text":""},{"location":"examples/#make-trainingvalidationtest-splits","title":"Make training/validation/test splits","text":"<p>Split your dataset for machine learning workflows.</p> make_splits.py<pre><code>import sleap_io as sio\n\n# Load source labels\nlabels = sio.load_file(\"labels.v001.slp\")\n\n# Make splits and export with embedded images\nlabels.make_training_splits(\n    n_train=0.8, \n    n_val=0.1, \n    n_test=0.1, \n    save_dir=\"split1\", \n    seed=42\n)\n\n# Splits are saved as self-contained SLP package files\nlabels_train = sio.load_file(\"split1/train.pkg.slp\")\nlabels_val = sio.load_file(\"split1/val.pkg.slp\")\nlabels_test = sio.load_file(\"split1/test.pkg.slp\")\n</code></pre> <p>Info</p> <p>The <code>.pkg.slp</code> extension indicates a self-contained package with embedded images, making the splits portable and shareable.</p> <p>See also</p> <p><code>Labels.make_training_splits</code>: Full documentation of splitting options</p>"},{"location":"examples/#working-with-dataset-splits-labelsset","title":"Working with dataset splits (LabelsSet)","text":"<p>Manage multiple related datasets as a group.</p> labels_set.py<pre><code>import sleap_io as sio\n\n# Load source labels\nlabels = sio.load_file(\"labels.v001.slp\")\n\n# Create splits and get them as a LabelsSet\nlabels_set = labels.make_training_splits(n_train=0.8, n_val=0.1, n_test=0.1)\n\n# Access individual splits\ntrain_labels = labels_set[\"train\"]\nval_labels = labels_set[\"val\"] \ntest_labels = labels_set[\"test\"]\n\n# Save the entire LabelsSet\nlabels_set.save(\"splits/\")  # Saves as SLP files by default\n\n# Save as Ultralytics YOLO format\nlabels_set.save(\"yolo_dataset/\", format=\"ultralytics\")\n\n# Load a LabelsSet from a directory\nloaded_set = sio.load_labels_set(\"splits/\")\n</code></pre> Loading from specific files <pre><code># Load from custom file paths\nfile_dict = {\n    \"train\": \"path/to/train.slp\",\n    \"val\": \"path/to/val.slp\",\n    \"test\": \"path/to/test.slp\"\n}\nloaded_set = sio.load_labels_set(file_dict)\n</code></pre> <p>Tip</p> <p>LabelsSet is particularly useful when exporting to formats that expect separate train/val/test files, like YOLO.</p> <p>See also</p> <ul> <li><code>LabelsSet</code>: LabelsSet class documentation</li> <li><code>load_labels_set</code>: Loading function for label sets</li> </ul>"},{"location":"examples/#data-manipulation","title":"Data manipulation","text":""},{"location":"examples/#fix-video-paths","title":"Fix video paths","text":"<p>Update file paths when moving projects between systems.</p> fix_paths.py<pre><code>import sleap_io as sio\n\n# Load labels without trying to open the video files\nlabels = sio.load_file(\"labels.v001.slp\", open_videos=False)\n\n# Fix paths using prefix replacement\nlabels.replace_filenames(prefix_map={\n    \"D:/data/sleap_projects\": \"/home/user/sleap_projects\",\n    \"C:/Users/sleaper/Desktop/test\": \"/home/user/sleap_projects\",\n})\n\n# Save labels with updated paths\nlabels.save(\"labels.v002.slp\")\n</code></pre> <p>Path separators</p> <p>The prefix map handles path separators automatically, but be consistent with forward slashes (<code>/</code>) for cross-platform compatibility.</p> <p>Tip</p> <p>Use <code>open_videos=False</code> when loading to avoid errors from missing videos at the old paths.</p> <p>See also</p> <p><code>Labels.replace_filenames</code>: Additional path manipulation options</p>"},{"location":"examples/#save-labels-with-embedded-images","title":"Save labels with embedded images","text":"<p>Create self-contained label files with embedded video frames.</p> embed_images.py<pre><code>import sleap_io as sio\n\n# Load source labels\nlabels = sio.load_file(\"labels.v001.slp\")\n\n# Save with embedded images for frames with user labeled data and suggested frames\nlabels.save(\"labels.v001.pkg.slp\", embed=\"user+suggestions\")\n</code></pre> <p>Embedding options</p> <ul> <li><code>\"user\"</code>: Only frames with manual annotations</li> <li><code>\"user+suggestions\"</code>: Manual annotations plus suggested frames</li> <li><code>\"all\"</code>: All frames with any labels (including predictions)</li> <li><code>\"source\"</code>: Embed source video if labels were loaded from embedded data</li> </ul> <p>See also</p> <p><code>Labels.save</code>: Complete save options including embedding</p>"},{"location":"examples/#replace-skeleton","title":"Replace skeleton","text":"<p>Change the skeleton structure while preserving existing annotations.</p> replace_skeleton.py<pre><code>import sleap_io as sio\n\n# Load existing labels with skeleton nodes: \"head\", \"trunk\", \"tti\"\nlabels = sio.load_file(\"labels.slp\")\n\n# Create a new skeleton with different nodes\nnew_skeleton = sio.Skeleton([\"HEAD\", \"CENTROID\", \"TAIL_BASE\", \"TAIL_TIP\"])\n\n# Replace skeleton with node correspondence mapping\nlabels.replace_skeleton(\n    new_skeleton,\n    node_map={\n        \"head\": \"HEAD\",\n        \"trunk\": \"CENTROID\",\n        \"tti\": \"TAIL_BASE\"\n        # \"TAIL_TIP\" will have NaN values since there's no correspondence\n    }\n)\n\n# Save with the new skeleton format\nlabels.save(\"labels_with_new_skeleton.slp\")\n</code></pre> <p>Warning</p> <p>Nodes without correspondence in the <code>node_map</code> will have NaN values in the resulting instances.</p> <p>Tip</p> <p>This is particularly useful when converting between different annotation tools or skeleton conventions.</p> <p>See also</p> <p><code>Labels.replace_skeleton</code>: Additional skeleton manipulation options</p>"},{"location":"examples/#convert-to-and-from-numpy-arrays","title":"Convert to and from numpy arrays","text":"<p>Work with pose data as NumPy arrays for filtering or analysis.</p> numpy_filtering.py<pre><code>import sleap_io as sio\nimport numpy as np\n\nlabels = sio.load_file(\"predictions.slp\")\n\n# Convert to array of shape (n_frames, n_tracks, n_nodes, xy)\ntrx = labels.numpy()\n\n# Apply temporal filtering (example: simple moving average)\nwindow_size = 5\ntrx_filtered = np.convolve(trx.reshape(-1), np.ones(window_size)/window_size, mode='same').reshape(trx.shape)\n\n# Update the labels with filtered data\nlabels.update_from_numpy(trx_filtered)\n\n# Save the filtered version\nlabels.save(\"predictions.filtered.slp\")\n</code></pre> Advanced filtering with movement <p>For more sophisticated analysis and filtering, check out the <code>movement</code> library for pose processing.</p> <p>Warning</p> <p>When updating from numpy, the array shape must match the original data structure exactly.</p> <p>See also</p> <ul> <li><code>Labels.numpy</code>: Array conversion options</li> <li><code>Labels.update_from_numpy</code>: Updating labels from arrays</li> <li><code>movement</code>: Advanced pose processing library</li> </ul>"},{"location":"examples/#nwb-format-operations","title":"NWB format operations","text":""},{"location":"examples/#working-with-nwb-files","title":"Working with NWB files","text":"<p>Neurodata Without Borders (NWB) provides a standardized format for neurophysiology data. sleap-io offers comprehensive NWB support with automatic format detection.</p> nwb_basic.py<pre><code>import sleap_io as sio\n\n# Load any NWB file - automatically detects if it contains\n# annotations (PoseTraining) or predictions (PoseEstimation)\nlabels = sio.load_nwb(\"pose_data.nwb\")\n\n# Save with automatic format detection\n# Uses \"annotations\" if data has user labels, \"predictions\" otherwise\nsio.save_nwb(labels, \"output.nwb\")\n\n# Force specific format\nsio.save_nwb(labels, \"training.nwb\", nwb_format=\"annotations\")\nsio.save_nwb(labels, \"inference.nwb\", nwb_format=\"predictions\")\n\n# Export with embedded video frames for sharing complete datasets\nsio.save_nwb(labels, \"dataset_export.nwb\", nwb_format=\"annotations_export\")\n</code></pre> <p>Format auto-detection</p> <p>The harmonization layer automatically determines the appropriate format:</p> <ul> <li>Annotations: Used when data contains user-labeled instances (training data)</li> <li>Predictions: Used when data contains only predicted instances (inference results)</li> <li>Annotations Export: Use explicitly to create self-contained files with embedded video frames</li> </ul>"},{"location":"examples/#save-training-data-with-rich-metadata","title":"Save training data with rich metadata","text":"<p>Include detailed experimental metadata when saving training annotations.</p> nwb_metadata.py<pre><code>from sleap_io.io.nwb_annotations import save_labels\n\n# Save with comprehensive metadata\nsave_labels(\n    labels,\n    \"training_data.nwb\",\n    session_description=\"Mouse skilled reaching task - training dataset\",\n    identifier=\"mouse_01_session_03_annotations\",\n    session_start_time=\"2024-01-15T09:30:00\",\n    annotator=\"John Doe\",\n    nwb_kwargs={\n        # Session metadata\n        \"session_id\": \"session_003\",\n        \"experimenter\": [\"John Doe\", \"Jane Smith\"],\n        \"lab\": \"Motor Control Lab\",\n        \"institution\": \"University of Example\",\n\n        # Experimental details\n        \"experiment_description\": \"Skilled reaching task with food pellet reward\",\n        \"protocol\": \"Protocol 2024-001\",\n        \"surgery\": \"Cranial window implant over M1\",\n\n        # Subject information\n        \"subject\": {\n            \"subject_id\": \"mouse_01\",\n            \"age\": \"P90\",\n            \"sex\": \"M\",\n            \"species\": \"Mus musculus\",\n            \"strain\": \"C57BL/6J\",\n            \"weight\": \"25g\"\n        }\n    }\n)\n</code></pre> <p>Metadata best practices</p> <p>Include as much metadata as possible for reproducibility:</p> <ul> <li>Experimental protocol details</li> <li>Subject information</li> <li>Recording conditions</li> <li>Annotator identity for tracking labeling provenance</li> </ul>"},{"location":"examples/#export-dataset-with-embedded-videos","title":"Export dataset with embedded videos","text":"<p>Create self-contained NWB files with video frames for sharing complete datasets.</p> nwb_export.py<pre><code>from sleap_io.io.nwb_annotations import export_labels, export_labeled_frames\n\n# Method 1: Export complete dataset with all videos\nexport_labels(\n    labels,\n    output_dir=\"export/\",\n    nwb_filename=\"complete_dataset.nwb\",\n    as_training=True,      # Include manual annotations\n    include_videos=True,    # Embed all video frames\n    include_skeleton=True   # Include skeleton definition\n)\n\n# Method 2: Export only frames with labels as a new video\nexport_labeled_frames(\n    labels,\n    output_path=\"labeled_frames.avi\",         # MJPEG video output\n    labels_output_path=\"labeled_frames.nwb\",  # Corresponding labels\n    fps=30.0,                                  # Output frame rate\n    scale=1.0                                  # Video scale factor\n)\n\n# The export includes a FrameMap JSON file tracking frame origins\nimport json\nwith open(\"labeled_frames.frame_map.json\", \"r\") as f:\n    frame_map = json.load(f)\n    print(f\"Exported {frame_map['total_frames']} frames from {len(frame_map['videos'])} videos\")\n</code></pre> <p>Export formats</p> <ul> <li>Full export: Includes all video frames, creating large but complete files</li> <li>Labeled frames only: Exports just frames with annotations, reducing file size</li> <li>Frame provenance: JSON metadata tracks which frames came from which source videos</li> </ul>"},{"location":"examples/#convert-between-nwb-and-other-formats","title":"Convert between NWB and other formats","text":"<p>Use NWB as an interchange format between different pose tracking tools.</p> nwb_conversion.py<pre><code>import sleap_io as sio\n\n# Load from DeepLabCut\ndlc_data = sio.load_file(\"dlc_predictions.h5\")\n\n# Save as NWB predictions\nsio.save_nwb(dlc_data, \"dlc_in_nwb.nwb\", nwb_format=\"predictions\")\n\n# Load SLEAP training data\nsleap_labels = sio.load_file(\"training.slp\")\n\n# Export as NWB with videos for sharing\nsio.save_nwb(sleap_labels, \"training_export.nwb\", nwb_format=\"annotations_export\")\n\n# Convert NWB back to SLEAP format\nnwb_labels = sio.load_nwb(\"training_export.nwb\")\nnwb_labels.save(\"converted.slp\")\n</code></pre> <p>Format preservation</p> <p>NWB format preserves:</p> <ul> <li>Complete skeleton structure with node names</li> <li>Track identities</li> <li>Confidence scores</li> <li>User vs predicted instance types</li> <li>Video metadata (when using <code>annotations_export</code>)</li> </ul> <p>See also</p> <ul> <li>NWB Format Documentation: Complete NWB format reference</li> <li><code>load_nwb</code>: NWB loading function</li> <li><code>save_nwb</code>: NWB saving function with format options</li> </ul>"},{"location":"formats/","title":"Data formats","text":"<p>sleap-io provides a unified interface for reading and writing pose tracking data across multiple formats. The library automatically detects file formats and provides harmonized I/O operations.</p>"},{"location":"formats/#universal-io-functions","title":"Universal I/O Functions","text":""},{"location":"formats/#sleap_io.load_file","title":"<code>sleap_io.load_file(filename, format=None, **kwargs)</code>","text":"<p>Load a file and return the appropriate object.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str | Path</code> <p>Path to a file.</p> required <code>format</code> <code>Optional[str]</code> <p>Optional format to load as. If not provided, will be inferred from the file extension. Available formats are: \"slp\", \"nwb\", \"alphatracker\", \"labelstudio\", \"coco\", \"jabs\", \"dlc\", \"ultralytics\", \"leap\", and \"video\".</p> <code>None</code> <code>**kwargs</code> <p>Additional arguments passed to the format-specific loading function: - For \"slp\" format: No additional arguments. - For \"nwb\" format: No additional arguments. - For \"alphatracker\" format: No additional arguments. - For \"leap\" format: skeleton (Optional[Skeleton]): Skeleton to use if not   defined in the file. - For \"labelstudio\" format: skeleton (Optional[Skeleton]): Skeleton to   use for   the labels. - For \"coco\" format: dataset_root (Optional[str]): Root directory of the   dataset. grayscale (bool): If True, load images as grayscale (1 channel).   If False, load as RGB (3 channels). Default is False. - For \"jabs\" format: skeleton (Optional[Skeleton]): Skeleton to use for   the labels. - For \"dlc\" format: video_search_paths (Optional[List[str]]): Paths to   search for video files. - For \"ultralytics\" format: See <code>load_ultralytics</code> for supported arguments. - For \"video\" format: See <code>load_video</code> for supported arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Union[Labels, Video]</code> <p>A <code>Labels</code> or <code>Video</code> object.</p> Source code in <code>sleap_io/io/main.py</code> <pre><code>def load_file(\n    filename: str | Path, format: Optional[str] = None, **kwargs\n) -&gt; Union[Labels, Video]:\n    \"\"\"Load a file and return the appropriate object.\n\n    Args:\n        filename: Path to a file.\n        format: Optional format to load as. If not provided, will be inferred from the\n            file extension. Available formats are: \"slp\", \"nwb\", \"alphatracker\",\n            \"labelstudio\", \"coco\", \"jabs\", \"dlc\", \"ultralytics\", \"leap\", and \"video\".\n        **kwargs: Additional arguments passed to the format-specific loading function:\n            - For \"slp\" format: No additional arguments.\n            - For \"nwb\" format: No additional arguments.\n            - For \"alphatracker\" format: No additional arguments.\n            - For \"leap\" format: skeleton (Optional[Skeleton]): Skeleton to use if not\n              defined in the file.\n            - For \"labelstudio\" format: skeleton (Optional[Skeleton]): Skeleton to\n              use for\n              the labels.\n            - For \"coco\" format: dataset_root (Optional[str]): Root directory of the\n              dataset. grayscale (bool): If True, load images as grayscale (1 channel).\n              If False, load as RGB (3 channels). Default is False.\n            - For \"jabs\" format: skeleton (Optional[Skeleton]): Skeleton to use for\n              the labels.\n            - For \"dlc\" format: video_search_paths (Optional[List[str]]): Paths to\n              search for video files.\n            - For \"ultralytics\" format: See `load_ultralytics` for supported arguments.\n            - For \"video\" format: See `load_video` for supported arguments.\n\n    Returns:\n        A `Labels` or `Video` object.\n    \"\"\"\n    if isinstance(filename, Path):\n        filename = filename.as_posix()\n\n    if format is None:\n        if filename.endswith(\".slp\"):\n            format = \"slp\"\n        elif filename.endswith(\".nwb\"):\n            format = \"nwb\"\n        elif filename.endswith(\".mat\"):\n            format = \"leap\"\n        elif filename.endswith(\".json\"):\n            # Detect JSON format: AlphaTracker, COCO, or Label Studio\n            if _detect_alphatracker_format(filename):\n                format = \"alphatracker\"\n            elif _detect_coco_format(filename):\n                format = \"coco\"\n            else:\n                format = \"json\"\n        elif filename.endswith(\".h5\"):\n            format = \"jabs\"\n        elif filename.endswith(\"data.yaml\") or (\n            Path(filename).is_dir() and (Path(filename) / \"data.yaml\").exists()\n        ):\n            format = \"ultralytics\"\n        elif filename.endswith(\".csv\") and dlc.is_dlc_file(filename):\n            format = \"dlc\"\n        else:\n            for vid_ext in Video.EXTS:\n                if filename.endswith(vid_ext):\n                    format = \"video\"\n                    break\n        if format is None:\n            raise ValueError(f\"Could not infer format from filename: '{filename}'.\")\n\n    if filename.endswith(\".slp\"):\n        return load_slp(filename, **kwargs)\n    elif filename.endswith(\".nwb\"):\n        return load_nwb(filename, **kwargs)\n    elif filename.endswith(\".mat\"):\n        return load_leap(filename, **kwargs)\n    elif filename.endswith(\".json\"):\n        if format == \"alphatracker\":\n            return load_alphatracker(filename, **kwargs)\n        elif format == \"coco\":\n            return load_coco(filename, **kwargs)\n        else:\n            return load_labelstudio(filename, **kwargs)\n    elif filename.endswith(\".h5\"):\n        return load_jabs(filename, **kwargs)\n    elif format == \"dlc\":\n        return load_dlc(filename, **kwargs)\n    elif format == \"ultralytics\":\n        return load_ultralytics(filename, **kwargs)\n    elif format == \"video\":\n        return load_video(filename, **kwargs)\n</code></pre>"},{"location":"formats/#sleap_io.save_file","title":"<code>sleap_io.save_file(labels, filename, format=None, verbose=True, **kwargs)</code>","text":"<p>Save a file based on the extension.</p> <p>Parameters:</p> Name Type Description Default <code>labels</code> <code>Labels</code> <p>A SLEAP <code>Labels</code> object (see <code>load_slp</code>).</p> required <code>filename</code> <code>str | Path</code> <p>Path to save labels to.</p> required <code>format</code> <code>Optional[str]</code> <p>Optional format to save as. If not provided, will be inferred from the file extension. Available formats are: \"slp\", \"nwb\", \"labelstudio\", \"jabs\", and \"ultralytics\".</p> <code>None</code> <code>verbose</code> <code>bool</code> <p>If <code>True</code> (the default), display a progress bar when embedding frames (only applies to the SLP format).</p> <code>True</code> <code>**kwargs</code> <p>Additional arguments passed to the format-specific saving function: - For \"slp\" format: embed (bool | str | list[tuple[Video, int]] |   None): Frames   to embed in the saved labels file. One of None, True, \"all\", \"user\",   \"suggestions\", \"user+suggestions\", \"source\" or list of tuples of   (video, frame_idx). If False (the default), no frames are embedded. - For \"nwb\" format: pose_estimation_metadata (dict): Metadata to store   in the   NWB file. append (bool): If True, append to existing NWB file. - For \"labelstudio\" format: No additional arguments. - For \"jabs\" format: pose_version (int): JABS pose format version (1-6).   root_folder (Optional[str]): Root folder for JABS project structure. - For \"ultralytics\" format: See <code>save_ultralytics</code> for supported arguments.</p> <code>{}</code> Source code in <code>sleap_io/io/main.py</code> <pre><code>def save_file(\n    labels: Labels,\n    filename: str | Path,\n    format: Optional[str] = None,\n    verbose: bool = True,\n    **kwargs,\n):\n    \"\"\"Save a file based on the extension.\n\n    Args:\n        labels: A SLEAP `Labels` object (see `load_slp`).\n        filename: Path to save labels to.\n        format: Optional format to save as. If not provided, will be inferred from the\n            file extension. Available formats are: \"slp\", \"nwb\", \"labelstudio\", \"jabs\",\n            and \"ultralytics\".\n        verbose: If `True` (the default), display a progress bar when embedding frames\n            (only applies to the SLP format).\n        **kwargs: Additional arguments passed to the format-specific saving function:\n            - For \"slp\" format: embed (bool | str | list[tuple[Video, int]] |\n              None): Frames\n              to embed in the saved labels file. One of None, True, \"all\", \"user\",\n              \"suggestions\", \"user+suggestions\", \"source\" or list of tuples of\n              (video, frame_idx). If False (the default), no frames are embedded.\n            - For \"nwb\" format: pose_estimation_metadata (dict): Metadata to store\n              in the\n              NWB file. append (bool): If True, append to existing NWB file.\n            - For \"labelstudio\" format: No additional arguments.\n            - For \"jabs\" format: pose_version (int): JABS pose format version (1-6).\n              root_folder (Optional[str]): Root folder for JABS project structure.\n            - For \"ultralytics\" format: See `save_ultralytics` for supported arguments.\n    \"\"\"\n    if isinstance(filename, Path):\n        filename = str(filename)\n\n    if format is None:\n        if filename.endswith(\".slp\"):\n            format = \"slp\"\n        elif filename.endswith(\".nwb\"):\n            format = \"nwb\"\n        elif filename.endswith(\".json\"):\n            format = \"labelstudio\"\n        elif \"pose_version\" in kwargs:\n            format = \"jabs\"\n        elif \"split_ratios\" in kwargs or Path(filename).is_dir():\n            format = \"ultralytics\"\n\n    if format == \"slp\":\n        save_slp(labels, filename, verbose=verbose, **kwargs)\n    elif format == \"nwb\":\n        save_nwb(labels, filename, **kwargs)\n    elif format == \"labelstudio\":\n        save_labelstudio(labels, filename, **kwargs)\n    elif format == \"jabs\":\n        pose_version = kwargs.pop(\"pose_version\", 5)\n        root_folder = kwargs.pop(\"root_folder\", filename)\n        save_jabs(labels, pose_version=pose_version, root_folder=root_folder)\n    elif format == \"ultralytics\":\n        save_ultralytics(labels, filename, **kwargs)\n    else:\n        raise ValueError(f\"Unknown format '{format}' for filename: '{filename}'.\")\n</code></pre>"},{"location":"formats/#video-io","title":"Video I/O","text":""},{"location":"formats/#sleap_io.load_video","title":"<code>sleap_io.load_video(filename, **kwargs)</code>","text":"<p>Load a video file.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>The filename(s) of the video. Supported extensions: \"mp4\", \"avi\", \"mov\", \"mj2\", \"mkv\", \"h5\", \"hdf5\", \"slp\", \"png\", \"jpg\", \"jpeg\", \"tif\", \"tiff\", \"bmp\". If the filename is a list, a list of image filenames are expected. If filename is a folder, it will be searched for images.</p> required <code>**kwargs</code> <p>Additional arguments passed to <code>Video.from_filename</code>. Currently supports: - dataset: Name of dataset in HDF5 file. - grayscale: Whether to force grayscale. If None, autodetect on first   frame load. - keep_open: Whether to keep the video reader open between calls to read   frames.   If False, will close the reader after each call. If True (the   default), it will   keep the reader open and cache it for subsequent calls which may   enhance the   performance of reading multiple frames. - source_video: Source video object if this is a proxy video. This is   metadata   and does not affect reading. - backend_metadata: Metadata to store on the video backend. This is   useful for   storing metadata that requires an open backend (e.g., shape   information) without   having to open the backend. - plugin: Video plugin to use for MediaVideo backend. One of \"opencv\",   \"FFMPEG\",   or \"pyav\". Also accepts aliases (case-insensitive):   * opencv: \"opencv\", \"cv\", \"cv2\", \"ocv\"   * FFMPEG: \"FFMPEG\", \"ffmpeg\", \"imageio-ffmpeg\", \"imageio_ffmpeg\"   * pyav: \"pyav\", \"av\"</p> <p>If not specified, uses the following priority:   1. Global default set via <code>sio.set_default_video_plugin()</code>   2. Auto-detection based on available packages</p> <p>To set a global default:</p> <p>import sleap_io as sio sio.set_default_video_plugin(\"opencv\") video = sio.load_video(\"video.mp4\")  # Uses opencv - input_format: Format of the data in HDF5 datasets. One of   \"channels_last\" (the   default) in (frames, height, width, channels) order or \"channels_first\" in   (frames, channels, width, height) order. - frame_map: Mapping from frame indices to indices in the HDF5 dataset.   This is   used to translate between frame indices of images within their source   video   and indices of images in the dataset. - source_filename: Path to the source video file for HDF5 embedded videos. - source_inds: Indices of frames in the source video file for HDF5   embedded videos. - image_format: Format of images in HDF5 embedded dataset.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Video</code> <p>A <code>Video</code> object.</p> See Also <p>set_default_video_plugin: Set the default video plugin globally. get_default_video_plugin: Get the current default video plugin.</p> Source code in <code>sleap_io/io/main.py</code> <pre><code>def load_video(filename: str, **kwargs) -&gt; Video:\n    \"\"\"Load a video file.\n\n    Args:\n        filename: The filename(s) of the video. Supported extensions: \"mp4\", \"avi\",\n            \"mov\", \"mj2\", \"mkv\", \"h5\", \"hdf5\", \"slp\", \"png\", \"jpg\", \"jpeg\", \"tif\",\n            \"tiff\", \"bmp\". If the filename is a list, a list of image filenames are\n            expected. If filename is a folder, it will be searched for images.\n        **kwargs: Additional arguments passed to `Video.from_filename`.\n            Currently supports:\n            - dataset: Name of dataset in HDF5 file.\n            - grayscale: Whether to force grayscale. If None, autodetect on first\n              frame load.\n            - keep_open: Whether to keep the video reader open between calls to read\n              frames.\n              If False, will close the reader after each call. If True (the\n              default), it will\n              keep the reader open and cache it for subsequent calls which may\n              enhance the\n              performance of reading multiple frames.\n            - source_video: Source video object if this is a proxy video. This is\n              metadata\n              and does not affect reading.\n            - backend_metadata: Metadata to store on the video backend. This is\n              useful for\n              storing metadata that requires an open backend (e.g., shape\n              information) without\n              having to open the backend.\n            - plugin: Video plugin to use for MediaVideo backend. One of \"opencv\",\n              \"FFMPEG\",\n              or \"pyav\". Also accepts aliases (case-insensitive):\n              * opencv: \"opencv\", \"cv\", \"cv2\", \"ocv\"\n              * FFMPEG: \"FFMPEG\", \"ffmpeg\", \"imageio-ffmpeg\", \"imageio_ffmpeg\"\n              * pyav: \"pyav\", \"av\"\n\n              If not specified, uses the following priority:\n              1. Global default set via `sio.set_default_video_plugin()`\n              2. Auto-detection based on available packages\n\n              To set a global default:\n              &gt;&gt;&gt; import sleap_io as sio\n              &gt;&gt;&gt; sio.set_default_video_plugin(\"opencv\")\n              &gt;&gt;&gt; video = sio.load_video(\"video.mp4\")  # Uses opencv\n            - input_format: Format of the data in HDF5 datasets. One of\n              \"channels_last\" (the\n              default) in (frames, height, width, channels) order or \"channels_first\" in\n              (frames, channels, width, height) order.\n            - frame_map: Mapping from frame indices to indices in the HDF5 dataset.\n              This is\n              used to translate between frame indices of images within their source\n              video\n              and indices of images in the dataset.\n            - source_filename: Path to the source video file for HDF5 embedded videos.\n            - source_inds: Indices of frames in the source video file for HDF5\n              embedded videos.\n            - image_format: Format of images in HDF5 embedded dataset.\n\n    Returns:\n        A `Video` object.\n\n    See Also:\n        set_default_video_plugin: Set the default video plugin globally.\n        get_default_video_plugin: Get the current default video plugin.\n    \"\"\"\n    return Video.from_filename(filename, **kwargs)\n</code></pre>"},{"location":"formats/#sleap_io.save_video","title":"<code>sleap_io.save_video(frames, filename, fps=30, pixelformat='yuv420p', codec='libx264', crf=25, preset='superfast', output_params=None)</code>","text":"<p>Write a list of frames to a video file.</p> <p>Parameters:</p> Name Type Description Default <code>frames</code> <code>ndarray | Video</code> <p>Sequence of frames to write to video. Each frame should be a 2D or 3D numpy array with dimensions (height, width) or (height, width, channels).</p> required <code>filename</code> <code>str | Path</code> <p>Path to output video file.</p> required <code>fps</code> <code>float</code> <p>Frames per second. Defaults to 30.</p> <code>30</code> <code>pixelformat</code> <code>str</code> <p>Pixel format for video. Defaults to \"yuv420p\".</p> <code>'yuv420p'</code> <code>codec</code> <code>str</code> <p>Codec to use for encoding. Defaults to \"libx264\".</p> <code>'libx264'</code> <code>crf</code> <code>int</code> <p>Constant rate factor to control lossiness of video. Values go from 2 to 32, with numbers in the 18 to 30 range being most common. Lower values mean less compressed/higher quality. Defaults to 25. No effect if codec is not \"libx264\".</p> <code>25</code> <code>preset</code> <code>str</code> <p>H264 encoding preset. Defaults to \"superfast\". No effect if codec is not \"libx264\".</p> <code>'superfast'</code> <code>output_params</code> <code>list | None</code> <p>Additional output parameters for FFMPEG. This should be a list of strings corresponding to command line arguments for FFMPEG and libx264. Use <code>ffmpeg -h encoder=libx264</code> to see all options for libx264 output_params.</p> <code>None</code> <p>See also: <code>sio.VideoWriter</code></p> Source code in <code>sleap_io/io/main.py</code> <pre><code>def save_video(\n    frames: np.ndarray | Video,\n    filename: str | Path,\n    fps: float = 30,\n    pixelformat: str = \"yuv420p\",\n    codec: str = \"libx264\",\n    crf: int = 25,\n    preset: str = \"superfast\",\n    output_params: list | None = None,\n):\n    \"\"\"Write a list of frames to a video file.\n\n    Args:\n        frames: Sequence of frames to write to video. Each frame should be a 2D or 3D\n            numpy array with dimensions (height, width) or (height, width, channels).\n        filename: Path to output video file.\n        fps: Frames per second. Defaults to 30.\n        pixelformat: Pixel format for video. Defaults to \"yuv420p\".\n        codec: Codec to use for encoding. Defaults to \"libx264\".\n        crf: Constant rate factor to control lossiness of video. Values go from 2 to 32,\n            with numbers in the 18 to 30 range being most common. Lower values mean less\n            compressed/higher quality. Defaults to 25. No effect if codec is not\n            \"libx264\".\n        preset: H264 encoding preset. Defaults to \"superfast\". No effect if codec is not\n            \"libx264\".\n        output_params: Additional output parameters for FFMPEG. This should be a list of\n            strings corresponding to command line arguments for FFMPEG and libx264. Use\n            `ffmpeg -h encoder=libx264` to see all options for libx264 output_params.\n\n    See also: `sio.VideoWriter`\n    \"\"\"\n    if output_params is None:\n        output_params = []\n\n    with video_writing.VideoWriter(\n        filename,\n        fps=fps,\n        pixelformat=pixelformat,\n        codec=codec,\n        crf=crf,\n        preset=preset,\n        output_params=output_params,\n    ) as writer:\n        for frame in frames:\n            writer(frame)\n</code></pre>"},{"location":"formats/#format-specific-functions","title":"Format-Specific Functions","text":""},{"location":"formats/#sleap-native-format-slp","title":"SLEAP Native Format (.slp)","text":"<p>The native SLEAP format stores complete pose tracking projects including videos, skeletons, and annotations.</p>"},{"location":"formats/#sleap_io.load_slp","title":"<code>sleap_io.load_slp(filename, open_videos=True)</code>","text":"<p>Load a SLEAP dataset.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>Path to a SLEAP labels file (<code>.slp</code>).</p> required <code>open_videos</code> <code>bool</code> <p>If <code>True</code> (the default), attempt to open the video backend for I/O. If <code>False</code>, the backend will not be opened (useful for reading metadata when the video files are not available).</p> <code>True</code> <p>Returns:</p> Type Description <code>Labels</code> <p>The dataset as a <code>Labels</code> object.</p> Source code in <code>sleap_io/io/main.py</code> <pre><code>def load_slp(filename: str, open_videos: bool = True) -&gt; Labels:\n    \"\"\"Load a SLEAP dataset.\n\n    Args:\n        filename: Path to a SLEAP labels file (`.slp`).\n        open_videos: If `True` (the default), attempt to open the video backend for\n            I/O. If `False`, the backend will not be opened (useful for reading metadata\n            when the video files are not available).\n\n    Returns:\n        The dataset as a `Labels` object.\n    \"\"\"\n    return slp.read_labels(filename, open_videos=open_videos)\n</code></pre>"},{"location":"formats/#sleap_io.save_slp","title":"<code>sleap_io.save_slp(labels, filename, embed=False, restore_original_videos=True, verbose=True)</code>","text":"<p>Save a SLEAP dataset to a <code>.slp</code> file.</p> <p>Parameters:</p> Name Type Description Default <code>labels</code> <code>Labels</code> <p>A SLEAP <code>Labels</code> object (see <code>load_slp</code>).</p> required <code>filename</code> <code>str</code> <p>Path to save labels to ending with <code>.slp</code>.</p> required <code>embed</code> <code>bool | str | list[tuple[Video, int]] | None</code> <p>Frames to embed in the saved labels file. One of <code>None</code>, <code>True</code>, <code>\"all\"</code>, <code>\"user\"</code>, <code>\"suggestions\"</code>, <code>\"user+suggestions\"</code>, <code>\"source\"</code> or list of tuples of <code>(video, frame_idx)</code>.</p> <p>If <code>False</code> is specified (the default), the source video will be restored if available, otherwise the embedded frames will be re-saved.</p> <p>If <code>True</code> or <code>\"all\"</code>, all labeled frames and suggested frames will be embedded.</p> <p>If <code>\"source\"</code> is specified, no images will be embedded and the source video will be restored if available.</p> <p>This argument is only valid for the SLP backend.</p> <code>False</code> <code>restore_original_videos</code> <code>bool</code> <p>If <code>True</code> (default) and <code>embed=False</code>, use original video files. If <code>False</code> and <code>embed=False</code>, keep references to source <code>.pkg.slp</code> files. Only applies when <code>embed=False</code>.</p> <code>True</code> <code>verbose</code> <code>bool</code> <p>If <code>True</code> (the default), display a progress bar when embedding frames.</p> <code>True</code> Source code in <code>sleap_io/io/main.py</code> <pre><code>def save_slp(\n    labels: Labels,\n    filename: str,\n    embed: bool | str | list[tuple[Video, int]] | None = False,\n    restore_original_videos: bool = True,\n    verbose: bool = True,\n):\n    \"\"\"Save a SLEAP dataset to a `.slp` file.\n\n    Args:\n        labels: A SLEAP `Labels` object (see `load_slp`).\n        filename: Path to save labels to ending with `.slp`.\n        embed: Frames to embed in the saved labels file. One of `None`, `True`,\n            `\"all\"`, `\"user\"`, `\"suggestions\"`, `\"user+suggestions\"`, `\"source\"` or list\n            of tuples of `(video, frame_idx)`.\n\n            If `False` is specified (the default), the source video will be restored\n            if available, otherwise the embedded frames will be re-saved.\n\n            If `True` or `\"all\"`, all labeled frames and suggested frames will be\n            embedded.\n\n            If `\"source\"` is specified, no images will be embedded and the source video\n            will be restored if available.\n\n            This argument is only valid for the SLP backend.\n        restore_original_videos: If `True` (default) and `embed=False`, use original\n            video files. If `False` and `embed=False`, keep references to source\n            `.pkg.slp` files. Only applies when `embed=False`.\n        verbose: If `True` (the default), display a progress bar when embedding frames.\n    \"\"\"\n    return slp.write_labels(\n        filename,\n        labels,\n        embed=embed,\n        restore_original_videos=restore_original_videos,\n        verbose=verbose,\n    )\n</code></pre>"},{"location":"formats/#nwb-format-nwb","title":"NWB Format (.nwb)","text":"<p>Neurodata Without Borders (NWB) is a standardized format for neurophysiology data. sleap-io provides comprehensive support for both reading and writing pose tracking data in NWB format.</p>"},{"location":"formats/#harmonized-nwb-io","title":"Harmonized NWB I/O","text":"<p>The harmonized API automatically detects and routes to the appropriate NWB backend:</p>"},{"location":"formats/#sleap_io.load_nwb","title":"<code>sleap_io.load_nwb(filename)</code>","text":"<p>Load an NWB dataset as a SLEAP <code>Labels</code> object.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>Path to a NWB file (<code>.nwb</code>).</p> required <p>Returns:</p> Type Description <code>Labels</code> <p>The dataset as a <code>Labels</code> object.</p> Source code in <code>sleap_io/io/main.py</code> <pre><code>def load_nwb(filename: str) -&gt; Labels:\n    \"\"\"Load an NWB dataset as a SLEAP `Labels` object.\n\n    Args:\n        filename: Path to a NWB file (`.nwb`).\n\n    Returns:\n        The dataset as a `Labels` object.\n    \"\"\"\n    return nwb.load_nwb(filename)\n</code></pre>"},{"location":"formats/#sleap_io.save_nwb","title":"<code>sleap_io.save_nwb(labels, filename, nwb_format=NwbFormat.AUTO, append=False)</code>","text":"<p>Save a SLEAP dataset to NWB format.</p> <p>Parameters:</p> Name Type Description Default <code>labels</code> <code>Labels</code> <p>A SLEAP <code>Labels</code> object (see <code>load_slp</code>).</p> required <code>filename</code> <code>Union[str, Path]</code> <p>Path to NWB file to save to. Must end in <code>.nwb</code>.</p> required <code>nwb_format</code> <code>Union[NwbFormat, str]</code> <p>Format to use for saving. Options are: - \"auto\" (default): Automatically detect based on data - \"annotations\": Save training annotations (PoseTraining) - \"annotations_export\": Export annotations with video frames - \"predictions\": Save predictions (PoseEstimation)</p> <code>AUTO</code> <code>append</code> <code>bool</code> <p>If True, append to existing NWB file. Only supported for predictions format. Defaults to False.</p> <code>False</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If an invalid format is specified.</p> Source code in <code>sleap_io/io/main.py</code> <pre><code>def save_nwb(\n    labels: Labels,\n    filename: Union[str, Path],\n    nwb_format: Union[NwbFormat, str] = NwbFormat.AUTO,\n    append: bool = False,\n) -&gt; None:\n    \"\"\"Save a SLEAP dataset to NWB format.\n\n    Args:\n        labels: A SLEAP `Labels` object (see `load_slp`).\n        filename: Path to NWB file to save to. Must end in `.nwb`.\n        nwb_format: Format to use for saving. Options are:\n            - \"auto\" (default): Automatically detect based on data\n            - \"annotations\": Save training annotations (PoseTraining)\n            - \"annotations_export\": Export annotations with video frames\n            - \"predictions\": Save predictions (PoseEstimation)\n        append: If True, append to existing NWB file. Only supported for\n            predictions format. Defaults to False.\n\n    Raises:\n        ValueError: If an invalid format is specified.\n    \"\"\"\n    nwb.save_nwb(labels, filename, nwb_format, append=append)\n</code></pre>"},{"location":"formats/#nwb-format-types","title":"NWB Format Types","text":"<p>sleap-io supports multiple NWB format types through the <code>nwb_format</code> parameter:</p> <ul> <li><code>\"auto\"</code> (default): Automatically detect based on data content</li> <li>Uses <code>\"annotations\"</code> if data contains user-labeled instances</li> <li> <p>Uses <code>\"predictions\"</code> if data contains only predicted instances</p> </li> <li> <p><code>\"annotations\"</code>: Save as PoseTraining format (ndx-pose extension)</p> </li> <li>Stores manual annotations for training data</li> <li>Preserves skeleton structure and node names</li> <li> <p>Includes annotator information</p> </li> <li> <p><code>\"annotations_export\"</code>: Export annotations with embedded video frames</p> </li> <li>Creates self-contained NWB file with video data</li> <li>Generates MJPEG video with frame provenance tracking</li> <li> <p>Useful for sharing complete datasets</p> </li> <li> <p><code>\"predictions\"</code>: Save as PoseEstimation format (ndx-pose extension)</p> </li> <li>Stores predicted pose data from inference</li> <li>Includes confidence scores</li> <li>Supports multiple animals/tracks</li> </ul>"},{"location":"formats/#examples","title":"Examples","text":""},{"location":"formats/#basic-nwb-usage","title":"Basic NWB Usage","text":"<pre><code>import sleap_io as sio\n\n# Load any NWB file (auto-detects format)\nlabels = sio.load_nwb(\"pose_data.nwb\")\n\n# Save with auto-detection\nsio.save_nwb(labels, \"output.nwb\")\n\n# Save with specific format\nsio.save_nwb(labels, \"training.nwb\", nwb_format=\"annotations\")\nsio.save_nwb(labels, \"predictions.nwb\", nwb_format=\"predictions\")\n</code></pre>"},{"location":"formats/#advanced-annotations-api","title":"Advanced Annotations API","text":"<p>For more control over NWB training data, use the annotations module directly:</p> <pre><code>from sleap_io.io.nwb_annotations import save_labels, load_labels\n\n# Save with custom metadata\nsave_labels(\n    labels,\n    \"training.nwb\",\n    session_description=\"Mouse reaching task\",\n    identifier=\"mouse_01_session_03\",\n    annotator=\"researcher_name\",\n    nwb_kwargs={\n        \"session_id\": \"session_003\",\n        \"experimenter\": [\"John Doe\", \"Jane Smith\"],\n        \"lab\": \"Motor Control Lab\",\n        \"institution\": \"University\",\n        \"experiment_description\": \"Skilled reaching behavior\"\n    }\n)\n\n# Load annotations\nlabels = load_labels(\"training.nwb\")\n</code></pre>"},{"location":"formats/#export-with-video-frames","title":"Export with Video Frames","text":"<pre><code>from sleap_io.io.nwb_annotations import export_labels, export_labeled_frames\n\n# Export complete dataset with videos\nexport_labels(\n    labels,\n    output_dir=\"export/\",\n    nwb_filename=\"dataset_with_videos.nwb\",\n    as_training=True,  # Include manual annotations\n    include_videos=True  # Embed video frames\n)\n\n# Export only labeled frames as video\nexport_labeled_frames(\n    labels,\n    output_path=\"labeled_frames.avi\",\n    labels_output_path=\"labels.nwb\",\n    fps=30.0\n)\n</code></pre>"},{"location":"formats/#nwb-metadata","title":"NWB Metadata","text":"<p>The NWB format requires certain metadata fields. sleap-io provides sensible defaults:</p> <ul> <li>Required fields (auto-generated if not provided):</li> <li><code>session_description</code>: Defaults to \"Processed SLEAP pose data\"</li> <li><code>identifier</code>: Auto-generated UUID string</li> <li> <p><code>session_start_time</code>: Current timestamp</p> </li> <li> <p>Optional fields (via <code>nwb_kwargs</code>):</p> </li> <li><code>session_id</code>: Unique session identifier</li> <li><code>experimenter</code>: List of experimenters</li> <li><code>lab</code>: Laboratory name</li> <li><code>institution</code>: Institution name</li> <li><code>experiment_description</code>: Detailed experiment description</li> <li>Any other valid NWB file fields</li> </ul>"},{"location":"formats/#jabs-format-h5","title":"JABS Format (.h5)","text":"<p>JABS (Janelia Automatic Behavior System) format for behavior classification.</p>"},{"location":"formats/#sleap_io.load_jabs","title":"<code>sleap_io.load_jabs(filename, skeleton=None)</code>","text":"<p>Read JABS-style predictions from a file and return a <code>Labels</code> object.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>Path to the jabs h5 pose file.</p> required <code>skeleton</code> <code>Optional[Skeleton]</code> <p>An optional <code>Skeleton</code> object.</p> <code>None</code> <p>Returns:</p> Type Description <code>Labels</code> <p>Parsed labels as a <code>Labels</code> instance.</p> Source code in <code>sleap_io/io/main.py</code> <pre><code>def load_jabs(filename: str, skeleton: Optional[Skeleton] = None) -&gt; Labels:\n    \"\"\"Read JABS-style predictions from a file and return a `Labels` object.\n\n    Args:\n        filename: Path to the jabs h5 pose file.\n        skeleton: An optional `Skeleton` object.\n\n    Returns:\n        Parsed labels as a `Labels` instance.\n    \"\"\"\n    return jabs.read_labels(filename, skeleton=skeleton)\n</code></pre>"},{"location":"formats/#sleap_io.save_jabs","title":"<code>sleap_io.save_jabs(labels, pose_version, root_folder=None)</code>","text":"<p>Save a SLEAP dataset to JABS pose file format.</p> <p>Parameters:</p> Name Type Description Default <code>labels</code> <code>Labels</code> <p>SLEAP <code>Labels</code> object.</p> required <code>pose_version</code> <code>int</code> <p>The JABS pose version to write data out.</p> required <code>root_folder</code> <code>Optional[str]</code> <p>Optional root folder where the files should be saved.</p> <code>None</code> Note <p>Filenames for JABS poses are based on video filenames.</p> Source code in <code>sleap_io/io/main.py</code> <pre><code>def save_jabs(labels: Labels, pose_version: int, root_folder: Optional[str] = None):\n    \"\"\"Save a SLEAP dataset to JABS pose file format.\n\n    Args:\n        labels: SLEAP `Labels` object.\n        pose_version: The JABS pose version to write data out.\n        root_folder: Optional root folder where the files should be saved.\n\n    Note:\n        Filenames for JABS poses are based on video filenames.\n    \"\"\"\n    jabs.write_labels(labels, pose_version, root_folder)\n</code></pre>"},{"location":"formats/#label-studio-format-json","title":"Label Studio Format (.json)","text":"<p>Label Studio is a multi-modal annotation platform. Export annotations from Label Studio and load them into SLEAP.</p>"},{"location":"formats/#sleap_io.load_labelstudio","title":"<code>sleap_io.load_labelstudio(filename, skeleton=None)</code>","text":"<p>Read Label Studio-style annotations from a file and return a <code>Labels</code> object.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>Path to the label-studio annotation file in JSON format.</p> required <code>skeleton</code> <code>Optional[Union[Skeleton, list[str]]]</code> <p>An optional <code>Skeleton</code> object or list of node names. If not provided (the default), skeleton will be inferred from the data. It may be useful to provide this so the keypoint label types can be filtered to just the ones in the skeleton.</p> <code>None</code> <p>Returns:</p> Type Description <code>Labels</code> <p>Parsed labels as a <code>Labels</code> instance.</p> Source code in <code>sleap_io/io/main.py</code> <pre><code>def load_labelstudio(\n    filename: str, skeleton: Optional[Union[Skeleton, list[str]]] = None\n) -&gt; Labels:\n    \"\"\"Read Label Studio-style annotations from a file and return a `Labels` object.\n\n    Args:\n        filename: Path to the label-studio annotation file in JSON format.\n        skeleton: An optional `Skeleton` object or list of node names. If not provided\n            (the default), skeleton will be inferred from the data. It may be useful to\n            provide this so the keypoint label types can be filtered to just the ones in\n            the skeleton.\n\n    Returns:\n        Parsed labels as a `Labels` instance.\n    \"\"\"\n    return labelstudio.read_labels(filename, skeleton=skeleton)\n</code></pre>"},{"location":"formats/#sleap_io.save_labelstudio","title":"<code>sleap_io.save_labelstudio(labels, filename)</code>","text":"<p>Save a SLEAP dataset to Label Studio format.</p> <p>Parameters:</p> Name Type Description Default <code>labels</code> <code>Labels</code> <p>A SLEAP <code>Labels</code> object (see <code>load_slp</code>).</p> required <code>filename</code> <code>str</code> <p>Path to save labels to ending with <code>.json</code>.</p> required Source code in <code>sleap_io/io/main.py</code> <pre><code>def save_labelstudio(labels: Labels, filename: str):\n    \"\"\"Save a SLEAP dataset to Label Studio format.\n\n    Args:\n        labels: A SLEAP `Labels` object (see `load_slp`).\n        filename: Path to save labels to ending with `.json`.\n    \"\"\"\n    labelstudio.write_labels(labels, filename)\n</code></pre>"},{"location":"formats/#deeplabcut-format-h5-csv","title":"DeepLabCut Format (.h5, .csv)","text":"<p>Load predictions from DeepLabCut, a popular markerless pose estimation tool.</p>"},{"location":"formats/#sleap_io.load_dlc","title":"<code>sleap_io.load_dlc(filename, video_search_paths=None, **kwargs)</code>","text":"<p>Read DeepLabCut annotations from a CSV file and return a <code>Labels</code> object.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>Path to DLC CSV file with annotations.</p> required <code>video_search_paths</code> <code>Optional[List[Union[str, Path]]]</code> <p>Optional list of paths to search for video files.</p> <code>None</code> <code>**kwargs</code> <p>Additional arguments passed to DLC loader.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Labels</code> <p>Parsed labels as a <code>Labels</code> instance.</p> Source code in <code>sleap_io/io/main.py</code> <pre><code>def load_dlc(\n    filename: str, video_search_paths: Optional[List[Union[str, Path]]] = None, **kwargs\n) -&gt; Labels:\n    \"\"\"Read DeepLabCut annotations from a CSV file and return a `Labels` object.\n\n    Args:\n        filename: Path to DLC CSV file with annotations.\n        video_search_paths: Optional list of paths to search for video files.\n        **kwargs: Additional arguments passed to DLC loader.\n\n    Returns:\n        Parsed labels as a `Labels` instance.\n    \"\"\"\n    return dlc.load_dlc(filename, video_search_paths=video_search_paths, **kwargs)\n</code></pre>"},{"location":"formats/#alphatracker-format","title":"AlphaTracker Format","text":"<p>Load predictions from AlphaTracker, a tracking system for socially-housed animals.</p>"},{"location":"formats/#sleap_io.load_alphatracker","title":"<code>sleap_io.load_alphatracker(filename)</code>","text":"<p>Read AlphaTracker annotations from a file and return a <code>Labels</code> object.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>Path to the AlphaTracker annotation file in JSON format.</p> required <p>Returns:</p> Type Description <code>Labels</code> <p>Parsed labels as a <code>Labels</code> instance.</p> Source code in <code>sleap_io/io/main.py</code> <pre><code>def load_alphatracker(filename: str) -&gt; Labels:\n    \"\"\"Read AlphaTracker annotations from a file and return a `Labels` object.\n\n    Args:\n        filename: Path to the AlphaTracker annotation file in JSON format.\n\n    Returns:\n        Parsed labels as a `Labels` instance.\n    \"\"\"\n    return alphatracker.read_labels(filename)\n</code></pre>"},{"location":"formats/#leap-format-mat","title":"LEAP Format (.mat)","text":"<p>Load predictions from LEAP, a SLEAP predecessor. Requires <code>scipy</code> for .mat file support.</p>"},{"location":"formats/#sleap_io.load_leap","title":"<code>sleap_io.load_leap(filename, skeleton=None, **kwargs)</code>","text":"<p>Load a LEAP dataset from a .mat file.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>Path to a LEAP .mat file.</p> required <code>skeleton</code> <code>Optional[Skeleton]</code> <p>An optional <code>Skeleton</code> object. If not provided, will be constructed from the data in the file.</p> <code>None</code> <code>**kwargs</code> <p>Additional arguments (currently unused).</p> <code>{}</code> <p>Returns:</p> Type Description <code>Labels</code> <p>The dataset as a <code>Labels</code> object.</p> Source code in <code>sleap_io/io/main.py</code> <pre><code>def load_leap(\n    filename: str,\n    skeleton: Optional[Skeleton] = None,\n    **kwargs,\n) -&gt; Labels:\n    \"\"\"Load a LEAP dataset from a .mat file.\n\n    Args:\n        filename: Path to a LEAP .mat file.\n        skeleton: An optional `Skeleton` object. If not provided, will be constructed\n            from the data in the file.\n        **kwargs: Additional arguments (currently unused).\n\n    Returns:\n        The dataset as a `Labels` object.\n    \"\"\"\n    return leap.read_labels(filename, skeleton=skeleton)\n</code></pre>"},{"location":"formats/#coco-format-json","title":"COCO Format (.json)","text":"<p>Load annotations in COCO (Common Objects in Context) format, widely used in computer vision.</p>"},{"location":"formats/#sleap_io.load_coco","title":"<code>sleap_io.load_coco(json_path, dataset_root=None, grayscale=False, **kwargs)</code>","text":"<p>Load a COCO-style pose dataset and return a Labels object.</p> <p>Parameters:</p> Name Type Description Default <code>json_path</code> <code>str</code> <p>Path to the COCO annotation JSON file.</p> required <code>dataset_root</code> <code>Optional[str]</code> <p>Root directory of the dataset. If None, uses parent directory          of json_path.</p> <code>None</code> <code>grayscale</code> <code>bool</code> <p>If True, load images as grayscale (1 channel). If False, load as        RGB (3 channels). Default is False.</p> <code>False</code> <code>**kwargs</code> <p>Additional arguments (currently unused).</p> <code>{}</code> <p>Returns:</p> Type Description <code>Labels</code> <p>The dataset as a <code>Labels</code> object.</p> Source code in <code>sleap_io/io/main.py</code> <pre><code>def load_coco(\n    json_path: str,\n    dataset_root: Optional[str] = None,\n    grayscale: bool = False,\n    **kwargs,\n) -&gt; Labels:\n    \"\"\"Load a COCO-style pose dataset and return a Labels object.\n\n    Args:\n        json_path: Path to the COCO annotation JSON file.\n        dataset_root: Root directory of the dataset. If None, uses parent directory\n                     of json_path.\n        grayscale: If True, load images as grayscale (1 channel). If False, load as\n                   RGB (3 channels). Default is False.\n        **kwargs: Additional arguments (currently unused).\n\n    Returns:\n        The dataset as a `Labels` object.\n    \"\"\"\n    return coco.read_labels(json_path, dataset_root=dataset_root, grayscale=grayscale)\n</code></pre>"},{"location":"formats/#ultralytics-yolo-format","title":"Ultralytics YOLO Format","text":"<p>Support for Ultralytics YOLO pose format.</p>"},{"location":"formats/#sleap_io.load_ultralytics","title":"<code>sleap_io.load_ultralytics(dataset_path, split='train', skeleton=None, **kwargs)</code>","text":"<p>Load an Ultralytics YOLO pose dataset as a SLEAP <code>Labels</code> object.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_path</code> <code>str</code> <p>Path to the Ultralytics dataset root directory containing data.yaml.</p> required <code>split</code> <code>str</code> <p>Dataset split to read ('train', 'val', or 'test'). Defaults to 'train'.</p> <code>'train'</code> <code>skeleton</code> <code>Optional[Skeleton]</code> <p>Optional skeleton to use. If not provided, will be inferred from data.yaml.</p> <code>None</code> <code>**kwargs</code> <p>Additional arguments passed to <code>ultralytics.read_labels</code>. Currently supports: - image_size: Tuple of (height, width) for coordinate denormalization.   Defaults to   (480, 640). Will attempt to infer from actual images if available.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Labels</code> <p>The dataset as a <code>Labels</code> object.</p> Source code in <code>sleap_io/io/main.py</code> <pre><code>def load_ultralytics(\n    dataset_path: str,\n    split: str = \"train\",\n    skeleton: Optional[Skeleton] = None,\n    **kwargs,\n) -&gt; Labels:\n    \"\"\"Load an Ultralytics YOLO pose dataset as a SLEAP `Labels` object.\n\n    Args:\n        dataset_path: Path to the Ultralytics dataset root directory containing\n            data.yaml.\n        split: Dataset split to read ('train', 'val', or 'test'). Defaults to 'train'.\n        skeleton: Optional skeleton to use. If not provided, will be inferred from\n            data.yaml.\n        **kwargs: Additional arguments passed to `ultralytics.read_labels`.\n            Currently supports:\n            - image_size: Tuple of (height, width) for coordinate denormalization.\n              Defaults to\n              (480, 640). Will attempt to infer from actual images if available.\n\n    Returns:\n        The dataset as a `Labels` object.\n    \"\"\"\n    return ultralytics.read_labels(\n        dataset_path, split=split, skeleton=skeleton, **kwargs\n    )\n</code></pre>"},{"location":"formats/#sleap_io.save_ultralytics","title":"<code>sleap_io.save_ultralytics(labels, dataset_path, split_ratios={'train': 0.8, 'val': 0.2}, **kwargs)</code>","text":"<p>Save a SLEAP dataset to Ultralytics YOLO pose format.</p> <p>Parameters:</p> Name Type Description Default <code>labels</code> <code>Labels</code> <p>A SLEAP <code>Labels</code> object.</p> required <code>dataset_path</code> <code>str</code> <p>Path to save the Ultralytics dataset.</p> required <code>split_ratios</code> <code>dict</code> <p>Dictionary mapping split names to ratios (must sum to 1.0).          Defaults to {\"train\": 0.8, \"val\": 0.2}.</p> <code>{'train': 0.8, 'val': 0.2}</code> <code>**kwargs</code> <p>Additional arguments passed to <code>ultralytics.write_labels</code>. Currently supports: - class_id: Class ID to use for all instances (default: 0). - image_format: Image format to use for saving frames. Either \"png\"   (default, lossless) or \"jpg\". - image_quality: Image quality for JPEG format (1-100). For PNG, this is   the compression   level (0-9). If None, uses default quality settings. - verbose: If True (default), show progress bars during export. - use_multiprocessing: If True, use multiprocessing for parallel image   saving. Default is False. - n_workers: Number of worker processes. If None, uses CPU count - 1.   Only used if   use_multiprocessing=True.</p> <code>{}</code> Source code in <code>sleap_io/io/main.py</code> <pre><code>def save_ultralytics(\n    labels: Labels,\n    dataset_path: str,\n    split_ratios: dict = {\"train\": 0.8, \"val\": 0.2},\n    **kwargs,\n):\n    \"\"\"Save a SLEAP dataset to Ultralytics YOLO pose format.\n\n    Args:\n        labels: A SLEAP `Labels` object.\n        dataset_path: Path to save the Ultralytics dataset.\n        split_ratios: Dictionary mapping split names to ratios (must sum to 1.0).\n                     Defaults to {\"train\": 0.8, \"val\": 0.2}.\n        **kwargs: Additional arguments passed to `ultralytics.write_labels`.\n            Currently supports:\n            - class_id: Class ID to use for all instances (default: 0).\n            - image_format: Image format to use for saving frames. Either \"png\"\n              (default, lossless) or \"jpg\".\n            - image_quality: Image quality for JPEG format (1-100). For PNG, this is\n              the compression\n              level (0-9). If None, uses default quality settings.\n            - verbose: If True (default), show progress bars during export.\n            - use_multiprocessing: If True, use multiprocessing for parallel image\n              saving. Default is False.\n            - n_workers: Number of worker processes. If None, uses CPU count - 1.\n              Only used if\n              use_multiprocessing=True.\n    \"\"\"\n    ultralytics.write_labels(labels, dataset_path, split_ratios=split_ratios, **kwargs)\n</code></pre>"},{"location":"formats/#working-with-multiple-datasets","title":"Working with Multiple Datasets","text":""},{"location":"formats/#load-multiple-files","title":"Load Multiple Files","text":"<p>Load and combine multiple pose tracking files:</p>"},{"location":"formats/#sleap_io.load_labels_set","title":"<code>sleap_io.load_labels_set(path, format=None, open_videos=True, **kwargs)</code>","text":"<p>Load a LabelsSet from multiple files.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Union[str, Path, list[Union[str, Path]], dict[str, Union[str, Path]]]</code> <p>Can be one of: - A directory path containing label files - A list of file paths - A dictionary mapping names to file paths</p> required <code>format</code> <code>Optional[str]</code> <p>Optional format specification. If None, will try to infer from path. Supported formats: \"slp\", \"ultralytics\"</p> <code>None</code> <code>open_videos</code> <code>bool</code> <p>If <code>True</code> (the default), attempt to open video backends.</p> <code>True</code> <code>**kwargs</code> <p>Additional format-specific arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>LabelsSet</code> <p>A LabelsSet containing the loaded Labels objects.</p> <p>Examples:</p> <p>Load from SLP directory:</p> <pre><code>&gt;&gt;&gt; labels_set = load_labels_set(\"path/to/splits/\")\n</code></pre> <p>Load from list of SLP files:</p> <pre><code>&gt;&gt;&gt; labels_set = load_labels_set([\"train.slp\", \"val.slp\"])\n</code></pre> <p>Load from Ultralytics dataset:</p> <pre><code>&gt;&gt;&gt; labels_set = load_labels_set(\"path/to/yolo_dataset/\", format=\"ultralytics\")\n</code></pre> Source code in <code>sleap_io/io/main.py</code> <pre><code>def load_labels_set(\n    path: Union[str, Path, list[Union[str, Path]], dict[str, Union[str, Path]]],\n    format: Optional[str] = None,\n    open_videos: bool = True,\n    **kwargs,\n) -&gt; LabelsSet:\n    \"\"\"Load a LabelsSet from multiple files.\n\n    Args:\n        path: Can be one of:\n            - A directory path containing label files\n            - A list of file paths\n            - A dictionary mapping names to file paths\n        format: Optional format specification. If None, will try to infer from path.\n            Supported formats: \"slp\", \"ultralytics\"\n        open_videos: If `True` (the default), attempt to open video backends.\n        **kwargs: Additional format-specific arguments.\n\n    Returns:\n        A LabelsSet containing the loaded Labels objects.\n\n    Examples:\n        Load from SLP directory:\n        &gt;&gt;&gt; labels_set = load_labels_set(\"path/to/splits/\")\n\n        Load from list of SLP files:\n        &gt;&gt;&gt; labels_set = load_labels_set([\"train.slp\", \"val.slp\"])\n\n        Load from Ultralytics dataset:\n        &gt;&gt;&gt; labels_set = load_labels_set(\"path/to/yolo_dataset/\", format=\"ultralytics\")\n    \"\"\"\n    # Try to infer format if not specified\n    if format is None:\n        if isinstance(path, (str, Path)):\n            path_obj = Path(path)\n            if path_obj.is_dir():\n                # Check for ultralytics structure\n                if (path_obj / \"data.yaml\").exists() or any(\n                    (path_obj / split).exists() for split in [\"train\", \"val\", \"test\"]\n                ):\n                    format = \"ultralytics\"\n                else:\n                    # Default to SLP for directories\n                    format = \"slp\"\n            else:\n                # Single file path - check extension\n                if path_obj.suffix == \".slp\":\n                    format = \"slp\"\n        elif isinstance(path, list) and len(path) &gt; 0:\n            # Check first file in list\n            first_path = Path(path[0])\n            if first_path.suffix == \".slp\":\n                format = \"slp\"\n        elif isinstance(path, dict):\n            # Dictionary input defaults to SLP\n            format = \"slp\"\n\n    if format == \"slp\":\n        return slp.read_labels_set(path, open_videos=open_videos)\n    elif format == \"ultralytics\":\n        # Extract ultralytics-specific kwargs\n        splits = kwargs.pop(\"splits\", None)\n        skeleton = kwargs.pop(\"skeleton\", None)\n        image_size = kwargs.pop(\"image_size\", (480, 640))\n        # Remove verbose from kwargs if present (for backward compatibility)\n        kwargs.pop(\"verbose\", None)\n\n        if not isinstance(path, (str, Path)):\n            raise ValueError(\n                \"Ultralytics format requires a directory path, \"\n                f\"got {type(path).__name__}\"\n            )\n\n        return ultralytics.read_labels_set(\n            str(path),\n            splits=splits,\n            skeleton=skeleton,\n            image_size=image_size,\n        )\n    else:\n        raise ValueError(\n            f\"Unknown format: {format}. Supported formats: 'slp', 'ultralytics'\"\n        )\n</code></pre>"},{"location":"formats/#skeleton-files","title":"Skeleton Files","text":"<p>Load and save skeleton definitions separately:</p>"},{"location":"formats/#sleap_io.load_skeleton","title":"<code>sleap_io.load_skeleton(filename)</code>","text":"<p>Load skeleton(s) from a JSON, YAML, or SLP file.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str | Path</code> <p>Path to a skeleton file. Supported formats: - JSON: Standalone skeleton or training config with embedded skeletons - YAML: Simplified skeleton format - SLP: SLEAP project file</p> required <p>Returns:</p> Type Description <code>Union[Skeleton, List[Skeleton]]</code> <p>A single <code>Skeleton</code> or list of <code>Skeleton</code> objects.</p> Notes <p>This function loads skeletons from various file types: - JSON files: Can be standalone skeleton files (jsonpickle format) or training   config files with embedded skeletons - YAML files: Use a simplified human-readable format - SLP files: Extracts skeletons from SLEAP project files The format is detected based on the file extension and content.</p> Source code in <code>sleap_io/io/main.py</code> <pre><code>def load_skeleton(filename: str | Path) -&gt; Union[Skeleton, List[Skeleton]]:\n    \"\"\"Load skeleton(s) from a JSON, YAML, or SLP file.\n\n    Args:\n        filename: Path to a skeleton file. Supported formats:\n            - JSON: Standalone skeleton or training config with embedded skeletons\n            - YAML: Simplified skeleton format\n            - SLP: SLEAP project file\n\n    Returns:\n        A single `Skeleton` or list of `Skeleton` objects.\n\n    Notes:\n        This function loads skeletons from various file types:\n        - JSON files: Can be standalone skeleton files (jsonpickle format) or training\n          config files with embedded skeletons\n        - YAML files: Use a simplified human-readable format\n        - SLP files: Extracts skeletons from SLEAP project files\n        The format is detected based on the file extension and content.\n    \"\"\"\n    if isinstance(filename, Path):\n        filename = str(filename)\n\n    # Detect format based on extension\n    if filename.lower().endswith(\".slp\"):\n        # SLP format - extract skeletons from SLEAP file\n        from sleap_io.io.slp import read_skeletons\n\n        return read_skeletons(filename)\n    elif filename.lower().endswith((\".yaml\", \".yml\")):\n        # YAML format\n        with open(filename, \"r\") as f:\n            yaml_data = f.read()\n        return decode_yaml_skeleton(yaml_data)\n    else:\n        # JSON format (default) - could be standalone or training config\n        with open(filename, \"r\") as f:\n            json_data = f.read()\n        return load_skeleton_from_json(json_data)\n</code></pre>"},{"location":"formats/#sleap_io.save_skeleton","title":"<code>sleap_io.save_skeleton(skeleton, filename)</code>","text":"<p>Save skeleton(s) to a JSON or YAML file.</p> <p>Parameters:</p> Name Type Description Default <code>skeleton</code> <code>Union[Skeleton, List[Skeleton]]</code> <p>A single <code>Skeleton</code> or list of <code>Skeleton</code> objects to save.</p> required <code>filename</code> <code>str | Path</code> <p>Path to save the skeleton file.</p> required Notes <p>This function saves skeletons in either JSON or YAML format based on the file extension. JSON files use the jsonpickle format compatible with SLEAP, while YAML files use a simplified human-readable format.</p> Source code in <code>sleap_io/io/main.py</code> <pre><code>def save_skeleton(skeleton: Union[Skeleton, List[Skeleton]], filename: str | Path):\n    \"\"\"Save skeleton(s) to a JSON or YAML file.\n\n    Args:\n        skeleton: A single `Skeleton` or list of `Skeleton` objects to save.\n        filename: Path to save the skeleton file.\n\n    Notes:\n        This function saves skeletons in either JSON or YAML format based on the\n        file extension. JSON files use the jsonpickle format compatible with SLEAP,\n        while YAML files use a simplified human-readable format.\n    \"\"\"\n    if isinstance(filename, Path):\n        filename = str(filename)\n\n    # Detect format based on extension\n    if filename.lower().endswith((\".yaml\", \".yml\")):\n        # YAML format\n        yaml_data = encode_yaml_skeleton(skeleton)\n        with open(filename, \"w\") as f:\n            f.write(yaml_data)\n    else:\n        # JSON format (default)\n        json_data = encode_skeleton(skeleton)\n        with open(filename, \"w\") as f:\n            f.write(json_data)\n</code></pre>"},{"location":"formats/#format-detection","title":"Format Detection","text":"<p>sleap-io automatically detects file formats based on:</p> <ol> <li>File extension: <code>.slp</code>, <code>.nwb</code>, <code>.h5</code>, <code>.json</code>, <code>.mat</code>, <code>.csv</code></li> <li>File content: For ambiguous extensions like <code>.h5</code> (JABS vs DLC) or <code>.json</code> (Label Studio vs COCO)</li> <li>Explicit format: Pass <code>format</code> parameter to override auto-detection</li> </ol>"},{"location":"formats/#format-conversion-examples","title":"Format Conversion Examples","text":""},{"location":"formats/#convert-between-formats","title":"Convert Between Formats","text":"<pre><code>import sleap_io as sio\n\n# Load from any supported format\nlabels = sio.load_file(\"data.slp\")\n\n# Save to different formats\nlabels.save(\"data.nwb\")  # NWB format\nlabels.save(\"data.labelstudio.json\")  # Label Studio\nlabels.save(\"data_yolo/\")  # Ultralytics YOLO\n</code></pre>"},{"location":"formats/#batch-conversion","title":"Batch Conversion","text":"<pre><code>import sleap_io as sio\nfrom pathlib import Path\n\n# Convert all SLEAP files to NWB\nfor slp_file in Path(\"data/\").glob(\"*.slp\"):\n    labels = sio.load_file(slp_file)\n    nwb_file = slp_file.with_suffix(\".nwb\")\n    labels.save(nwb_file)\n</code></pre>"},{"location":"formats/#round-trip-preservation","title":"Round-Trip Preservation","text":"<p>Most formats preserve data during round-trip conversion:</p> <pre><code>import sleap_io as sio\n\n# Load original\nlabels_original = sio.load_file(\"data.slp\")\n\n# Save and reload\nlabels_original.save(\"temp.nwb\")\nlabels_reloaded = sio.load_file(\"temp.nwb\")\n\n# Data is preserved\nassert len(labels_original) == len(labels_reloaded)\nassert labels_original.skeleton == labels_reloaded.skeleton\n</code></pre>"},{"location":"formats/#format-limitations","title":"Format Limitations","text":"<p>Different formats have varying capabilities:</p> Format Read Write Videos Skeletons Tracks Confidence User/Predicted SLEAP (.slp) \u2705 \u2705 \u2705 \u2705 \u2705 \u2705 \u2705 NWB (.nwb) \u2705 \u2705 \u2705* \u2705 \u2705 \u2705 \u2705 JABS (.h5) \u2705 \u2705 \u2705 \u2705 \u2705 \u2705 \u274c Label Studio \u2705 \u2705 \u2705 \u2705 \u274c \u2705 \u2705 DeepLabCut \u2705 \u274c \u274c \u2705 \u2705 \u2705 \u274c AlphaTracker \u2705 \u274c \u274c \u2705 \u274c \u2705 \u274c LEAP (.mat) \u2705 \u274c \u274c \u274c \u274c \u274c \u274c COCO \u2705 \u274c \u274c \u2705 \u274c \u274c \u2705 Ultralytics \u2705 \u2705 \u274c \u2705 \u274c \u2705 \u274c <p>*NWB can embed videos with <code>annotations_export</code> format</p>"},{"location":"formats/#see-also","title":"See Also","text":"<ul> <li>Data Model: Understanding the core data structures</li> <li>Examples: More usage examples and recipes</li> <li>Merging: Combining data from multiple sources</li> </ul>"},{"location":"merging/","title":"Merging annotations","text":"<p>The merging system in sleap-io provides powerful tools for combining multiple annotation files while intelligently handling conflicts, duplicates, and different data sources. This is essential for collaborative annotation, human-in-the-loop workflows, and consolidating predictions from multiple models.</p> <p>Key concepts</p> <ul> <li>Merging: Combining annotations from multiple sources into a single dataset</li> <li>Matching: Determining which objects (skeletons, videos, tracks, instances) correspond between datasets</li> <li>Conflict resolution: Handling overlapping or contradicting annotations using configurable strategies</li> <li>Provenance tracking: Automatic recording of merge history and data sources</li> </ul>"},{"location":"merging/#quick-start","title":"Quick start","text":"<p>The simplest and most common use case is merging predictions back into a manually annotated project:</p> Basic merge example<pre><code>import sleap_io as sio\n\n# Load your manual annotations and new predictions\nbase_labels = sio.load_file(\"manual_annotations.slp\")\npredictions = sio.load_file(\"model_predictions.slp\")\n\n# Merge predictions into base project\n# Default 'smart' strategy preserves manual labels\nresult = base_labels.merge(predictions)\n\n# Check what happened\nprint(f\"Frames merged: {result.frames_merged}\")\nprint(f\"Instances added: {result.instances_added}\")\n\n# Save the merged project\nbase_labels.save(\"merged_project.slp\")\n</code></pre> <p>Tip</p> <p>The default <code>smart</code> strategy automatically preserves your manual annotations while adding new predictions, making it ideal for human-in-the-loop workflows.</p>"},{"location":"merging/#how-merging-works","title":"How merging works","text":"<p>The merge process follows a systematic approach to combine data structures while maintaining consistency:</p> <pre><code>graph TD\n    A[Start Merge] --&gt; B[Match Skeletons]\n    B --&gt; C[Match Videos]\n    C --&gt; D[Match Tracks]\n    D --&gt; E[For Each Frame]\n    E --&gt; F{Frame Exists?}\n    F --&gt;|No| G[Add New Frame]\n    F --&gt;|Yes| H[Match Instances]\n    H --&gt; I[Apply Strategy]\n    I --&gt; J[Resolve Conflicts]\n    G --&gt; K[Next Frame]\n    J --&gt; K\n    K --&gt; E\n    K --&gt; L[Return MergeResult]</code></pre>"},{"location":"merging/#step-by-step-process","title":"Step-by-step process","text":"<ol> <li>Skeleton matching: Identifies corresponding skeletons between datasets based on node names and structure</li> <li>Video matching: Determines which videos represent the same source data (handles different paths, formats)</li> <li>Track matching: Maps tracks (instance identities) between datasets</li> <li>Frame merging: For each frame, applies the chosen strategy to combine instances</li> <li>Conflict resolution: Handles overlapping instances according to the selected strategy</li> </ol>"},{"location":"merging/#merging-strategies","title":"Merging strategies","text":"<p>The merge strategy determines how instances are combined when frames overlap. Each strategy is designed for specific workflows and requirements.</p>"},{"location":"merging/#smart-strategy-default","title":"Smart strategy (default)","text":"<p>Intelligently preserves manual annotations while updating predictions. This is the recommended strategy for most use cases.</p> Algorithm details Smart merge logic (simplified)<pre><code>def smart_merge(base_frame, new_frame):\n    merged = []\n\n    # Step 1: Always keep user labels from base\n    for instance in base_frame:\n        if isinstance(instance, Instance):  # User label\n            merged.append(instance)\n\n    # Step 2: Find spatial matches between frames\n    matches = find_spatial_matches(base_frame, new_frame)\n\n    # Step 3: Process each match\n    for base_inst, new_inst in matches:\n        if both_are_user_labels:\n            keep(base_inst)  # Preserve original\n        elif base_is_user_label:\n            keep(base_inst)  # User labels always win\n        elif new_is_user_label:\n            keep(new_inst)   # New user label replaces prediction\n        else:  # Both are predictions\n            keep(higher_score_instance)\n\n    # Step 4: Add unmatched instances from new frame\n    merged.extend(unmatched_new_instances)\n\n    return merged\n</code></pre> <p>When to use</p> <ul> <li>Merging model predictions into manually annotated projects</li> <li>Updating predictions while preserving validated annotations</li> <li>Human-in-the-loop training workflows</li> </ul> Using smart strategy<pre><code>result = base_labels.merge(new_labels, frame_strategy=\"smart\")\n</code></pre> <p>Behavior matrix:</p> Base frame New frame Result Reasoning User label Prediction User label Manual annotations are preserved User label User label Base user label Avoid duplicates, keep original Prediction User label User label Manual corrections override predictions Prediction (score: 0.8) Prediction (score: 0.9) Prediction (0.9) Higher confidence wins Empty Any New instance Add missing annotations"},{"location":"merging/#keep-original-strategy","title":"Keep original strategy","text":"<p>Preserves all instances from the base dataset, ignoring new instances at matching positions.</p> <p>When to use</p> <ul> <li>Protecting validated datasets from modification</li> <li>Reviewing changes without applying them</li> <li>Maintaining data integrity for published datasets</li> </ul> Using keep original strategy<pre><code>result = base_labels.merge(new_labels, frame_strategy=\"keep_original\")\n</code></pre>"},{"location":"merging/#keep-new-strategy","title":"Keep new strategy","text":"<p>Replaces matched instances with new ones, effectively updating the base dataset.</p> <p>When to use</p> <ul> <li>Completely replacing old predictions with new ones</li> <li>Applying corrections from a revised annotation pass</li> <li>Updating with higher quality annotations</li> </ul> Using keep new strategy<pre><code>result = base_labels.merge(new_labels, frame_strategy=\"keep_new\")\n</code></pre>"},{"location":"merging/#keep-both-strategy","title":"Keep both strategy","text":"<p>Retains all instances from both datasets without filtering duplicates.</p> <p>Warning</p> <p>This strategy can create overlapping instances at the same locations. Use with caution and consider post-processing to remove duplicates.</p> <p>When to use</p> <ul> <li>Combining annotations from multiple annotators</li> <li>Preserving all data for later review</li> <li>Creating training data with augmented annotations</li> </ul> Using keep both strategy<pre><code>result = base_labels.merge(new_labels, frame_strategy=\"keep_both\")\n</code></pre>"},{"location":"merging/#matching-configuration","title":"Matching configuration","text":"<p>Matching determines which objects correspond between datasets. Different matchers handle various scenarios and data inconsistencies.</p>"},{"location":"merging/#video-matching","title":"Video matching","text":"<p>Controls how videos are matched between projects, essential for cross-platform workflows and different file organizations.</p> AUTO (default)PATHBASENAMECONTENTIMAGE_DEDUP <p>Tries multiple strategies in sequence until a match is found:</p> <pre><code>graph LR\n    A[Try PATH match] --&gt;|Fail| B[Try BASENAME match]\n    B --&gt;|Fail| C[Try CONTENT match]\n    C --&gt;|Fail| D[No match]\n    A --&gt;|Success| E[Match found]\n    B --&gt;|Success| E\n    C --&gt;|Success| E</code></pre> <pre><code>from sleap_io.model.matching import VideoMatcher, VideoMatchMethod\n\nmatcher = VideoMatcher(method=VideoMatchMethod.AUTO)\nresult = base_labels.merge(new_labels, video_matcher=matcher)\n</code></pre> <p>Exact path matching with optional strict mode:</p> <pre><code># Strict: paths must be identical\nstrict_matcher = VideoMatcher(method=VideoMatchMethod.PATH, strict=True)\n\n# Lenient: normalizes paths before comparison\nlenient_matcher = VideoMatcher(method=VideoMatchMethod.PATH, strict=False)\n</code></pre> <p>Matches by filename only, ignoring directories:</p> <pre><code>from sleap_io.model.matching import BASENAME_VIDEO_MATCHER\n\n# Matches \"video.mp4\" regardless of path\nresult = base_labels.merge(new_labels, video_matcher=BASENAME_VIDEO_MATCHER)\n</code></pre> <p>Tip</p> <p>Perfect for cross-platform collaboration where the same files exist in different locations.</p> <p>Matches videos by shape and backend type:</p> <pre><code># Useful when files are renamed but content is identical\ncontent_matcher = VideoMatcher(method=VideoMatchMethod.CONTENT)\n</code></pre> <p>For image sequences, removes duplicate images:</p> <pre><code>from sleap_io.model.matching import IMAGE_DEDUP_VIDEO_MATCHER\n\n# Automatically deduplicates overlapping images\nresult = labels1.merge(labels2, video_matcher=IMAGE_DEDUP_VIDEO_MATCHER)\n</code></pre> <p>Note</p> <p>Only works with <code>ImageVideo</code> backends (image sequences from COCO/CVAT exports).</p>"},{"location":"merging/#instance-matching","title":"Instance matching","text":"<p>Determines when two instances represent the same annotation.</p> Spatial (default)IdentityIoU <p>Matches instances by Euclidean distance between corresponding points:</p> <pre><code>from sleap_io.model.matching import InstanceMatcher\n\n# Threshold is maximum pixel distance\nmatcher = InstanceMatcher(method=\"spatial\", threshold=5.0)\n</code></pre> <p>How it works</p> <p>Computes average distance between visible points. Instances match if distance &lt; threshold.</p> <p>Matches instances by track identity:</p> <pre><code># Only matches if instances belong to the same track\nmatcher = InstanceMatcher(method=\"identity\")\n</code></pre> <p>Matches by bounding box overlap:</p> <pre><code># Threshold is minimum Intersection over Union\nmatcher = InstanceMatcher(method=\"iou\", threshold=0.5)\n</code></pre>"},{"location":"merging/#skeleton-matching","title":"Skeleton matching","text":"<p>Controls how skeletons are matched and mapped between datasets.</p> Structure (default)ExactOverlapSubset <p>Same nodes and edges, order doesn't matter:</p> <pre><code>from sleap_io.model.matching import STRUCTURE_SKELETON_MATCHER\n\nresult = base_labels.merge(new_labels, skeleton_matcher=STRUCTURE_SKELETON_MATCHER)\n</code></pre> <p>Nodes must be identical and in the same order:</p> <pre><code>matcher = SkeletonMatcher(method=\"exact\")\n</code></pre> <p>Partial match based on Jaccard similarity:</p> <pre><code># Requires 70% node overlap\nmatcher = SkeletonMatcher(method=\"overlap\", min_overlap=0.7)\n</code></pre> <p>One skeleton's nodes must be a subset of the other:</p> <pre><code>from sleap_io.model.matching import SUBSET_SKELETON_MATCHER\n\n# Useful for adding nodes to existing skeletons\nresult = base_labels.merge(new_labels, skeleton_matcher=SUBSET_SKELETON_MATCHER)\n</code></pre>"},{"location":"merging/#common-workflows","title":"Common workflows","text":""},{"location":"merging/#human-in-the-loop-hitl-training","title":"Human-in-the-loop (HITL) training","text":"<p>The most common workflow: merging model predictions back into your training data.</p> HITL workflow<pre><code>import sleap_io as sio\n\n# Load manual annotations and predictions\nmanual_labels = sio.load_file(\"manual_annotations.slp\")\npredictions = sio.load_file(\"predictions.slp\")\n\n# Merge with smart strategy (default)\n# This preserves all manual labels while adding predictions\nresult = manual_labels.merge(predictions)\n\n# Review what was merged\nprint(f\"Frames merged: {result.frames_merged}\")\nprint(f\"New instances: {result.instances_added}\")\nprint(f\"Conflicts resolved: {len(result.conflicts)}\")\n\n# Check for any errors\nif result.errors:\n    for error in result.errors:\n        print(f\"Error: {error.message}\")\n\n# Save the updated project\nmanual_labels.save(\"updated_project.slp\")\n</code></pre>"},{"location":"merging/#cross-platform-collaboration","title":"Cross-platform collaboration","text":"<p>When working across different operating systems or file structures:</p> <p>Scenario: Windows and Linux collaboration</p> <p>Your team uses different operating systems with different file paths:</p> <ul> <li>Windows: <code>C:\\research\\videos\\session_001.mp4</code></li> <li>Linux: <code>/home/lab/data/videos/session_001.mp4</code></li> </ul> Cross-platform merging<pre><code>from sleap_io.model.matching import BASENAME_VIDEO_MATCHER\n\n# Load annotations from different systems\nwindows_annotations = sio.load_file(\"windows_annotations.slp\")\nlinux_predictions = sio.load_file(\"linux_predictions.slp\")\n\n# Use basename matching to ignore path differences\nresult = windows_annotations.merge(\n    linux_predictions,\n    video_matcher=BASENAME_VIDEO_MATCHER  # Matches by filename only\n)\n\nprint(f\"Successfully matched {len(result.videos_merged)} videos across platforms\")\n</code></pre>"},{"location":"merging/#combining-multiple-annotators","title":"Combining multiple annotators","text":"<p>Merge annotations from different team members:</p> Multi-annotator workflow<pre><code># Load annotations from multiple sources\nannotator1 = sio.load_file(\"annotator1.slp\")\nannotator2 = sio.load_file(\"annotator2.slp\")\nannotator3 = sio.load_file(\"annotator3.slp\")\n\n# Start with first annotator\nmerged = annotator1\n\n# Merge others, keeping all annotations for review\nfor labels in [annotator2, annotator3]:\n    result = merged.merge(labels, frame_strategy=\"keep_both\")\n    print(f\"Added {result.instances_added} instances from {labels.filename}\")\n\n# Review overlapping annotations\nfor frame in merged:\n    instances = frame.instances\n    if len(instances) &gt; expected_count:\n        print(f\"Frame {frame.frame_idx}: {len(instances)} instances (review needed)\")\n</code></pre>"},{"location":"merging/#updating-predictions","title":"Updating predictions","text":"<p>Replace old predictions with improved ones:</p> Updating predictions<pre><code># Load existing project\nproject = sio.load_file(\"project_with_old_predictions.slp\")\n\n# Load new predictions from improved model\nnew_predictions = sio.load_file(\"better_model_predictions.slp\")\n\n# Configure matching to be more lenient for predictions\nfrom sleap_io.model.matching import InstanceMatcher\n\ninstance_matcher = InstanceMatcher(\n    method=\"spatial\",\n    threshold=10.0  # More lenient for predictions\n)\n\n# Merge with smart strategy to preserve manual labels\nresult = project.merge(\n    new_predictions,\n    frame_strategy=\"smart\",\n    instance_matcher=instance_matcher\n)\n\nprint(f\"Updated {result.frames_merged} frames with new predictions\")\nprint(f\"Preserved {sum(1 for f in project for i in f.instances if type(i).__name__ == 'Instance')} manual labels\")\n</code></pre>"},{"location":"merging/#advanced-topics","title":"Advanced topics","text":""},{"location":"merging/#image-sequence-deduplication","title":"Image sequence deduplication","text":"<p>When working with COCO or CVAT exports that contain overlapping images:</p> Background <p>CVAT and COCO exports often use image sequences (ImageVideo) rather than video files. When merging multiple exports, you may have duplicate images that need to be handled intelligently.</p> Deduplicating image sequences<pre><code>from sleap_io.model.matching import IMAGE_DEDUP_VIDEO_MATCHER, SHAPE_VIDEO_MATCHER\n\n# Load CVAT exports with potential overlaps\nbatch1 = sio.load_file(\"cvat_batch1.json\")  # 1000 images\nbatch2 = sio.load_file(\"cvat_batch2.json\")  # 1000 images, 22 overlapping\n\n# Option 1: Remove duplicates, keep videos separate\nresult = batch1.merge(batch2, video_matcher=IMAGE_DEDUP_VIDEO_MATCHER)\nprint(f\"Result: {sum(len(v.filename) for v in batch1.videos)} unique images\")\n\n# Option 2: Merge same-shaped videos into one\nresult = batch1.merge(batch2, video_matcher=SHAPE_VIDEO_MATCHER)\nprint(f\"Result: Single video with {len(batch1.videos[0].filename)} images\")\n</code></pre>"},{"location":"merging/#frame-level-merging","title":"Frame-level merging","text":"<p>For fine-grained control over individual frames:</p> Frame-level merge control<pre><code>from sleap_io.model.matching import InstanceMatcher\n\n# Get specific frames\nframe1 = base_labels.labeled_frames[0]\nframe2 = new_labels.labeled_frames[0]\n\n# Configure matching\nmatcher = InstanceMatcher(method=\"spatial\", threshold=5.0)\n\n# Merge at frame level\nmerged_instances, conflicts = frame1.merge(\n    frame2,\n    instance_matcher=matcher,\n    strategy=\"smart\"\n)\n\n# Apply merged instances\nframe1.instances = merged_instances\n\n# Review conflicts\nfor original, new, resolution in conflicts:\n    print(f\"Conflict resolved: {resolution}\")\n</code></pre>"},{"location":"merging/#error-handling","title":"Error handling","text":"<p>Configure how merge errors are handled:</p> Error handling strategies<pre><code># Strict mode: Stop on first error\ntry:\n    result = labels.merge(other, error_mode=\"strict\")\nexcept Exception as e:\n    print(f\"Merge failed: {e}\")\n    # Handle error...\n\n# Continue mode: Collect errors but continue (default)\nresult = labels.merge(other, error_mode=\"continue\")\nif result.errors:\n    for error in result.errors:\n        print(f\"Error: {error.message}\")\n\n# Warning mode: Print warnings but continue\nresult = labels.merge(other, error_mode=\"warn\")\n</code></pre>"},{"location":"merging/#provenance-tracking","title":"Provenance tracking","text":"<p>All merge operations are automatically tracked:</p> Accessing merge history<pre><code># After merging\nresult = base_labels.merge(new_labels)\n\n# Check merge history\nmerge_history = base_labels.provenance.get(\"merge_history\", [])\n\nfor merge in merge_history:\n    print(f\"Merged at: {merge['timestamp']}\")\n    print(f\"Source: {merge['source_labels']['filename']}\")\n    print(f\"Frames merged: {merge['result']['frames_merged']}\")\n    print(f\"Instances added: {merge['result']['instances_added']}\")\n</code></pre>"},{"location":"merging/#troubleshooting","title":"Troubleshooting","text":"<p>Common issues and solutions when merging datasets.</p> No frames merged <p>Symptom: <code>result.frames_merged == 0</code></p> <p>Possible causes and solutions:</p> <ol> <li> <p>Videos don't match <pre><code># Try different video matching strategies\nresult = labels.merge(other, video_matcher=BASENAME_VIDEO_MATCHER)\n# or\nresult = labels.merge(other, video_matcher=AUTO_VIDEO_MATCHER)\n</code></pre></p> </li> <li> <p>Frame indices don't align <pre><code># Check frame indices\nprint(f\"Base frames: {[f.frame_idx for f in base_labels]}\")\nprint(f\"New frames: {[f.frame_idx for f in new_labels]}\")\n</code></pre></p> </li> <li> <p>Skeleton mismatch <pre><code># Validate and use lenient matching\nresult = labels.merge(\n    other,\n    validate=True,\n    skeleton_matcher=OVERLAP_SKELETON_MATCHER\n)\n</code></pre></p> </li> </ol> Manual annotations lost <p>Symptom: User labels disappear after merging</p> <p>Solution: Ensure you're using the <code>smart</code> strategy (default): <pre><code># Explicitly set smart strategy\nresult = labels.merge(other, frame_strategy=\"smart\")\n\n# Verify manual labels are preserved\nmanual_count_before = sum(1 for f in labels for i in f.instances \n                         if type(i).__name__ == 'Instance')\nresult = labels.merge(other)\nmanual_count_after = sum(1 for f in labels for i in f.instances \n                        if type(i).__name__ == 'Instance')\nassert manual_count_after &gt;= manual_count_before\n</code></pre></p> Duplicate instances <p>Symptom: Multiple instances at the same location</p> <p>Solutions:</p> <ol> <li> <p>Tighten spatial matching <pre><code>matcher = InstanceMatcher(method=\"spatial\", threshold=2.0)  # Stricter\nresult = labels.merge(other, instance_matcher=matcher)\n</code></pre></p> </li> <li> <p>Use identity matching for tracked data <pre><code>matcher = InstanceMatcher(method=\"identity\")\nresult = labels.merge(other, instance_matcher=matcher)\n</code></pre></p> </li> <li> <p>Post-process to remove duplicates <pre><code>from sleap_io.model.instance import PredictedInstance\n\nfor frame in labels:\n    # Remove duplicate predictions within threshold\n    cleaned = []\n    for inst in frame.instances:\n        is_duplicate = False\n        for other in cleaned:\n            if inst.numpy().mean(axis=0).dist(other.numpy().mean(axis=0)) &lt; 5:\n                is_duplicate = True\n                break\n        if not is_duplicate:\n            cleaned.append(inst)\n    frame.instances = cleaned\n</code></pre></p> </li> </ol> Memory issues with large datasets <p>Symptom: Out of memory errors during merge</p> <p>Solutions:</p> <ol> <li> <p>Process in batches <pre><code># Split by video\nfor video in new_labels.videos:\n    video_labels = new_labels.extract_video(video)\n    result = base_labels.merge(video_labels)\n</code></pre></p> </li> <li> <p>Use progress callback to monitor <pre><code>def progress(current, total, message):\n    print(f\"{current}/{total}: {message}\")\n    # Add memory monitoring here if needed\n\nresult = labels.merge(other, progress_callback=progress)\n</code></pre></p> </li> </ol>"},{"location":"merging/#api-reference","title":"API reference","text":""},{"location":"merging/#labels-merge-method","title":"Labels merge method","text":""},{"location":"merging/#sleap_io.model.labels.Labels.merge","title":"<code>sleap_io.model.labels.Labels.merge(other, instance_matcher=None, skeleton_matcher=None, video_matcher=None, track_matcher=None, frame_strategy='smart', validate=True, progress_callback=None, error_mode='continue')</code>","text":"<p>Merge another Labels object into this one.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>'Labels'</code> <p>Another Labels object to merge into this one.</p> required <code>instance_matcher</code> <code>Optional['InstanceMatcher']</code> <p>Matcher for comparing instances. If None, uses default spatial matching with 5px tolerance.</p> <code>None</code> <code>skeleton_matcher</code> <code>Optional['SkeletonMatcher']</code> <p>Matcher for comparing skeletons. If None, uses structure matching.</p> <code>None</code> <code>video_matcher</code> <code>Optional['VideoMatcher']</code> <p>Matcher for comparing videos. If None, uses auto matching.</p> <code>None</code> <code>track_matcher</code> <code>Optional['TrackMatcher']</code> <p>Matcher for comparing tracks. If None, uses name matching.</p> <code>None</code> <code>frame_strategy</code> <code>str</code> <p>Strategy for merging frames: - \"smart\": Keep user labels, update predictions - \"keep_original\": Keep original frames - \"keep_new\": Replace with new frames - \"keep_both\": Keep all frames</p> <code>'smart'</code> <code>validate</code> <code>bool</code> <p>If True, validate for conflicts before merging.</p> <code>True</code> <code>progress_callback</code> <code>Optional[Callable]</code> <p>Optional callback for progress updates. Should accept (current, total, message) arguments.</p> <code>None</code> <code>error_mode</code> <code>str</code> <p>How to handle errors: - \"continue\": Log errors but continue - \"strict\": Raise exception on first error - \"warn\": Print warnings but continue</p> <code>'continue'</code> <p>Returns:</p> Type Description <code>'MergeResult'</code> <p>MergeResult object with statistics and any errors/conflicts.</p> Notes <p>This method modifies the Labels object in place. The merge is designed to handle common workflows like merging predictions back into a project.</p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def merge(\n    self,\n    other: \"Labels\",\n    instance_matcher: Optional[\"InstanceMatcher\"] = None,\n    skeleton_matcher: Optional[\"SkeletonMatcher\"] = None,\n    video_matcher: Optional[\"VideoMatcher\"] = None,\n    track_matcher: Optional[\"TrackMatcher\"] = None,\n    frame_strategy: str = \"smart\",\n    validate: bool = True,\n    progress_callback: Optional[Callable] = None,\n    error_mode: str = \"continue\",\n) -&gt; \"MergeResult\":\n    \"\"\"Merge another Labels object into this one.\n\n    Args:\n        other: Another Labels object to merge into this one.\n        instance_matcher: Matcher for comparing instances. If None, uses default\n            spatial matching with 5px tolerance.\n        skeleton_matcher: Matcher for comparing skeletons. If None, uses structure\n            matching.\n        video_matcher: Matcher for comparing videos. If None, uses auto matching.\n        track_matcher: Matcher for comparing tracks. If None, uses name matching.\n        frame_strategy: Strategy for merging frames:\n            - \"smart\": Keep user labels, update predictions\n            - \"keep_original\": Keep original frames\n            - \"keep_new\": Replace with new frames\n            - \"keep_both\": Keep all frames\n        validate: If True, validate for conflicts before merging.\n        progress_callback: Optional callback for progress updates.\n            Should accept (current, total, message) arguments.\n        error_mode: How to handle errors:\n            - \"continue\": Log errors but continue\n            - \"strict\": Raise exception on first error\n            - \"warn\": Print warnings but continue\n\n    Returns:\n        MergeResult object with statistics and any errors/conflicts.\n\n    Notes:\n        This method modifies the Labels object in place. The merge is designed to\n        handle common workflows like merging predictions back into a project.\n    \"\"\"\n    from datetime import datetime\n    from pathlib import Path\n\n    from sleap_io.model.matching import (\n        ConflictResolution,\n        ErrorMode,\n        InstanceMatcher,\n        MergeError,\n        MergeResult,\n        SkeletonMatcher,\n        SkeletonMatchMethod,\n        SkeletonMismatchError,\n        TrackMatcher,\n        VideoMatcher,\n        VideoMatchMethod,\n    )\n\n    # Initialize matchers with defaults if not provided\n    if instance_matcher is None:\n        instance_matcher = InstanceMatcher()\n    if skeleton_matcher is None:\n        skeleton_matcher = SkeletonMatcher(method=SkeletonMatchMethod.STRUCTURE)\n    if video_matcher is None:\n        video_matcher = VideoMatcher()\n    if track_matcher is None:\n        track_matcher = TrackMatcher()\n\n    # Parse error mode\n    error_mode_enum = ErrorMode(error_mode)\n\n    # Initialize result\n    result = MergeResult(successful=True)\n\n    # Track merge history in provenance\n    if \"merge_history\" not in self.provenance:\n        self.provenance[\"merge_history\"] = []\n\n    merge_record = {\n        \"timestamp\": datetime.now().isoformat(),\n        \"source_labels\": {\n            \"n_frames\": len(other.labeled_frames),\n            \"n_videos\": len(other.videos),\n            \"n_skeletons\": len(other.skeletons),\n            \"n_tracks\": len(other.tracks),\n        },\n        \"strategy\": frame_strategy,\n    }\n\n    try:\n        # Step 1: Match and merge skeletons\n        skeleton_map = {}\n        for other_skel in other.skeletons:\n            matched = False\n            for self_skel in self.skeletons:\n                if skeleton_matcher.match(self_skel, other_skel):\n                    skeleton_map[other_skel] = self_skel\n                    matched = True\n                    break\n\n            if not matched:\n                if validate and error_mode_enum == ErrorMode.STRICT:\n                    raise SkeletonMismatchError(\n                        message=f\"No matching skeleton found for {other_skel.name}\",\n                        details={\"skeleton\": other_skel},\n                    )\n                elif error_mode_enum == ErrorMode.WARN:\n                    print(f\"Warning: No matching skeleton for {other_skel.name}\")\n\n                # Add new skeleton if no match\n                self.skeletons.append(other_skel)\n                skeleton_map[other_skel] = other_skel\n\n        # Step 2: Match and merge videos\n        video_map = {}\n        frame_idx_map = {}  # Maps (old_video, old_idx) -&gt; (new_video, new_idx)\n\n        for other_video in other.videos:\n            matched = False\n            for self_video in self.videos:\n                if video_matcher.match(self_video, other_video):\n                    # Special handling for different match methods\n                    if video_matcher.method == VideoMatchMethod.IMAGE_DEDUP:\n                        # Deduplicate images from other_video\n                        deduped_video = other_video.deduplicate_with(self_video)\n                        if deduped_video is None:\n                            # All images were duplicates, map to existing video\n                            video_map[other_video] = self_video\n                            # Build frame index mapping for deduplicated frames\n                            if isinstance(\n                                other_video.filename, list\n                            ) and isinstance(self_video.filename, list):\n                                other_basenames = [\n                                    Path(f).name for f in other_video.filename\n                                ]\n                                self_basenames = [\n                                    Path(f).name for f in self_video.filename\n                                ]\n                                for old_idx, basename in enumerate(other_basenames):\n                                    if basename in self_basenames:\n                                        new_idx = self_basenames.index(basename)\n                                        frame_idx_map[(other_video, old_idx)] = (\n                                            self_video,\n                                            new_idx,\n                                        )\n                        else:\n                            # Add deduplicated video as new\n                            self.videos.append(deduped_video)\n                            video_map[other_video] = deduped_video\n                            # Build frame index mapping for remaining frames\n                            if isinstance(\n                                other_video.filename, list\n                            ) and isinstance(deduped_video.filename, list):\n                                other_basenames = [\n                                    Path(f).name for f in other_video.filename\n                                ]\n                                deduped_basenames = [\n                                    Path(f).name for f in deduped_video.filename\n                                ]\n                                for old_idx, basename in enumerate(other_basenames):\n                                    if basename in deduped_basenames:\n                                        new_idx = deduped_basenames.index(basename)\n                                        frame_idx_map[(other_video, old_idx)] = (\n                                            deduped_video,\n                                            new_idx,\n                                        )\n                    elif video_matcher.method == VideoMatchMethod.SHAPE:\n                        # Merge videos with same shape\n                        merged_video = self_video.merge_with(other_video)\n                        # Replace self_video with merged version\n                        self_video_idx = self.videos.index(self_video)\n                        self.videos[self_video_idx] = merged_video\n                        video_map[other_video] = merged_video\n                        video_map[self_video] = (\n                            merged_video  # Update mapping for self too\n                        )\n                        # Build frame index mapping\n                        if isinstance(other_video.filename, list) and isinstance(\n                            merged_video.filename, list\n                        ):\n                            other_basenames = [\n                                Path(f).name for f in other_video.filename\n                            ]\n                            merged_basenames = [\n                                Path(f).name for f in merged_video.filename\n                            ]\n                            for old_idx, basename in enumerate(other_basenames):\n                                if basename in merged_basenames:\n                                    new_idx = merged_basenames.index(basename)\n                                    frame_idx_map[(other_video, old_idx)] = (\n                                        merged_video,\n                                        new_idx,\n                                    )\n                    else:\n                        # Regular matching, no special handling\n                        video_map[other_video] = self_video\n                    matched = True\n                    break\n\n            if not matched:\n                # Add new video if no match\n                self.videos.append(other_video)\n                video_map[other_video] = other_video\n\n        # Step 3: Match and merge tracks\n        track_map = {}\n        for other_track in other.tracks:\n            matched = False\n            for self_track in self.tracks:\n                if track_matcher.match(self_track, other_track):\n                    track_map[other_track] = self_track\n                    matched = True\n                    break\n\n            if not matched:\n                # Add new track if no match\n                self.tracks.append(other_track)\n                track_map[other_track] = other_track\n\n        # Step 4: Merge frames\n        total_frames = len(other.labeled_frames)\n\n        for frame_idx, other_frame in enumerate(other.labeled_frames):\n            if progress_callback:\n                progress_callback(\n                    frame_idx,\n                    total_frames,\n                    f\"Merging frame {frame_idx + 1}/{total_frames}\",\n                )\n\n            # Check if frame index needs remapping (for deduplicated/merged videos)\n            if (other_frame.video, other_frame.frame_idx) in frame_idx_map:\n                mapped_video, mapped_frame_idx = frame_idx_map[\n                    (other_frame.video, other_frame.frame_idx)\n                ]\n            else:\n                # Map video to self\n                mapped_video = video_map.get(other_frame.video, other_frame.video)\n                mapped_frame_idx = other_frame.frame_idx\n\n            # Find matching frame in self\n            matching_frames = self.find(mapped_video, mapped_frame_idx)\n\n            if len(matching_frames) == 0:\n                # No matching frame, create new one\n                new_frame = LabeledFrame(\n                    video=mapped_video,\n                    frame_idx=mapped_frame_idx,\n                    instances=[],\n                )\n\n                # Map instances to new skeleton/track\n                for inst in other_frame.instances:\n                    new_inst = self._map_instance(inst, skeleton_map, track_map)\n                    new_frame.instances.append(new_inst)\n                    result.instances_added += 1\n\n                self.append(new_frame)\n                result.frames_merged += 1\n\n            else:\n                # Merge into existing frame\n                self_frame = matching_frames[0]\n\n                # Merge instances using frame-level merge\n                merged_instances, conflicts = self_frame.merge(\n                    other_frame,\n                    instance_matcher=instance_matcher,\n                    strategy=frame_strategy,\n                )\n\n                # Remap skeleton and track references for instances from other frame\n                remapped_instances = []\n                for inst in merged_instances:\n                    # Check if instance needs remapping (from other_frame)\n                    if inst.skeleton in skeleton_map:\n                        # Instance needs remapping\n                        remapped_inst = self._map_instance(\n                            inst, skeleton_map, track_map\n                        )\n                        remapped_instances.append(remapped_inst)\n                    else:\n                        # Instance already has correct skeleton (from self_frame)\n                        remapped_instances.append(inst)\n                merged_instances = remapped_instances\n\n                # Count changes\n                n_before = len(self_frame.instances)\n                n_after = len(merged_instances)\n                result.instances_added += max(0, n_after - n_before)\n\n                # Record conflicts\n                for orig, new, resolution in conflicts:\n                    result.conflicts.append(\n                        ConflictResolution(\n                            frame=self_frame,\n                            conflict_type=\"instance_conflict\",\n                            original_data=orig,\n                            new_data=new,\n                            resolution=resolution,\n                        )\n                    )\n\n                # Update frame instances\n                self_frame.instances = merged_instances\n                result.frames_merged += 1\n\n        # Step 5: Merge suggestions\n        for other_suggestion in other.suggestions:\n            mapped_video = video_map.get(\n                other_suggestion.video, other_suggestion.video\n            )\n            # Check if suggestion already exists\n            exists = False\n            for self_suggestion in self.suggestions:\n                if (\n                    self_suggestion.video == mapped_video\n                    and self_suggestion.frame_idx == other_suggestion.frame_idx\n                ):\n                    exists = True\n                    break\n            if not exists:\n                # Create new suggestion with mapped video\n                new_suggestion = SuggestionFrame(\n                    video=mapped_video, frame_idx=other_suggestion.frame_idx\n                )\n                self.suggestions.append(new_suggestion)\n\n        # Update merge record\n        merge_record[\"result\"] = {\n            \"frames_merged\": result.frames_merged,\n            \"instances_added\": result.instances_added,\n            \"conflicts\": len(result.conflicts),\n        }\n        self.provenance[\"merge_history\"].append(merge_record)\n\n    except MergeError as e:\n        result.successful = False\n        result.errors.append(e)\n        if error_mode_enum == ErrorMode.STRICT:\n            raise\n    except Exception as e:\n        result.successful = False\n        result.errors.append(\n            MergeError(message=str(e), details={\"exception\": type(e).__name__})\n        )\n        if error_mode_enum == ErrorMode.STRICT:\n            raise\n\n    if progress_callback:\n        progress_callback(total_frames, total_frames, \"Merge complete\")\n\n    return result\n</code></pre>"},{"location":"merging/#enums","title":"Enums","text":""},{"location":"merging/#sleap_io.model.matching.SkeletonMatchMethod","title":"<code>sleap_io.model.matching.SkeletonMatchMethod</code>","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Methods for matching skeletons.</p> <p>Attributes:</p> Name Type Description <code>EXACT</code> <p>Exact match requiring same nodes in the same order.</p> <code>STRUCTURE</code> <p>Match requiring same nodes and edges, but order doesn't matter.</p> <code>OVERLAP</code> <p>Partial match based on overlapping nodes (uses Jaccard similarity).</p> <code>SUBSET</code> <p>Match if one skeleton's nodes are a subset of another's.</p> Source code in <code>sleap_io/model/matching.py</code> <pre><code>class SkeletonMatchMethod(str, Enum):\n    \"\"\"Methods for matching skeletons.\n\n    Attributes:\n        EXACT: Exact match requiring same nodes in the same order.\n        STRUCTURE: Match requiring same nodes and edges, but order doesn't matter.\n        OVERLAP: Partial match based on overlapping nodes (uses Jaccard similarity).\n        SUBSET: Match if one skeleton's nodes are a subset of another's.\n    \"\"\"\n\n    EXACT = \"exact\"\n    STRUCTURE = \"structure\"\n    OVERLAP = \"overlap\"\n    SUBSET = \"subset\"\n</code></pre>"},{"location":"merging/#sleap_io.model.matching.InstanceMatchMethod","title":"<code>sleap_io.model.matching.InstanceMatchMethod</code>","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Methods for matching instances.</p> <p>Attributes:</p> Name Type Description <code>SPATIAL</code> <p>Match instances by spatial proximity using Euclidean distance.</p> <code>IDENTITY</code> <p>Match instances by track identity (same track object).</p> <code>IOU</code> <p>Match instances by bounding box Intersection over Union.</p> Source code in <code>sleap_io/model/matching.py</code> <pre><code>class InstanceMatchMethod(str, Enum):\n    \"\"\"Methods for matching instances.\n\n    Attributes:\n        SPATIAL: Match instances by spatial proximity using Euclidean distance.\n        IDENTITY: Match instances by track identity (same track object).\n        IOU: Match instances by bounding box Intersection over Union.\n    \"\"\"\n\n    SPATIAL = \"spatial\"\n    IDENTITY = \"identity\"\n    IOU = \"iou\"\n</code></pre>"},{"location":"merging/#sleap_io.model.matching.TrackMatchMethod","title":"<code>sleap_io.model.matching.TrackMatchMethod</code>","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Methods for matching tracks.</p> <p>Attributes:</p> Name Type Description <code>NAME</code> <p>Match tracks by their name attribute.</p> <code>IDENTITY</code> <p>Match tracks by object identity (same Python object).</p> Source code in <code>sleap_io/model/matching.py</code> <pre><code>class TrackMatchMethod(str, Enum):\n    \"\"\"Methods for matching tracks.\n\n    Attributes:\n        NAME: Match tracks by their name attribute.\n        IDENTITY: Match tracks by object identity (same Python object).\n    \"\"\"\n\n    NAME = \"name\"\n    IDENTITY = \"identity\"\n</code></pre>"},{"location":"merging/#sleap_io.model.matching.VideoMatchMethod","title":"<code>sleap_io.model.matching.VideoMatchMethod</code>","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Methods for matching videos.</p> <p>Attributes:</p> Name Type Description <code>PATH</code> <p>Match by exact file path (strict or lenient based on VideoMatcher.strict setting).</p> <code>BASENAME</code> <p>Match by filename only, ignoring directory paths.</p> <code>CONTENT</code> <p>Match by video shape (frames, height, width, channels) and backend type.</p> <code>AUTO</code> <p>Automatic matching - tries BASENAME first, then falls back to CONTENT.</p> <code>IMAGE_DEDUP</code> <p>(ImageVideo only) Match ImageVideo instances with overlapping image files. Used to deduplicate individual images when merging datasets where videos are image sequences.</p> <code>SHAPE</code> <p>Match videos by shape only (height, width, channels), ignoring filenames and frame count. Commonly used with ImageVideo to merge same-shaped image sequences.</p> Source code in <code>sleap_io/model/matching.py</code> <pre><code>class VideoMatchMethod(str, Enum):\n    \"\"\"Methods for matching videos.\n\n    Attributes:\n        PATH: Match by exact file path (strict or lenient based on\n            VideoMatcher.strict setting).\n        BASENAME: Match by filename only, ignoring directory paths.\n        CONTENT: Match by video shape (frames, height, width, channels) and\n            backend type.\n        AUTO: Automatic matching - tries BASENAME first, then falls back to CONTENT.\n        IMAGE_DEDUP: (ImageVideo only) Match ImageVideo instances with overlapping\n            image files. Used to deduplicate individual images when merging datasets\n            where videos are image sequences.\n        SHAPE: Match videos by shape only (height, width, channels), ignoring\n            filenames and frame count. Commonly used with ImageVideo to merge\n            same-shaped image sequences.\n    \"\"\"\n\n    PATH = \"path\"\n    BASENAME = \"basename\"\n    CONTENT = \"content\"\n    AUTO = \"auto\"\n    IMAGE_DEDUP = \"image_dedup\"\n    SHAPE = \"shape\"\n</code></pre>"},{"location":"merging/#sleap_io.model.matching.FrameStrategy","title":"<code>sleap_io.model.matching.FrameStrategy</code>","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Strategies for handling frame merging.</p> <p>Attributes:</p> Name Type Description <code>SMART</code> <p>Smart merging that preserves user labels over predictions when they overlap.</p> <code>KEEP_ORIGINAL</code> <p>Always keep instances from the original (base) frame.</p> <code>KEEP_NEW</code> <p>Always keep instances from the new (incoming) frame.</p> <code>KEEP_BOTH</code> <p>Keep all instances from both frames without filtering.</p> Source code in <code>sleap_io/model/matching.py</code> <pre><code>class FrameStrategy(str, Enum):\n    \"\"\"Strategies for handling frame merging.\n\n    Attributes:\n        SMART: Smart merging that preserves user labels over predictions when\n            they overlap.\n        KEEP_ORIGINAL: Always keep instances from the original (base) frame.\n        KEEP_NEW: Always keep instances from the new (incoming) frame.\n        KEEP_BOTH: Keep all instances from both frames without filtering.\n    \"\"\"\n\n    SMART = \"smart\"\n    KEEP_ORIGINAL = \"keep_original\"\n    KEEP_NEW = \"keep_new\"\n    KEEP_BOTH = \"keep_both\"\n</code></pre>"},{"location":"merging/#sleap_io.model.matching.ErrorMode","title":"<code>sleap_io.model.matching.ErrorMode</code>","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Error handling modes for merge operations.</p> <p>Attributes:</p> Name Type Description <code>CONTINUE</code> <p>Continue merging on errors, collecting them in the result.</p> <code>STRICT</code> <p>Raise an exception on the first error encountered.</p> <code>WARN</code> <p>Issue warnings about errors but continue merging.</p> Source code in <code>sleap_io/model/matching.py</code> <pre><code>class ErrorMode(str, Enum):\n    \"\"\"Error handling modes for merge operations.\n\n    Attributes:\n        CONTINUE: Continue merging on errors, collecting them in the result.\n        STRICT: Raise an exception on the first error encountered.\n        WARN: Issue warnings about errors but continue merging.\n    \"\"\"\n\n    CONTINUE = \"continue\"\n    STRICT = \"strict\"\n    WARN = \"warn\"\n</code></pre>"},{"location":"merging/#matcher-classes","title":"Matcher classes","text":""},{"location":"merging/#sleap_io.model.matching.SkeletonMatcher","title":"<code>sleap_io.model.matching.SkeletonMatcher</code>","text":"<p>Matcher for comparing and matching skeletons.</p> <p>Attributes:</p> Name Type Description <code>method</code> <code>Union[SkeletonMatchMethod, str]</code> <p>The matching method to use. Can be a SkeletonMatchMethod enum value or a string that will be converted to the enum. Default is STRUCTURE.</p> <code>require_same_order</code> <code>bool</code> <p>Whether to require nodes in the same order for STRUCTURE matching. Only used when method is STRUCTURE. Default is False.</p> <code>min_overlap</code> <code>float</code> <p>Minimum Jaccard similarity required for OVERLAP matching. Only used when method is OVERLAP. Default is 0.5.</p> <p>Methods:</p> Name Description <code>match</code> <p>Check if two skeletons match according to the configured method.</p> Source code in <code>sleap_io/model/matching.py</code> <pre><code>@attrs.define\nclass SkeletonMatcher:\n    \"\"\"Matcher for comparing and matching skeletons.\n\n    Attributes:\n        method: The matching method to use. Can be a SkeletonMatchMethod enum value\n            or a string that will be converted to the enum. Default is STRUCTURE.\n        require_same_order: Whether to require nodes in the same order for STRUCTURE\n            matching. Only used when method is STRUCTURE. Default is False.\n        min_overlap: Minimum Jaccard similarity required for OVERLAP matching.\n            Only used when method is OVERLAP. Default is 0.5.\n    \"\"\"\n\n    method: Union[SkeletonMatchMethod, str] = attrs.field(\n        default=SkeletonMatchMethod.STRUCTURE,\n        converter=lambda x: SkeletonMatchMethod(x) if isinstance(x, str) else x,\n    )\n    require_same_order: bool = False\n    min_overlap: float = 0.5\n\n    def match(self, skeleton1: Skeleton, skeleton2: Skeleton) -&gt; bool:\n        \"\"\"Check if two skeletons match according to the configured method.\"\"\"\n        if self.method == SkeletonMatchMethod.EXACT:\n            return skeleton1.matches(skeleton2, require_same_order=True)\n        elif self.method == SkeletonMatchMethod.STRUCTURE:\n            return skeleton1.matches(\n                skeleton2, require_same_order=self.require_same_order\n            )\n        elif self.method == SkeletonMatchMethod.OVERLAP:\n            metrics = skeleton1.node_similarities(skeleton2)\n            return metrics[\"jaccard\"] &gt;= self.min_overlap\n        elif self.method == SkeletonMatchMethod.SUBSET:\n            # Check if skeleton1 nodes are subset of skeleton2\n            nodes1 = set(skeleton1.node_names)\n            nodes2 = set(skeleton2.node_names)\n            return nodes1.issubset(nodes2)\n        else:\n            raise ValueError(f\"Unknown skeleton match method: {self.method}\")\n</code></pre>"},{"location":"merging/#sleap_io.model.matching.SkeletonMatcher.match","title":"<code>match(skeleton1, skeleton2)</code>","text":"<p>Check if two skeletons match according to the configured method.</p> Source code in <code>sleap_io/model/matching.py</code> <pre><code>def match(self, skeleton1: Skeleton, skeleton2: Skeleton) -&gt; bool:\n    \"\"\"Check if two skeletons match according to the configured method.\"\"\"\n    if self.method == SkeletonMatchMethod.EXACT:\n        return skeleton1.matches(skeleton2, require_same_order=True)\n    elif self.method == SkeletonMatchMethod.STRUCTURE:\n        return skeleton1.matches(\n            skeleton2, require_same_order=self.require_same_order\n        )\n    elif self.method == SkeletonMatchMethod.OVERLAP:\n        metrics = skeleton1.node_similarities(skeleton2)\n        return metrics[\"jaccard\"] &gt;= self.min_overlap\n    elif self.method == SkeletonMatchMethod.SUBSET:\n        # Check if skeleton1 nodes are subset of skeleton2\n        nodes1 = set(skeleton1.node_names)\n        nodes2 = set(skeleton2.node_names)\n        return nodes1.issubset(nodes2)\n    else:\n        raise ValueError(f\"Unknown skeleton match method: {self.method}\")\n</code></pre>"},{"location":"merging/#sleap_io.model.matching.InstanceMatcher","title":"<code>sleap_io.model.matching.InstanceMatcher</code>","text":"<p>Matcher for comparing and matching instances.</p> <p>Attributes:</p> Name Type Description <code>method</code> <code>Union[InstanceMatchMethod, str]</code> <p>The matching method to use. Can be an InstanceMatchMethod enum value or a string that will be converted to the enum. Default is SPATIAL.</p> <code>threshold</code> <code>float</code> <p>The threshold value used for matching. For SPATIAL method, this is the maximum pixel distance. For IOU method, this is the minimum IoU value. Not used for IDENTITY method. Default is 5.0.</p> <p>Methods:</p> Name Description <code>find_matches</code> <p>Find all matching instances between two lists.</p> <code>match</code> <p>Check if two instances match according to the configured method.</p> Source code in <code>sleap_io/model/matching.py</code> <pre><code>@attrs.define\nclass InstanceMatcher:\n    \"\"\"Matcher for comparing and matching instances.\n\n    Attributes:\n        method: The matching method to use. Can be an InstanceMatchMethod enum value\n            or a string that will be converted to the enum. Default is SPATIAL.\n        threshold: The threshold value used for matching. For SPATIAL method, this is\n            the maximum pixel distance. For IOU method, this is the minimum IoU value.\n            Not used for IDENTITY method. Default is 5.0.\n    \"\"\"\n\n    method: Union[InstanceMatchMethod, str] = attrs.field(\n        default=InstanceMatchMethod.SPATIAL,\n        converter=lambda x: InstanceMatchMethod(x) if isinstance(x, str) else x,\n    )\n    threshold: float = 5.0\n\n    def match(self, instance1: Instance, instance2: Instance) -&gt; bool:\n        \"\"\"Check if two instances match according to the configured method.\"\"\"\n        if self.method == InstanceMatchMethod.SPATIAL:\n            return instance1.same_pose_as(instance2, tolerance=self.threshold)\n        elif self.method == InstanceMatchMethod.IDENTITY:\n            return instance1.same_identity_as(instance2)\n        elif self.method == InstanceMatchMethod.IOU:\n            return instance1.overlaps_with(instance2, iou_threshold=self.threshold)\n        else:\n            raise ValueError(f\"Unknown instance match method: {self.method}\")\n\n    def find_matches(\n        self, instances1: list[Instance], instances2: list[Instance]\n    ) -&gt; list[tuple[int, int, float]]:\n        \"\"\"Find all matching instances between two lists.\n\n        Returns:\n            List of (idx1, idx2, score) tuples for matching instances.\n        \"\"\"\n        matches = []\n\n        for i, inst1 in enumerate(instances1):\n            for j, inst2 in enumerate(instances2):\n                if self.match(inst1, inst2):\n                    # Calculate match score based on method\n                    if self.method == InstanceMatchMethod.SPATIAL:\n                        # Use inverse distance as score\n                        pts1 = inst1.numpy()\n                        pts2 = inst2.numpy()\n                        valid = ~(np.isnan(pts1[:, 0]) | np.isnan(pts2[:, 0]))\n                        if valid.any():\n                            distances = np.linalg.norm(\n                                pts1[valid] - pts2[valid], axis=1\n                            )\n                            score = 1.0 / (1.0 + np.mean(distances))\n                        else:\n                            score = 0.0\n                    elif self.method == InstanceMatchMethod.IOU:\n                        # Calculate actual IoU as score\n                        bbox1 = inst1.bounding_box()\n                        bbox2 = inst2.bounding_box()\n                        if bbox1 is not None and bbox2 is not None:\n                            # Calculate IoU\n                            intersection_min = np.maximum(bbox1[0], bbox2[0])\n                            intersection_max = np.minimum(bbox1[1], bbox2[1])\n                            if np.all(intersection_min &lt; intersection_max):\n                                intersection_area = np.prod(\n                                    intersection_max - intersection_min\n                                )\n                                area1 = np.prod(bbox1[1] - bbox1[0])\n                                area2 = np.prod(bbox2[1] - bbox2[0])\n                                union_area = area1 + area2 - intersection_area\n                                score = (\n                                    intersection_area / union_area\n                                    if union_area &gt; 0\n                                    else 0\n                                )\n                            else:\n                                score = 0.0\n                        else:\n                            score = 0.0\n                    else:\n                        score = 1.0  # Binary match for identity\n\n                    matches.append((i, j, score))\n\n        return matches\n</code></pre>"},{"location":"merging/#sleap_io.model.matching.InstanceMatcher.find_matches","title":"<code>find_matches(instances1, instances2)</code>","text":"<p>Find all matching instances between two lists.</p> <p>Returns:</p> Type Description <code>list[tuple[int, int, float]]</code> <p>List of (idx1, idx2, score) tuples for matching instances.</p> Source code in <code>sleap_io/model/matching.py</code> <pre><code>def find_matches(\n    self, instances1: list[Instance], instances2: list[Instance]\n) -&gt; list[tuple[int, int, float]]:\n    \"\"\"Find all matching instances between two lists.\n\n    Returns:\n        List of (idx1, idx2, score) tuples for matching instances.\n    \"\"\"\n    matches = []\n\n    for i, inst1 in enumerate(instances1):\n        for j, inst2 in enumerate(instances2):\n            if self.match(inst1, inst2):\n                # Calculate match score based on method\n                if self.method == InstanceMatchMethod.SPATIAL:\n                    # Use inverse distance as score\n                    pts1 = inst1.numpy()\n                    pts2 = inst2.numpy()\n                    valid = ~(np.isnan(pts1[:, 0]) | np.isnan(pts2[:, 0]))\n                    if valid.any():\n                        distances = np.linalg.norm(\n                            pts1[valid] - pts2[valid], axis=1\n                        )\n                        score = 1.0 / (1.0 + np.mean(distances))\n                    else:\n                        score = 0.0\n                elif self.method == InstanceMatchMethod.IOU:\n                    # Calculate actual IoU as score\n                    bbox1 = inst1.bounding_box()\n                    bbox2 = inst2.bounding_box()\n                    if bbox1 is not None and bbox2 is not None:\n                        # Calculate IoU\n                        intersection_min = np.maximum(bbox1[0], bbox2[0])\n                        intersection_max = np.minimum(bbox1[1], bbox2[1])\n                        if np.all(intersection_min &lt; intersection_max):\n                            intersection_area = np.prod(\n                                intersection_max - intersection_min\n                            )\n                            area1 = np.prod(bbox1[1] - bbox1[0])\n                            area2 = np.prod(bbox2[1] - bbox2[0])\n                            union_area = area1 + area2 - intersection_area\n                            score = (\n                                intersection_area / union_area\n                                if union_area &gt; 0\n                                else 0\n                            )\n                        else:\n                            score = 0.0\n                    else:\n                        score = 0.0\n                else:\n                    score = 1.0  # Binary match for identity\n\n                matches.append((i, j, score))\n\n    return matches\n</code></pre>"},{"location":"merging/#sleap_io.model.matching.InstanceMatcher.match","title":"<code>match(instance1, instance2)</code>","text":"<p>Check if two instances match according to the configured method.</p> Source code in <code>sleap_io/model/matching.py</code> <pre><code>def match(self, instance1: Instance, instance2: Instance) -&gt; bool:\n    \"\"\"Check if two instances match according to the configured method.\"\"\"\n    if self.method == InstanceMatchMethod.SPATIAL:\n        return instance1.same_pose_as(instance2, tolerance=self.threshold)\n    elif self.method == InstanceMatchMethod.IDENTITY:\n        return instance1.same_identity_as(instance2)\n    elif self.method == InstanceMatchMethod.IOU:\n        return instance1.overlaps_with(instance2, iou_threshold=self.threshold)\n    else:\n        raise ValueError(f\"Unknown instance match method: {self.method}\")\n</code></pre>"},{"location":"merging/#sleap_io.model.matching.TrackMatcher","title":"<code>sleap_io.model.matching.TrackMatcher</code>","text":"<p>Matcher for comparing and matching tracks.</p> <p>Attributes:</p> Name Type Description <code>method</code> <code>Union[TrackMatchMethod, str]</code> <p>The matching method to use. Can be a TrackMatchMethod enum value or a string that will be converted to the enum. Default is NAME.</p> <p>Methods:</p> Name Description <code>match</code> <p>Check if two tracks match according to the configured method.</p> Source code in <code>sleap_io/model/matching.py</code> <pre><code>@attrs.define\nclass TrackMatcher:\n    \"\"\"Matcher for comparing and matching tracks.\n\n    Attributes:\n        method: The matching method to use. Can be a TrackMatchMethod enum value\n            or a string that will be converted to the enum. Default is NAME.\n    \"\"\"\n\n    method: Union[TrackMatchMethod, str] = attrs.field(\n        default=TrackMatchMethod.NAME,\n        converter=lambda x: TrackMatchMethod(x) if isinstance(x, str) else x,\n    )\n\n    def match(self, track1: Track, track2: Track) -&gt; bool:\n        \"\"\"Check if two tracks match according to the configured method.\"\"\"\n        return track1.matches(track2, method=self.method.value)\n</code></pre>"},{"location":"merging/#sleap_io.model.matching.TrackMatcher.match","title":"<code>match(track1, track2)</code>","text":"<p>Check if two tracks match according to the configured method.</p> Source code in <code>sleap_io/model/matching.py</code> <pre><code>def match(self, track1: Track, track2: Track) -&gt; bool:\n    \"\"\"Check if two tracks match according to the configured method.\"\"\"\n    return track1.matches(track2, method=self.method.value)\n</code></pre>"},{"location":"merging/#sleap_io.model.matching.VideoMatcher","title":"<code>sleap_io.model.matching.VideoMatcher</code>","text":"<p>Matcher for comparing and matching videos.</p> <p>Attributes:</p> Name Type Description <code>method</code> <code>Union[VideoMatchMethod, str]</code> <p>The matching method to use. Can be a VideoMatchMethod enum value or a string that will be converted to the enum. Default is AUTO.</p> <code>strict</code> <code>bool</code> <p>Whether to use strict path matching for the PATH method. When True, paths must be exactly identical. When False, paths are normalized before comparison. Only used when method is PATH. Default is False.</p> <p>Methods:</p> Name Description <code>match</code> <p>Check if two videos match according to the configured method.</p> Source code in <code>sleap_io/model/matching.py</code> <pre><code>@attrs.define\nclass VideoMatcher:\n    \"\"\"Matcher for comparing and matching videos.\n\n    Attributes:\n        method: The matching method to use. Can be a VideoMatchMethod enum value\n            or a string that will be converted to the enum. Default is AUTO.\n        strict: Whether to use strict path matching for the PATH method.\n            When True, paths must be exactly identical. When False, paths\n            are normalized before comparison. Only used when method is PATH.\n            Default is False.\n    \"\"\"\n\n    method: Union[VideoMatchMethod, str] = attrs.field(\n        default=VideoMatchMethod.AUTO,\n        converter=lambda x: VideoMatchMethod(x) if isinstance(x, str) else x,\n    )\n    strict: bool = False\n\n    def match(self, video1: Video, video2: Video) -&gt; bool:\n        \"\"\"Check if two videos match according to the configured method.\"\"\"\n        if self.method == VideoMatchMethod.AUTO:\n            # Try different methods in order (identity check is redundant)\n            if video1.matches_path(video2, strict=False):\n                return True\n            if video1.matches_content(video2):\n                return True\n            return False\n        elif self.method == VideoMatchMethod.PATH:\n            return video1.matches_path(video2, strict=self.strict)\n        elif self.method == VideoMatchMethod.BASENAME:\n            return video1.matches_path(video2, strict=False)\n        elif self.method == VideoMatchMethod.CONTENT:\n            return video1.matches_content(video2)\n        elif self.method == VideoMatchMethod.IMAGE_DEDUP:\n            # Match ImageVideo instances with overlapping images (ImageVideo only)\n            return video1.has_overlapping_images(video2)\n        elif self.method == VideoMatchMethod.SHAPE:\n            # Match videos by shape only (height, width, channels)\n            return video1.matches_shape(video2)\n        else:\n            raise ValueError(f\"Unknown video match method: {self.method}\")\n</code></pre>"},{"location":"merging/#sleap_io.model.matching.VideoMatcher.match","title":"<code>match(video1, video2)</code>","text":"<p>Check if two videos match according to the configured method.</p> Source code in <code>sleap_io/model/matching.py</code> <pre><code>def match(self, video1: Video, video2: Video) -&gt; bool:\n    \"\"\"Check if two videos match according to the configured method.\"\"\"\n    if self.method == VideoMatchMethod.AUTO:\n        # Try different methods in order (identity check is redundant)\n        if video1.matches_path(video2, strict=False):\n            return True\n        if video1.matches_content(video2):\n            return True\n        return False\n    elif self.method == VideoMatchMethod.PATH:\n        return video1.matches_path(video2, strict=self.strict)\n    elif self.method == VideoMatchMethod.BASENAME:\n        return video1.matches_path(video2, strict=False)\n    elif self.method == VideoMatchMethod.CONTENT:\n        return video1.matches_content(video2)\n    elif self.method == VideoMatchMethod.IMAGE_DEDUP:\n        # Match ImageVideo instances with overlapping images (ImageVideo only)\n        return video1.has_overlapping_images(video2)\n    elif self.method == VideoMatchMethod.SHAPE:\n        # Match videos by shape only (height, width, channels)\n        return video1.matches_shape(video2)\n    else:\n        raise ValueError(f\"Unknown video match method: {self.method}\")\n</code></pre>"},{"location":"merging/#sleap_io.model.matching.FrameMatcher","title":"<code>sleap_io.model.matching.FrameMatcher</code>","text":"<p>Matcher for comparing and matching labeled frames.</p> <p>Attributes:</p> Name Type Description <code>video_must_match</code> <code>bool</code> <p>Whether frames must belong to the same video to be considered a match. Default is True.</p> <p>Methods:</p> Name Description <code>match</code> <p>Check if two frames match.</p> Source code in <code>sleap_io/model/matching.py</code> <pre><code>@attrs.define\nclass FrameMatcher:\n    \"\"\"Matcher for comparing and matching labeled frames.\n\n    Attributes:\n        video_must_match: Whether frames must belong to the same video to be\n            considered a match. Default is True.\n    \"\"\"\n\n    video_must_match: bool = True\n\n    def match(self, frame1: LabeledFrame, frame2: LabeledFrame) -&gt; bool:\n        \"\"\"Check if two frames match.\"\"\"\n        return frame1.matches(frame2, video_must_match=self.video_must_match)\n</code></pre>"},{"location":"merging/#sleap_io.model.matching.FrameMatcher.match","title":"<code>match(frame1, frame2)</code>","text":"<p>Check if two frames match.</p> Source code in <code>sleap_io/model/matching.py</code> <pre><code>def match(self, frame1: LabeledFrame, frame2: LabeledFrame) -&gt; bool:\n    \"\"\"Check if two frames match.\"\"\"\n    return frame1.matches(frame2, video_must_match=self.video_must_match)\n</code></pre>"},{"location":"merging/#pre-configured-matchers","title":"Pre-configured matchers","text":""},{"location":"merging/#sleap_io.model.matching.STRUCTURE_SKELETON_MATCHER","title":"<code>sleap_io.model.matching.STRUCTURE_SKELETON_MATCHER = SkeletonMatcher(method=(SkeletonMatchMethod.STRUCTURE))</code>  <code>module-attribute</code>","text":""},{"location":"merging/#sleap_io.model.matching.SUBSET_SKELETON_MATCHER","title":"<code>sleap_io.model.matching.SUBSET_SKELETON_MATCHER = SkeletonMatcher(method=(SkeletonMatchMethod.SUBSET))</code>  <code>module-attribute</code>","text":""},{"location":"merging/#sleap_io.model.matching.OVERLAP_SKELETON_MATCHER","title":"<code>sleap_io.model.matching.OVERLAP_SKELETON_MATCHER = SkeletonMatcher(method=(SkeletonMatchMethod.OVERLAP), min_overlap=0.7)</code>  <code>module-attribute</code>","text":""},{"location":"merging/#sleap_io.model.matching.DUPLICATE_MATCHER","title":"<code>sleap_io.model.matching.DUPLICATE_MATCHER = InstanceMatcher(method=(InstanceMatchMethod.SPATIAL), threshold=5.0)</code>  <code>module-attribute</code>","text":""},{"location":"merging/#sleap_io.model.matching.IOU_MATCHER","title":"<code>sleap_io.model.matching.IOU_MATCHER = InstanceMatcher(method=(InstanceMatchMethod.IOU), threshold=0.5)</code>  <code>module-attribute</code>","text":""},{"location":"merging/#sleap_io.model.matching.IDENTITY_INSTANCE_MATCHER","title":"<code>sleap_io.model.matching.IDENTITY_INSTANCE_MATCHER = InstanceMatcher(method=(InstanceMatchMethod.IDENTITY))</code>  <code>module-attribute</code>","text":""},{"location":"merging/#sleap_io.model.matching.NAME_TRACK_MATCHER","title":"<code>sleap_io.model.matching.NAME_TRACK_MATCHER = TrackMatcher(method=(TrackMatchMethod.NAME))</code>  <code>module-attribute</code>","text":""},{"location":"merging/#sleap_io.model.matching.IDENTITY_TRACK_MATCHER","title":"<code>sleap_io.model.matching.IDENTITY_TRACK_MATCHER = TrackMatcher(method=(TrackMatchMethod.IDENTITY))</code>  <code>module-attribute</code>","text":""},{"location":"merging/#sleap_io.model.matching.AUTO_VIDEO_MATCHER","title":"<code>sleap_io.model.matching.AUTO_VIDEO_MATCHER = VideoMatcher(method=(VideoMatchMethod.AUTO))</code>  <code>module-attribute</code>","text":""},{"location":"merging/#sleap_io.model.matching.SOURCE_VIDEO_MATCHER","title":"<code>sleap_io.model.matching.SOURCE_VIDEO_MATCHER = VideoMatcher(method=(VideoMatchMethod.BASENAME))</code>  <code>module-attribute</code>","text":""},{"location":"merging/#sleap_io.model.matching.PATH_VIDEO_MATCHER","title":"<code>sleap_io.model.matching.PATH_VIDEO_MATCHER = VideoMatcher(method=(VideoMatchMethod.PATH), strict=True)</code>  <code>module-attribute</code>","text":""},{"location":"merging/#sleap_io.model.matching.BASENAME_VIDEO_MATCHER","title":"<code>sleap_io.model.matching.BASENAME_VIDEO_MATCHER = VideoMatcher(method=(VideoMatchMethod.BASENAME))</code>  <code>module-attribute</code>","text":""},{"location":"merging/#sleap_io.model.matching.IMAGE_DEDUP_VIDEO_MATCHER","title":"<code>sleap_io.model.matching.IMAGE_DEDUP_VIDEO_MATCHER = VideoMatcher(method=(VideoMatchMethod.IMAGE_DEDUP))</code>  <code>module-attribute</code>","text":""},{"location":"merging/#sleap_io.model.matching.SHAPE_VIDEO_MATCHER","title":"<code>sleap_io.model.matching.SHAPE_VIDEO_MATCHER = VideoMatcher(method=(VideoMatchMethod.SHAPE))</code>  <code>module-attribute</code>","text":""},{"location":"merging/#result-classes","title":"Result classes","text":""},{"location":"merging/#sleap_io.model.matching.MergeResult","title":"<code>sleap_io.model.matching.MergeResult</code>","text":"<p>Result of a merge operation.</p> <p>Attributes:</p> Name Type Description <code>successful</code> <code>bool</code> <p>Whether the merge completed successfully.</p> <code>frames_merged</code> <code>int</code> <p>Number of frames that were merged.</p> <code>instances_added</code> <code>int</code> <p>Number of new instances added.</p> <code>instances_updated</code> <code>int</code> <p>Number of existing instances that were updated.</p> <code>instances_skipped</code> <code>int</code> <p>Number of instances that were skipped.</p> <code>conflicts</code> <code>list[ConflictResolution]</code> <p>List of conflicts that were resolved during merging.</p> <code>errors</code> <code>list[MergeError]</code> <p>List of errors encountered during merging.</p> <p>Methods:</p> Name Description <code>summary</code> <p>Generate a human-readable summary of the merge result.</p> Source code in <code>sleap_io/model/matching.py</code> <pre><code>@attrs.define\nclass MergeResult:\n    \"\"\"Result of a merge operation.\n\n    Attributes:\n        successful: Whether the merge completed successfully.\n        frames_merged: Number of frames that were merged.\n        instances_added: Number of new instances added.\n        instances_updated: Number of existing instances that were updated.\n        instances_skipped: Number of instances that were skipped.\n        conflicts: List of conflicts that were resolved during merging.\n        errors: List of errors encountered during merging.\n    \"\"\"\n\n    successful: bool\n    frames_merged: int = 0\n    instances_added: int = 0\n    instances_updated: int = 0\n    instances_skipped: int = 0\n    conflicts: list[ConflictResolution] = attrs.field(factory=list)\n    errors: list[MergeError] = attrs.field(factory=list)\n\n    def summary(self) -&gt; str:\n        \"\"\"Generate a human-readable summary of the merge result.\"\"\"\n        lines = []\n\n        if self.successful:\n            lines.append(\"\u2713 Merge completed successfully\")\n        else:\n            lines.append(\"\u2717 Merge completed with errors\")\n\n        lines.append(f\"  Frames merged: {self.frames_merged}\")\n        lines.append(f\"  Instances added: {self.instances_added}\")\n\n        if self.instances_updated:\n            lines.append(f\"  Instances updated: {self.instances_updated}\")\n\n        if self.instances_skipped:\n            lines.append(f\"  Instances skipped: {self.instances_skipped}\")\n\n        if self.conflicts:\n            lines.append(f\"  Conflicts resolved: {len(self.conflicts)}\")\n\n        if self.errors:\n            lines.append(f\"  Errors encountered: {len(self.errors)}\")\n            for error in self.errors[:5]:  # Show first 5 errors\n                lines.append(f\"    - {error.message}\")\n            if len(self.errors) &gt; 5:\n                lines.append(f\"    ... and {len(self.errors) - 5} more\")\n\n        return \"\\n\".join(lines)\n</code></pre>"},{"location":"merging/#sleap_io.model.matching.MergeResult.summary","title":"<code>summary()</code>","text":"<p>Generate a human-readable summary of the merge result.</p> Source code in <code>sleap_io/model/matching.py</code> <pre><code>def summary(self) -&gt; str:\n    \"\"\"Generate a human-readable summary of the merge result.\"\"\"\n    lines = []\n\n    if self.successful:\n        lines.append(\"\u2713 Merge completed successfully\")\n    else:\n        lines.append(\"\u2717 Merge completed with errors\")\n\n    lines.append(f\"  Frames merged: {self.frames_merged}\")\n    lines.append(f\"  Instances added: {self.instances_added}\")\n\n    if self.instances_updated:\n        lines.append(f\"  Instances updated: {self.instances_updated}\")\n\n    if self.instances_skipped:\n        lines.append(f\"  Instances skipped: {self.instances_skipped}\")\n\n    if self.conflicts:\n        lines.append(f\"  Conflicts resolved: {len(self.conflicts)}\")\n\n    if self.errors:\n        lines.append(f\"  Errors encountered: {len(self.errors)}\")\n        for error in self.errors[:5]:  # Show first 5 errors\n            lines.append(f\"    - {error.message}\")\n        if len(self.errors) &gt; 5:\n            lines.append(f\"    ... and {len(self.errors) - 5} more\")\n\n    return \"\\n\".join(lines)\n</code></pre>"},{"location":"merging/#sleap_io.model.matching.ConflictResolution","title":"<code>sleap_io.model.matching.ConflictResolution</code>","text":"<p>Information about a conflict that was resolved during merging.</p> <p>Attributes:</p> Name Type Description <code>frame</code> <code>LabeledFrame</code> <p>The labeled frame where the conflict occurred.</p> <code>conflict_type</code> <code>str</code> <p>Type of conflict (e.g., \"duplicate_instance\", \"skeleton_mismatch\").</p> <code>original_data</code> <code>Any</code> <p>The original data before resolution.</p> <code>new_data</code> <code>Any</code> <p>The new/incoming data that caused the conflict.</p> <code>resolution</code> <code>str</code> <p>Description of how the conflict was resolved.</p> Source code in <code>sleap_io/model/matching.py</code> <pre><code>@attrs.define\nclass ConflictResolution:\n    \"\"\"Information about a conflict that was resolved during merging.\n\n    Attributes:\n        frame: The labeled frame where the conflict occurred.\n        conflict_type: Type of conflict (e.g., \"duplicate_instance\",\n            \"skeleton_mismatch\").\n        original_data: The original data before resolution.\n        new_data: The new/incoming data that caused the conflict.\n        resolution: Description of how the conflict was resolved.\n    \"\"\"\n\n    frame: LabeledFrame\n    conflict_type: str\n    original_data: Any\n    new_data: Any\n    resolution: str\n</code></pre>"},{"location":"merging/#sleap_io.model.matching.MergeError","title":"<code>sleap_io.model.matching.MergeError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Base exception for merge errors.</p> <p>Attributes:</p> Name Type Description <code>message</code> <code>str</code> <p>Human-readable error message.</p> <code>details</code> <code>dict</code> <p>Dictionary containing additional error details and context.</p> Source code in <code>sleap_io/model/matching.py</code> <pre><code>@attrs.define\nclass MergeError(Exception):\n    \"\"\"Base exception for merge errors.\n\n    Attributes:\n        message: Human-readable error message.\n        details: Dictionary containing additional error details and context.\n    \"\"\"\n\n    message: str\n    details: dict = attrs.field(factory=dict)\n</code></pre>"},{"location":"merging/#sleap_io.model.matching.SkeletonMismatchError","title":"<code>sleap_io.model.matching.SkeletonMismatchError</code>","text":"<p>               Bases: <code>MergeError</code></p> <p>Raised when skeletons don't match during merge.</p> Source code in <code>sleap_io/model/matching.py</code> <pre><code>class SkeletonMismatchError(MergeError):\n    \"\"\"Raised when skeletons don't match during merge.\"\"\"\n\n    pass\n</code></pre>"},{"location":"merging/#sleap_io.model.matching.VideoNotFoundError","title":"<code>sleap_io.model.matching.VideoNotFoundError</code>","text":"<p>               Bases: <code>MergeError</code></p> <p>Raised when a video file cannot be found during merge.</p> Source code in <code>sleap_io/model/matching.py</code> <pre><code>class VideoNotFoundError(MergeError):\n    \"\"\"Raised when a video file cannot be found during merge.\"\"\"\n\n    pass\n</code></pre>"},{"location":"merging/#progress-tracking","title":"Progress tracking","text":""},{"location":"merging/#sleap_io.model.matching.MergeProgressBar","title":"<code>sleap_io.model.matching.MergeProgressBar</code>","text":"<p>Context manager for merge progress tracking using tqdm.</p> <p>This provides a clean interface for tracking merge progress with visual feedback.</p> Example <p>with MergeProgressBar(\"Merging predictions\") as progress:     result = labels.merge(predictions, progress_callback=progress.callback)</p> <p>Methods:</p> Name Description <code>__enter__</code> <p>Enter the context manager.</p> <code>__exit__</code> <p>Exit the context manager and close the progress bar.</p> <code>__init__</code> <p>Initialize the progress bar.</p> <code>callback</code> <p>Progress callback for merge operations.</p> Source code in <code>sleap_io/model/matching.py</code> <pre><code>class MergeProgressBar:\n    \"\"\"Context manager for merge progress tracking using tqdm.\n\n    This provides a clean interface for tracking merge progress with visual feedback.\n\n    Example:\n        with MergeProgressBar(\"Merging predictions\") as progress:\n            result = labels.merge(predictions, progress_callback=progress.callback)\n    \"\"\"\n\n    def __init__(self, desc: str = \"Merging\", leave: bool = True):\n        \"\"\"Initialize the progress bar.\n\n        Args:\n            desc: Description to show in the progress bar.\n            leave: Whether to leave the progress bar on screen after completion.\n        \"\"\"\n        self.desc = desc\n        self.leave = leave\n        self.pbar = None\n\n    def __enter__(self):\n        \"\"\"Enter the context manager.\"\"\"\n        return self\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        \"\"\"Exit the context manager and close the progress bar.\"\"\"\n        if self.pbar is not None:\n            self.pbar.close()\n\n    def callback(self, current: int, total: int, message: str = \"\"):\n        \"\"\"Progress callback for merge operations.\n\n        Args:\n            current: Current progress value.\n            total: Total items to process.\n            message: Optional message to display.\n        \"\"\"\n        from tqdm import tqdm\n\n        if self.pbar is None and total:\n            self.pbar = tqdm(total=total, desc=self.desc, leave=self.leave)\n\n        if self.pbar:\n            if message:\n                self.pbar.set_description(f\"{self.desc}: {message}\")\n            else:\n                self.pbar.set_description(self.desc)\n            self.pbar.n = current\n            self.pbar.refresh()\n</code></pre>"},{"location":"merging/#sleap_io.model.matching.MergeProgressBar.__enter__","title":"<code>__enter__()</code>","text":"<p>Enter the context manager.</p> Source code in <code>sleap_io/model/matching.py</code> <pre><code>def __enter__(self):\n    \"\"\"Enter the context manager.\"\"\"\n    return self\n</code></pre>"},{"location":"merging/#sleap_io.model.matching.MergeProgressBar.__exit__","title":"<code>__exit__(exc_type, exc_val, exc_tb)</code>","text":"<p>Exit the context manager and close the progress bar.</p> Source code in <code>sleap_io/model/matching.py</code> <pre><code>def __exit__(self, exc_type, exc_val, exc_tb):\n    \"\"\"Exit the context manager and close the progress bar.\"\"\"\n    if self.pbar is not None:\n        self.pbar.close()\n</code></pre>"},{"location":"merging/#sleap_io.model.matching.MergeProgressBar.__init__","title":"<code>__init__(desc='Merging', leave=True)</code>","text":"<p>Initialize the progress bar.</p> <p>Parameters:</p> Name Type Description Default <code>desc</code> <code>str</code> <p>Description to show in the progress bar.</p> <code>'Merging'</code> <code>leave</code> <code>bool</code> <p>Whether to leave the progress bar on screen after completion.</p> <code>True</code> Source code in <code>sleap_io/model/matching.py</code> <pre><code>def __init__(self, desc: str = \"Merging\", leave: bool = True):\n    \"\"\"Initialize the progress bar.\n\n    Args:\n        desc: Description to show in the progress bar.\n        leave: Whether to leave the progress bar on screen after completion.\n    \"\"\"\n    self.desc = desc\n    self.leave = leave\n    self.pbar = None\n</code></pre>"},{"location":"merging/#sleap_io.model.matching.MergeProgressBar.callback","title":"<code>callback(current, total, message='')</code>","text":"<p>Progress callback for merge operations.</p> <p>Parameters:</p> Name Type Description Default <code>current</code> <code>int</code> <p>Current progress value.</p> required <code>total</code> <code>int</code> <p>Total items to process.</p> required <code>message</code> <code>str</code> <p>Optional message to display.</p> <code>''</code> Source code in <code>sleap_io/model/matching.py</code> <pre><code>def callback(self, current: int, total: int, message: str = \"\"):\n    \"\"\"Progress callback for merge operations.\n\n    Args:\n        current: Current progress value.\n        total: Total items to process.\n        message: Optional message to display.\n    \"\"\"\n    from tqdm import tqdm\n\n    if self.pbar is None and total:\n        self.pbar = tqdm(total=total, desc=self.desc, leave=self.leave)\n\n    if self.pbar:\n        if message:\n            self.pbar.set_description(f\"{self.desc}: {message}\")\n        else:\n            self.pbar.set_description(self.desc)\n        self.pbar.n = current\n        self.pbar.refresh()\n</code></pre>"},{"location":"model/","title":"Data model","text":"<p><code>sleap-io</code> implements the core data structures used in SLEAP for storing data related to multi-instance pose tracking, including for annotation, training and inference.</p>"},{"location":"model/#class-relationships","title":"Class Relationships","text":"<p>The following diagram shows the relationships between the main classes in the <code>sleap-io</code> data model:</p> <pre><code>classDiagram\n    class Labels {\n        +List~LabeledFrame~ labeled_frames\n        +List~Video~ videos\n        +List~Skeleton~ skeletons\n        +List~Track~ tracks\n    }\n\n    class LabeledFrame {\n        +Video video\n        +int frame_idx\n        +List~Instance~ instances\n    }\n\n    class Instance {\n        +Skeleton skeleton\n        +Track track\n        +PointsArray points\n    }\n\n    class PredictedInstance {\n        +float score\n        +int tracking_score\n    }\n\n    class Skeleton {\n        +List~Node~ nodes\n        +List~Edge~ edges\n        +List~Symmetry~ symmetries\n    }\n\n    class Node {\n        +str name\n    }\n\n    class Edge {\n        +Node source\n        +Node destination\n    }\n\n    class Symmetry {\n        +Set~Node~ nodes\n    }\n\n    class Track {\n        +str name\n    }\n\n    class Video {\n        +str filename\n        +VideoBackend backend\n    }\n\n    class LabelsSet {\n        +List~Labels~ labels\n    }\n\n    Labels \"1\" *-- \"0..*\" LabeledFrame : contains\n    Labels \"1\" *-- \"0..*\" Video : contains\n    Labels \"1\" *-- \"0..*\" Skeleton : contains\n    Labels \"1\" *-- \"0..*\" Track : contains\n\n    LabeledFrame \"0..*\" --&gt; \"1\" Video : references\n    LabeledFrame \"1\" *-- \"0..*\" Instance : contains\n\n    Instance \"0..*\" --&gt; \"1\" Skeleton : uses\n    Instance \"0..*\" --&gt; \"0..1\" Track : belongs to\n    Instance &lt;|-- PredictedInstance : inherits\n\n    Skeleton \"1\" *-- \"1..*\" Node : contains\n    Skeleton \"1\" *-- \"0..*\" Edge : contains\n    Skeleton \"1\" *-- \"0..*\" Symmetry : contains\n\n    Edge \"0..*\" --&gt; \"2\" Node : connects\n    Symmetry \"0..*\" --&gt; \"2\" Node : pairs\n\n    LabelsSet \"1\" *-- \"1..*\" Labels : contains</code></pre>"},{"location":"model/#sleap_io.Labels","title":"<code>sleap_io.Labels</code>","text":"<p>Pose data for a set of videos that have user labels and/or predictions.</p> <p>Attributes:</p> Name Type Description <code>labeled_frames</code> <code>list[LabeledFrame]</code> <p>A list of <code>LabeledFrame</code>s that are associated with this dataset.</p> <code>videos</code> <code>list[Video]</code> <p>A list of <code>Video</code>s that are associated with this dataset. Videos do not need to have corresponding <code>LabeledFrame</code>s if they do not have any labels or predictions yet.</p> <code>skeletons</code> <code>list[Skeleton]</code> <p>A list of <code>Skeleton</code>s that are associated with this dataset. This should generally only contain a single skeleton.</p> <code>tracks</code> <code>list[Track]</code> <p>A list of <code>Track</code>s that are associated with this dataset.</p> <code>suggestions</code> <code>list[SuggestionFrame]</code> <p>A list of <code>SuggestionFrame</code>s that are associated with this dataset.</p> <code>sessions</code> <code>list[RecordingSession]</code> <p>A list of <code>RecordingSession</code>s that are associated with this dataset.</p> <code>provenance</code> <code>dict[str, Any]</code> <p>Dictionary of arbitrary metadata providing additional information about where the dataset came from.</p> Notes <p><code>Video</code>s in contain <code>LabeledFrame</code>s, and <code>Skeleton</code>s and <code>Track</code>s in contained <code>Instance</code>s are added to the respective lists automatically.</p> <p>Methods:</p> Name Description <code>__attrs_post_init__</code> <p>Append videos, skeletons, and tracks seen in <code>labeled_frames</code> to <code>Labels</code>.</p> <code>__getitem__</code> <p>Return one or more labeled frames based on indexing criteria.</p> <code>__iter__</code> <p>Iterate over <code>labeled_frames</code> list when calling iter method on <code>Labels</code>.</p> <code>__len__</code> <p>Return number of labeled frames.</p> <code>__repr__</code> <p>Return a readable representation of the labels.</p> <code>__str__</code> <p>Return a readable representation of the labels.</p> <code>append</code> <p>Append a labeled frame to the labels.</p> <code>clean</code> <p>Remove empty frames, unused skeletons, tracks and videos.</p> <code>extend</code> <p>Append a labeled frame to the labels.</p> <code>extract</code> <p>Extract a set of frames into a new Labels object.</p> <code>find</code> <p>Search for labeled frames given video and/or frame index.</p> <code>from_numpy</code> <p>Create a new Labels object from a numpy array of tracks.</p> <code>make_training_splits</code> <p>Make splits for training with embedded images.</p> <code>merge</code> <p>Merge another Labels object into this one.</p> <code>numpy</code> <p>Construct a numpy array from instance points.</p> <code>remove_nodes</code> <p>Remove nodes from the skeleton.</p> <code>remove_predictions</code> <p>Remove all predicted instances from the labels.</p> <code>rename_nodes</code> <p>Rename nodes in the skeleton.</p> <code>reorder_nodes</code> <p>Reorder nodes in the skeleton.</p> <code>replace_filenames</code> <p>Replace video filenames.</p> <code>replace_skeleton</code> <p>Replace the skeleton in the labels.</p> <code>replace_videos</code> <p>Replace videos and update all references.</p> <code>save</code> <p>Save labels to file in specified format.</p> <code>set_video_plugin</code> <p>Reopen all media videos with the specified plugin.</p> <code>split</code> <p>Separate the labels into random splits.</p> <code>trim</code> <p>Trim the labels to a subset of frames and videos accordingly.</p> <code>update</code> <p>Update data structures based on contents.</p> <code>update_from_numpy</code> <p>Update instances from a numpy array of tracks.</p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>@define\nclass Labels:\n    \"\"\"Pose data for a set of videos that have user labels and/or predictions.\n\n    Attributes:\n        labeled_frames: A list of `LabeledFrame`s that are associated with this dataset.\n        videos: A list of `Video`s that are associated with this dataset. Videos do not\n            need to have corresponding `LabeledFrame`s if they do not have any\n            labels or predictions yet.\n        skeletons: A list of `Skeleton`s that are associated with this dataset. This\n            should generally only contain a single skeleton.\n        tracks: A list of `Track`s that are associated with this dataset.\n        suggestions: A list of `SuggestionFrame`s that are associated with this dataset.\n        sessions: A list of `RecordingSession`s that are associated with this dataset.\n        provenance: Dictionary of arbitrary metadata providing additional information\n            about where the dataset came from.\n\n    Notes:\n        `Video`s in contain `LabeledFrame`s, and `Skeleton`s and `Track`s in contained\n        `Instance`s are added to the respective lists automatically.\n    \"\"\"\n\n    labeled_frames: list[LabeledFrame] = field(factory=list)\n    videos: list[Video] = field(factory=list)\n    skeletons: list[Skeleton] = field(factory=list)\n    tracks: list[Track] = field(factory=list)\n    suggestions: list[SuggestionFrame] = field(factory=list)\n    sessions: list[RecordingSession] = field(factory=list)\n    provenance: dict[str, Any] = field(factory=dict)\n\n    def __attrs_post_init__(self):\n        \"\"\"Append videos, skeletons, and tracks seen in `labeled_frames` to `Labels`.\"\"\"\n        self.update()\n\n    def update(self):\n        \"\"\"Update data structures based on contents.\n\n        This function will update the list of skeletons, videos and tracks from the\n        labeled frames, instances and suggestions.\n        \"\"\"\n        for lf in self.labeled_frames:\n            if lf.video not in self.videos:\n                self.videos.append(lf.video)\n\n            for inst in lf:\n                if inst.skeleton not in self.skeletons:\n                    self.skeletons.append(inst.skeleton)\n\n                if inst.track is not None and inst.track not in self.tracks:\n                    self.tracks.append(inst.track)\n\n        for sf in self.suggestions:\n            if sf.video not in self.videos:\n                self.videos.append(sf.video)\n\n    def __getitem__(\n        self, key: int | slice | list[int] | np.ndarray | tuple[Video, int]\n    ) -&gt; list[LabeledFrame] | LabeledFrame:\n        \"\"\"Return one or more labeled frames based on indexing criteria.\"\"\"\n        if type(key) is int:\n            return self.labeled_frames[key]\n        elif type(key) is slice:\n            return [self.labeled_frames[i] for i in range(*key.indices(len(self)))]\n        elif type(key) is list:\n            return [self.labeled_frames[i] for i in key]\n        elif isinstance(key, np.ndarray):\n            return [self.labeled_frames[i] for i in key.tolist()]\n        elif type(key) is tuple and len(key) == 2:\n            video, frame_idx = key\n            res = self.find(video, frame_idx)\n            if len(res) == 1:\n                return res[0]\n            elif len(res) == 0:\n                raise IndexError(\n                    f\"No labeled frames found for video {video} and \"\n                    f\"frame index {frame_idx}.\"\n                )\n        elif type(key) is Video:\n            res = self.find(key)\n            if len(res) == 0:\n                raise IndexError(f\"No labeled frames found for video {key}.\")\n            return res\n        else:\n            raise IndexError(f\"Invalid indexing argument for labels: {key}\")\n\n    def __iter__(self):\n        \"\"\"Iterate over `labeled_frames` list when calling iter method on `Labels`.\"\"\"\n        return iter(self.labeled_frames)\n\n    def __len__(self) -&gt; int:\n        \"\"\"Return number of labeled frames.\"\"\"\n        return len(self.labeled_frames)\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return a readable representation of the labels.\"\"\"\n        return (\n            \"Labels(\"\n            f\"labeled_frames={len(self.labeled_frames)}, \"\n            f\"videos={len(self.videos)}, \"\n            f\"skeletons={len(self.skeletons)}, \"\n            f\"tracks={len(self.tracks)}, \"\n            f\"suggestions={len(self.suggestions)}, \"\n            f\"sessions={len(self.sessions)}\"\n            \")\"\n        )\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return a readable representation of the labels.\"\"\"\n        return self.__repr__()\n\n    def append(self, lf: LabeledFrame, update: bool = True):\n        \"\"\"Append a labeled frame to the labels.\n\n        Args:\n            lf: A labeled frame to add to the labels.\n            update: If `True` (the default), update list of videos, tracks and\n                skeletons from the contents.\n        \"\"\"\n        self.labeled_frames.append(lf)\n\n        if update:\n            if lf.video not in self.videos:\n                self.videos.append(lf.video)\n\n            for inst in lf:\n                if inst.skeleton not in self.skeletons:\n                    self.skeletons.append(inst.skeleton)\n\n                if inst.track is not None and inst.track not in self.tracks:\n                    self.tracks.append(inst.track)\n\n    def extend(self, lfs: list[LabeledFrame], update: bool = True):\n        \"\"\"Append a labeled frame to the labels.\n\n        Args:\n            lfs: A list of labeled frames to add to the labels.\n            update: If `True` (the default), update list of videos, tracks and\n                skeletons from the contents.\n        \"\"\"\n        self.labeled_frames.extend(lfs)\n\n        if update:\n            for lf in lfs:\n                if lf.video not in self.videos:\n                    self.videos.append(lf.video)\n\n                for inst in lf:\n                    if inst.skeleton not in self.skeletons:\n                        self.skeletons.append(inst.skeleton)\n\n                    if inst.track is not None and inst.track not in self.tracks:\n                        self.tracks.append(inst.track)\n\n    def numpy(\n        self,\n        video: Optional[Union[Video, int]] = None,\n        untracked: bool = False,\n        return_confidence: bool = False,\n        user_instances: bool = True,\n    ) -&gt; np.ndarray:\n        \"\"\"Construct a numpy array from instance points.\n\n        Args:\n            video: Video or video index to convert to numpy arrays. If `None` (the\n                default), uses the first video.\n            untracked: If `False` (the default), include only instances that have a\n                track assignment. If `True`, includes all instances in each frame in\n                arbitrary order.\n            return_confidence: If `False` (the default), only return points of nodes. If\n                `True`, return the points and scores of nodes.\n            user_instances: If `True` (the default), include user instances when\n                available, preferring them over predicted instances with the same track.\n                If `False`,\n                only include predicted instances.\n\n        Returns:\n            An array of tracks of shape `(n_frames, n_tracks, n_nodes, 2)` if\n            `return_confidence` is `False`. Otherwise returned shape is\n            `(n_frames, n_tracks, n_nodes, 3)` if `return_confidence` is `True`.\n\n            Missing data will be replaced with `np.nan`.\n\n            If this is a single instance project, a track does not need to be assigned.\n\n            When `user_instances=False`, only predicted instances will be returned.\n            When `user_instances=True`, user instances will be preferred over predicted\n            instances with the same track or if linked via `from_predicted`.\n\n        Notes:\n            This method assumes that instances have tracks assigned and is intended to\n            function primarily for single-video prediction results.\n        \"\"\"\n        # Get labeled frames for specified video.\n        if video is None:\n            video = 0\n        if type(video) is int:\n            video = self.videos[video]\n        lfs = [lf for lf in self.labeled_frames if lf.video == video]\n\n        # Figure out frame index range.\n        first_frame, last_frame = 0, 0\n        for lf in lfs:\n            first_frame = min(first_frame, lf.frame_idx)\n            last_frame = max(last_frame, lf.frame_idx)\n\n        # Figure out the number of tracks based on number of instances in each frame.\n        # Check the max number of instances (predicted or user, depending on settings)\n        n_instances = 0\n        for lf in lfs:\n            if user_instances:\n                # Count max of either user or predicted instances per frame (not sum)\n                n_frame_instances = max(\n                    len(lf.user_instances), len(lf.predicted_instances)\n                )\n            else:\n                n_frame_instances = len(lf.predicted_instances)\n            n_instances = max(n_instances, n_frame_instances)\n\n        # Case 1: We don't care about order because there's only 1 instance per frame,\n        # or we're considering untracked instances.\n        is_single_instance = n_instances == 1\n        untracked = untracked or is_single_instance\n        if untracked:\n            n_tracks = n_instances\n        else:\n            # Case 2: We're considering only tracked instances.\n            n_tracks = len(self.tracks)\n\n        n_frames = int(last_frame - first_frame + 1)\n        skeleton = self.skeletons[-1]  # Assume project only uses last skeleton\n        n_nodes = len(skeleton.nodes)\n\n        if return_confidence:\n            tracks = np.full((n_frames, n_tracks, n_nodes, 3), np.nan, dtype=\"float32\")\n        else:\n            tracks = np.full((n_frames, n_tracks, n_nodes, 2), np.nan, dtype=\"float32\")\n\n        for lf in lfs:\n            i = int(lf.frame_idx - first_frame)\n\n            if untracked:\n                # For untracked instances, fill them in arbitrary order\n                j = 0\n                instances_to_include = []\n\n                # If user instances are preferred, add them first\n                if user_instances and lf.has_user_instances:\n                    # First collect all user instances\n                    for inst in lf.user_instances:\n                        instances_to_include.append(inst)\n\n                    # For the trivial case (single instance per frame), if we found\n                    # user instances, we shouldn't include any predicted instances\n                    if is_single_instance and len(instances_to_include) &gt; 0:\n                        pass  # Skip adding predicted instances\n                    else:\n                        # Add predicted instances that don't have a corresponding\n                        # user instance\n                        for inst in lf.predicted_instances:\n                            skip = False\n                            for user_inst in lf.user_instances:\n                                # Skip if this predicted instance is linked to a user\n                                # instance via from_predicted\n                                if (\n                                    hasattr(user_inst, \"from_predicted\")\n                                    and user_inst.from_predicted == inst\n                                ):\n                                    skip = True\n                                    break\n                                # Skip if user and predicted instances share same track\n                                if (\n                                    user_inst.track is not None\n                                    and inst.track is not None\n                                    and user_inst.track == inst.track\n                                ):\n                                    skip = True\n                                    break\n                            if not skip:\n                                instances_to_include.append(inst)\n                else:\n                    # If user_instances=False, only include predicted instances\n                    instances_to_include = lf.predicted_instances\n\n                # Now process all the instances we want to include\n                for inst in instances_to_include:\n                    if j &lt; n_tracks:\n                        if return_confidence:\n                            if isinstance(inst, PredictedInstance):\n                                tracks[i, j] = inst.numpy(scores=True)\n                            else:\n                                # For user instances, set confidence to 1.0\n                                points_data = inst.numpy()\n                                confidence = np.ones(\n                                    (points_data.shape[0], 1), dtype=\"float32\"\n                                )\n                                tracks[i, j] = np.hstack((points_data, confidence))\n                        else:\n                            tracks[i, j] = inst.numpy()\n                        j += 1\n            else:  # untracked is False\n                # For tracked instances, organize by track ID\n\n                # Create mapping from track to best instance for this frame\n                track_to_instance = {}\n\n                # First, add predicted instances to the mapping\n                for inst in lf.predicted_instances:\n                    if inst.track is not None:\n                        track_to_instance[inst.track] = inst\n\n                # Then, add user instances to the mapping (if user_instances=True)\n                if user_instances:\n                    for inst in lf.user_instances:\n                        if inst.track is not None:\n                            track_to_instance[inst.track] = inst\n\n                # Process the preferred instances for each track\n                for track in track_to_instance:\n                    inst = track_to_instance[track]\n                    j = self.tracks.index(track)\n\n                    if type(inst) is PredictedInstance:\n                        tracks[i, j] = inst.numpy(scores=return_confidence)\n                    elif type(inst) is Instance:\n                        tracks[i, j, :, :2] = inst.numpy()\n\n                        # If return_confidence is True, add dummy confidence scores\n                        if return_confidence:\n                            tracks[i, j, :, 2] = 1.0\n\n        return tracks\n\n    @classmethod\n    def from_numpy(\n        cls,\n        tracks_arr: np.ndarray,\n        videos: list[Video],\n        skeletons: list[Skeleton] | Skeleton | None = None,\n        tracks: list[Track] | None = None,\n        first_frame: int = 0,\n        return_confidence: bool = False,\n    ) -&gt; \"Labels\":\n        \"\"\"Create a new Labels object from a numpy array of tracks.\n\n        This factory method creates a new Labels object with instances constructed from\n        the provided numpy array. It is the inverse operation of `Labels.numpy()`.\n\n        Args:\n            tracks_arr: A numpy array of tracks, with shape\n                `(n_frames, n_tracks, n_nodes, 2)` or\n                `(n_frames, n_tracks, n_nodes, 3)`,\n                where the last dimension contains the x,y coordinates (and optionally\n                confidence scores).\n            videos: List of Video objects to associate with the labels. At least one\n                video\n                is required.\n            skeletons: Skeleton or list of Skeleton objects to use for the instances.\n                At least one skeleton is required.\n            tracks: List of Track objects corresponding to the second dimension of the\n                array. If not specified, new tracks will be created automatically.\n            first_frame: Frame index to start the labeled frames from. Default is 0.\n            return_confidence: Whether the tracks_arr contains confidence scores in the\n                last dimension. If True, tracks_arr.shape[-1] should be 3.\n\n        Returns:\n            A new Labels object with instances constructed from the numpy array.\n\n        Raises:\n            ValueError: If the array dimensions are invalid, or if no videos or\n                skeletons are provided.\n\n        Examples:\n            &gt;&gt;&gt; import numpy as np\n            &gt;&gt;&gt; from sleap_io import Labels, Video, Skeleton\n            &gt;&gt;&gt; # Create a simple tracking array for 2 frames, 1 track, 2 nodes\n            &gt;&gt;&gt; arr = np.zeros((2, 1, 2, 2))\n            &gt;&gt;&gt; arr[0, 0] = [[10, 20], [30, 40]]  # Frame 0\n            &gt;&gt;&gt; arr[1, 0] = [[15, 25], [35, 45]]  # Frame 1\n            &gt;&gt;&gt; # Create a video and skeleton\n            &gt;&gt;&gt; video = Video(filename=\"example.mp4\")\n            &gt;&gt;&gt; skeleton = Skeleton([\"head\", \"tail\"])\n            &gt;&gt;&gt; # Create labels from the array\n            &gt;&gt;&gt; labels = Labels.from_numpy(arr, videos=[video], skeletons=[skeleton])\n        \"\"\"\n        # Check dimensions\n        if len(tracks_arr.shape) != 4:\n            raise ValueError(\n                f\"Array must have 4 dimensions (n_frames, n_tracks, n_nodes, 2 or 3), \"\n                f\"but got {tracks_arr.shape}\"\n            )\n\n        # Validate videos\n        if not videos:\n            raise ValueError(\"At least one video must be provided\")\n        video = videos[0]  # Use the first video for creating labeled frames\n\n        # Process skeletons input\n        if skeletons is None:\n            raise ValueError(\"At least one skeleton must be provided\")\n        elif isinstance(skeletons, Skeleton):\n            skeletons = [skeletons]\n        elif not skeletons:  # Check for empty list\n            raise ValueError(\"At least one skeleton must be provided\")\n\n        skeleton = skeletons[0]  # Use the first skeleton for creating instances\n        n_nodes = len(skeleton.nodes)\n\n        # Check if tracks_arr contains confidence scores\n        has_confidence = tracks_arr.shape[-1] == 3 or return_confidence\n\n        # Get dimensions\n        n_frames, n_tracks_arr, _ = tracks_arr.shape[:3]\n\n        # Create or validate tracks\n        if tracks is None:\n            # Auto-create tracks if not provided\n            tracks = [Track(f\"track_{i}\") for i in range(n_tracks_arr)]\n        elif len(tracks) &lt; n_tracks_arr:\n            # Add missing tracks if needed\n            original_len = len(tracks)\n            for i in range(n_tracks_arr - original_len):\n                tracks.append(Track(f\"track_{i}\"))\n\n        # Create a new empty Labels object\n        labels = cls()\n        labels.videos = list(videos)\n        labels.skeletons = list(skeletons)\n        labels.tracks = list(tracks)\n\n        # Create labeled frames and instances from the array data\n        for i in range(n_frames):\n            frame_idx = i + first_frame\n\n            # Check if this frame has any valid data across all tracks\n            frame_has_valid_data = False\n            for j in range(n_tracks_arr):\n                track_data = tracks_arr[i, j]\n                # Check if at least one node in this track has valid xy coordinates\n                if np.any(~np.isnan(track_data[:, 0])):\n                    frame_has_valid_data = True\n                    break\n\n            # Skip creating a frame if there's no valid data\n            if not frame_has_valid_data:\n                continue\n\n            # Create a new labeled frame\n            labeled_frame = LabeledFrame(video=video, frame_idx=frame_idx)\n            frame_has_valid_instances = False\n\n            # Process each track in this frame\n            for j in range(n_tracks_arr):\n                track = tracks[j]\n                track_data = tracks_arr[i, j]\n\n                # Check if there's any valid data for this track at this frame\n                valid_points = ~np.isnan(track_data[:, 0])\n                if not np.any(valid_points):\n                    continue\n\n                # Create points from numpy data\n                points = track_data[:, :2].copy()\n\n                # Create new instance\n                if has_confidence:\n                    # Get confidence scores\n                    if tracks_arr.shape[-1] == 3:\n                        scores = track_data[:, 2].copy()\n                    else:\n                        scores = np.ones(n_nodes)\n\n                    # Fix NaN scores\n                    scores = np.where(np.isnan(scores), 1.0, scores)\n\n                    # Create instance with confidence scores\n                    new_instance = PredictedInstance.from_numpy(\n                        points_data=points,\n                        skeleton=skeleton,\n                        point_scores=scores,\n                        score=1.0,\n                        track=track,\n                    )\n                else:\n                    # Create instance with default scores\n                    new_instance = PredictedInstance.from_numpy(\n                        points_data=points,\n                        skeleton=skeleton,\n                        point_scores=np.ones(n_nodes),\n                        score=1.0,\n                        track=track,\n                    )\n\n                # Add to frame\n                labeled_frame.instances.append(new_instance)\n                frame_has_valid_instances = True\n\n            # Only add frames that have instances\n            if frame_has_valid_instances:\n                labels.append(labeled_frame, update=False)\n\n        # Update internal references\n        labels.update()\n\n        return labels\n\n    @property\n    def video(self) -&gt; Video:\n        \"\"\"Return the video if there is only a single video in the labels.\"\"\"\n        if len(self.videos) == 0:\n            raise ValueError(\"There are no videos in the labels.\")\n        elif len(self.videos) == 1:\n            return self.videos[0]\n        else:\n            raise ValueError(\n                \"Labels.video can only be used when there is only a single video saved \"\n                \"in the labels. Use Labels.videos instead.\"\n            )\n\n    @property\n    def skeleton(self) -&gt; Skeleton:\n        \"\"\"Return the skeleton if there is only a single skeleton in the labels.\"\"\"\n        if len(self.skeletons) == 0:\n            raise ValueError(\"There are no skeletons in the labels.\")\n        elif len(self.skeletons) == 1:\n            return self.skeletons[0]\n        else:\n            raise ValueError(\n                \"Labels.skeleton can only be used when there is only a single skeleton \"\n                \"saved in the labels. Use Labels.skeletons instead.\"\n            )\n\n    def find(\n        self,\n        video: Video,\n        frame_idx: int | list[int] | None = None,\n        return_new: bool = False,\n    ) -&gt; list[LabeledFrame]:\n        \"\"\"Search for labeled frames given video and/or frame index.\n\n        Args:\n            video: A `Video` that is associated with the project.\n            frame_idx: The frame index (or indices) which we want to find in the video.\n                If a range is specified, we'll return all frames with indices in that\n                range. If not specific, then we'll return all labeled frames for video.\n            return_new: Whether to return singleton of new and empty `LabeledFrame` if\n                none are found in project.\n\n        Returns:\n            List of `LabeledFrame` objects that match the criteria.\n\n            The list will be empty if no matches found, unless return_new is True, in\n            which case it contains new (empty) `LabeledFrame` objects with `video` and\n            `frame_index` set.\n        \"\"\"\n        results = []\n\n        if frame_idx is None:\n            for lf in self.labeled_frames:\n                if lf.video == video:\n                    results.append(lf)\n            return results\n\n        if np.isscalar(frame_idx):\n            frame_idx = np.array(frame_idx).reshape(-1)\n\n        for frame_ind in frame_idx:\n            result = None\n            for lf in self.labeled_frames:\n                if lf.video == video and lf.frame_idx == frame_ind:\n                    result = lf\n                    results.append(result)\n                    break\n            if result is None and return_new:\n                results.append(LabeledFrame(video=video, frame_idx=frame_ind))\n\n        return results\n\n    def save(\n        self,\n        filename: str,\n        format: Optional[str] = None,\n        embed: bool | str | list[tuple[Video, int]] | None = False,\n        restore_original_videos: bool = True,\n        verbose: bool = True,\n        **kwargs,\n    ):\n        \"\"\"Save labels to file in specified format.\n\n        Args:\n            filename: Path to save labels to.\n            format: The format to save the labels in. If `None`, the format will be\n                inferred from the file extension. Available formats are `\"slp\"`,\n                `\"nwb\"`, `\"labelstudio\"`, and `\"jabs\"`.\n            embed: Frames to embed in the saved labels file. One of `None`, `True`,\n                `\"all\"`, `\"user\"`, `\"suggestions\"`, `\"user+suggestions\"`, `\"source\"` or\n                list of tuples of `(video, frame_idx)`.\n\n                If `False` is specified (the default), the source video will be\n                restored if available, otherwise the embedded frames will be re-saved.\n\n                If `True` or `\"all\"`, all labeled frames and suggested frames will be\n                embedded.\n\n                If `\"source\"` is specified, no images will be embedded and the source\n                video will be restored if available.\n\n                This argument is only valid for the SLP backend.\n            restore_original_videos: If `True` (default) and `embed=False`, use original\n                video files. If `False` and `embed=False`, keep references to source\n                `.pkg.slp` files. Only applies when `embed=False`.\n            verbose: If `True` (the default), display a progress bar when embedding\n                frames.\n            **kwargs: Additional format-specific arguments passed to the save function.\n                See `save_file` for format-specific options.\n        \"\"\"\n        from pathlib import Path\n\n        from sleap_io import save_file\n        from sleap_io.io.slp import sanitize_filename\n\n        # Check for self-referential save when embed=False\n        if embed is False and (format == \"slp\" or str(filename).endswith(\".slp\")):\n            # Check if any videos have embedded images and would be self-referential\n            sanitized_save_path = Path(sanitize_filename(filename)).resolve()\n            for video in self.videos:\n                if (\n                    hasattr(video.backend, \"has_embedded_images\")\n                    and video.backend.has_embedded_images\n                    and video.source_video is None\n                ):\n                    sanitized_video_path = Path(\n                        sanitize_filename(video.filename)\n                    ).resolve()\n                    if sanitized_video_path == sanitized_save_path:\n                        raise ValueError(\n                            f\"Cannot save with embed=False when overwriting a file \"\n                            f\"that contains embedded videos. Use \"\n                            f\"labels.save('{filename}', embed=True) to re-embed the \"\n                            f\"frames, or save to a different filename.\"\n                        )\n\n        save_file(\n            self,\n            filename,\n            format=format,\n            embed=embed,\n            restore_original_videos=restore_original_videos,\n            verbose=verbose,\n            **kwargs,\n        )\n\n    def clean(\n        self,\n        frames: bool = True,\n        empty_instances: bool = False,\n        skeletons: bool = True,\n        tracks: bool = True,\n        videos: bool = False,\n    ):\n        \"\"\"Remove empty frames, unused skeletons, tracks and videos.\n\n        Args:\n            frames: If `True` (the default), remove empty frames.\n            empty_instances: If `True` (NOT default), remove instances that have no\n                visible points.\n            skeletons: If `True` (the default), remove unused skeletons.\n            tracks: If `True` (the default), remove unused tracks.\n            videos: If `True` (NOT default), remove videos that have no labeled frames.\n        \"\"\"\n        used_skeletons = []\n        used_tracks = []\n        used_videos = []\n        kept_frames = []\n        for lf in self.labeled_frames:\n            if empty_instances:\n                lf.remove_empty_instances()\n\n            if frames and len(lf) == 0:\n                continue\n\n            if videos and lf.video not in used_videos:\n                used_videos.append(lf.video)\n\n            if skeletons or tracks:\n                for inst in lf:\n                    if skeletons and inst.skeleton not in used_skeletons:\n                        used_skeletons.append(inst.skeleton)\n                    if (\n                        tracks\n                        and inst.track is not None\n                        and inst.track not in used_tracks\n                    ):\n                        used_tracks.append(inst.track)\n\n            if frames:\n                kept_frames.append(lf)\n\n        if videos:\n            self.videos = [video for video in self.videos if video in used_videos]\n\n        if skeletons:\n            self.skeletons = [\n                skeleton for skeleton in self.skeletons if skeleton in used_skeletons\n            ]\n\n        if tracks:\n            self.tracks = [track for track in self.tracks if track in used_tracks]\n\n        if frames:\n            self.labeled_frames = kept_frames\n\n    def remove_predictions(self, clean: bool = True):\n        \"\"\"Remove all predicted instances from the labels.\n\n        Args:\n            clean: If `True` (the default), also remove any empty frames and unused\n                tracks and skeletons. It does NOT remove videos that have no labeled\n                frames or instances with no visible points.\n\n        See also: `Labels.clean`\n        \"\"\"\n        for lf in self.labeled_frames:\n            lf.remove_predictions()\n\n        if clean:\n            self.clean(\n                frames=True,\n                empty_instances=False,\n                skeletons=True,\n                tracks=True,\n                videos=False,\n            )\n\n    @property\n    def user_labeled_frames(self) -&gt; list[LabeledFrame]:\n        \"\"\"Return all labeled frames with user (non-predicted) instances.\"\"\"\n        return [lf for lf in self.labeled_frames if lf.has_user_instances]\n\n    @property\n    def instances(self) -&gt; Iterator[Instance]:\n        \"\"\"Return an iterator over all instances within all labeled frames.\"\"\"\n        return (instance for lf in self.labeled_frames for instance in lf.instances)\n\n    def rename_nodes(\n        self,\n        name_map: dict[NodeOrIndex, str] | list[str],\n        skeleton: Skeleton | None = None,\n    ):\n        \"\"\"Rename nodes in the skeleton.\n\n        Args:\n            name_map: A dictionary mapping old node names to new node names. Keys can be\n                specified as `Node` objects, integer indices, or string names. Values\n                must be specified as string names.\n\n                If a list of strings is provided of the same length as the current\n                nodes, the nodes will be renamed to the names in the list in order.\n            skeleton: `Skeleton` to update. If `None` (the default), assumes there is\n                only one skeleton in the labels and raises `ValueError` otherwise.\n\n        Raises:\n            ValueError: If the new node names exist in the skeleton, if the old node\n                names are not found in the skeleton, or if there is more than one\n                skeleton in the `Labels` but it is not specified.\n\n        Notes:\n            This method is recommended over `Skeleton.rename_nodes` as it will update\n            all instances in the labels to reflect the new node names.\n\n        Example:\n            &gt;&gt;&gt; labels = Labels(skeletons=[Skeleton([\"A\", \"B\", \"C\"])])\n            &gt;&gt;&gt; labels.rename_nodes({\"A\": \"X\", \"B\": \"Y\", \"C\": \"Z\"})\n            &gt;&gt;&gt; labels.skeleton.node_names\n            [\"X\", \"Y\", \"Z\"]\n            &gt;&gt;&gt; labels.rename_nodes([\"a\", \"b\", \"c\"])\n            &gt;&gt;&gt; labels.skeleton.node_names\n            [\"a\", \"b\", \"c\"]\n        \"\"\"\n        if skeleton is None:\n            if len(self.skeletons) != 1:\n                raise ValueError(\n                    \"Skeleton must be specified when there is more than one skeleton \"\n                    \"in the labels.\"\n                )\n            skeleton = self.skeleton\n\n        skeleton.rename_nodes(name_map)\n\n        # Update instances.\n        for inst in self.instances:\n            if inst.skeleton == skeleton:\n                inst.points[\"name\"] = inst.skeleton.node_names\n\n    def remove_nodes(self, nodes: list[NodeOrIndex], skeleton: Skeleton | None = None):\n        \"\"\"Remove nodes from the skeleton.\n\n        Args:\n            nodes: A list of node names, indices, or `Node` objects to remove.\n            skeleton: `Skeleton` to update. If `None` (the default), assumes there is\n                only one skeleton in the labels and raises `ValueError` otherwise.\n\n        Raises:\n            ValueError: If the nodes are not found in the skeleton, or if there is more\n                than one skeleton in the labels and it is not specified.\n\n        Notes:\n            This method should always be used when removing nodes from the skeleton as\n            it handles updating the lookup caches necessary for indexing nodes by name,\n            and updating instances to reflect the changes made to the skeleton.\n\n            Any edges and symmetries that are connected to the removed nodes will also\n            be removed.\n        \"\"\"\n        if skeleton is None:\n            if len(self.skeletons) != 1:\n                raise ValueError(\n                    \"Skeleton must be specified when there is more than one skeleton \"\n                    \"in the labels.\"\n                )\n            skeleton = self.skeleton\n\n        skeleton.remove_nodes(nodes)\n\n        for inst in self.instances:\n            if inst.skeleton == skeleton:\n                inst.update_skeleton()\n\n    def reorder_nodes(\n        self, new_order: list[NodeOrIndex], skeleton: Skeleton | None = None\n    ):\n        \"\"\"Reorder nodes in the skeleton.\n\n        Args:\n            new_order: A list of node names, indices, or `Node` objects specifying the\n                new order of the nodes.\n            skeleton: `Skeleton` to update. If `None` (the default), assumes there is\n                only one skeleton in the labels and raises `ValueError` otherwise.\n\n        Raises:\n            ValueError: If the new order of nodes is not the same length as the current\n                nodes, or if there is more than one skeleton in the `Labels` but it is\n                not specified.\n\n        Notes:\n            This method handles updating the lookup caches necessary for indexing nodes\n            by name, as well as updating instances to reflect the changes made to the\n            skeleton.\n        \"\"\"\n        if skeleton is None:\n            if len(self.skeletons) != 1:\n                raise ValueError(\n                    \"Skeleton must be specified when there is more than one skeleton \"\n                    \"in the labels.\"\n                )\n            skeleton = self.skeleton\n\n        skeleton.reorder_nodes(new_order)\n\n        for inst in self.instances:\n            if inst.skeleton == skeleton:\n                inst.update_skeleton()\n\n    def replace_skeleton(\n        self,\n        new_skeleton: Skeleton,\n        old_skeleton: Skeleton | None = None,\n        node_map: dict[NodeOrIndex, NodeOrIndex] | None = None,\n    ):\n        \"\"\"Replace the skeleton in the labels.\n\n        Args:\n            new_skeleton: The new `Skeleton` to replace the old skeleton with.\n            old_skeleton: The old `Skeleton` to replace. If `None` (the default),\n                assumes there is only one skeleton in the labels and raises `ValueError`\n                otherwise.\n            node_map: Dictionary mapping nodes in the old skeleton to nodes in the new\n                skeleton. Keys and values can be specified as `Node` objects, integer\n                indices, or string names. If not provided, only nodes with identical\n                names will be mapped. Points associated with unmapped nodes will be\n                removed.\n\n        Raises:\n            ValueError: If there is more than one skeleton in the `Labels` but it is not\n                specified.\n\n        Warning:\n            This method will replace the skeleton in all instances in the labels that\n            have the old skeleton. **All point data associated with nodes not in the\n            `node_map` will be lost.**\n        \"\"\"\n        if old_skeleton is None:\n            if len(self.skeletons) != 1:\n                raise ValueError(\n                    \"Old skeleton must be specified when there is more than one \"\n                    \"skeleton in the labels.\"\n                )\n            old_skeleton = self.skeleton\n\n        if node_map is None:\n            node_map = {}\n            for old_node in old_skeleton.nodes:\n                for new_node in new_skeleton.nodes:\n                    if old_node.name == new_node.name:\n                        node_map[old_node] = new_node\n                        break\n        else:\n            node_map = {\n                old_skeleton.require_node(\n                    old, add_missing=False\n                ): new_skeleton.require_node(new, add_missing=False)\n                for old, new in node_map.items()\n            }\n\n        # Create node name map.\n        node_names_map = {old.name: new.name for old, new in node_map.items()}\n\n        # Replace the skeleton in the instances.\n        for inst in self.instances:\n            if inst.skeleton == old_skeleton:\n                inst.replace_skeleton(\n                    new_skeleton=new_skeleton, node_names_map=node_names_map\n                )\n\n        # Replace the skeleton in the labels.\n        self.skeletons[self.skeletons.index(old_skeleton)] = new_skeleton\n\n    def replace_videos(\n        self,\n        old_videos: list[Video] | None = None,\n        new_videos: list[Video] | None = None,\n        video_map: dict[Video, Video] | None = None,\n    ):\n        \"\"\"Replace videos and update all references.\n\n        Args:\n            old_videos: List of videos to be replaced.\n            new_videos: List of videos to replace with.\n            video_map: Alternative input of dictionary where keys are the old videos and\n                values are the new videos.\n        \"\"\"\n        if (\n            old_videos is None\n            and new_videos is not None\n            and len(new_videos) == len(self.videos)\n        ):\n            old_videos = self.videos\n\n        if video_map is None:\n            video_map = {o: n for o, n in zip(old_videos, new_videos)}\n\n        # Update the labeled frames with the new videos.\n        for lf in self.labeled_frames:\n            if lf.video in video_map:\n                lf.video = video_map[lf.video]\n\n        # Update suggestions with the new videos.\n        for sf in self.suggestions:\n            if sf.video in video_map:\n                sf.video = video_map[sf.video]\n\n        # Update the list of videos.\n        self.videos = [video_map.get(video, video) for video in self.videos]\n\n    def replace_filenames(\n        self,\n        new_filenames: list[str | Path] | None = None,\n        filename_map: dict[str | Path, str | Path] | None = None,\n        prefix_map: dict[str | Path, str | Path] | None = None,\n        open_videos: bool = True,\n    ):\n        \"\"\"Replace video filenames.\n\n        Args:\n            new_filenames: List of new filenames. Must have the same length as the\n                number of videos in the labels.\n            filename_map: Dictionary mapping old filenames (keys) to new filenames\n                (values).\n            prefix_map: Dictionary mapping old prefixes (keys) to new prefixes (values).\n            open_videos: If `True` (the default), attempt to open the video backend for\n                I/O after replacing the filename. If `False`, the backend will not be\n                opened (useful for operations with costly file existence checks).\n\n        Notes:\n            Only one of the argument types can be provided.\n        \"\"\"\n        n = 0\n        if new_filenames is not None:\n            n += 1\n        if filename_map is not None:\n            n += 1\n        if prefix_map is not None:\n            n += 1\n        if n != 1:\n            raise ValueError(\n                \"Exactly one input method must be provided to replace filenames.\"\n            )\n\n        if new_filenames is not None:\n            if len(self.videos) != len(new_filenames):\n                raise ValueError(\n                    f\"Number of new filenames ({len(new_filenames)}) does not match \"\n                    f\"the number of videos ({len(self.videos)}).\"\n                )\n\n            for video, new_filename in zip(self.videos, new_filenames):\n                video.replace_filename(new_filename, open=open_videos)\n\n        elif filename_map is not None:\n            for video in self.videos:\n                for old_fn, new_fn in filename_map.items():\n                    if type(video.filename) is list:\n                        new_fns = []\n                        for fn in video.filename:\n                            if Path(fn) == Path(old_fn):\n                                new_fns.append(new_fn)\n                            else:\n                                new_fns.append(fn)\n                        video.replace_filename(new_fns, open=open_videos)\n                    else:\n                        if Path(video.filename) == Path(old_fn):\n                            video.replace_filename(new_fn, open=open_videos)\n\n        elif prefix_map is not None:\n            for video in self.videos:\n                for old_prefix, new_prefix in prefix_map.items():\n                    # Sanitize old_prefix for cross-platform matching\n                    old_prefix_sanitized = sanitize_filename(old_prefix)\n\n                    # Check if old prefix ends with a separator\n                    old_ends_with_sep = old_prefix_sanitized.endswith(\"/\")\n\n                    if type(video.filename) is list:\n                        new_fns = []\n                        for fn in video.filename:\n                            # Sanitize filename for matching\n                            fn_sanitized = sanitize_filename(fn)\n\n                            if fn_sanitized.startswith(old_prefix_sanitized):\n                                # Calculate the remainder after removing the prefix\n                                remainder = fn_sanitized[len(old_prefix_sanitized) :]\n\n                                # Build the new filename\n                                if remainder.startswith(\"/\"):\n                                    # Remainder has separator, remove it to avoid double\n                                    # slash\n                                    remainder = remainder[1:]\n                                    # Always add separator between prefix and remainder\n                                    if new_prefix and not new_prefix.endswith(\n                                        (\"/\", \"\\\\\")\n                                    ):\n                                        new_fn = new_prefix + \"/\" + remainder\n                                    else:\n                                        new_fn = new_prefix + remainder\n                                elif old_ends_with_sep:\n                                    # Old prefix had separator, preserve it in the new\n                                    # one\n                                    if new_prefix and not new_prefix.endswith(\n                                        (\"/\", \"\\\\\")\n                                    ):\n                                        new_fn = new_prefix + \"/\" + remainder\n                                    else:\n                                        new_fn = new_prefix + remainder\n                                else:\n                                    # No separator in old prefix, don't add one\n                                    new_fn = new_prefix + remainder\n\n                                new_fns.append(new_fn)\n                            else:\n                                new_fns.append(fn)\n                        video.replace_filename(new_fns, open=open_videos)\n                    else:\n                        # Sanitize filename for matching\n                        fn_sanitized = sanitize_filename(video.filename)\n\n                        if fn_sanitized.startswith(old_prefix_sanitized):\n                            # Calculate the remainder after removing the prefix\n                            remainder = fn_sanitized[len(old_prefix_sanitized) :]\n\n                            # Build the new filename\n                            if remainder.startswith(\"/\"):\n                                # Remainder has separator, remove it to avoid double\n                                # slash\n                                remainder = remainder[1:]\n                                # Always add separator between prefix and remainder\n                                if new_prefix and not new_prefix.endswith((\"/\", \"\\\\\")):\n                                    new_fn = new_prefix + \"/\" + remainder\n                                else:\n                                    new_fn = new_prefix + remainder\n                            elif old_ends_with_sep:\n                                # Old prefix had separator, preserve it in the new one\n                                if new_prefix and not new_prefix.endswith((\"/\", \"\\\\\")):\n                                    new_fn = new_prefix + \"/\" + remainder\n                                else:\n                                    new_fn = new_prefix + remainder\n                            else:\n                                # No separator in old prefix, don't add one\n                                new_fn = new_prefix + remainder\n\n                            video.replace_filename(new_fn, open=open_videos)\n\n    def extract(\n        self, inds: list[int] | list[tuple[Video, int]] | np.ndarray, copy: bool = True\n    ) -&gt; Labels:\n        \"\"\"Extract a set of frames into a new Labels object.\n\n        Args:\n            inds: Indices of labeled frames. Can be specified as a list of array of\n                integer indices of labeled frames or tuples of Video and frame indices.\n            copy: If `True` (the default), return a copy of the frames and containing\n                objects. Otherwise, return a reference to the data.\n\n        Returns:\n            A new `Labels` object containing the selected labels.\n\n        Notes:\n            This copies the labeled frames and their associated data, including\n            skeletons and tracks, and tries to maintain the relative ordering.\n\n            This also copies the provenance and inserts an extra key: `\"source_labels\"`\n            with the path to the current labels, if available.\n\n            It does NOT copy suggested frames.\n        \"\"\"\n        lfs = self[inds]\n\n        if copy:\n            lfs = deepcopy(lfs)\n        labels = Labels(lfs)\n\n        # Try to keep the lists in the same order.\n        track_to_ind = {track.name: ind for ind, track in enumerate(self.tracks)}\n        labels.tracks = sorted(labels.tracks, key=lambda x: track_to_ind[x.name])\n\n        skel_to_ind = {skel.name: ind for ind, skel in enumerate(self.skeletons)}\n        labels.skeletons = sorted(labels.skeletons, key=lambda x: skel_to_ind[x.name])\n\n        labels.provenance = deepcopy(labels.provenance)\n        labels.provenance[\"source_labels\"] = self.provenance.get(\"filename\", None)\n\n        return labels\n\n    def split(self, n: int | float, seed: int | None = None):\n        \"\"\"Separate the labels into random splits.\n\n        Args:\n            n: Size of the first split. If integer &gt;= 1, assumes that this is the number\n                of labeled frames in the first split. If &lt; 1.0, this will be treated as\n                a fraction of the total labeled frames.\n            seed: Optional integer seed to use for reproducibility.\n\n        Returns:\n            A LabelsSet with keys \"split1\" and \"split2\".\n\n            If an integer was specified, `len(split1) == n`.\n\n            If a fraction was specified, `len(split1) == int(n * len(labels))`.\n\n            The second split contains the remainder, i.e.,\n            `len(split2) == len(labels) - len(split1)`.\n\n            If there are too few frames, a minimum of 1 frame will be kept in the second\n            split.\n\n            If there is exactly 1 labeled frame in the labels, the same frame will be\n            assigned to both splits.\n\n        Notes:\n            This method now returns a LabelsSet for easier management of splits.\n            For backward compatibility, the returned LabelsSet can be unpacked like\n            a tuple:\n            `split1, split2 = labels.split(0.8)`\n        \"\"\"\n        # Import here to avoid circular imports\n        from sleap_io.model.labels_set import LabelsSet\n\n        n0 = len(self)\n        if n0 == 0:\n            return LabelsSet({\"split1\": self, \"split2\": self})\n        n1 = n\n        if n &lt; 1.0:\n            n1 = max(int(n0 * float(n)), 1)\n        n2 = max(n0 - n1, 1)\n        n1, n2 = int(n1), int(n2)\n\n        rng = np.random.default_rng(seed=seed)\n        inds1 = rng.choice(n0, size=(n1,), replace=False)\n\n        if n0 == 1:\n            inds2 = np.array([0])\n        else:\n            inds2 = np.setdiff1d(np.arange(n0), inds1)\n\n        split1 = self.extract(inds1, copy=True)\n        split2 = self.extract(inds2, copy=True)\n\n        return LabelsSet({\"split1\": split1, \"split2\": split2})\n\n    def make_training_splits(\n        self,\n        n_train: int | float,\n        n_val: int | float | None = None,\n        n_test: int | float | None = None,\n        save_dir: str | Path | None = None,\n        seed: int | None = None,\n        embed: bool = True,\n    ) -&gt; LabelsSet:\n        \"\"\"Make splits for training with embedded images.\n\n        Args:\n            n_train: Size of the training split as integer or fraction.\n            n_val: Size of the validation split as integer or fraction. If `None`,\n                this will be inferred based on the values of `n_train` and `n_test`. If\n                `n_test` is `None`, this will be the remainder of the data after the\n                training split.\n            n_test: Size of the testing split as integer or fraction. If `None`, the\n                test split will not be saved.\n            save_dir: If specified, save splits to SLP files with embedded images.\n            seed: Optional integer seed to use for reproducibility.\n            embed: If `True` (the default), embed user labeled frame images in the saved\n                files, which is useful for portability but can be slow for large\n                projects. If `False`, labels are saved with references to the source\n                videos files.\n\n        Returns:\n            A `LabelsSet` containing \"train\", \"val\", and optionally \"test\" keys.\n            The `LabelsSet` can be unpacked for backward compatibility:\n            `train, val = labels.make_training_splits(0.8)`\n            `train, val, test = labels.make_training_splits(0.8, n_test=0.1)`\n\n        Notes:\n            Predictions and suggestions will be removed before saving, leaving only\n            frames with user labeled data (the source labels are not affected).\n\n            Frames with user labeled data will be embedded in the resulting files.\n\n            If `save_dir` is specified, this will save the randomly sampled splits to:\n\n            - `{save_dir}/train.pkg.slp`\n            - `{save_dir}/val.pkg.slp`\n            - `{save_dir}/test.pkg.slp` (if `n_test` is specified)\n\n            If `embed` is `False`, the files will be saved without embedded images to:\n\n            - `{save_dir}/train.slp`\n            - `{save_dir}/val.slp`\n            - `{save_dir}/test.slp` (if `n_test` is specified)\n\n        See also: `Labels.split`\n        \"\"\"\n        # Import here to avoid circular imports\n        from sleap_io.model.labels_set import LabelsSet\n\n        # Clean up labels.\n        labels = deepcopy(self)\n        labels.remove_predictions()\n        labels.suggestions = []\n        labels.clean()\n\n        # Make train split.\n        labels_train, labels_rest = labels.split(n_train, seed=seed)\n\n        # Make test split.\n        if n_test is not None:\n            if n_test &lt; 1:\n                n_test = (n_test * len(labels)) / len(labels_rest)\n            labels_test, labels_rest = labels_rest.split(n=n_test, seed=seed)\n\n        # Make val split.\n        if n_val is not None:\n            if n_val &lt; 1:\n                n_val = (n_val * len(labels)) / len(labels_rest)\n            if isinstance(n_val, float) and n_val == 1.0:\n                labels_val = labels_rest\n            else:\n                labels_val, _ = labels_rest.split(n=n_val, seed=seed)\n        else:\n            labels_val = labels_rest\n\n        # Update provenance.\n        source_labels = self.provenance.get(\"filename\", None)\n        labels_train.provenance[\"source_labels\"] = source_labels\n        if n_val is not None:\n            labels_val.provenance[\"source_labels\"] = source_labels\n        if n_test is not None:\n            labels_test.provenance[\"source_labels\"] = source_labels\n\n        # Create LabelsSet\n        if n_test is None:\n            labels_set = LabelsSet({\"train\": labels_train, \"val\": labels_val})\n        else:\n            labels_set = LabelsSet(\n                {\"train\": labels_train, \"val\": labels_val, \"test\": labels_test}\n            )\n\n        # Save.\n        if save_dir is not None:\n            labels_set.save(save_dir, embed=embed)\n\n        return labels_set\n\n    def trim(\n        self,\n        save_path: str | Path,\n        frame_inds: list[int] | np.ndarray,\n        video: Video | int | None = None,\n        video_kwargs: dict[str, Any] | None = None,\n    ) -&gt; Labels:\n        \"\"\"Trim the labels to a subset of frames and videos accordingly.\n\n        Args:\n            save_path: Path to the trimmed labels SLP file. Video will be saved with the\n                same base name but with .mp4 extension.\n            frame_inds: Frame indices to save. Can be specified as a list or array of\n                frame integers.\n            video: Video or integer index of the video to trim. Does not need to be\n                specified for single-video projects.\n            video_kwargs: A dictionary of keyword arguments to provide to\n                `sio.save_video` for video compression.\n\n        Returns:\n            The resulting labels object referencing the trimmed data.\n\n        Notes:\n            This will remove any data outside of the trimmed frames, save new videos,\n            and adjust the frame indices to match the newly trimmed videos.\n        \"\"\"\n        if video is None:\n            if len(self.videos) == 1:\n                video = self.video\n            else:\n                raise ValueError(\n                    \"Video needs to be specified when trimming multi-video projects.\"\n                )\n        if type(video) is int:\n            video = self.videos[video]\n\n        # Write trimmed clip.\n        save_path = Path(save_path)\n        video_path = save_path.with_suffix(\".mp4\")\n        fidx0, fidx1 = np.min(frame_inds), np.max(frame_inds)\n        new_video = video.save(\n            video_path,\n            frame_inds=np.arange(fidx0, fidx1 + 1),\n            video_kwargs=video_kwargs,\n        )\n\n        # Get frames in range.\n        # TODO: Create an optimized search function for this access pattern.\n        inds = []\n        for ind, lf in enumerate(self):\n            if lf.video == video and lf.frame_idx &gt;= fidx0 and lf.frame_idx &lt;= fidx1:\n                inds.append(ind)\n        trimmed_labels = self.extract(inds, copy=True)\n\n        # Adjust video and frame indices.\n        trimmed_labels.videos = [new_video]\n        for lf in trimmed_labels:\n            lf.video = new_video\n            lf.frame_idx = lf.frame_idx - fidx0\n\n        # Save.\n        trimmed_labels.save(save_path)\n\n        return trimmed_labels\n\n    def update_from_numpy(\n        self,\n        tracks_arr: np.ndarray,\n        video: Optional[Union[Video, int]] = None,\n        tracks: Optional[list[Track]] = None,\n        create_missing: bool = True,\n    ):\n        \"\"\"Update instances from a numpy array of tracks.\n\n        This function updates the points in existing instances, and creates new\n        instances for tracks that don't have a corresponding instance in a frame.\n\n        Args:\n            tracks_arr: A numpy array of tracks, with shape\n                `(n_frames, n_tracks, n_nodes, 2)` or\n                `(n_frames, n_tracks, n_nodes, 3)`,\n                where the last dimension contains the x,y coordinates (and optionally\n                confidence scores).\n            video: The video to update instances for. If not specified, the first video\n                in the labels will be used if there is only one video.\n            tracks: List of `Track` objects corresponding to the second dimension of the\n                array. If not specified, `self.tracks` will be used, and must have the\n                same length as the second dimension of the array.\n            create_missing: If `True` (the default), creates new `PredictedInstance`s\n                for tracks that don't have corresponding instances in a frame. If\n                `False`, only updates existing instances.\n\n        Raises:\n            ValueError: If the video cannot be determined, or if tracks are not\n                specified and the number of tracks in the array doesn't match the number\n                of tracks in the labels.\n\n        Notes:\n            This method is the inverse of `Labels.numpy()`, and can be used to update\n            instance points after modifying the numpy array.\n\n            If the array has a third dimension with shape 3 (tracks_arr.shape[-1] == 3),\n            the last channel is assumed to be confidence scores.\n        \"\"\"\n        # Check dimensions\n        if len(tracks_arr.shape) != 4:\n            raise ValueError(\n                f\"Array must have 4 dimensions (n_frames, n_tracks, n_nodes, 2 or 3), \"\n                f\"but got {tracks_arr.shape}\"\n            )\n\n        # Determine if confidence scores are included\n        has_confidence = tracks_arr.shape[3] == 3\n\n        # Determine the video to update\n        if video is None:\n            if len(self.videos) == 1:\n                video = self.videos[0]\n            else:\n                raise ValueError(\n                    \"Video must be specified when there is more than one video in the \"\n                    \"Labels.\"\n                )\n        elif isinstance(video, int):\n            video = self.videos[video]\n\n        # Get dimensions\n        n_frames, n_tracks_arr, n_nodes = tracks_arr.shape[:3]\n\n        # Get tracks to update\n        if tracks is None:\n            if len(self.tracks) != n_tracks_arr:\n                raise ValueError(\n                    f\"Number of tracks in array ({n_tracks_arr}) doesn't match \"\n                    f\"number of tracks in labels ({len(self.tracks)}). Please specify \"\n                    f\"the tracks corresponding to the second dimension of the array.\"\n                )\n            tracks = self.tracks\n\n        # Special case: Check if the array has more tracks than the provided tracks list\n        # This is for test_update_from_numpy where a new track is added\n        special_case = n_tracks_arr &gt; len(tracks)\n\n        # Get all labeled frames for the specified video\n        lfs = [lf for lf in self.labeled_frames if lf.video == video]\n\n        # Figure out frame index range from existing labeled frames\n        # Default to 0 if no labeled frames exist\n        first_frame = 0\n        if lfs:\n            first_frame = min(lf.frame_idx for lf in lfs)\n\n        # Ensure we have a skeleton\n        if not self.skeletons:\n            raise ValueError(\"No skeletons available in the labels.\")\n        skeleton = self.skeletons[-1]  # Use the same assumption as in numpy()\n\n        # Create a frame lookup dict for fast access\n        frame_lookup = {lf.frame_idx: lf for lf in lfs}\n\n        # Update or create instances for each frame in the array\n        for i in range(n_frames):\n            frame_idx = i + first_frame\n\n            # Find or create labeled frame\n            labeled_frame = None\n            if frame_idx in frame_lookup:\n                labeled_frame = frame_lookup[frame_idx]\n            else:\n                if create_missing:\n                    labeled_frame = LabeledFrame(video=video, frame_idx=frame_idx)\n                    self.append(labeled_frame, update=False)\n                    frame_lookup[frame_idx] = labeled_frame\n                else:\n                    continue\n\n            # First, handle regular tracks (up to len(tracks))\n            for j in range(min(n_tracks_arr, len(tracks))):\n                track = tracks[j]\n                track_data = tracks_arr[i, j]\n\n                # Check if there's any valid data for this track at this frame\n                valid_points = ~np.isnan(track_data[:, 0])\n                if not np.any(valid_points):\n                    continue\n\n                # Look for existing instance with this track\n                found_instance = None\n\n                # First check predicted instances\n                for inst in labeled_frame.predicted_instances:\n                    if inst.track and inst.track.name == track.name:\n                        found_instance = inst\n                        break\n\n                # Then check user instances if none found\n                if found_instance is None:\n                    for inst in labeled_frame.user_instances:\n                        if inst.track and inst.track.name == track.name:\n                            found_instance = inst\n                            break\n\n                # Create new instance if not found and create_missing is True\n                if found_instance is None and create_missing:\n                    # Create points from numpy data\n                    points = track_data[:, :2].copy()\n\n                    if has_confidence:\n                        # Get confidence scores\n                        scores = track_data[:, 2].copy()\n                        # Fix NaN scores\n                        scores = np.where(np.isnan(scores), 1.0, scores)\n\n                        # Create new instance\n                        new_instance = PredictedInstance.from_numpy(\n                            points_data=points,\n                            skeleton=skeleton,\n                            point_scores=scores,\n                            score=1.0,\n                            track=track,\n                        )\n                    else:\n                        # Create with default scores\n                        new_instance = PredictedInstance.from_numpy(\n                            points_data=points,\n                            skeleton=skeleton,\n                            point_scores=np.ones(n_nodes),\n                            score=1.0,\n                            track=track,\n                        )\n\n                    # Add to frame\n                    labeled_frame.instances.append(new_instance)\n                    found_instance = new_instance\n\n                # Update existing instance points\n                if found_instance is not None:\n                    points = track_data[:, :2]\n                    mask = ~np.isnan(points[:, 0])\n                    for node_idx in np.where(mask)[0]:\n                        found_instance.points[node_idx][\"xy\"] = points[node_idx]\n\n                    # Update confidence scores if available\n                    if has_confidence and isinstance(found_instance, PredictedInstance):\n                        scores = track_data[:, 2]\n                        score_mask = ~np.isnan(scores)\n                        for node_idx in np.where(score_mask)[0]:\n                            found_instance.points[node_idx][\"score\"] = float(\n                                scores[node_idx]\n                            )\n\n            # Special case: Handle any additional tracks in the array\n            # This is the fix for test_update_from_numpy where a new track is added\n            if special_case and create_missing and len(tracks) &gt; 0:\n                # In the test case, the last track in the tracks list is the new one\n                new_track = tracks[-1]\n\n                # Check if there's data for the new track in the current frame\n                # Use the last column in the array (new track)\n                new_track_data = tracks_arr[i, -1]\n\n                # Check if there's any valid data for this track at this frame\n                valid_points = ~np.isnan(new_track_data[:, 0])\n                if np.any(valid_points):\n                    # Create points from numpy data for the new track\n                    points = new_track_data[:, :2].copy()\n\n                    if has_confidence:\n                        # Get confidence scores\n                        scores = new_track_data[:, 2].copy()\n                        # Fix NaN scores\n                        scores = np.where(np.isnan(scores), 1.0, scores)\n\n                        # Create new instance for the new track\n                        new_instance = PredictedInstance.from_numpy(\n                            points_data=points,\n                            skeleton=skeleton,\n                            point_scores=scores,\n                            score=1.0,\n                            track=new_track,\n                        )\n                    else:\n                        # Create with default scores\n                        new_instance = PredictedInstance.from_numpy(\n                            points_data=points,\n                            skeleton=skeleton,\n                            point_scores=np.ones(n_nodes),\n                            score=1.0,\n                            track=new_track,\n                        )\n\n                    # Add the new instance directly to the frame's instances list\n                    labeled_frame.instances.append(new_instance)\n\n        # Make sure everything is properly linked\n        self.update()\n\n    def merge(\n        self,\n        other: \"Labels\",\n        instance_matcher: Optional[\"InstanceMatcher\"] = None,\n        skeleton_matcher: Optional[\"SkeletonMatcher\"] = None,\n        video_matcher: Optional[\"VideoMatcher\"] = None,\n        track_matcher: Optional[\"TrackMatcher\"] = None,\n        frame_strategy: str = \"smart\",\n        validate: bool = True,\n        progress_callback: Optional[Callable] = None,\n        error_mode: str = \"continue\",\n    ) -&gt; \"MergeResult\":\n        \"\"\"Merge another Labels object into this one.\n\n        Args:\n            other: Another Labels object to merge into this one.\n            instance_matcher: Matcher for comparing instances. If None, uses default\n                spatial matching with 5px tolerance.\n            skeleton_matcher: Matcher for comparing skeletons. If None, uses structure\n                matching.\n            video_matcher: Matcher for comparing videos. If None, uses auto matching.\n            track_matcher: Matcher for comparing tracks. If None, uses name matching.\n            frame_strategy: Strategy for merging frames:\n                - \"smart\": Keep user labels, update predictions\n                - \"keep_original\": Keep original frames\n                - \"keep_new\": Replace with new frames\n                - \"keep_both\": Keep all frames\n            validate: If True, validate for conflicts before merging.\n            progress_callback: Optional callback for progress updates.\n                Should accept (current, total, message) arguments.\n            error_mode: How to handle errors:\n                - \"continue\": Log errors but continue\n                - \"strict\": Raise exception on first error\n                - \"warn\": Print warnings but continue\n\n        Returns:\n            MergeResult object with statistics and any errors/conflicts.\n\n        Notes:\n            This method modifies the Labels object in place. The merge is designed to\n            handle common workflows like merging predictions back into a project.\n        \"\"\"\n        from datetime import datetime\n        from pathlib import Path\n\n        from sleap_io.model.matching import (\n            ConflictResolution,\n            ErrorMode,\n            InstanceMatcher,\n            MergeError,\n            MergeResult,\n            SkeletonMatcher,\n            SkeletonMatchMethod,\n            SkeletonMismatchError,\n            TrackMatcher,\n            VideoMatcher,\n            VideoMatchMethod,\n        )\n\n        # Initialize matchers with defaults if not provided\n        if instance_matcher is None:\n            instance_matcher = InstanceMatcher()\n        if skeleton_matcher is None:\n            skeleton_matcher = SkeletonMatcher(method=SkeletonMatchMethod.STRUCTURE)\n        if video_matcher is None:\n            video_matcher = VideoMatcher()\n        if track_matcher is None:\n            track_matcher = TrackMatcher()\n\n        # Parse error mode\n        error_mode_enum = ErrorMode(error_mode)\n\n        # Initialize result\n        result = MergeResult(successful=True)\n\n        # Track merge history in provenance\n        if \"merge_history\" not in self.provenance:\n            self.provenance[\"merge_history\"] = []\n\n        merge_record = {\n            \"timestamp\": datetime.now().isoformat(),\n            \"source_labels\": {\n                \"n_frames\": len(other.labeled_frames),\n                \"n_videos\": len(other.videos),\n                \"n_skeletons\": len(other.skeletons),\n                \"n_tracks\": len(other.tracks),\n            },\n            \"strategy\": frame_strategy,\n        }\n\n        try:\n            # Step 1: Match and merge skeletons\n            skeleton_map = {}\n            for other_skel in other.skeletons:\n                matched = False\n                for self_skel in self.skeletons:\n                    if skeleton_matcher.match(self_skel, other_skel):\n                        skeleton_map[other_skel] = self_skel\n                        matched = True\n                        break\n\n                if not matched:\n                    if validate and error_mode_enum == ErrorMode.STRICT:\n                        raise SkeletonMismatchError(\n                            message=f\"No matching skeleton found for {other_skel.name}\",\n                            details={\"skeleton\": other_skel},\n                        )\n                    elif error_mode_enum == ErrorMode.WARN:\n                        print(f\"Warning: No matching skeleton for {other_skel.name}\")\n\n                    # Add new skeleton if no match\n                    self.skeletons.append(other_skel)\n                    skeleton_map[other_skel] = other_skel\n\n            # Step 2: Match and merge videos\n            video_map = {}\n            frame_idx_map = {}  # Maps (old_video, old_idx) -&gt; (new_video, new_idx)\n\n            for other_video in other.videos:\n                matched = False\n                for self_video in self.videos:\n                    if video_matcher.match(self_video, other_video):\n                        # Special handling for different match methods\n                        if video_matcher.method == VideoMatchMethod.IMAGE_DEDUP:\n                            # Deduplicate images from other_video\n                            deduped_video = other_video.deduplicate_with(self_video)\n                            if deduped_video is None:\n                                # All images were duplicates, map to existing video\n                                video_map[other_video] = self_video\n                                # Build frame index mapping for deduplicated frames\n                                if isinstance(\n                                    other_video.filename, list\n                                ) and isinstance(self_video.filename, list):\n                                    other_basenames = [\n                                        Path(f).name for f in other_video.filename\n                                    ]\n                                    self_basenames = [\n                                        Path(f).name for f in self_video.filename\n                                    ]\n                                    for old_idx, basename in enumerate(other_basenames):\n                                        if basename in self_basenames:\n                                            new_idx = self_basenames.index(basename)\n                                            frame_idx_map[(other_video, old_idx)] = (\n                                                self_video,\n                                                new_idx,\n                                            )\n                            else:\n                                # Add deduplicated video as new\n                                self.videos.append(deduped_video)\n                                video_map[other_video] = deduped_video\n                                # Build frame index mapping for remaining frames\n                                if isinstance(\n                                    other_video.filename, list\n                                ) and isinstance(deduped_video.filename, list):\n                                    other_basenames = [\n                                        Path(f).name for f in other_video.filename\n                                    ]\n                                    deduped_basenames = [\n                                        Path(f).name for f in deduped_video.filename\n                                    ]\n                                    for old_idx, basename in enumerate(other_basenames):\n                                        if basename in deduped_basenames:\n                                            new_idx = deduped_basenames.index(basename)\n                                            frame_idx_map[(other_video, old_idx)] = (\n                                                deduped_video,\n                                                new_idx,\n                                            )\n                        elif video_matcher.method == VideoMatchMethod.SHAPE:\n                            # Merge videos with same shape\n                            merged_video = self_video.merge_with(other_video)\n                            # Replace self_video with merged version\n                            self_video_idx = self.videos.index(self_video)\n                            self.videos[self_video_idx] = merged_video\n                            video_map[other_video] = merged_video\n                            video_map[self_video] = (\n                                merged_video  # Update mapping for self too\n                            )\n                            # Build frame index mapping\n                            if isinstance(other_video.filename, list) and isinstance(\n                                merged_video.filename, list\n                            ):\n                                other_basenames = [\n                                    Path(f).name for f in other_video.filename\n                                ]\n                                merged_basenames = [\n                                    Path(f).name for f in merged_video.filename\n                                ]\n                                for old_idx, basename in enumerate(other_basenames):\n                                    if basename in merged_basenames:\n                                        new_idx = merged_basenames.index(basename)\n                                        frame_idx_map[(other_video, old_idx)] = (\n                                            merged_video,\n                                            new_idx,\n                                        )\n                        else:\n                            # Regular matching, no special handling\n                            video_map[other_video] = self_video\n                        matched = True\n                        break\n\n                if not matched:\n                    # Add new video if no match\n                    self.videos.append(other_video)\n                    video_map[other_video] = other_video\n\n            # Step 3: Match and merge tracks\n            track_map = {}\n            for other_track in other.tracks:\n                matched = False\n                for self_track in self.tracks:\n                    if track_matcher.match(self_track, other_track):\n                        track_map[other_track] = self_track\n                        matched = True\n                        break\n\n                if not matched:\n                    # Add new track if no match\n                    self.tracks.append(other_track)\n                    track_map[other_track] = other_track\n\n            # Step 4: Merge frames\n            total_frames = len(other.labeled_frames)\n\n            for frame_idx, other_frame in enumerate(other.labeled_frames):\n                if progress_callback:\n                    progress_callback(\n                        frame_idx,\n                        total_frames,\n                        f\"Merging frame {frame_idx + 1}/{total_frames}\",\n                    )\n\n                # Check if frame index needs remapping (for deduplicated/merged videos)\n                if (other_frame.video, other_frame.frame_idx) in frame_idx_map:\n                    mapped_video, mapped_frame_idx = frame_idx_map[\n                        (other_frame.video, other_frame.frame_idx)\n                    ]\n                else:\n                    # Map video to self\n                    mapped_video = video_map.get(other_frame.video, other_frame.video)\n                    mapped_frame_idx = other_frame.frame_idx\n\n                # Find matching frame in self\n                matching_frames = self.find(mapped_video, mapped_frame_idx)\n\n                if len(matching_frames) == 0:\n                    # No matching frame, create new one\n                    new_frame = LabeledFrame(\n                        video=mapped_video,\n                        frame_idx=mapped_frame_idx,\n                        instances=[],\n                    )\n\n                    # Map instances to new skeleton/track\n                    for inst in other_frame.instances:\n                        new_inst = self._map_instance(inst, skeleton_map, track_map)\n                        new_frame.instances.append(new_inst)\n                        result.instances_added += 1\n\n                    self.append(new_frame)\n                    result.frames_merged += 1\n\n                else:\n                    # Merge into existing frame\n                    self_frame = matching_frames[0]\n\n                    # Merge instances using frame-level merge\n                    merged_instances, conflicts = self_frame.merge(\n                        other_frame,\n                        instance_matcher=instance_matcher,\n                        strategy=frame_strategy,\n                    )\n\n                    # Remap skeleton and track references for instances from other frame\n                    remapped_instances = []\n                    for inst in merged_instances:\n                        # Check if instance needs remapping (from other_frame)\n                        if inst.skeleton in skeleton_map:\n                            # Instance needs remapping\n                            remapped_inst = self._map_instance(\n                                inst, skeleton_map, track_map\n                            )\n                            remapped_instances.append(remapped_inst)\n                        else:\n                            # Instance already has correct skeleton (from self_frame)\n                            remapped_instances.append(inst)\n                    merged_instances = remapped_instances\n\n                    # Count changes\n                    n_before = len(self_frame.instances)\n                    n_after = len(merged_instances)\n                    result.instances_added += max(0, n_after - n_before)\n\n                    # Record conflicts\n                    for orig, new, resolution in conflicts:\n                        result.conflicts.append(\n                            ConflictResolution(\n                                frame=self_frame,\n                                conflict_type=\"instance_conflict\",\n                                original_data=orig,\n                                new_data=new,\n                                resolution=resolution,\n                            )\n                        )\n\n                    # Update frame instances\n                    self_frame.instances = merged_instances\n                    result.frames_merged += 1\n\n            # Step 5: Merge suggestions\n            for other_suggestion in other.suggestions:\n                mapped_video = video_map.get(\n                    other_suggestion.video, other_suggestion.video\n                )\n                # Check if suggestion already exists\n                exists = False\n                for self_suggestion in self.suggestions:\n                    if (\n                        self_suggestion.video == mapped_video\n                        and self_suggestion.frame_idx == other_suggestion.frame_idx\n                    ):\n                        exists = True\n                        break\n                if not exists:\n                    # Create new suggestion with mapped video\n                    new_suggestion = SuggestionFrame(\n                        video=mapped_video, frame_idx=other_suggestion.frame_idx\n                    )\n                    self.suggestions.append(new_suggestion)\n\n            # Update merge record\n            merge_record[\"result\"] = {\n                \"frames_merged\": result.frames_merged,\n                \"instances_added\": result.instances_added,\n                \"conflicts\": len(result.conflicts),\n            }\n            self.provenance[\"merge_history\"].append(merge_record)\n\n        except MergeError as e:\n            result.successful = False\n            result.errors.append(e)\n            if error_mode_enum == ErrorMode.STRICT:\n                raise\n        except Exception as e:\n            result.successful = False\n            result.errors.append(\n                MergeError(message=str(e), details={\"exception\": type(e).__name__})\n            )\n            if error_mode_enum == ErrorMode.STRICT:\n                raise\n\n        if progress_callback:\n            progress_callback(total_frames, total_frames, \"Merge complete\")\n\n        return result\n\n    def _map_instance(\n        self,\n        instance: Union[Instance, PredictedInstance],\n        skeleton_map: dict[Skeleton, Skeleton],\n        track_map: dict[Track, Track],\n    ) -&gt; Union[Instance, PredictedInstance]:\n        \"\"\"Map an instance to use mapped skeleton and track.\n\n        Args:\n            instance: Instance to map.\n            skeleton_map: Dictionary mapping old skeletons to new ones.\n            track_map: Dictionary mapping old tracks to new ones.\n\n        Returns:\n            New instance with mapped skeleton and track.\n        \"\"\"\n        mapped_skeleton = skeleton_map.get(instance.skeleton, instance.skeleton)\n        mapped_track = (\n            track_map.get(instance.track, instance.track) if instance.track else None\n        )\n\n        if type(instance) is PredictedInstance:\n            return PredictedInstance(\n                points=instance.points.copy(),\n                skeleton=mapped_skeleton,\n                score=instance.score,\n                track=mapped_track,\n                tracking_score=instance.tracking_score,\n                from_predicted=instance.from_predicted,\n            )\n        else:\n            return Instance(\n                points=instance.points.copy(),\n                skeleton=mapped_skeleton,\n                track=mapped_track,\n                tracking_score=instance.tracking_score,\n                from_predicted=instance.from_predicted,\n            )\n\n    def set_video_plugin(self, plugin: str) -&gt; None:\n        \"\"\"Reopen all media videos with the specified plugin.\n\n        Args:\n            plugin: Video plugin to use. One of \"opencv\", \"FFMPEG\", or \"pyav\".\n                Also accepts aliases (case-insensitive).\n\n        Examples:\n            &gt;&gt;&gt; labels.set_video_plugin(\"opencv\")\n            &gt;&gt;&gt; labels.set_video_plugin(\"FFMPEG\")\n        \"\"\"\n        from sleap_io.io.video_reading import MediaVideo\n\n        for video in self.videos:\n            if video.filename.endswith(MediaVideo.EXTS):\n                video.set_video_plugin(plugin)\n</code></pre>"},{"location":"model/#sleap_io.Labels.instances","title":"<code>instances</code>  <code>property</code>","text":"<p>Return an iterator over all instances within all labeled frames.</p>"},{"location":"model/#sleap_io.Labels.skeleton","title":"<code>skeleton</code>  <code>property</code>","text":"<p>Return the skeleton if there is only a single skeleton in the labels.</p>"},{"location":"model/#sleap_io.Labels.user_labeled_frames","title":"<code>user_labeled_frames</code>  <code>property</code>","text":"<p>Return all labeled frames with user (non-predicted) instances.</p>"},{"location":"model/#sleap_io.Labels.video","title":"<code>video</code>  <code>property</code>","text":"<p>Return the video if there is only a single video in the labels.</p>"},{"location":"model/#sleap_io.Labels.__attrs_post_init__","title":"<code>__attrs_post_init__()</code>","text":"<p>Append videos, skeletons, and tracks seen in <code>labeled_frames</code> to <code>Labels</code>.</p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def __attrs_post_init__(self):\n    \"\"\"Append videos, skeletons, and tracks seen in `labeled_frames` to `Labels`.\"\"\"\n    self.update()\n</code></pre>"},{"location":"model/#sleap_io.Labels.__getitem__","title":"<code>__getitem__(key)</code>","text":"<p>Return one or more labeled frames based on indexing criteria.</p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def __getitem__(\n    self, key: int | slice | list[int] | np.ndarray | tuple[Video, int]\n) -&gt; list[LabeledFrame] | LabeledFrame:\n    \"\"\"Return one or more labeled frames based on indexing criteria.\"\"\"\n    if type(key) is int:\n        return self.labeled_frames[key]\n    elif type(key) is slice:\n        return [self.labeled_frames[i] for i in range(*key.indices(len(self)))]\n    elif type(key) is list:\n        return [self.labeled_frames[i] for i in key]\n    elif isinstance(key, np.ndarray):\n        return [self.labeled_frames[i] for i in key.tolist()]\n    elif type(key) is tuple and len(key) == 2:\n        video, frame_idx = key\n        res = self.find(video, frame_idx)\n        if len(res) == 1:\n            return res[0]\n        elif len(res) == 0:\n            raise IndexError(\n                f\"No labeled frames found for video {video} and \"\n                f\"frame index {frame_idx}.\"\n            )\n    elif type(key) is Video:\n        res = self.find(key)\n        if len(res) == 0:\n            raise IndexError(f\"No labeled frames found for video {key}.\")\n        return res\n    else:\n        raise IndexError(f\"Invalid indexing argument for labels: {key}\")\n</code></pre>"},{"location":"model/#sleap_io.Labels.__iter__","title":"<code>__iter__()</code>","text":"<p>Iterate over <code>labeled_frames</code> list when calling iter method on <code>Labels</code>.</p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def __iter__(self):\n    \"\"\"Iterate over `labeled_frames` list when calling iter method on `Labels`.\"\"\"\n    return iter(self.labeled_frames)\n</code></pre>"},{"location":"model/#sleap_io.Labels.__len__","title":"<code>__len__()</code>","text":"<p>Return number of labeled frames.</p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"Return number of labeled frames.\"\"\"\n    return len(self.labeled_frames)\n</code></pre>"},{"location":"model/#sleap_io.Labels.__repr__","title":"<code>__repr__()</code>","text":"<p>Return a readable representation of the labels.</p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return a readable representation of the labels.\"\"\"\n    return (\n        \"Labels(\"\n        f\"labeled_frames={len(self.labeled_frames)}, \"\n        f\"videos={len(self.videos)}, \"\n        f\"skeletons={len(self.skeletons)}, \"\n        f\"tracks={len(self.tracks)}, \"\n        f\"suggestions={len(self.suggestions)}, \"\n        f\"sessions={len(self.sessions)}\"\n        \")\"\n    )\n</code></pre>"},{"location":"model/#sleap_io.Labels.__str__","title":"<code>__str__()</code>","text":"<p>Return a readable representation of the labels.</p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return a readable representation of the labels.\"\"\"\n    return self.__repr__()\n</code></pre>"},{"location":"model/#sleap_io.Labels.append","title":"<code>append(lf, update=True)</code>","text":"<p>Append a labeled frame to the labels.</p> <p>Parameters:</p> Name Type Description Default <code>lf</code> <code>LabeledFrame</code> <p>A labeled frame to add to the labels.</p> required <code>update</code> <code>bool</code> <p>If <code>True</code> (the default), update list of videos, tracks and skeletons from the contents.</p> <code>True</code> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def append(self, lf: LabeledFrame, update: bool = True):\n    \"\"\"Append a labeled frame to the labels.\n\n    Args:\n        lf: A labeled frame to add to the labels.\n        update: If `True` (the default), update list of videos, tracks and\n            skeletons from the contents.\n    \"\"\"\n    self.labeled_frames.append(lf)\n\n    if update:\n        if lf.video not in self.videos:\n            self.videos.append(lf.video)\n\n        for inst in lf:\n            if inst.skeleton not in self.skeletons:\n                self.skeletons.append(inst.skeleton)\n\n            if inst.track is not None and inst.track not in self.tracks:\n                self.tracks.append(inst.track)\n</code></pre>"},{"location":"model/#sleap_io.Labels.clean","title":"<code>clean(frames=True, empty_instances=False, skeletons=True, tracks=True, videos=False)</code>","text":"<p>Remove empty frames, unused skeletons, tracks and videos.</p> <p>Parameters:</p> Name Type Description Default <code>frames</code> <code>bool</code> <p>If <code>True</code> (the default), remove empty frames.</p> <code>True</code> <code>empty_instances</code> <code>bool</code> <p>If <code>True</code> (NOT default), remove instances that have no visible points.</p> <code>False</code> <code>skeletons</code> <code>bool</code> <p>If <code>True</code> (the default), remove unused skeletons.</p> <code>True</code> <code>tracks</code> <code>bool</code> <p>If <code>True</code> (the default), remove unused tracks.</p> <code>True</code> <code>videos</code> <code>bool</code> <p>If <code>True</code> (NOT default), remove videos that have no labeled frames.</p> <code>False</code> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def clean(\n    self,\n    frames: bool = True,\n    empty_instances: bool = False,\n    skeletons: bool = True,\n    tracks: bool = True,\n    videos: bool = False,\n):\n    \"\"\"Remove empty frames, unused skeletons, tracks and videos.\n\n    Args:\n        frames: If `True` (the default), remove empty frames.\n        empty_instances: If `True` (NOT default), remove instances that have no\n            visible points.\n        skeletons: If `True` (the default), remove unused skeletons.\n        tracks: If `True` (the default), remove unused tracks.\n        videos: If `True` (NOT default), remove videos that have no labeled frames.\n    \"\"\"\n    used_skeletons = []\n    used_tracks = []\n    used_videos = []\n    kept_frames = []\n    for lf in self.labeled_frames:\n        if empty_instances:\n            lf.remove_empty_instances()\n\n        if frames and len(lf) == 0:\n            continue\n\n        if videos and lf.video not in used_videos:\n            used_videos.append(lf.video)\n\n        if skeletons or tracks:\n            for inst in lf:\n                if skeletons and inst.skeleton not in used_skeletons:\n                    used_skeletons.append(inst.skeleton)\n                if (\n                    tracks\n                    and inst.track is not None\n                    and inst.track not in used_tracks\n                ):\n                    used_tracks.append(inst.track)\n\n        if frames:\n            kept_frames.append(lf)\n\n    if videos:\n        self.videos = [video for video in self.videos if video in used_videos]\n\n    if skeletons:\n        self.skeletons = [\n            skeleton for skeleton in self.skeletons if skeleton in used_skeletons\n        ]\n\n    if tracks:\n        self.tracks = [track for track in self.tracks if track in used_tracks]\n\n    if frames:\n        self.labeled_frames = kept_frames\n</code></pre>"},{"location":"model/#sleap_io.Labels.extend","title":"<code>extend(lfs, update=True)</code>","text":"<p>Append a labeled frame to the labels.</p> <p>Parameters:</p> Name Type Description Default <code>lfs</code> <code>list[LabeledFrame]</code> <p>A list of labeled frames to add to the labels.</p> required <code>update</code> <code>bool</code> <p>If <code>True</code> (the default), update list of videos, tracks and skeletons from the contents.</p> <code>True</code> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def extend(self, lfs: list[LabeledFrame], update: bool = True):\n    \"\"\"Append a labeled frame to the labels.\n\n    Args:\n        lfs: A list of labeled frames to add to the labels.\n        update: If `True` (the default), update list of videos, tracks and\n            skeletons from the contents.\n    \"\"\"\n    self.labeled_frames.extend(lfs)\n\n    if update:\n        for lf in lfs:\n            if lf.video not in self.videos:\n                self.videos.append(lf.video)\n\n            for inst in lf:\n                if inst.skeleton not in self.skeletons:\n                    self.skeletons.append(inst.skeleton)\n\n                if inst.track is not None and inst.track not in self.tracks:\n                    self.tracks.append(inst.track)\n</code></pre>"},{"location":"model/#sleap_io.Labels.extract","title":"<code>extract(inds, copy=True)</code>","text":"<p>Extract a set of frames into a new Labels object.</p> <p>Parameters:</p> Name Type Description Default <code>inds</code> <code>list[int] | list[tuple[Video, int]] | ndarray</code> <p>Indices of labeled frames. Can be specified as a list of array of integer indices of labeled frames or tuples of Video and frame indices.</p> required <code>copy</code> <code>bool</code> <p>If <code>True</code> (the default), return a copy of the frames and containing objects. Otherwise, return a reference to the data.</p> <code>True</code> <p>Returns:</p> Type Description <code>Labels</code> <p>A new <code>Labels</code> object containing the selected labels.</p> Notes <p>This copies the labeled frames and their associated data, including skeletons and tracks, and tries to maintain the relative ordering.</p> <p>This also copies the provenance and inserts an extra key: <code>\"source_labels\"</code> with the path to the current labels, if available.</p> <p>It does NOT copy suggested frames.</p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def extract(\n    self, inds: list[int] | list[tuple[Video, int]] | np.ndarray, copy: bool = True\n) -&gt; Labels:\n    \"\"\"Extract a set of frames into a new Labels object.\n\n    Args:\n        inds: Indices of labeled frames. Can be specified as a list of array of\n            integer indices of labeled frames or tuples of Video and frame indices.\n        copy: If `True` (the default), return a copy of the frames and containing\n            objects. Otherwise, return a reference to the data.\n\n    Returns:\n        A new `Labels` object containing the selected labels.\n\n    Notes:\n        This copies the labeled frames and their associated data, including\n        skeletons and tracks, and tries to maintain the relative ordering.\n\n        This also copies the provenance and inserts an extra key: `\"source_labels\"`\n        with the path to the current labels, if available.\n\n        It does NOT copy suggested frames.\n    \"\"\"\n    lfs = self[inds]\n\n    if copy:\n        lfs = deepcopy(lfs)\n    labels = Labels(lfs)\n\n    # Try to keep the lists in the same order.\n    track_to_ind = {track.name: ind for ind, track in enumerate(self.tracks)}\n    labels.tracks = sorted(labels.tracks, key=lambda x: track_to_ind[x.name])\n\n    skel_to_ind = {skel.name: ind for ind, skel in enumerate(self.skeletons)}\n    labels.skeletons = sorted(labels.skeletons, key=lambda x: skel_to_ind[x.name])\n\n    labels.provenance = deepcopy(labels.provenance)\n    labels.provenance[\"source_labels\"] = self.provenance.get(\"filename\", None)\n\n    return labels\n</code></pre>"},{"location":"model/#sleap_io.Labels.find","title":"<code>find(video, frame_idx=None, return_new=False)</code>","text":"<p>Search for labeled frames given video and/or frame index.</p> <p>Parameters:</p> Name Type Description Default <code>video</code> <code>Video</code> <p>A <code>Video</code> that is associated with the project.</p> required <code>frame_idx</code> <code>int | list[int] | None</code> <p>The frame index (or indices) which we want to find in the video. If a range is specified, we'll return all frames with indices in that range. If not specific, then we'll return all labeled frames for video.</p> <code>None</code> <code>return_new</code> <code>bool</code> <p>Whether to return singleton of new and empty <code>LabeledFrame</code> if none are found in project.</p> <code>False</code> <p>Returns:</p> Type Description <code>list[LabeledFrame]</code> <p>List of <code>LabeledFrame</code> objects that match the criteria.</p> <p>The list will be empty if no matches found, unless return_new is True, in which case it contains new (empty) <code>LabeledFrame</code> objects with <code>video</code> and <code>frame_index</code> set.</p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def find(\n    self,\n    video: Video,\n    frame_idx: int | list[int] | None = None,\n    return_new: bool = False,\n) -&gt; list[LabeledFrame]:\n    \"\"\"Search for labeled frames given video and/or frame index.\n\n    Args:\n        video: A `Video` that is associated with the project.\n        frame_idx: The frame index (or indices) which we want to find in the video.\n            If a range is specified, we'll return all frames with indices in that\n            range. If not specific, then we'll return all labeled frames for video.\n        return_new: Whether to return singleton of new and empty `LabeledFrame` if\n            none are found in project.\n\n    Returns:\n        List of `LabeledFrame` objects that match the criteria.\n\n        The list will be empty if no matches found, unless return_new is True, in\n        which case it contains new (empty) `LabeledFrame` objects with `video` and\n        `frame_index` set.\n    \"\"\"\n    results = []\n\n    if frame_idx is None:\n        for lf in self.labeled_frames:\n            if lf.video == video:\n                results.append(lf)\n        return results\n\n    if np.isscalar(frame_idx):\n        frame_idx = np.array(frame_idx).reshape(-1)\n\n    for frame_ind in frame_idx:\n        result = None\n        for lf in self.labeled_frames:\n            if lf.video == video and lf.frame_idx == frame_ind:\n                result = lf\n                results.append(result)\n                break\n        if result is None and return_new:\n            results.append(LabeledFrame(video=video, frame_idx=frame_ind))\n\n    return results\n</code></pre>"},{"location":"model/#sleap_io.Labels.from_numpy","title":"<code>from_numpy(tracks_arr, videos, skeletons=None, tracks=None, first_frame=0, return_confidence=False)</code>  <code>classmethod</code>","text":"<p>Create a new Labels object from a numpy array of tracks.</p> <p>This factory method creates a new Labels object with instances constructed from the provided numpy array. It is the inverse operation of <code>Labels.numpy()</code>.</p> <p>Parameters:</p> Name Type Description Default <code>tracks_arr</code> <code>ndarray</code> <p>A numpy array of tracks, with shape <code>(n_frames, n_tracks, n_nodes, 2)</code> or <code>(n_frames, n_tracks, n_nodes, 3)</code>, where the last dimension contains the x,y coordinates (and optionally confidence scores).</p> required <code>videos</code> <code>list[Video]</code> <p>List of Video objects to associate with the labels. At least one video is required.</p> required <code>skeletons</code> <code>list[Skeleton] | Skeleton | None</code> <p>Skeleton or list of Skeleton objects to use for the instances. At least one skeleton is required.</p> <code>None</code> <code>tracks</code> <code>list[Track] | None</code> <p>List of Track objects corresponding to the second dimension of the array. If not specified, new tracks will be created automatically.</p> <code>None</code> <code>first_frame</code> <code>int</code> <p>Frame index to start the labeled frames from. Default is 0.</p> <code>0</code> <code>return_confidence</code> <code>bool</code> <p>Whether the tracks_arr contains confidence scores in the last dimension. If True, tracks_arr.shape[-1] should be 3.</p> <code>False</code> <p>Returns:</p> Type Description <code>'Labels'</code> <p>A new Labels object with instances constructed from the numpy array.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the array dimensions are invalid, or if no videos or skeletons are provided.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from sleap_io import Labels, Video, Skeleton\n&gt;&gt;&gt; # Create a simple tracking array for 2 frames, 1 track, 2 nodes\n&gt;&gt;&gt; arr = np.zeros((2, 1, 2, 2))\n&gt;&gt;&gt; arr[0, 0] = [[10, 20], [30, 40]]  # Frame 0\n&gt;&gt;&gt; arr[1, 0] = [[15, 25], [35, 45]]  # Frame 1\n&gt;&gt;&gt; # Create a video and skeleton\n&gt;&gt;&gt; video = Video(filename=\"example.mp4\")\n&gt;&gt;&gt; skeleton = Skeleton([\"head\", \"tail\"])\n&gt;&gt;&gt; # Create labels from the array\n&gt;&gt;&gt; labels = Labels.from_numpy(arr, videos=[video], skeletons=[skeleton])\n</code></pre> Source code in <code>sleap_io/model/labels.py</code> <pre><code>@classmethod\ndef from_numpy(\n    cls,\n    tracks_arr: np.ndarray,\n    videos: list[Video],\n    skeletons: list[Skeleton] | Skeleton | None = None,\n    tracks: list[Track] | None = None,\n    first_frame: int = 0,\n    return_confidence: bool = False,\n) -&gt; \"Labels\":\n    \"\"\"Create a new Labels object from a numpy array of tracks.\n\n    This factory method creates a new Labels object with instances constructed from\n    the provided numpy array. It is the inverse operation of `Labels.numpy()`.\n\n    Args:\n        tracks_arr: A numpy array of tracks, with shape\n            `(n_frames, n_tracks, n_nodes, 2)` or\n            `(n_frames, n_tracks, n_nodes, 3)`,\n            where the last dimension contains the x,y coordinates (and optionally\n            confidence scores).\n        videos: List of Video objects to associate with the labels. At least one\n            video\n            is required.\n        skeletons: Skeleton or list of Skeleton objects to use for the instances.\n            At least one skeleton is required.\n        tracks: List of Track objects corresponding to the second dimension of the\n            array. If not specified, new tracks will be created automatically.\n        first_frame: Frame index to start the labeled frames from. Default is 0.\n        return_confidence: Whether the tracks_arr contains confidence scores in the\n            last dimension. If True, tracks_arr.shape[-1] should be 3.\n\n    Returns:\n        A new Labels object with instances constructed from the numpy array.\n\n    Raises:\n        ValueError: If the array dimensions are invalid, or if no videos or\n            skeletons are provided.\n\n    Examples:\n        &gt;&gt;&gt; import numpy as np\n        &gt;&gt;&gt; from sleap_io import Labels, Video, Skeleton\n        &gt;&gt;&gt; # Create a simple tracking array for 2 frames, 1 track, 2 nodes\n        &gt;&gt;&gt; arr = np.zeros((2, 1, 2, 2))\n        &gt;&gt;&gt; arr[0, 0] = [[10, 20], [30, 40]]  # Frame 0\n        &gt;&gt;&gt; arr[1, 0] = [[15, 25], [35, 45]]  # Frame 1\n        &gt;&gt;&gt; # Create a video and skeleton\n        &gt;&gt;&gt; video = Video(filename=\"example.mp4\")\n        &gt;&gt;&gt; skeleton = Skeleton([\"head\", \"tail\"])\n        &gt;&gt;&gt; # Create labels from the array\n        &gt;&gt;&gt; labels = Labels.from_numpy(arr, videos=[video], skeletons=[skeleton])\n    \"\"\"\n    # Check dimensions\n    if len(tracks_arr.shape) != 4:\n        raise ValueError(\n            f\"Array must have 4 dimensions (n_frames, n_tracks, n_nodes, 2 or 3), \"\n            f\"but got {tracks_arr.shape}\"\n        )\n\n    # Validate videos\n    if not videos:\n        raise ValueError(\"At least one video must be provided\")\n    video = videos[0]  # Use the first video for creating labeled frames\n\n    # Process skeletons input\n    if skeletons is None:\n        raise ValueError(\"At least one skeleton must be provided\")\n    elif isinstance(skeletons, Skeleton):\n        skeletons = [skeletons]\n    elif not skeletons:  # Check for empty list\n        raise ValueError(\"At least one skeleton must be provided\")\n\n    skeleton = skeletons[0]  # Use the first skeleton for creating instances\n    n_nodes = len(skeleton.nodes)\n\n    # Check if tracks_arr contains confidence scores\n    has_confidence = tracks_arr.shape[-1] == 3 or return_confidence\n\n    # Get dimensions\n    n_frames, n_tracks_arr, _ = tracks_arr.shape[:3]\n\n    # Create or validate tracks\n    if tracks is None:\n        # Auto-create tracks if not provided\n        tracks = [Track(f\"track_{i}\") for i in range(n_tracks_arr)]\n    elif len(tracks) &lt; n_tracks_arr:\n        # Add missing tracks if needed\n        original_len = len(tracks)\n        for i in range(n_tracks_arr - original_len):\n            tracks.append(Track(f\"track_{i}\"))\n\n    # Create a new empty Labels object\n    labels = cls()\n    labels.videos = list(videos)\n    labels.skeletons = list(skeletons)\n    labels.tracks = list(tracks)\n\n    # Create labeled frames and instances from the array data\n    for i in range(n_frames):\n        frame_idx = i + first_frame\n\n        # Check if this frame has any valid data across all tracks\n        frame_has_valid_data = False\n        for j in range(n_tracks_arr):\n            track_data = tracks_arr[i, j]\n            # Check if at least one node in this track has valid xy coordinates\n            if np.any(~np.isnan(track_data[:, 0])):\n                frame_has_valid_data = True\n                break\n\n        # Skip creating a frame if there's no valid data\n        if not frame_has_valid_data:\n            continue\n\n        # Create a new labeled frame\n        labeled_frame = LabeledFrame(video=video, frame_idx=frame_idx)\n        frame_has_valid_instances = False\n\n        # Process each track in this frame\n        for j in range(n_tracks_arr):\n            track = tracks[j]\n            track_data = tracks_arr[i, j]\n\n            # Check if there's any valid data for this track at this frame\n            valid_points = ~np.isnan(track_data[:, 0])\n            if not np.any(valid_points):\n                continue\n\n            # Create points from numpy data\n            points = track_data[:, :2].copy()\n\n            # Create new instance\n            if has_confidence:\n                # Get confidence scores\n                if tracks_arr.shape[-1] == 3:\n                    scores = track_data[:, 2].copy()\n                else:\n                    scores = np.ones(n_nodes)\n\n                # Fix NaN scores\n                scores = np.where(np.isnan(scores), 1.0, scores)\n\n                # Create instance with confidence scores\n                new_instance = PredictedInstance.from_numpy(\n                    points_data=points,\n                    skeleton=skeleton,\n                    point_scores=scores,\n                    score=1.0,\n                    track=track,\n                )\n            else:\n                # Create instance with default scores\n                new_instance = PredictedInstance.from_numpy(\n                    points_data=points,\n                    skeleton=skeleton,\n                    point_scores=np.ones(n_nodes),\n                    score=1.0,\n                    track=track,\n                )\n\n            # Add to frame\n            labeled_frame.instances.append(new_instance)\n            frame_has_valid_instances = True\n\n        # Only add frames that have instances\n        if frame_has_valid_instances:\n            labels.append(labeled_frame, update=False)\n\n    # Update internal references\n    labels.update()\n\n    return labels\n</code></pre>"},{"location":"model/#sleap_io.Labels.make_training_splits","title":"<code>make_training_splits(n_train, n_val=None, n_test=None, save_dir=None, seed=None, embed=True)</code>","text":"<p>Make splits for training with embedded images.</p> <p>Parameters:</p> Name Type Description Default <code>n_train</code> <code>int | float</code> <p>Size of the training split as integer or fraction.</p> required <code>n_val</code> <code>int | float | None</code> <p>Size of the validation split as integer or fraction. If <code>None</code>, this will be inferred based on the values of <code>n_train</code> and <code>n_test</code>. If <code>n_test</code> is <code>None</code>, this will be the remainder of the data after the training split.</p> <code>None</code> <code>n_test</code> <code>int | float | None</code> <p>Size of the testing split as integer or fraction. If <code>None</code>, the test split will not be saved.</p> <code>None</code> <code>save_dir</code> <code>str | Path | None</code> <p>If specified, save splits to SLP files with embedded images.</p> <code>None</code> <code>seed</code> <code>int | None</code> <p>Optional integer seed to use for reproducibility.</p> <code>None</code> <code>embed</code> <code>bool</code> <p>If <code>True</code> (the default), embed user labeled frame images in the saved files, which is useful for portability but can be slow for large projects. If <code>False</code>, labels are saved with references to the source videos files.</p> <code>True</code> <p>Returns:</p> Type Description <code>LabelsSet</code> <p>A <code>LabelsSet</code> containing \"train\", \"val\", and optionally \"test\" keys. The <code>LabelsSet</code> can be unpacked for backward compatibility: <code>train, val = labels.make_training_splits(0.8)</code> <code>train, val, test = labels.make_training_splits(0.8, n_test=0.1)</code></p> Notes <p>Predictions and suggestions will be removed before saving, leaving only frames with user labeled data (the source labels are not affected).</p> <p>Frames with user labeled data will be embedded in the resulting files.</p> <p>If <code>save_dir</code> is specified, this will save the randomly sampled splits to:</p> <ul> <li><code>{save_dir}/train.pkg.slp</code></li> <li><code>{save_dir}/val.pkg.slp</code></li> <li><code>{save_dir}/test.pkg.slp</code> (if <code>n_test</code> is specified)</li> </ul> <p>If <code>embed</code> is <code>False</code>, the files will be saved without embedded images to:</p> <ul> <li><code>{save_dir}/train.slp</code></li> <li><code>{save_dir}/val.slp</code></li> <li><code>{save_dir}/test.slp</code> (if <code>n_test</code> is specified)</li> </ul> <p>See also: <code>Labels.split</code></p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def make_training_splits(\n    self,\n    n_train: int | float,\n    n_val: int | float | None = None,\n    n_test: int | float | None = None,\n    save_dir: str | Path | None = None,\n    seed: int | None = None,\n    embed: bool = True,\n) -&gt; LabelsSet:\n    \"\"\"Make splits for training with embedded images.\n\n    Args:\n        n_train: Size of the training split as integer or fraction.\n        n_val: Size of the validation split as integer or fraction. If `None`,\n            this will be inferred based on the values of `n_train` and `n_test`. If\n            `n_test` is `None`, this will be the remainder of the data after the\n            training split.\n        n_test: Size of the testing split as integer or fraction. If `None`, the\n            test split will not be saved.\n        save_dir: If specified, save splits to SLP files with embedded images.\n        seed: Optional integer seed to use for reproducibility.\n        embed: If `True` (the default), embed user labeled frame images in the saved\n            files, which is useful for portability but can be slow for large\n            projects. If `False`, labels are saved with references to the source\n            videos files.\n\n    Returns:\n        A `LabelsSet` containing \"train\", \"val\", and optionally \"test\" keys.\n        The `LabelsSet` can be unpacked for backward compatibility:\n        `train, val = labels.make_training_splits(0.8)`\n        `train, val, test = labels.make_training_splits(0.8, n_test=0.1)`\n\n    Notes:\n        Predictions and suggestions will be removed before saving, leaving only\n        frames with user labeled data (the source labels are not affected).\n\n        Frames with user labeled data will be embedded in the resulting files.\n\n        If `save_dir` is specified, this will save the randomly sampled splits to:\n\n        - `{save_dir}/train.pkg.slp`\n        - `{save_dir}/val.pkg.slp`\n        - `{save_dir}/test.pkg.slp` (if `n_test` is specified)\n\n        If `embed` is `False`, the files will be saved without embedded images to:\n\n        - `{save_dir}/train.slp`\n        - `{save_dir}/val.slp`\n        - `{save_dir}/test.slp` (if `n_test` is specified)\n\n    See also: `Labels.split`\n    \"\"\"\n    # Import here to avoid circular imports\n    from sleap_io.model.labels_set import LabelsSet\n\n    # Clean up labels.\n    labels = deepcopy(self)\n    labels.remove_predictions()\n    labels.suggestions = []\n    labels.clean()\n\n    # Make train split.\n    labels_train, labels_rest = labels.split(n_train, seed=seed)\n\n    # Make test split.\n    if n_test is not None:\n        if n_test &lt; 1:\n            n_test = (n_test * len(labels)) / len(labels_rest)\n        labels_test, labels_rest = labels_rest.split(n=n_test, seed=seed)\n\n    # Make val split.\n    if n_val is not None:\n        if n_val &lt; 1:\n            n_val = (n_val * len(labels)) / len(labels_rest)\n        if isinstance(n_val, float) and n_val == 1.0:\n            labels_val = labels_rest\n        else:\n            labels_val, _ = labels_rest.split(n=n_val, seed=seed)\n    else:\n        labels_val = labels_rest\n\n    # Update provenance.\n    source_labels = self.provenance.get(\"filename\", None)\n    labels_train.provenance[\"source_labels\"] = source_labels\n    if n_val is not None:\n        labels_val.provenance[\"source_labels\"] = source_labels\n    if n_test is not None:\n        labels_test.provenance[\"source_labels\"] = source_labels\n\n    # Create LabelsSet\n    if n_test is None:\n        labels_set = LabelsSet({\"train\": labels_train, \"val\": labels_val})\n    else:\n        labels_set = LabelsSet(\n            {\"train\": labels_train, \"val\": labels_val, \"test\": labels_test}\n        )\n\n    # Save.\n    if save_dir is not None:\n        labels_set.save(save_dir, embed=embed)\n\n    return labels_set\n</code></pre>"},{"location":"model/#sleap_io.Labels.merge","title":"<code>merge(other, instance_matcher=None, skeleton_matcher=None, video_matcher=None, track_matcher=None, frame_strategy='smart', validate=True, progress_callback=None, error_mode='continue')</code>","text":"<p>Merge another Labels object into this one.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>'Labels'</code> <p>Another Labels object to merge into this one.</p> required <code>instance_matcher</code> <code>Optional['InstanceMatcher']</code> <p>Matcher for comparing instances. If None, uses default spatial matching with 5px tolerance.</p> <code>None</code> <code>skeleton_matcher</code> <code>Optional['SkeletonMatcher']</code> <p>Matcher for comparing skeletons. If None, uses structure matching.</p> <code>None</code> <code>video_matcher</code> <code>Optional['VideoMatcher']</code> <p>Matcher for comparing videos. If None, uses auto matching.</p> <code>None</code> <code>track_matcher</code> <code>Optional['TrackMatcher']</code> <p>Matcher for comparing tracks. If None, uses name matching.</p> <code>None</code> <code>frame_strategy</code> <code>str</code> <p>Strategy for merging frames: - \"smart\": Keep user labels, update predictions - \"keep_original\": Keep original frames - \"keep_new\": Replace with new frames - \"keep_both\": Keep all frames</p> <code>'smart'</code> <code>validate</code> <code>bool</code> <p>If True, validate for conflicts before merging.</p> <code>True</code> <code>progress_callback</code> <code>Optional[Callable]</code> <p>Optional callback for progress updates. Should accept (current, total, message) arguments.</p> <code>None</code> <code>error_mode</code> <code>str</code> <p>How to handle errors: - \"continue\": Log errors but continue - \"strict\": Raise exception on first error - \"warn\": Print warnings but continue</p> <code>'continue'</code> <p>Returns:</p> Type Description <code>'MergeResult'</code> <p>MergeResult object with statistics and any errors/conflicts.</p> Notes <p>This method modifies the Labels object in place. The merge is designed to handle common workflows like merging predictions back into a project.</p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def merge(\n    self,\n    other: \"Labels\",\n    instance_matcher: Optional[\"InstanceMatcher\"] = None,\n    skeleton_matcher: Optional[\"SkeletonMatcher\"] = None,\n    video_matcher: Optional[\"VideoMatcher\"] = None,\n    track_matcher: Optional[\"TrackMatcher\"] = None,\n    frame_strategy: str = \"smart\",\n    validate: bool = True,\n    progress_callback: Optional[Callable] = None,\n    error_mode: str = \"continue\",\n) -&gt; \"MergeResult\":\n    \"\"\"Merge another Labels object into this one.\n\n    Args:\n        other: Another Labels object to merge into this one.\n        instance_matcher: Matcher for comparing instances. If None, uses default\n            spatial matching with 5px tolerance.\n        skeleton_matcher: Matcher for comparing skeletons. If None, uses structure\n            matching.\n        video_matcher: Matcher for comparing videos. If None, uses auto matching.\n        track_matcher: Matcher for comparing tracks. If None, uses name matching.\n        frame_strategy: Strategy for merging frames:\n            - \"smart\": Keep user labels, update predictions\n            - \"keep_original\": Keep original frames\n            - \"keep_new\": Replace with new frames\n            - \"keep_both\": Keep all frames\n        validate: If True, validate for conflicts before merging.\n        progress_callback: Optional callback for progress updates.\n            Should accept (current, total, message) arguments.\n        error_mode: How to handle errors:\n            - \"continue\": Log errors but continue\n            - \"strict\": Raise exception on first error\n            - \"warn\": Print warnings but continue\n\n    Returns:\n        MergeResult object with statistics and any errors/conflicts.\n\n    Notes:\n        This method modifies the Labels object in place. The merge is designed to\n        handle common workflows like merging predictions back into a project.\n    \"\"\"\n    from datetime import datetime\n    from pathlib import Path\n\n    from sleap_io.model.matching import (\n        ConflictResolution,\n        ErrorMode,\n        InstanceMatcher,\n        MergeError,\n        MergeResult,\n        SkeletonMatcher,\n        SkeletonMatchMethod,\n        SkeletonMismatchError,\n        TrackMatcher,\n        VideoMatcher,\n        VideoMatchMethod,\n    )\n\n    # Initialize matchers with defaults if not provided\n    if instance_matcher is None:\n        instance_matcher = InstanceMatcher()\n    if skeleton_matcher is None:\n        skeleton_matcher = SkeletonMatcher(method=SkeletonMatchMethod.STRUCTURE)\n    if video_matcher is None:\n        video_matcher = VideoMatcher()\n    if track_matcher is None:\n        track_matcher = TrackMatcher()\n\n    # Parse error mode\n    error_mode_enum = ErrorMode(error_mode)\n\n    # Initialize result\n    result = MergeResult(successful=True)\n\n    # Track merge history in provenance\n    if \"merge_history\" not in self.provenance:\n        self.provenance[\"merge_history\"] = []\n\n    merge_record = {\n        \"timestamp\": datetime.now().isoformat(),\n        \"source_labels\": {\n            \"n_frames\": len(other.labeled_frames),\n            \"n_videos\": len(other.videos),\n            \"n_skeletons\": len(other.skeletons),\n            \"n_tracks\": len(other.tracks),\n        },\n        \"strategy\": frame_strategy,\n    }\n\n    try:\n        # Step 1: Match and merge skeletons\n        skeleton_map = {}\n        for other_skel in other.skeletons:\n            matched = False\n            for self_skel in self.skeletons:\n                if skeleton_matcher.match(self_skel, other_skel):\n                    skeleton_map[other_skel] = self_skel\n                    matched = True\n                    break\n\n            if not matched:\n                if validate and error_mode_enum == ErrorMode.STRICT:\n                    raise SkeletonMismatchError(\n                        message=f\"No matching skeleton found for {other_skel.name}\",\n                        details={\"skeleton\": other_skel},\n                    )\n                elif error_mode_enum == ErrorMode.WARN:\n                    print(f\"Warning: No matching skeleton for {other_skel.name}\")\n\n                # Add new skeleton if no match\n                self.skeletons.append(other_skel)\n                skeleton_map[other_skel] = other_skel\n\n        # Step 2: Match and merge videos\n        video_map = {}\n        frame_idx_map = {}  # Maps (old_video, old_idx) -&gt; (new_video, new_idx)\n\n        for other_video in other.videos:\n            matched = False\n            for self_video in self.videos:\n                if video_matcher.match(self_video, other_video):\n                    # Special handling for different match methods\n                    if video_matcher.method == VideoMatchMethod.IMAGE_DEDUP:\n                        # Deduplicate images from other_video\n                        deduped_video = other_video.deduplicate_with(self_video)\n                        if deduped_video is None:\n                            # All images were duplicates, map to existing video\n                            video_map[other_video] = self_video\n                            # Build frame index mapping for deduplicated frames\n                            if isinstance(\n                                other_video.filename, list\n                            ) and isinstance(self_video.filename, list):\n                                other_basenames = [\n                                    Path(f).name for f in other_video.filename\n                                ]\n                                self_basenames = [\n                                    Path(f).name for f in self_video.filename\n                                ]\n                                for old_idx, basename in enumerate(other_basenames):\n                                    if basename in self_basenames:\n                                        new_idx = self_basenames.index(basename)\n                                        frame_idx_map[(other_video, old_idx)] = (\n                                            self_video,\n                                            new_idx,\n                                        )\n                        else:\n                            # Add deduplicated video as new\n                            self.videos.append(deduped_video)\n                            video_map[other_video] = deduped_video\n                            # Build frame index mapping for remaining frames\n                            if isinstance(\n                                other_video.filename, list\n                            ) and isinstance(deduped_video.filename, list):\n                                other_basenames = [\n                                    Path(f).name for f in other_video.filename\n                                ]\n                                deduped_basenames = [\n                                    Path(f).name for f in deduped_video.filename\n                                ]\n                                for old_idx, basename in enumerate(other_basenames):\n                                    if basename in deduped_basenames:\n                                        new_idx = deduped_basenames.index(basename)\n                                        frame_idx_map[(other_video, old_idx)] = (\n                                            deduped_video,\n                                            new_idx,\n                                        )\n                    elif video_matcher.method == VideoMatchMethod.SHAPE:\n                        # Merge videos with same shape\n                        merged_video = self_video.merge_with(other_video)\n                        # Replace self_video with merged version\n                        self_video_idx = self.videos.index(self_video)\n                        self.videos[self_video_idx] = merged_video\n                        video_map[other_video] = merged_video\n                        video_map[self_video] = (\n                            merged_video  # Update mapping for self too\n                        )\n                        # Build frame index mapping\n                        if isinstance(other_video.filename, list) and isinstance(\n                            merged_video.filename, list\n                        ):\n                            other_basenames = [\n                                Path(f).name for f in other_video.filename\n                            ]\n                            merged_basenames = [\n                                Path(f).name for f in merged_video.filename\n                            ]\n                            for old_idx, basename in enumerate(other_basenames):\n                                if basename in merged_basenames:\n                                    new_idx = merged_basenames.index(basename)\n                                    frame_idx_map[(other_video, old_idx)] = (\n                                        merged_video,\n                                        new_idx,\n                                    )\n                    else:\n                        # Regular matching, no special handling\n                        video_map[other_video] = self_video\n                    matched = True\n                    break\n\n            if not matched:\n                # Add new video if no match\n                self.videos.append(other_video)\n                video_map[other_video] = other_video\n\n        # Step 3: Match and merge tracks\n        track_map = {}\n        for other_track in other.tracks:\n            matched = False\n            for self_track in self.tracks:\n                if track_matcher.match(self_track, other_track):\n                    track_map[other_track] = self_track\n                    matched = True\n                    break\n\n            if not matched:\n                # Add new track if no match\n                self.tracks.append(other_track)\n                track_map[other_track] = other_track\n\n        # Step 4: Merge frames\n        total_frames = len(other.labeled_frames)\n\n        for frame_idx, other_frame in enumerate(other.labeled_frames):\n            if progress_callback:\n                progress_callback(\n                    frame_idx,\n                    total_frames,\n                    f\"Merging frame {frame_idx + 1}/{total_frames}\",\n                )\n\n            # Check if frame index needs remapping (for deduplicated/merged videos)\n            if (other_frame.video, other_frame.frame_idx) in frame_idx_map:\n                mapped_video, mapped_frame_idx = frame_idx_map[\n                    (other_frame.video, other_frame.frame_idx)\n                ]\n            else:\n                # Map video to self\n                mapped_video = video_map.get(other_frame.video, other_frame.video)\n                mapped_frame_idx = other_frame.frame_idx\n\n            # Find matching frame in self\n            matching_frames = self.find(mapped_video, mapped_frame_idx)\n\n            if len(matching_frames) == 0:\n                # No matching frame, create new one\n                new_frame = LabeledFrame(\n                    video=mapped_video,\n                    frame_idx=mapped_frame_idx,\n                    instances=[],\n                )\n\n                # Map instances to new skeleton/track\n                for inst in other_frame.instances:\n                    new_inst = self._map_instance(inst, skeleton_map, track_map)\n                    new_frame.instances.append(new_inst)\n                    result.instances_added += 1\n\n                self.append(new_frame)\n                result.frames_merged += 1\n\n            else:\n                # Merge into existing frame\n                self_frame = matching_frames[0]\n\n                # Merge instances using frame-level merge\n                merged_instances, conflicts = self_frame.merge(\n                    other_frame,\n                    instance_matcher=instance_matcher,\n                    strategy=frame_strategy,\n                )\n\n                # Remap skeleton and track references for instances from other frame\n                remapped_instances = []\n                for inst in merged_instances:\n                    # Check if instance needs remapping (from other_frame)\n                    if inst.skeleton in skeleton_map:\n                        # Instance needs remapping\n                        remapped_inst = self._map_instance(\n                            inst, skeleton_map, track_map\n                        )\n                        remapped_instances.append(remapped_inst)\n                    else:\n                        # Instance already has correct skeleton (from self_frame)\n                        remapped_instances.append(inst)\n                merged_instances = remapped_instances\n\n                # Count changes\n                n_before = len(self_frame.instances)\n                n_after = len(merged_instances)\n                result.instances_added += max(0, n_after - n_before)\n\n                # Record conflicts\n                for orig, new, resolution in conflicts:\n                    result.conflicts.append(\n                        ConflictResolution(\n                            frame=self_frame,\n                            conflict_type=\"instance_conflict\",\n                            original_data=orig,\n                            new_data=new,\n                            resolution=resolution,\n                        )\n                    )\n\n                # Update frame instances\n                self_frame.instances = merged_instances\n                result.frames_merged += 1\n\n        # Step 5: Merge suggestions\n        for other_suggestion in other.suggestions:\n            mapped_video = video_map.get(\n                other_suggestion.video, other_suggestion.video\n            )\n            # Check if suggestion already exists\n            exists = False\n            for self_suggestion in self.suggestions:\n                if (\n                    self_suggestion.video == mapped_video\n                    and self_suggestion.frame_idx == other_suggestion.frame_idx\n                ):\n                    exists = True\n                    break\n            if not exists:\n                # Create new suggestion with mapped video\n                new_suggestion = SuggestionFrame(\n                    video=mapped_video, frame_idx=other_suggestion.frame_idx\n                )\n                self.suggestions.append(new_suggestion)\n\n        # Update merge record\n        merge_record[\"result\"] = {\n            \"frames_merged\": result.frames_merged,\n            \"instances_added\": result.instances_added,\n            \"conflicts\": len(result.conflicts),\n        }\n        self.provenance[\"merge_history\"].append(merge_record)\n\n    except MergeError as e:\n        result.successful = False\n        result.errors.append(e)\n        if error_mode_enum == ErrorMode.STRICT:\n            raise\n    except Exception as e:\n        result.successful = False\n        result.errors.append(\n            MergeError(message=str(e), details={\"exception\": type(e).__name__})\n        )\n        if error_mode_enum == ErrorMode.STRICT:\n            raise\n\n    if progress_callback:\n        progress_callback(total_frames, total_frames, \"Merge complete\")\n\n    return result\n</code></pre>"},{"location":"model/#sleap_io.Labels.numpy","title":"<code>numpy(video=None, untracked=False, return_confidence=False, user_instances=True)</code>","text":"<p>Construct a numpy array from instance points.</p> <p>Parameters:</p> Name Type Description Default <code>video</code> <code>Optional[Union[Video, int]]</code> <p>Video or video index to convert to numpy arrays. If <code>None</code> (the default), uses the first video.</p> <code>None</code> <code>untracked</code> <code>bool</code> <p>If <code>False</code> (the default), include only instances that have a track assignment. If <code>True</code>, includes all instances in each frame in arbitrary order.</p> <code>False</code> <code>return_confidence</code> <code>bool</code> <p>If <code>False</code> (the default), only return points of nodes. If <code>True</code>, return the points and scores of nodes.</p> <code>False</code> <code>user_instances</code> <code>bool</code> <p>If <code>True</code> (the default), include user instances when available, preferring them over predicted instances with the same track. If <code>False</code>, only include predicted instances.</p> <code>True</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>An array of tracks of shape <code>(n_frames, n_tracks, n_nodes, 2)</code> if <code>return_confidence</code> is <code>False</code>. Otherwise returned shape is <code>(n_frames, n_tracks, n_nodes, 3)</code> if <code>return_confidence</code> is <code>True</code>.</p> <p>Missing data will be replaced with <code>np.nan</code>.</p> <p>If this is a single instance project, a track does not need to be assigned.</p> <p>When <code>user_instances=False</code>, only predicted instances will be returned. When <code>user_instances=True</code>, user instances will be preferred over predicted instances with the same track or if linked via <code>from_predicted</code>.</p> Notes <p>This method assumes that instances have tracks assigned and is intended to function primarily for single-video prediction results.</p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def numpy(\n    self,\n    video: Optional[Union[Video, int]] = None,\n    untracked: bool = False,\n    return_confidence: bool = False,\n    user_instances: bool = True,\n) -&gt; np.ndarray:\n    \"\"\"Construct a numpy array from instance points.\n\n    Args:\n        video: Video or video index to convert to numpy arrays. If `None` (the\n            default), uses the first video.\n        untracked: If `False` (the default), include only instances that have a\n            track assignment. If `True`, includes all instances in each frame in\n            arbitrary order.\n        return_confidence: If `False` (the default), only return points of nodes. If\n            `True`, return the points and scores of nodes.\n        user_instances: If `True` (the default), include user instances when\n            available, preferring them over predicted instances with the same track.\n            If `False`,\n            only include predicted instances.\n\n    Returns:\n        An array of tracks of shape `(n_frames, n_tracks, n_nodes, 2)` if\n        `return_confidence` is `False`. Otherwise returned shape is\n        `(n_frames, n_tracks, n_nodes, 3)` if `return_confidence` is `True`.\n\n        Missing data will be replaced with `np.nan`.\n\n        If this is a single instance project, a track does not need to be assigned.\n\n        When `user_instances=False`, only predicted instances will be returned.\n        When `user_instances=True`, user instances will be preferred over predicted\n        instances with the same track or if linked via `from_predicted`.\n\n    Notes:\n        This method assumes that instances have tracks assigned and is intended to\n        function primarily for single-video prediction results.\n    \"\"\"\n    # Get labeled frames for specified video.\n    if video is None:\n        video = 0\n    if type(video) is int:\n        video = self.videos[video]\n    lfs = [lf for lf in self.labeled_frames if lf.video == video]\n\n    # Figure out frame index range.\n    first_frame, last_frame = 0, 0\n    for lf in lfs:\n        first_frame = min(first_frame, lf.frame_idx)\n        last_frame = max(last_frame, lf.frame_idx)\n\n    # Figure out the number of tracks based on number of instances in each frame.\n    # Check the max number of instances (predicted or user, depending on settings)\n    n_instances = 0\n    for lf in lfs:\n        if user_instances:\n            # Count max of either user or predicted instances per frame (not sum)\n            n_frame_instances = max(\n                len(lf.user_instances), len(lf.predicted_instances)\n            )\n        else:\n            n_frame_instances = len(lf.predicted_instances)\n        n_instances = max(n_instances, n_frame_instances)\n\n    # Case 1: We don't care about order because there's only 1 instance per frame,\n    # or we're considering untracked instances.\n    is_single_instance = n_instances == 1\n    untracked = untracked or is_single_instance\n    if untracked:\n        n_tracks = n_instances\n    else:\n        # Case 2: We're considering only tracked instances.\n        n_tracks = len(self.tracks)\n\n    n_frames = int(last_frame - first_frame + 1)\n    skeleton = self.skeletons[-1]  # Assume project only uses last skeleton\n    n_nodes = len(skeleton.nodes)\n\n    if return_confidence:\n        tracks = np.full((n_frames, n_tracks, n_nodes, 3), np.nan, dtype=\"float32\")\n    else:\n        tracks = np.full((n_frames, n_tracks, n_nodes, 2), np.nan, dtype=\"float32\")\n\n    for lf in lfs:\n        i = int(lf.frame_idx - first_frame)\n\n        if untracked:\n            # For untracked instances, fill them in arbitrary order\n            j = 0\n            instances_to_include = []\n\n            # If user instances are preferred, add them first\n            if user_instances and lf.has_user_instances:\n                # First collect all user instances\n                for inst in lf.user_instances:\n                    instances_to_include.append(inst)\n\n                # For the trivial case (single instance per frame), if we found\n                # user instances, we shouldn't include any predicted instances\n                if is_single_instance and len(instances_to_include) &gt; 0:\n                    pass  # Skip adding predicted instances\n                else:\n                    # Add predicted instances that don't have a corresponding\n                    # user instance\n                    for inst in lf.predicted_instances:\n                        skip = False\n                        for user_inst in lf.user_instances:\n                            # Skip if this predicted instance is linked to a user\n                            # instance via from_predicted\n                            if (\n                                hasattr(user_inst, \"from_predicted\")\n                                and user_inst.from_predicted == inst\n                            ):\n                                skip = True\n                                break\n                            # Skip if user and predicted instances share same track\n                            if (\n                                user_inst.track is not None\n                                and inst.track is not None\n                                and user_inst.track == inst.track\n                            ):\n                                skip = True\n                                break\n                        if not skip:\n                            instances_to_include.append(inst)\n            else:\n                # If user_instances=False, only include predicted instances\n                instances_to_include = lf.predicted_instances\n\n            # Now process all the instances we want to include\n            for inst in instances_to_include:\n                if j &lt; n_tracks:\n                    if return_confidence:\n                        if isinstance(inst, PredictedInstance):\n                            tracks[i, j] = inst.numpy(scores=True)\n                        else:\n                            # For user instances, set confidence to 1.0\n                            points_data = inst.numpy()\n                            confidence = np.ones(\n                                (points_data.shape[0], 1), dtype=\"float32\"\n                            )\n                            tracks[i, j] = np.hstack((points_data, confidence))\n                    else:\n                        tracks[i, j] = inst.numpy()\n                    j += 1\n        else:  # untracked is False\n            # For tracked instances, organize by track ID\n\n            # Create mapping from track to best instance for this frame\n            track_to_instance = {}\n\n            # First, add predicted instances to the mapping\n            for inst in lf.predicted_instances:\n                if inst.track is not None:\n                    track_to_instance[inst.track] = inst\n\n            # Then, add user instances to the mapping (if user_instances=True)\n            if user_instances:\n                for inst in lf.user_instances:\n                    if inst.track is not None:\n                        track_to_instance[inst.track] = inst\n\n            # Process the preferred instances for each track\n            for track in track_to_instance:\n                inst = track_to_instance[track]\n                j = self.tracks.index(track)\n\n                if type(inst) is PredictedInstance:\n                    tracks[i, j] = inst.numpy(scores=return_confidence)\n                elif type(inst) is Instance:\n                    tracks[i, j, :, :2] = inst.numpy()\n\n                    # If return_confidence is True, add dummy confidence scores\n                    if return_confidence:\n                        tracks[i, j, :, 2] = 1.0\n\n    return tracks\n</code></pre>"},{"location":"model/#sleap_io.Labels.remove_nodes","title":"<code>remove_nodes(nodes, skeleton=None)</code>","text":"<p>Remove nodes from the skeleton.</p> <p>Parameters:</p> Name Type Description Default <code>nodes</code> <code>list[NodeOrIndex]</code> <p>A list of node names, indices, or <code>Node</code> objects to remove.</p> required <code>skeleton</code> <code>Skeleton | None</code> <p><code>Skeleton</code> to update. If <code>None</code> (the default), assumes there is only one skeleton in the labels and raises <code>ValueError</code> otherwise.</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the nodes are not found in the skeleton, or if there is more than one skeleton in the labels and it is not specified.</p> Notes <p>This method should always be used when removing nodes from the skeleton as it handles updating the lookup caches necessary for indexing nodes by name, and updating instances to reflect the changes made to the skeleton.</p> <p>Any edges and symmetries that are connected to the removed nodes will also be removed.</p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def remove_nodes(self, nodes: list[NodeOrIndex], skeleton: Skeleton | None = None):\n    \"\"\"Remove nodes from the skeleton.\n\n    Args:\n        nodes: A list of node names, indices, or `Node` objects to remove.\n        skeleton: `Skeleton` to update. If `None` (the default), assumes there is\n            only one skeleton in the labels and raises `ValueError` otherwise.\n\n    Raises:\n        ValueError: If the nodes are not found in the skeleton, or if there is more\n            than one skeleton in the labels and it is not specified.\n\n    Notes:\n        This method should always be used when removing nodes from the skeleton as\n        it handles updating the lookup caches necessary for indexing nodes by name,\n        and updating instances to reflect the changes made to the skeleton.\n\n        Any edges and symmetries that are connected to the removed nodes will also\n        be removed.\n    \"\"\"\n    if skeleton is None:\n        if len(self.skeletons) != 1:\n            raise ValueError(\n                \"Skeleton must be specified when there is more than one skeleton \"\n                \"in the labels.\"\n            )\n        skeleton = self.skeleton\n\n    skeleton.remove_nodes(nodes)\n\n    for inst in self.instances:\n        if inst.skeleton == skeleton:\n            inst.update_skeleton()\n</code></pre>"},{"location":"model/#sleap_io.Labels.remove_predictions","title":"<code>remove_predictions(clean=True)</code>","text":"<p>Remove all predicted instances from the labels.</p> <p>Parameters:</p> Name Type Description Default <code>clean</code> <code>bool</code> <p>If <code>True</code> (the default), also remove any empty frames and unused tracks and skeletons. It does NOT remove videos that have no labeled frames or instances with no visible points.</p> <code>True</code> <p>See also: <code>Labels.clean</code></p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def remove_predictions(self, clean: bool = True):\n    \"\"\"Remove all predicted instances from the labels.\n\n    Args:\n        clean: If `True` (the default), also remove any empty frames and unused\n            tracks and skeletons. It does NOT remove videos that have no labeled\n            frames or instances with no visible points.\n\n    See also: `Labels.clean`\n    \"\"\"\n    for lf in self.labeled_frames:\n        lf.remove_predictions()\n\n    if clean:\n        self.clean(\n            frames=True,\n            empty_instances=False,\n            skeletons=True,\n            tracks=True,\n            videos=False,\n        )\n</code></pre>"},{"location":"model/#sleap_io.Labels.rename_nodes","title":"<code>rename_nodes(name_map, skeleton=None)</code>","text":"<p>Rename nodes in the skeleton.</p> <p>Parameters:</p> Name Type Description Default <code>name_map</code> <code>dict[NodeOrIndex, str] | list[str]</code> <p>A dictionary mapping old node names to new node names. Keys can be specified as <code>Node</code> objects, integer indices, or string names. Values must be specified as string names.</p> <p>If a list of strings is provided of the same length as the current nodes, the nodes will be renamed to the names in the list in order.</p> required <code>skeleton</code> <code>Skeleton | None</code> <p><code>Skeleton</code> to update. If <code>None</code> (the default), assumes there is only one skeleton in the labels and raises <code>ValueError</code> otherwise.</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the new node names exist in the skeleton, if the old node names are not found in the skeleton, or if there is more than one skeleton in the <code>Labels</code> but it is not specified.</p> Notes <p>This method is recommended over <code>Skeleton.rename_nodes</code> as it will update all instances in the labels to reflect the new node names.</p> Example <p>labels = Labels(skeletons=[Skeleton([\"A\", \"B\", \"C\"])]) labels.rename_nodes({\"A\": \"X\", \"B\": \"Y\", \"C\": \"Z\"}) labels.skeleton.node_names [\"X\", \"Y\", \"Z\"] labels.rename_nodes([\"a\", \"b\", \"c\"]) labels.skeleton.node_names [\"a\", \"b\", \"c\"]</p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def rename_nodes(\n    self,\n    name_map: dict[NodeOrIndex, str] | list[str],\n    skeleton: Skeleton | None = None,\n):\n    \"\"\"Rename nodes in the skeleton.\n\n    Args:\n        name_map: A dictionary mapping old node names to new node names. Keys can be\n            specified as `Node` objects, integer indices, or string names. Values\n            must be specified as string names.\n\n            If a list of strings is provided of the same length as the current\n            nodes, the nodes will be renamed to the names in the list in order.\n        skeleton: `Skeleton` to update. If `None` (the default), assumes there is\n            only one skeleton in the labels and raises `ValueError` otherwise.\n\n    Raises:\n        ValueError: If the new node names exist in the skeleton, if the old node\n            names are not found in the skeleton, or if there is more than one\n            skeleton in the `Labels` but it is not specified.\n\n    Notes:\n        This method is recommended over `Skeleton.rename_nodes` as it will update\n        all instances in the labels to reflect the new node names.\n\n    Example:\n        &gt;&gt;&gt; labels = Labels(skeletons=[Skeleton([\"A\", \"B\", \"C\"])])\n        &gt;&gt;&gt; labels.rename_nodes({\"A\": \"X\", \"B\": \"Y\", \"C\": \"Z\"})\n        &gt;&gt;&gt; labels.skeleton.node_names\n        [\"X\", \"Y\", \"Z\"]\n        &gt;&gt;&gt; labels.rename_nodes([\"a\", \"b\", \"c\"])\n        &gt;&gt;&gt; labels.skeleton.node_names\n        [\"a\", \"b\", \"c\"]\n    \"\"\"\n    if skeleton is None:\n        if len(self.skeletons) != 1:\n            raise ValueError(\n                \"Skeleton must be specified when there is more than one skeleton \"\n                \"in the labels.\"\n            )\n        skeleton = self.skeleton\n\n    skeleton.rename_nodes(name_map)\n\n    # Update instances.\n    for inst in self.instances:\n        if inst.skeleton == skeleton:\n            inst.points[\"name\"] = inst.skeleton.node_names\n</code></pre>"},{"location":"model/#sleap_io.Labels.reorder_nodes","title":"<code>reorder_nodes(new_order, skeleton=None)</code>","text":"<p>Reorder nodes in the skeleton.</p> <p>Parameters:</p> Name Type Description Default <code>new_order</code> <code>list[NodeOrIndex]</code> <p>A list of node names, indices, or <code>Node</code> objects specifying the new order of the nodes.</p> required <code>skeleton</code> <code>Skeleton | None</code> <p><code>Skeleton</code> to update. If <code>None</code> (the default), assumes there is only one skeleton in the labels and raises <code>ValueError</code> otherwise.</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the new order of nodes is not the same length as the current nodes, or if there is more than one skeleton in the <code>Labels</code> but it is not specified.</p> Notes <p>This method handles updating the lookup caches necessary for indexing nodes by name, as well as updating instances to reflect the changes made to the skeleton.</p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def reorder_nodes(\n    self, new_order: list[NodeOrIndex], skeleton: Skeleton | None = None\n):\n    \"\"\"Reorder nodes in the skeleton.\n\n    Args:\n        new_order: A list of node names, indices, or `Node` objects specifying the\n            new order of the nodes.\n        skeleton: `Skeleton` to update. If `None` (the default), assumes there is\n            only one skeleton in the labels and raises `ValueError` otherwise.\n\n    Raises:\n        ValueError: If the new order of nodes is not the same length as the current\n            nodes, or if there is more than one skeleton in the `Labels` but it is\n            not specified.\n\n    Notes:\n        This method handles updating the lookup caches necessary for indexing nodes\n        by name, as well as updating instances to reflect the changes made to the\n        skeleton.\n    \"\"\"\n    if skeleton is None:\n        if len(self.skeletons) != 1:\n            raise ValueError(\n                \"Skeleton must be specified when there is more than one skeleton \"\n                \"in the labels.\"\n            )\n        skeleton = self.skeleton\n\n    skeleton.reorder_nodes(new_order)\n\n    for inst in self.instances:\n        if inst.skeleton == skeleton:\n            inst.update_skeleton()\n</code></pre>"},{"location":"model/#sleap_io.Labels.replace_filenames","title":"<code>replace_filenames(new_filenames=None, filename_map=None, prefix_map=None, open_videos=True)</code>","text":"<p>Replace video filenames.</p> <p>Parameters:</p> Name Type Description Default <code>new_filenames</code> <code>list[str | Path] | None</code> <p>List of new filenames. Must have the same length as the number of videos in the labels.</p> <code>None</code> <code>filename_map</code> <code>dict[str | Path, str | Path] | None</code> <p>Dictionary mapping old filenames (keys) to new filenames (values).</p> <code>None</code> <code>prefix_map</code> <code>dict[str | Path, str | Path] | None</code> <p>Dictionary mapping old prefixes (keys) to new prefixes (values).</p> <code>None</code> <code>open_videos</code> <code>bool</code> <p>If <code>True</code> (the default), attempt to open the video backend for I/O after replacing the filename. If <code>False</code>, the backend will not be opened (useful for operations with costly file existence checks).</p> <code>True</code> Notes <p>Only one of the argument types can be provided.</p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def replace_filenames(\n    self,\n    new_filenames: list[str | Path] | None = None,\n    filename_map: dict[str | Path, str | Path] | None = None,\n    prefix_map: dict[str | Path, str | Path] | None = None,\n    open_videos: bool = True,\n):\n    \"\"\"Replace video filenames.\n\n    Args:\n        new_filenames: List of new filenames. Must have the same length as the\n            number of videos in the labels.\n        filename_map: Dictionary mapping old filenames (keys) to new filenames\n            (values).\n        prefix_map: Dictionary mapping old prefixes (keys) to new prefixes (values).\n        open_videos: If `True` (the default), attempt to open the video backend for\n            I/O after replacing the filename. If `False`, the backend will not be\n            opened (useful for operations with costly file existence checks).\n\n    Notes:\n        Only one of the argument types can be provided.\n    \"\"\"\n    n = 0\n    if new_filenames is not None:\n        n += 1\n    if filename_map is not None:\n        n += 1\n    if prefix_map is not None:\n        n += 1\n    if n != 1:\n        raise ValueError(\n            \"Exactly one input method must be provided to replace filenames.\"\n        )\n\n    if new_filenames is not None:\n        if len(self.videos) != len(new_filenames):\n            raise ValueError(\n                f\"Number of new filenames ({len(new_filenames)}) does not match \"\n                f\"the number of videos ({len(self.videos)}).\"\n            )\n\n        for video, new_filename in zip(self.videos, new_filenames):\n            video.replace_filename(new_filename, open=open_videos)\n\n    elif filename_map is not None:\n        for video in self.videos:\n            for old_fn, new_fn in filename_map.items():\n                if type(video.filename) is list:\n                    new_fns = []\n                    for fn in video.filename:\n                        if Path(fn) == Path(old_fn):\n                            new_fns.append(new_fn)\n                        else:\n                            new_fns.append(fn)\n                    video.replace_filename(new_fns, open=open_videos)\n                else:\n                    if Path(video.filename) == Path(old_fn):\n                        video.replace_filename(new_fn, open=open_videos)\n\n    elif prefix_map is not None:\n        for video in self.videos:\n            for old_prefix, new_prefix in prefix_map.items():\n                # Sanitize old_prefix for cross-platform matching\n                old_prefix_sanitized = sanitize_filename(old_prefix)\n\n                # Check if old prefix ends with a separator\n                old_ends_with_sep = old_prefix_sanitized.endswith(\"/\")\n\n                if type(video.filename) is list:\n                    new_fns = []\n                    for fn in video.filename:\n                        # Sanitize filename for matching\n                        fn_sanitized = sanitize_filename(fn)\n\n                        if fn_sanitized.startswith(old_prefix_sanitized):\n                            # Calculate the remainder after removing the prefix\n                            remainder = fn_sanitized[len(old_prefix_sanitized) :]\n\n                            # Build the new filename\n                            if remainder.startswith(\"/\"):\n                                # Remainder has separator, remove it to avoid double\n                                # slash\n                                remainder = remainder[1:]\n                                # Always add separator between prefix and remainder\n                                if new_prefix and not new_prefix.endswith(\n                                    (\"/\", \"\\\\\")\n                                ):\n                                    new_fn = new_prefix + \"/\" + remainder\n                                else:\n                                    new_fn = new_prefix + remainder\n                            elif old_ends_with_sep:\n                                # Old prefix had separator, preserve it in the new\n                                # one\n                                if new_prefix and not new_prefix.endswith(\n                                    (\"/\", \"\\\\\")\n                                ):\n                                    new_fn = new_prefix + \"/\" + remainder\n                                else:\n                                    new_fn = new_prefix + remainder\n                            else:\n                                # No separator in old prefix, don't add one\n                                new_fn = new_prefix + remainder\n\n                            new_fns.append(new_fn)\n                        else:\n                            new_fns.append(fn)\n                    video.replace_filename(new_fns, open=open_videos)\n                else:\n                    # Sanitize filename for matching\n                    fn_sanitized = sanitize_filename(video.filename)\n\n                    if fn_sanitized.startswith(old_prefix_sanitized):\n                        # Calculate the remainder after removing the prefix\n                        remainder = fn_sanitized[len(old_prefix_sanitized) :]\n\n                        # Build the new filename\n                        if remainder.startswith(\"/\"):\n                            # Remainder has separator, remove it to avoid double\n                            # slash\n                            remainder = remainder[1:]\n                            # Always add separator between prefix and remainder\n                            if new_prefix and not new_prefix.endswith((\"/\", \"\\\\\")):\n                                new_fn = new_prefix + \"/\" + remainder\n                            else:\n                                new_fn = new_prefix + remainder\n                        elif old_ends_with_sep:\n                            # Old prefix had separator, preserve it in the new one\n                            if new_prefix and not new_prefix.endswith((\"/\", \"\\\\\")):\n                                new_fn = new_prefix + \"/\" + remainder\n                            else:\n                                new_fn = new_prefix + remainder\n                        else:\n                            # No separator in old prefix, don't add one\n                            new_fn = new_prefix + remainder\n\n                        video.replace_filename(new_fn, open=open_videos)\n</code></pre>"},{"location":"model/#sleap_io.Labels.replace_skeleton","title":"<code>replace_skeleton(new_skeleton, old_skeleton=None, node_map=None)</code>","text":"<p>Replace the skeleton in the labels.</p> <p>Parameters:</p> Name Type Description Default <code>new_skeleton</code> <code>Skeleton</code> <p>The new <code>Skeleton</code> to replace the old skeleton with.</p> required <code>old_skeleton</code> <code>Skeleton | None</code> <p>The old <code>Skeleton</code> to replace. If <code>None</code> (the default), assumes there is only one skeleton in the labels and raises <code>ValueError</code> otherwise.</p> <code>None</code> <code>node_map</code> <code>dict[NodeOrIndex, NodeOrIndex] | None</code> <p>Dictionary mapping nodes in the old skeleton to nodes in the new skeleton. Keys and values can be specified as <code>Node</code> objects, integer indices, or string names. If not provided, only nodes with identical names will be mapped. Points associated with unmapped nodes will be removed.</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If there is more than one skeleton in the <code>Labels</code> but it is not specified.</p> Warning <p>This method will replace the skeleton in all instances in the labels that have the old skeleton. All point data associated with nodes not in the <code>node_map</code> will be lost.</p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def replace_skeleton(\n    self,\n    new_skeleton: Skeleton,\n    old_skeleton: Skeleton | None = None,\n    node_map: dict[NodeOrIndex, NodeOrIndex] | None = None,\n):\n    \"\"\"Replace the skeleton in the labels.\n\n    Args:\n        new_skeleton: The new `Skeleton` to replace the old skeleton with.\n        old_skeleton: The old `Skeleton` to replace. If `None` (the default),\n            assumes there is only one skeleton in the labels and raises `ValueError`\n            otherwise.\n        node_map: Dictionary mapping nodes in the old skeleton to nodes in the new\n            skeleton. Keys and values can be specified as `Node` objects, integer\n            indices, or string names. If not provided, only nodes with identical\n            names will be mapped. Points associated with unmapped nodes will be\n            removed.\n\n    Raises:\n        ValueError: If there is more than one skeleton in the `Labels` but it is not\n            specified.\n\n    Warning:\n        This method will replace the skeleton in all instances in the labels that\n        have the old skeleton. **All point data associated with nodes not in the\n        `node_map` will be lost.**\n    \"\"\"\n    if old_skeleton is None:\n        if len(self.skeletons) != 1:\n            raise ValueError(\n                \"Old skeleton must be specified when there is more than one \"\n                \"skeleton in the labels.\"\n            )\n        old_skeleton = self.skeleton\n\n    if node_map is None:\n        node_map = {}\n        for old_node in old_skeleton.nodes:\n            for new_node in new_skeleton.nodes:\n                if old_node.name == new_node.name:\n                    node_map[old_node] = new_node\n                    break\n    else:\n        node_map = {\n            old_skeleton.require_node(\n                old, add_missing=False\n            ): new_skeleton.require_node(new, add_missing=False)\n            for old, new in node_map.items()\n        }\n\n    # Create node name map.\n    node_names_map = {old.name: new.name for old, new in node_map.items()}\n\n    # Replace the skeleton in the instances.\n    for inst in self.instances:\n        if inst.skeleton == old_skeleton:\n            inst.replace_skeleton(\n                new_skeleton=new_skeleton, node_names_map=node_names_map\n            )\n\n    # Replace the skeleton in the labels.\n    self.skeletons[self.skeletons.index(old_skeleton)] = new_skeleton\n</code></pre>"},{"location":"model/#sleap_io.Labels.replace_videos","title":"<code>replace_videos(old_videos=None, new_videos=None, video_map=None)</code>","text":"<p>Replace videos and update all references.</p> <p>Parameters:</p> Name Type Description Default <code>old_videos</code> <code>list[Video] | None</code> <p>List of videos to be replaced.</p> <code>None</code> <code>new_videos</code> <code>list[Video] | None</code> <p>List of videos to replace with.</p> <code>None</code> <code>video_map</code> <code>dict[Video, Video] | None</code> <p>Alternative input of dictionary where keys are the old videos and values are the new videos.</p> <code>None</code> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def replace_videos(\n    self,\n    old_videos: list[Video] | None = None,\n    new_videos: list[Video] | None = None,\n    video_map: dict[Video, Video] | None = None,\n):\n    \"\"\"Replace videos and update all references.\n\n    Args:\n        old_videos: List of videos to be replaced.\n        new_videos: List of videos to replace with.\n        video_map: Alternative input of dictionary where keys are the old videos and\n            values are the new videos.\n    \"\"\"\n    if (\n        old_videos is None\n        and new_videos is not None\n        and len(new_videos) == len(self.videos)\n    ):\n        old_videos = self.videos\n\n    if video_map is None:\n        video_map = {o: n for o, n in zip(old_videos, new_videos)}\n\n    # Update the labeled frames with the new videos.\n    for lf in self.labeled_frames:\n        if lf.video in video_map:\n            lf.video = video_map[lf.video]\n\n    # Update suggestions with the new videos.\n    for sf in self.suggestions:\n        if sf.video in video_map:\n            sf.video = video_map[sf.video]\n\n    # Update the list of videos.\n    self.videos = [video_map.get(video, video) for video in self.videos]\n</code></pre>"},{"location":"model/#sleap_io.Labels.save","title":"<code>save(filename, format=None, embed=False, restore_original_videos=True, verbose=True, **kwargs)</code>","text":"<p>Save labels to file in specified format.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>Path to save labels to.</p> required <code>format</code> <code>Optional[str]</code> <p>The format to save the labels in. If <code>None</code>, the format will be inferred from the file extension. Available formats are <code>\"slp\"</code>, <code>\"nwb\"</code>, <code>\"labelstudio\"</code>, and <code>\"jabs\"</code>.</p> <code>None</code> <code>embed</code> <code>bool | str | list[tuple[Video, int]] | None</code> <p>Frames to embed in the saved labels file. One of <code>None</code>, <code>True</code>, <code>\"all\"</code>, <code>\"user\"</code>, <code>\"suggestions\"</code>, <code>\"user+suggestions\"</code>, <code>\"source\"</code> or list of tuples of <code>(video, frame_idx)</code>.</p> <p>If <code>False</code> is specified (the default), the source video will be restored if available, otherwise the embedded frames will be re-saved.</p> <p>If <code>True</code> or <code>\"all\"</code>, all labeled frames and suggested frames will be embedded.</p> <p>If <code>\"source\"</code> is specified, no images will be embedded and the source video will be restored if available.</p> <p>This argument is only valid for the SLP backend.</p> <code>False</code> <code>restore_original_videos</code> <code>bool</code> <p>If <code>True</code> (default) and <code>embed=False</code>, use original video files. If <code>False</code> and <code>embed=False</code>, keep references to source <code>.pkg.slp</code> files. Only applies when <code>embed=False</code>.</p> <code>True</code> <code>verbose</code> <code>bool</code> <p>If <code>True</code> (the default), display a progress bar when embedding frames.</p> <code>True</code> <code>**kwargs</code> <p>Additional format-specific arguments passed to the save function. See <code>save_file</code> for format-specific options.</p> <code>{}</code> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def save(\n    self,\n    filename: str,\n    format: Optional[str] = None,\n    embed: bool | str | list[tuple[Video, int]] | None = False,\n    restore_original_videos: bool = True,\n    verbose: bool = True,\n    **kwargs,\n):\n    \"\"\"Save labels to file in specified format.\n\n    Args:\n        filename: Path to save labels to.\n        format: The format to save the labels in. If `None`, the format will be\n            inferred from the file extension. Available formats are `\"slp\"`,\n            `\"nwb\"`, `\"labelstudio\"`, and `\"jabs\"`.\n        embed: Frames to embed in the saved labels file. One of `None`, `True`,\n            `\"all\"`, `\"user\"`, `\"suggestions\"`, `\"user+suggestions\"`, `\"source\"` or\n            list of tuples of `(video, frame_idx)`.\n\n            If `False` is specified (the default), the source video will be\n            restored if available, otherwise the embedded frames will be re-saved.\n\n            If `True` or `\"all\"`, all labeled frames and suggested frames will be\n            embedded.\n\n            If `\"source\"` is specified, no images will be embedded and the source\n            video will be restored if available.\n\n            This argument is only valid for the SLP backend.\n        restore_original_videos: If `True` (default) and `embed=False`, use original\n            video files. If `False` and `embed=False`, keep references to source\n            `.pkg.slp` files. Only applies when `embed=False`.\n        verbose: If `True` (the default), display a progress bar when embedding\n            frames.\n        **kwargs: Additional format-specific arguments passed to the save function.\n            See `save_file` for format-specific options.\n    \"\"\"\n    from pathlib import Path\n\n    from sleap_io import save_file\n    from sleap_io.io.slp import sanitize_filename\n\n    # Check for self-referential save when embed=False\n    if embed is False and (format == \"slp\" or str(filename).endswith(\".slp\")):\n        # Check if any videos have embedded images and would be self-referential\n        sanitized_save_path = Path(sanitize_filename(filename)).resolve()\n        for video in self.videos:\n            if (\n                hasattr(video.backend, \"has_embedded_images\")\n                and video.backend.has_embedded_images\n                and video.source_video is None\n            ):\n                sanitized_video_path = Path(\n                    sanitize_filename(video.filename)\n                ).resolve()\n                if sanitized_video_path == sanitized_save_path:\n                    raise ValueError(\n                        f\"Cannot save with embed=False when overwriting a file \"\n                        f\"that contains embedded videos. Use \"\n                        f\"labels.save('{filename}', embed=True) to re-embed the \"\n                        f\"frames, or save to a different filename.\"\n                    )\n\n    save_file(\n        self,\n        filename,\n        format=format,\n        embed=embed,\n        restore_original_videos=restore_original_videos,\n        verbose=verbose,\n        **kwargs,\n    )\n</code></pre>"},{"location":"model/#sleap_io.Labels.set_video_plugin","title":"<code>set_video_plugin(plugin)</code>","text":"<p>Reopen all media videos with the specified plugin.</p> <p>Parameters:</p> Name Type Description Default <code>plugin</code> <code>str</code> <p>Video plugin to use. One of \"opencv\", \"FFMPEG\", or \"pyav\". Also accepts aliases (case-insensitive).</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; labels.set_video_plugin(\"opencv\")\n&gt;&gt;&gt; labels.set_video_plugin(\"FFMPEG\")\n</code></pre> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def set_video_plugin(self, plugin: str) -&gt; None:\n    \"\"\"Reopen all media videos with the specified plugin.\n\n    Args:\n        plugin: Video plugin to use. One of \"opencv\", \"FFMPEG\", or \"pyav\".\n            Also accepts aliases (case-insensitive).\n\n    Examples:\n        &gt;&gt;&gt; labels.set_video_plugin(\"opencv\")\n        &gt;&gt;&gt; labels.set_video_plugin(\"FFMPEG\")\n    \"\"\"\n    from sleap_io.io.video_reading import MediaVideo\n\n    for video in self.videos:\n        if video.filename.endswith(MediaVideo.EXTS):\n            video.set_video_plugin(plugin)\n</code></pre>"},{"location":"model/#sleap_io.Labels.split","title":"<code>split(n, seed=None)</code>","text":"<p>Separate the labels into random splits.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int | float</code> <p>Size of the first split. If integer &gt;= 1, assumes that this is the number of labeled frames in the first split. If &lt; 1.0, this will be treated as a fraction of the total labeled frames.</p> required <code>seed</code> <code>int | None</code> <p>Optional integer seed to use for reproducibility.</p> <code>None</code> <p>Returns:</p> Type Description <p>A LabelsSet with keys \"split1\" and \"split2\".</p> <p>If an integer was specified, <code>len(split1) == n</code>.</p> <p>If a fraction was specified, <code>len(split1) == int(n * len(labels))</code>.</p> <p>The second split contains the remainder, i.e., <code>len(split2) == len(labels) - len(split1)</code>.</p> <p>If there are too few frames, a minimum of 1 frame will be kept in the second split.</p> <p>If there is exactly 1 labeled frame in the labels, the same frame will be assigned to both splits.</p> Notes <p>This method now returns a LabelsSet for easier management of splits. For backward compatibility, the returned LabelsSet can be unpacked like a tuple: <code>split1, split2 = labels.split(0.8)</code></p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def split(self, n: int | float, seed: int | None = None):\n    \"\"\"Separate the labels into random splits.\n\n    Args:\n        n: Size of the first split. If integer &gt;= 1, assumes that this is the number\n            of labeled frames in the first split. If &lt; 1.0, this will be treated as\n            a fraction of the total labeled frames.\n        seed: Optional integer seed to use for reproducibility.\n\n    Returns:\n        A LabelsSet with keys \"split1\" and \"split2\".\n\n        If an integer was specified, `len(split1) == n`.\n\n        If a fraction was specified, `len(split1) == int(n * len(labels))`.\n\n        The second split contains the remainder, i.e.,\n        `len(split2) == len(labels) - len(split1)`.\n\n        If there are too few frames, a minimum of 1 frame will be kept in the second\n        split.\n\n        If there is exactly 1 labeled frame in the labels, the same frame will be\n        assigned to both splits.\n\n    Notes:\n        This method now returns a LabelsSet for easier management of splits.\n        For backward compatibility, the returned LabelsSet can be unpacked like\n        a tuple:\n        `split1, split2 = labels.split(0.8)`\n    \"\"\"\n    # Import here to avoid circular imports\n    from sleap_io.model.labels_set import LabelsSet\n\n    n0 = len(self)\n    if n0 == 0:\n        return LabelsSet({\"split1\": self, \"split2\": self})\n    n1 = n\n    if n &lt; 1.0:\n        n1 = max(int(n0 * float(n)), 1)\n    n2 = max(n0 - n1, 1)\n    n1, n2 = int(n1), int(n2)\n\n    rng = np.random.default_rng(seed=seed)\n    inds1 = rng.choice(n0, size=(n1,), replace=False)\n\n    if n0 == 1:\n        inds2 = np.array([0])\n    else:\n        inds2 = np.setdiff1d(np.arange(n0), inds1)\n\n    split1 = self.extract(inds1, copy=True)\n    split2 = self.extract(inds2, copy=True)\n\n    return LabelsSet({\"split1\": split1, \"split2\": split2})\n</code></pre>"},{"location":"model/#sleap_io.Labels.trim","title":"<code>trim(save_path, frame_inds, video=None, video_kwargs=None)</code>","text":"<p>Trim the labels to a subset of frames and videos accordingly.</p> <p>Parameters:</p> Name Type Description Default <code>save_path</code> <code>str | Path</code> <p>Path to the trimmed labels SLP file. Video will be saved with the same base name but with .mp4 extension.</p> required <code>frame_inds</code> <code>list[int] | ndarray</code> <p>Frame indices to save. Can be specified as a list or array of frame integers.</p> required <code>video</code> <code>Video | int | None</code> <p>Video or integer index of the video to trim. Does not need to be specified for single-video projects.</p> <code>None</code> <code>video_kwargs</code> <code>dict[str, Any] | None</code> <p>A dictionary of keyword arguments to provide to <code>sio.save_video</code> for video compression.</p> <code>None</code> <p>Returns:</p> Type Description <code>Labels</code> <p>The resulting labels object referencing the trimmed data.</p> Notes <p>This will remove any data outside of the trimmed frames, save new videos, and adjust the frame indices to match the newly trimmed videos.</p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def trim(\n    self,\n    save_path: str | Path,\n    frame_inds: list[int] | np.ndarray,\n    video: Video | int | None = None,\n    video_kwargs: dict[str, Any] | None = None,\n) -&gt; Labels:\n    \"\"\"Trim the labels to a subset of frames and videos accordingly.\n\n    Args:\n        save_path: Path to the trimmed labels SLP file. Video will be saved with the\n            same base name but with .mp4 extension.\n        frame_inds: Frame indices to save. Can be specified as a list or array of\n            frame integers.\n        video: Video or integer index of the video to trim. Does not need to be\n            specified for single-video projects.\n        video_kwargs: A dictionary of keyword arguments to provide to\n            `sio.save_video` for video compression.\n\n    Returns:\n        The resulting labels object referencing the trimmed data.\n\n    Notes:\n        This will remove any data outside of the trimmed frames, save new videos,\n        and adjust the frame indices to match the newly trimmed videos.\n    \"\"\"\n    if video is None:\n        if len(self.videos) == 1:\n            video = self.video\n        else:\n            raise ValueError(\n                \"Video needs to be specified when trimming multi-video projects.\"\n            )\n    if type(video) is int:\n        video = self.videos[video]\n\n    # Write trimmed clip.\n    save_path = Path(save_path)\n    video_path = save_path.with_suffix(\".mp4\")\n    fidx0, fidx1 = np.min(frame_inds), np.max(frame_inds)\n    new_video = video.save(\n        video_path,\n        frame_inds=np.arange(fidx0, fidx1 + 1),\n        video_kwargs=video_kwargs,\n    )\n\n    # Get frames in range.\n    # TODO: Create an optimized search function for this access pattern.\n    inds = []\n    for ind, lf in enumerate(self):\n        if lf.video == video and lf.frame_idx &gt;= fidx0 and lf.frame_idx &lt;= fidx1:\n            inds.append(ind)\n    trimmed_labels = self.extract(inds, copy=True)\n\n    # Adjust video and frame indices.\n    trimmed_labels.videos = [new_video]\n    for lf in trimmed_labels:\n        lf.video = new_video\n        lf.frame_idx = lf.frame_idx - fidx0\n\n    # Save.\n    trimmed_labels.save(save_path)\n\n    return trimmed_labels\n</code></pre>"},{"location":"model/#sleap_io.Labels.update","title":"<code>update()</code>","text":"<p>Update data structures based on contents.</p> <p>This function will update the list of skeletons, videos and tracks from the labeled frames, instances and suggestions.</p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def update(self):\n    \"\"\"Update data structures based on contents.\n\n    This function will update the list of skeletons, videos and tracks from the\n    labeled frames, instances and suggestions.\n    \"\"\"\n    for lf in self.labeled_frames:\n        if lf.video not in self.videos:\n            self.videos.append(lf.video)\n\n        for inst in lf:\n            if inst.skeleton not in self.skeletons:\n                self.skeletons.append(inst.skeleton)\n\n            if inst.track is not None and inst.track not in self.tracks:\n                self.tracks.append(inst.track)\n\n    for sf in self.suggestions:\n        if sf.video not in self.videos:\n            self.videos.append(sf.video)\n</code></pre>"},{"location":"model/#sleap_io.Labels.update_from_numpy","title":"<code>update_from_numpy(tracks_arr, video=None, tracks=None, create_missing=True)</code>","text":"<p>Update instances from a numpy array of tracks.</p> <p>This function updates the points in existing instances, and creates new instances for tracks that don't have a corresponding instance in a frame.</p> <p>Parameters:</p> Name Type Description Default <code>tracks_arr</code> <code>ndarray</code> <p>A numpy array of tracks, with shape <code>(n_frames, n_tracks, n_nodes, 2)</code> or <code>(n_frames, n_tracks, n_nodes, 3)</code>, where the last dimension contains the x,y coordinates (and optionally confidence scores).</p> required <code>video</code> <code>Optional[Union[Video, int]]</code> <p>The video to update instances for. If not specified, the first video in the labels will be used if there is only one video.</p> <code>None</code> <code>tracks</code> <code>Optional[list[Track]]</code> <p>List of <code>Track</code> objects corresponding to the second dimension of the array. If not specified, <code>self.tracks</code> will be used, and must have the same length as the second dimension of the array.</p> <code>None</code> <code>create_missing</code> <code>bool</code> <p>If <code>True</code> (the default), creates new <code>PredictedInstance</code>s for tracks that don't have corresponding instances in a frame. If <code>False</code>, only updates existing instances.</p> <code>True</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the video cannot be determined, or if tracks are not specified and the number of tracks in the array doesn't match the number of tracks in the labels.</p> Notes <p>This method is the inverse of <code>Labels.numpy()</code>, and can be used to update instance points after modifying the numpy array.</p> <p>If the array has a third dimension with shape 3 (tracks_arr.shape[-1] == 3), the last channel is assumed to be confidence scores.</p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def update_from_numpy(\n    self,\n    tracks_arr: np.ndarray,\n    video: Optional[Union[Video, int]] = None,\n    tracks: Optional[list[Track]] = None,\n    create_missing: bool = True,\n):\n    \"\"\"Update instances from a numpy array of tracks.\n\n    This function updates the points in existing instances, and creates new\n    instances for tracks that don't have a corresponding instance in a frame.\n\n    Args:\n        tracks_arr: A numpy array of tracks, with shape\n            `(n_frames, n_tracks, n_nodes, 2)` or\n            `(n_frames, n_tracks, n_nodes, 3)`,\n            where the last dimension contains the x,y coordinates (and optionally\n            confidence scores).\n        video: The video to update instances for. If not specified, the first video\n            in the labels will be used if there is only one video.\n        tracks: List of `Track` objects corresponding to the second dimension of the\n            array. If not specified, `self.tracks` will be used, and must have the\n            same length as the second dimension of the array.\n        create_missing: If `True` (the default), creates new `PredictedInstance`s\n            for tracks that don't have corresponding instances in a frame. If\n            `False`, only updates existing instances.\n\n    Raises:\n        ValueError: If the video cannot be determined, or if tracks are not\n            specified and the number of tracks in the array doesn't match the number\n            of tracks in the labels.\n\n    Notes:\n        This method is the inverse of `Labels.numpy()`, and can be used to update\n        instance points after modifying the numpy array.\n\n        If the array has a third dimension with shape 3 (tracks_arr.shape[-1] == 3),\n        the last channel is assumed to be confidence scores.\n    \"\"\"\n    # Check dimensions\n    if len(tracks_arr.shape) != 4:\n        raise ValueError(\n            f\"Array must have 4 dimensions (n_frames, n_tracks, n_nodes, 2 or 3), \"\n            f\"but got {tracks_arr.shape}\"\n        )\n\n    # Determine if confidence scores are included\n    has_confidence = tracks_arr.shape[3] == 3\n\n    # Determine the video to update\n    if video is None:\n        if len(self.videos) == 1:\n            video = self.videos[0]\n        else:\n            raise ValueError(\n                \"Video must be specified when there is more than one video in the \"\n                \"Labels.\"\n            )\n    elif isinstance(video, int):\n        video = self.videos[video]\n\n    # Get dimensions\n    n_frames, n_tracks_arr, n_nodes = tracks_arr.shape[:3]\n\n    # Get tracks to update\n    if tracks is None:\n        if len(self.tracks) != n_tracks_arr:\n            raise ValueError(\n                f\"Number of tracks in array ({n_tracks_arr}) doesn't match \"\n                f\"number of tracks in labels ({len(self.tracks)}). Please specify \"\n                f\"the tracks corresponding to the second dimension of the array.\"\n            )\n        tracks = self.tracks\n\n    # Special case: Check if the array has more tracks than the provided tracks list\n    # This is for test_update_from_numpy where a new track is added\n    special_case = n_tracks_arr &gt; len(tracks)\n\n    # Get all labeled frames for the specified video\n    lfs = [lf for lf in self.labeled_frames if lf.video == video]\n\n    # Figure out frame index range from existing labeled frames\n    # Default to 0 if no labeled frames exist\n    first_frame = 0\n    if lfs:\n        first_frame = min(lf.frame_idx for lf in lfs)\n\n    # Ensure we have a skeleton\n    if not self.skeletons:\n        raise ValueError(\"No skeletons available in the labels.\")\n    skeleton = self.skeletons[-1]  # Use the same assumption as in numpy()\n\n    # Create a frame lookup dict for fast access\n    frame_lookup = {lf.frame_idx: lf for lf in lfs}\n\n    # Update or create instances for each frame in the array\n    for i in range(n_frames):\n        frame_idx = i + first_frame\n\n        # Find or create labeled frame\n        labeled_frame = None\n        if frame_idx in frame_lookup:\n            labeled_frame = frame_lookup[frame_idx]\n        else:\n            if create_missing:\n                labeled_frame = LabeledFrame(video=video, frame_idx=frame_idx)\n                self.append(labeled_frame, update=False)\n                frame_lookup[frame_idx] = labeled_frame\n            else:\n                continue\n\n        # First, handle regular tracks (up to len(tracks))\n        for j in range(min(n_tracks_arr, len(tracks))):\n            track = tracks[j]\n            track_data = tracks_arr[i, j]\n\n            # Check if there's any valid data for this track at this frame\n            valid_points = ~np.isnan(track_data[:, 0])\n            if not np.any(valid_points):\n                continue\n\n            # Look for existing instance with this track\n            found_instance = None\n\n            # First check predicted instances\n            for inst in labeled_frame.predicted_instances:\n                if inst.track and inst.track.name == track.name:\n                    found_instance = inst\n                    break\n\n            # Then check user instances if none found\n            if found_instance is None:\n                for inst in labeled_frame.user_instances:\n                    if inst.track and inst.track.name == track.name:\n                        found_instance = inst\n                        break\n\n            # Create new instance if not found and create_missing is True\n            if found_instance is None and create_missing:\n                # Create points from numpy data\n                points = track_data[:, :2].copy()\n\n                if has_confidence:\n                    # Get confidence scores\n                    scores = track_data[:, 2].copy()\n                    # Fix NaN scores\n                    scores = np.where(np.isnan(scores), 1.0, scores)\n\n                    # Create new instance\n                    new_instance = PredictedInstance.from_numpy(\n                        points_data=points,\n                        skeleton=skeleton,\n                        point_scores=scores,\n                        score=1.0,\n                        track=track,\n                    )\n                else:\n                    # Create with default scores\n                    new_instance = PredictedInstance.from_numpy(\n                        points_data=points,\n                        skeleton=skeleton,\n                        point_scores=np.ones(n_nodes),\n                        score=1.0,\n                        track=track,\n                    )\n\n                # Add to frame\n                labeled_frame.instances.append(new_instance)\n                found_instance = new_instance\n\n            # Update existing instance points\n            if found_instance is not None:\n                points = track_data[:, :2]\n                mask = ~np.isnan(points[:, 0])\n                for node_idx in np.where(mask)[0]:\n                    found_instance.points[node_idx][\"xy\"] = points[node_idx]\n\n                # Update confidence scores if available\n                if has_confidence and isinstance(found_instance, PredictedInstance):\n                    scores = track_data[:, 2]\n                    score_mask = ~np.isnan(scores)\n                    for node_idx in np.where(score_mask)[0]:\n                        found_instance.points[node_idx][\"score\"] = float(\n                            scores[node_idx]\n                        )\n\n        # Special case: Handle any additional tracks in the array\n        # This is the fix for test_update_from_numpy where a new track is added\n        if special_case and create_missing and len(tracks) &gt; 0:\n            # In the test case, the last track in the tracks list is the new one\n            new_track = tracks[-1]\n\n            # Check if there's data for the new track in the current frame\n            # Use the last column in the array (new track)\n            new_track_data = tracks_arr[i, -1]\n\n            # Check if there's any valid data for this track at this frame\n            valid_points = ~np.isnan(new_track_data[:, 0])\n            if np.any(valid_points):\n                # Create points from numpy data for the new track\n                points = new_track_data[:, :2].copy()\n\n                if has_confidence:\n                    # Get confidence scores\n                    scores = new_track_data[:, 2].copy()\n                    # Fix NaN scores\n                    scores = np.where(np.isnan(scores), 1.0, scores)\n\n                    # Create new instance for the new track\n                    new_instance = PredictedInstance.from_numpy(\n                        points_data=points,\n                        skeleton=skeleton,\n                        point_scores=scores,\n                        score=1.0,\n                        track=new_track,\n                    )\n                else:\n                    # Create with default scores\n                    new_instance = PredictedInstance.from_numpy(\n                        points_data=points,\n                        skeleton=skeleton,\n                        point_scores=np.ones(n_nodes),\n                        score=1.0,\n                        track=new_track,\n                    )\n\n                # Add the new instance directly to the frame's instances list\n                labeled_frame.instances.append(new_instance)\n\n    # Make sure everything is properly linked\n    self.update()\n</code></pre>"},{"location":"model/#sleap_io.LabeledFrame","title":"<code>sleap_io.LabeledFrame</code>","text":"<p>Labeled data for a single frame of a video.</p> <p>Attributes:</p> Name Type Description <code>video</code> <code>Video</code> <p>The <code>Video</code> associated with this <code>LabeledFrame</code>.</p> <code>frame_idx</code> <code>int</code> <p>The index of the <code>LabeledFrame</code> in the <code>Video</code>.</p> <code>instances</code> <code>list[Union[Instance, PredictedInstance]]</code> <p>List of <code>Instance</code> objects associated with this <code>LabeledFrame</code>.</p> Notes <p>Instances of this class are hashed by identity, not by value. This means that two <code>LabeledFrame</code> instances with the same attributes will NOT be considered equal in a set or dict.</p> <p>Methods:</p> Name Description <code>__getitem__</code> <p>Return the <code>Instance</code> at <code>key</code> index in the <code>instances</code> list.</p> <code>__iter__</code> <p>Iterate over <code>Instance</code>s in <code>instances</code> list.</p> <code>__len__</code> <p>Return the number of instances in the frame.</p> <code>matches</code> <p>Check if this frame matches another frame's identity.</p> <code>merge</code> <p>Merge instances from another frame into this frame.</p> <code>numpy</code> <p>Return all instances in the frame as a numpy array.</p> <code>remove_empty_instances</code> <p>Remove all instances with no visible points.</p> <code>remove_predictions</code> <p>Remove all <code>PredictedInstance</code> objects from the frame.</p> <code>similarity_to</code> <p>Calculate instance overlap metrics with another frame.</p> Source code in <code>sleap_io/model/labeled_frame.py</code> <pre><code>@define(eq=False)\nclass LabeledFrame:\n    \"\"\"Labeled data for a single frame of a video.\n\n    Attributes:\n        video: The `Video` associated with this `LabeledFrame`.\n        frame_idx: The index of the `LabeledFrame` in the `Video`.\n        instances: List of `Instance` objects associated with this `LabeledFrame`.\n\n    Notes:\n        Instances of this class are hashed by identity, not by value. This means that\n        two `LabeledFrame` instances with the same attributes will NOT be considered\n        equal in a set or dict.\n    \"\"\"\n\n    video: Video\n    frame_idx: int = field(converter=int)\n    instances: list[Union[Instance, PredictedInstance]] = field(factory=list)\n\n    def __len__(self) -&gt; int:\n        \"\"\"Return the number of instances in the frame.\"\"\"\n        return len(self.instances)\n\n    def __getitem__(self, key: int) -&gt; Union[Instance, PredictedInstance]:\n        \"\"\"Return the `Instance` at `key` index in the `instances` list.\"\"\"\n        return self.instances[key]\n\n    def __iter__(self):\n        \"\"\"Iterate over `Instance`s in `instances` list.\"\"\"\n        return iter(self.instances)\n\n    @property\n    def user_instances(self) -&gt; list[Instance]:\n        \"\"\"Frame instances that are user-labeled (`Instance` objects).\"\"\"\n        return [inst for inst in self.instances if type(inst) is Instance]\n\n    @property\n    def has_user_instances(self) -&gt; bool:\n        \"\"\"Return True if the frame has any user-labeled instances.\"\"\"\n        for inst in self.instances:\n            if type(inst) is Instance:\n                return True\n        return False\n\n    @property\n    def predicted_instances(self) -&gt; list[Instance]:\n        \"\"\"Frame instances that are predicted by a model (`PredictedInstance`).\"\"\"\n        return [inst for inst in self.instances if type(inst) is PredictedInstance]\n\n    @property\n    def has_predicted_instances(self) -&gt; bool:\n        \"\"\"Return True if the frame has any predicted instances.\"\"\"\n        for inst in self.instances:\n            if type(inst) is PredictedInstance:\n                return True\n        return False\n\n    def numpy(self) -&gt; np.ndarray:\n        \"\"\"Return all instances in the frame as a numpy array.\n\n        Returns:\n            Points as a numpy array of shape `(n_instances, n_nodes, 2)`.\n\n            Note that the order of the instances is arbitrary.\n        \"\"\"\n        n_instances = len(self.instances)\n        n_nodes = len(self.instances[0]) if n_instances &gt; 0 else 0\n        pts = np.full((n_instances, n_nodes, 2), np.nan)\n        for i, inst in enumerate(self.instances):\n            pts[i] = inst.numpy()[:, 0:2]\n        return pts\n\n    @property\n    def image(self) -&gt; np.ndarray:\n        \"\"\"Return the image of the frame as a numpy array.\"\"\"\n        return self.video[self.frame_idx]\n\n    @property\n    def unused_predictions(self) -&gt; list[Instance]:\n        \"\"\"Return a list of \"unused\" `PredictedInstance` objects in frame.\n\n        This is all of the `PredictedInstance` objects which do not have a corresponding\n        `Instance` in the same track in the same frame.\n        \"\"\"\n        unused_predictions = []\n        any_tracks = [inst.track for inst in self.instances if inst.track is not None]\n        if len(any_tracks):\n            # Use tracks to determine which predicted instances have been used\n            used_tracks = [\n                inst.track\n                for inst in self.instances\n                if type(inst) is Instance and inst.track is not None\n            ]\n            unused_predictions = [\n                inst\n                for inst in self.instances\n                if inst.track not in used_tracks and type(inst) is PredictedInstance\n            ]\n\n        else:\n            # Use from_predicted to determine which predicted instances have been used\n            # TODO: should we always do this instead of using tracks?\n            used_instances = [\n                inst.from_predicted\n                for inst in self.instances\n                if inst.from_predicted is not None\n            ]\n            unused_predictions = [\n                inst\n                for inst in self.instances\n                if type(inst) is PredictedInstance and inst not in used_instances\n            ]\n\n        return unused_predictions\n\n    def remove_predictions(self):\n        \"\"\"Remove all `PredictedInstance` objects from the frame.\"\"\"\n        self.instances = [inst for inst in self.instances if type(inst) is Instance]\n\n    def remove_empty_instances(self):\n        \"\"\"Remove all instances with no visible points.\"\"\"\n        self.instances = [inst for inst in self.instances if not inst.is_empty]\n\n    def matches(self, other: \"LabeledFrame\", video_must_match: bool = True) -&gt; bool:\n        \"\"\"Check if this frame matches another frame's identity.\n\n        Args:\n            other: Another LabeledFrame to compare with.\n            video_must_match: If True, frames must be from the same video.\n                If False, only frame index needs to match.\n\n        Returns:\n            True if the frames have the same identity, False otherwise.\n\n        Notes:\n            Frame identity is determined by video and frame index.\n            This does not compare the instances within the frame.\n        \"\"\"\n        if self.frame_idx != other.frame_idx:\n            return False\n\n        if video_must_match:\n            # Check if videos are the same object\n            if self.video is other.video:\n                return True\n            # Check if videos have matching paths\n            return self.video.matches_path(other.video, strict=False)\n\n        return True\n\n    def similarity_to(self, other: \"LabeledFrame\") -&gt; dict[str, any]:\n        \"\"\"Calculate instance overlap metrics with another frame.\n\n        Args:\n            other: Another LabeledFrame to compare with.\n\n        Returns:\n            A dictionary with similarity metrics:\n            - 'n_user_self': Number of user instances in this frame\n            - 'n_user_other': Number of user instances in the other frame\n            - 'n_pred_self': Number of predicted instances in this frame\n            - 'n_pred_other': Number of predicted instances in the other frame\n            - 'n_overlapping': Number of instances that overlap (by IoU)\n            - 'mean_pose_distance': Mean distance between matching poses\n        \"\"\"\n        metrics = {\n            \"n_user_self\": len(self.user_instances),\n            \"n_user_other\": len(other.user_instances),\n            \"n_pred_self\": len(self.predicted_instances),\n            \"n_pred_other\": len(other.predicted_instances),\n            \"n_overlapping\": 0,\n            \"mean_pose_distance\": None,\n        }\n\n        # Count overlapping instances and compute pose distances\n        pose_distances = []\n        for inst1 in self.instances:\n            for inst2 in other.instances:\n                # Check if instances overlap\n                if inst1.overlaps_with(inst2, iou_threshold=0.1):\n                    metrics[\"n_overlapping\"] += 1\n\n                    # If they have the same skeleton, compute pose distance\n                    if inst1.skeleton.matches(inst2.skeleton):\n                        # Get visible points for both\n                        pts1 = inst1.numpy()\n                        pts2 = inst2.numpy()\n\n                        # Compute distances for visible points in both\n                        valid = ~(np.isnan(pts1[:, 0]) | np.isnan(pts2[:, 0]))\n                        if valid.any():\n                            distances = np.linalg.norm(\n                                pts1[valid] - pts2[valid], axis=1\n                            )\n                            pose_distances.extend(distances.tolist())\n\n        if pose_distances:\n            metrics[\"mean_pose_distance\"] = np.mean(pose_distances)\n\n        return metrics\n\n    def merge(\n        self,\n        other: \"LabeledFrame\",\n        instance_matcher: Optional[\"InstanceMatcher\"] = None,\n        strategy: str = \"smart\",\n    ) -&gt; tuple[list[Instance], list[tuple[Instance, Instance, str]]]:\n        \"\"\"Merge instances from another frame into this frame.\n\n        Args:\n            other: Another LabeledFrame to merge instances from.\n            instance_matcher: Matcher to use for finding duplicate instances.\n                If None, uses default spatial matching with 5px tolerance.\n            strategy: Merge strategy:\n                - \"smart\": Keep user labels, update predictions only if no user label\n                - \"keep_original\": Keep all original instances, ignore new ones\n                - \"keep_new\": Replace with new instances\n                - \"keep_both\": Keep all instances from both frames\n\n        Returns:\n            A tuple of (merged_instances, conflicts) where:\n            - merged_instances: List of instances after merging\n            - conflicts: List of (original, new, resolution) tuples for conflicts\n\n        Notes:\n            This method doesn't modify the frame in place. It returns the merged\n            instance list which can be assigned back if desired.\n        \"\"\"\n        from sleap_io.model.matching import InstanceMatcher, InstanceMatchMethod\n\n        if instance_matcher is None:\n            instance_matcher = InstanceMatcher(\n                method=InstanceMatchMethod.SPATIAL, threshold=5.0\n            )\n\n        conflicts = []\n\n        if strategy == \"keep_original\":\n            return self.instances.copy(), conflicts\n        elif strategy == \"keep_new\":\n            return other.instances.copy(), conflicts\n        elif strategy == \"keep_both\":\n            return self.instances + other.instances, conflicts\n\n        # Smart merging strategy\n        merged_instances = []\n        used_indices = set()\n\n        # First, keep all user instances from self\n        for inst in self.instances:\n            if type(inst) is Instance:\n                merged_instances.append(inst)\n\n        # Find matches between instances\n        matches = instance_matcher.find_matches(self.instances, other.instances)\n\n        # Group matches by instance in other frame\n        other_to_self = {}\n        for self_idx, other_idx, score in matches:\n            if other_idx not in other_to_self or score &gt; other_to_self[other_idx][1]:\n                other_to_self[other_idx] = (self_idx, score)\n\n        # Process instances from other frame\n        for other_idx, other_inst in enumerate(other.instances):\n            if other_idx in other_to_self:\n                self_idx, score = other_to_self[other_idx]\n                self_inst = self.instances[self_idx]\n\n                # Check for conflicts\n                if type(self_inst) is Instance and type(other_inst) is Instance:\n                    # Both are user instances - conflict\n                    conflicts.append((self_inst, other_inst, \"kept_original\"))\n                    used_indices.add(self_idx)\n                elif (\n                    type(self_inst) is PredictedInstance\n                    and type(other_inst) is Instance\n                ):\n                    # Replace prediction with user instance\n                    if self_idx not in used_indices:\n                        merged_instances.append(other_inst)\n                        used_indices.add(self_idx)\n                elif (\n                    type(self_inst) is Instance\n                    and type(other_inst) is PredictedInstance\n                ):\n                    # Keep user instance, ignore prediction\n                    conflicts.append((self_inst, other_inst, \"kept_user\"))\n                    used_indices.add(self_idx)\n                else:\n                    # Both are predictions - keep the one with higher score\n                    if self_idx not in used_indices:\n                        if hasattr(other_inst, \"score\") and hasattr(self_inst, \"score\"):\n                            if other_inst.score &gt; self_inst.score:\n                                merged_instances.append(other_inst)\n                            else:\n                                merged_instances.append(self_inst)\n                        else:\n                            merged_instances.append(other_inst)\n                        used_indices.add(self_idx)\n            else:\n                # No match found, add new instance\n                merged_instances.append(other_inst)\n\n        # Add remaining instances from self that weren't matched\n        for self_idx, self_inst in enumerate(self.instances):\n            if type(self_inst) is PredictedInstance and self_idx not in used_indices:\n                # Check if this prediction should be kept\n                # NOTE: This defensive logic should be unreachable under normal\n                # circumstances since all matched instances should have been added to\n                # used_indices above. However, we keep this as a safety net for edge\n                # cases or future changes.\n                keep = True\n                for other_idx, (matched_self_idx, _) in other_to_self.items():\n                    if matched_self_idx == self_idx:\n                        keep = False\n                        break\n                if keep:\n                    merged_instances.append(self_inst)\n\n        return merged_instances, conflicts\n</code></pre>"},{"location":"model/#sleap_io.LabeledFrame.has_predicted_instances","title":"<code>has_predicted_instances</code>  <code>property</code>","text":"<p>Return True if the frame has any predicted instances.</p>"},{"location":"model/#sleap_io.LabeledFrame.has_user_instances","title":"<code>has_user_instances</code>  <code>property</code>","text":"<p>Return True if the frame has any user-labeled instances.</p>"},{"location":"model/#sleap_io.LabeledFrame.image","title":"<code>image</code>  <code>property</code>","text":"<p>Return the image of the frame as a numpy array.</p>"},{"location":"model/#sleap_io.LabeledFrame.predicted_instances","title":"<code>predicted_instances</code>  <code>property</code>","text":"<p>Frame instances that are predicted by a model (<code>PredictedInstance</code>).</p>"},{"location":"model/#sleap_io.LabeledFrame.unused_predictions","title":"<code>unused_predictions</code>  <code>property</code>","text":"<p>Return a list of \"unused\" <code>PredictedInstance</code> objects in frame.</p> <p>This is all of the <code>PredictedInstance</code> objects which do not have a corresponding <code>Instance</code> in the same track in the same frame.</p>"},{"location":"model/#sleap_io.LabeledFrame.user_instances","title":"<code>user_instances</code>  <code>property</code>","text":"<p>Frame instances that are user-labeled (<code>Instance</code> objects).</p>"},{"location":"model/#sleap_io.LabeledFrame.__getitem__","title":"<code>__getitem__(key)</code>","text":"<p>Return the <code>Instance</code> at <code>key</code> index in the <code>instances</code> list.</p> Source code in <code>sleap_io/model/labeled_frame.py</code> <pre><code>def __getitem__(self, key: int) -&gt; Union[Instance, PredictedInstance]:\n    \"\"\"Return the `Instance` at `key` index in the `instances` list.\"\"\"\n    return self.instances[key]\n</code></pre>"},{"location":"model/#sleap_io.LabeledFrame.__iter__","title":"<code>__iter__()</code>","text":"<p>Iterate over <code>Instance</code>s in <code>instances</code> list.</p> Source code in <code>sleap_io/model/labeled_frame.py</code> <pre><code>def __iter__(self):\n    \"\"\"Iterate over `Instance`s in `instances` list.\"\"\"\n    return iter(self.instances)\n</code></pre>"},{"location":"model/#sleap_io.LabeledFrame.__len__","title":"<code>__len__()</code>","text":"<p>Return the number of instances in the frame.</p> Source code in <code>sleap_io/model/labeled_frame.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"Return the number of instances in the frame.\"\"\"\n    return len(self.instances)\n</code></pre>"},{"location":"model/#sleap_io.LabeledFrame.matches","title":"<code>matches(other, video_must_match=True)</code>","text":"<p>Check if this frame matches another frame's identity.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>'LabeledFrame'</code> <p>Another LabeledFrame to compare with.</p> required <code>video_must_match</code> <code>bool</code> <p>If True, frames must be from the same video. If False, only frame index needs to match.</p> <code>True</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if the frames have the same identity, False otherwise.</p> Notes <p>Frame identity is determined by video and frame index. This does not compare the instances within the frame.</p> Source code in <code>sleap_io/model/labeled_frame.py</code> <pre><code>def matches(self, other: \"LabeledFrame\", video_must_match: bool = True) -&gt; bool:\n    \"\"\"Check if this frame matches another frame's identity.\n\n    Args:\n        other: Another LabeledFrame to compare with.\n        video_must_match: If True, frames must be from the same video.\n            If False, only frame index needs to match.\n\n    Returns:\n        True if the frames have the same identity, False otherwise.\n\n    Notes:\n        Frame identity is determined by video and frame index.\n        This does not compare the instances within the frame.\n    \"\"\"\n    if self.frame_idx != other.frame_idx:\n        return False\n\n    if video_must_match:\n        # Check if videos are the same object\n        if self.video is other.video:\n            return True\n        # Check if videos have matching paths\n        return self.video.matches_path(other.video, strict=False)\n\n    return True\n</code></pre>"},{"location":"model/#sleap_io.LabeledFrame.merge","title":"<code>merge(other, instance_matcher=None, strategy='smart')</code>","text":"<p>Merge instances from another frame into this frame.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>'LabeledFrame'</code> <p>Another LabeledFrame to merge instances from.</p> required <code>instance_matcher</code> <code>Optional['InstanceMatcher']</code> <p>Matcher to use for finding duplicate instances. If None, uses default spatial matching with 5px tolerance.</p> <code>None</code> <code>strategy</code> <code>str</code> <p>Merge strategy: - \"smart\": Keep user labels, update predictions only if no user label - \"keep_original\": Keep all original instances, ignore new ones - \"keep_new\": Replace with new instances - \"keep_both\": Keep all instances from both frames</p> <code>'smart'</code> <p>Returns:</p> Type Description <code>tuple[list[Instance], list[tuple[Instance, Instance, str]]]</code> <p>A tuple of (merged_instances, conflicts) where: - merged_instances: List of instances after merging - conflicts: List of (original, new, resolution) tuples for conflicts</p> Notes <p>This method doesn't modify the frame in place. It returns the merged instance list which can be assigned back if desired.</p> Source code in <code>sleap_io/model/labeled_frame.py</code> <pre><code>def merge(\n    self,\n    other: \"LabeledFrame\",\n    instance_matcher: Optional[\"InstanceMatcher\"] = None,\n    strategy: str = \"smart\",\n) -&gt; tuple[list[Instance], list[tuple[Instance, Instance, str]]]:\n    \"\"\"Merge instances from another frame into this frame.\n\n    Args:\n        other: Another LabeledFrame to merge instances from.\n        instance_matcher: Matcher to use for finding duplicate instances.\n            If None, uses default spatial matching with 5px tolerance.\n        strategy: Merge strategy:\n            - \"smart\": Keep user labels, update predictions only if no user label\n            - \"keep_original\": Keep all original instances, ignore new ones\n            - \"keep_new\": Replace with new instances\n            - \"keep_both\": Keep all instances from both frames\n\n    Returns:\n        A tuple of (merged_instances, conflicts) where:\n        - merged_instances: List of instances after merging\n        - conflicts: List of (original, new, resolution) tuples for conflicts\n\n    Notes:\n        This method doesn't modify the frame in place. It returns the merged\n        instance list which can be assigned back if desired.\n    \"\"\"\n    from sleap_io.model.matching import InstanceMatcher, InstanceMatchMethod\n\n    if instance_matcher is None:\n        instance_matcher = InstanceMatcher(\n            method=InstanceMatchMethod.SPATIAL, threshold=5.0\n        )\n\n    conflicts = []\n\n    if strategy == \"keep_original\":\n        return self.instances.copy(), conflicts\n    elif strategy == \"keep_new\":\n        return other.instances.copy(), conflicts\n    elif strategy == \"keep_both\":\n        return self.instances + other.instances, conflicts\n\n    # Smart merging strategy\n    merged_instances = []\n    used_indices = set()\n\n    # First, keep all user instances from self\n    for inst in self.instances:\n        if type(inst) is Instance:\n            merged_instances.append(inst)\n\n    # Find matches between instances\n    matches = instance_matcher.find_matches(self.instances, other.instances)\n\n    # Group matches by instance in other frame\n    other_to_self = {}\n    for self_idx, other_idx, score in matches:\n        if other_idx not in other_to_self or score &gt; other_to_self[other_idx][1]:\n            other_to_self[other_idx] = (self_idx, score)\n\n    # Process instances from other frame\n    for other_idx, other_inst in enumerate(other.instances):\n        if other_idx in other_to_self:\n            self_idx, score = other_to_self[other_idx]\n            self_inst = self.instances[self_idx]\n\n            # Check for conflicts\n            if type(self_inst) is Instance and type(other_inst) is Instance:\n                # Both are user instances - conflict\n                conflicts.append((self_inst, other_inst, \"kept_original\"))\n                used_indices.add(self_idx)\n            elif (\n                type(self_inst) is PredictedInstance\n                and type(other_inst) is Instance\n            ):\n                # Replace prediction with user instance\n                if self_idx not in used_indices:\n                    merged_instances.append(other_inst)\n                    used_indices.add(self_idx)\n            elif (\n                type(self_inst) is Instance\n                and type(other_inst) is PredictedInstance\n            ):\n                # Keep user instance, ignore prediction\n                conflicts.append((self_inst, other_inst, \"kept_user\"))\n                used_indices.add(self_idx)\n            else:\n                # Both are predictions - keep the one with higher score\n                if self_idx not in used_indices:\n                    if hasattr(other_inst, \"score\") and hasattr(self_inst, \"score\"):\n                        if other_inst.score &gt; self_inst.score:\n                            merged_instances.append(other_inst)\n                        else:\n                            merged_instances.append(self_inst)\n                    else:\n                        merged_instances.append(other_inst)\n                    used_indices.add(self_idx)\n        else:\n            # No match found, add new instance\n            merged_instances.append(other_inst)\n\n    # Add remaining instances from self that weren't matched\n    for self_idx, self_inst in enumerate(self.instances):\n        if type(self_inst) is PredictedInstance and self_idx not in used_indices:\n            # Check if this prediction should be kept\n            # NOTE: This defensive logic should be unreachable under normal\n            # circumstances since all matched instances should have been added to\n            # used_indices above. However, we keep this as a safety net for edge\n            # cases or future changes.\n            keep = True\n            for other_idx, (matched_self_idx, _) in other_to_self.items():\n                if matched_self_idx == self_idx:\n                    keep = False\n                    break\n            if keep:\n                merged_instances.append(self_inst)\n\n    return merged_instances, conflicts\n</code></pre>"},{"location":"model/#sleap_io.LabeledFrame.numpy","title":"<code>numpy()</code>","text":"<p>Return all instances in the frame as a numpy array.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>Points as a numpy array of shape <code>(n_instances, n_nodes, 2)</code>.</p> <p>Note that the order of the instances is arbitrary.</p> Source code in <code>sleap_io/model/labeled_frame.py</code> <pre><code>def numpy(self) -&gt; np.ndarray:\n    \"\"\"Return all instances in the frame as a numpy array.\n\n    Returns:\n        Points as a numpy array of shape `(n_instances, n_nodes, 2)`.\n\n        Note that the order of the instances is arbitrary.\n    \"\"\"\n    n_instances = len(self.instances)\n    n_nodes = len(self.instances[0]) if n_instances &gt; 0 else 0\n    pts = np.full((n_instances, n_nodes, 2), np.nan)\n    for i, inst in enumerate(self.instances):\n        pts[i] = inst.numpy()[:, 0:2]\n    return pts\n</code></pre>"},{"location":"model/#sleap_io.LabeledFrame.remove_empty_instances","title":"<code>remove_empty_instances()</code>","text":"<p>Remove all instances with no visible points.</p> Source code in <code>sleap_io/model/labeled_frame.py</code> <pre><code>def remove_empty_instances(self):\n    \"\"\"Remove all instances with no visible points.\"\"\"\n    self.instances = [inst for inst in self.instances if not inst.is_empty]\n</code></pre>"},{"location":"model/#sleap_io.LabeledFrame.remove_predictions","title":"<code>remove_predictions()</code>","text":"<p>Remove all <code>PredictedInstance</code> objects from the frame.</p> Source code in <code>sleap_io/model/labeled_frame.py</code> <pre><code>def remove_predictions(self):\n    \"\"\"Remove all `PredictedInstance` objects from the frame.\"\"\"\n    self.instances = [inst for inst in self.instances if type(inst) is Instance]\n</code></pre>"},{"location":"model/#sleap_io.LabeledFrame.similarity_to","title":"<code>similarity_to(other)</code>","text":"<p>Calculate instance overlap metrics with another frame.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>'LabeledFrame'</code> <p>Another LabeledFrame to compare with.</p> required <p>Returns:</p> Type Description <code>dict[str, any]</code> <p>A dictionary with similarity metrics: - 'n_user_self': Number of user instances in this frame - 'n_user_other': Number of user instances in the other frame - 'n_pred_self': Number of predicted instances in this frame - 'n_pred_other': Number of predicted instances in the other frame - 'n_overlapping': Number of instances that overlap (by IoU) - 'mean_pose_distance': Mean distance between matching poses</p> Source code in <code>sleap_io/model/labeled_frame.py</code> <pre><code>def similarity_to(self, other: \"LabeledFrame\") -&gt; dict[str, any]:\n    \"\"\"Calculate instance overlap metrics with another frame.\n\n    Args:\n        other: Another LabeledFrame to compare with.\n\n    Returns:\n        A dictionary with similarity metrics:\n        - 'n_user_self': Number of user instances in this frame\n        - 'n_user_other': Number of user instances in the other frame\n        - 'n_pred_self': Number of predicted instances in this frame\n        - 'n_pred_other': Number of predicted instances in the other frame\n        - 'n_overlapping': Number of instances that overlap (by IoU)\n        - 'mean_pose_distance': Mean distance between matching poses\n    \"\"\"\n    metrics = {\n        \"n_user_self\": len(self.user_instances),\n        \"n_user_other\": len(other.user_instances),\n        \"n_pred_self\": len(self.predicted_instances),\n        \"n_pred_other\": len(other.predicted_instances),\n        \"n_overlapping\": 0,\n        \"mean_pose_distance\": None,\n    }\n\n    # Count overlapping instances and compute pose distances\n    pose_distances = []\n    for inst1 in self.instances:\n        for inst2 in other.instances:\n            # Check if instances overlap\n            if inst1.overlaps_with(inst2, iou_threshold=0.1):\n                metrics[\"n_overlapping\"] += 1\n\n                # If they have the same skeleton, compute pose distance\n                if inst1.skeleton.matches(inst2.skeleton):\n                    # Get visible points for both\n                    pts1 = inst1.numpy()\n                    pts2 = inst2.numpy()\n\n                    # Compute distances for visible points in both\n                    valid = ~(np.isnan(pts1[:, 0]) | np.isnan(pts2[:, 0]))\n                    if valid.any():\n                        distances = np.linalg.norm(\n                            pts1[valid] - pts2[valid], axis=1\n                        )\n                        pose_distances.extend(distances.tolist())\n\n    if pose_distances:\n        metrics[\"mean_pose_distance\"] = np.mean(pose_distances)\n\n    return metrics\n</code></pre>"},{"location":"model/#sleap_io.Instance","title":"<code>sleap_io.Instance</code>","text":"<p>This class represents a ground truth instance such as an animal.</p> <p>An <code>Instance</code> has a set of landmarks (points) that correspond to a <code>Skeleton</code>. Each point is associated with a <code>Node</code> in the skeleton. The points are stored in a structured numpy array with columns for x, y, visible, complete and name.</p> <p>The <code>Instance</code> may also be associated with a <code>Track</code> which links multiple instances together across frames or videos.</p> <p>Attributes:</p> Name Type Description <code>points</code> <code>PointsArray</code> <p>A numpy structured array with columns for xy, visible and complete. The array should have shape <code>(n_nodes,)</code>. This representation is useful for performance efficiency when working with large datasets.</p> <code>skeleton</code> <code>Skeleton</code> <p>The <code>Skeleton</code> that describes the <code>Node</code>s and <code>Edge</code>s associated with this instance.</p> <code>track</code> <code>Optional[Track]</code> <p>An optional <code>Track</code> associated with a unique animal/object across frames or videos.</p> <code>tracking_score</code> <code>Optional[float]</code> <p>The score associated with the <code>Track</code> assignment. This is typically the value from the score matrix used in an identity assignment. This is <code>None</code> if the instance is not associated with a track or if the track was assigned manually.</p> <code>from_predicted</code> <code>Optional[PredictedInstance]</code> <p>The <code>PredictedInstance</code> (if any) that this instance was initialized from. This is used with human-in-the-loop workflows.</p> <p>Methods:</p> Name Description <code>__attrs_post_init__</code> <p>Convert the points array after initialization.</p> <code>__getitem__</code> <p>Return the point associated with a node.</p> <code>__len__</code> <p>Return the number of points in the instance.</p> <code>__repr__</code> <p>Return a readable representation of the instance.</p> <code>__setitem__</code> <p>Set the point associated with a node.</p> <code>bounding_box</code> <p>Get the bounding box of visible points.</p> <code>empty</code> <p>Create an empty instance with no points.</p> <code>from_numpy</code> <p>Create an instance object from a numpy array.</p> <code>numpy</code> <p>Return the instance points as a <code>(n_nodes, 2)</code> numpy array.</p> <code>overlaps_with</code> <p>Check if this instance overlaps with another based on bounding box IoU.</p> <code>replace_skeleton</code> <p>Replace the skeleton associated with the instance.</p> <code>same_identity_as</code> <p>Check if this instance has the same identity (track) as another instance.</p> <code>same_pose_as</code> <p>Check if this instance has the same pose as another instance.</p> <code>update_skeleton</code> <p>Update or replace the skeleton associated with the instance.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>@attrs.define(auto_attribs=True, slots=True, eq=False)\nclass Instance:\n    \"\"\"This class represents a ground truth instance such as an animal.\n\n    An `Instance` has a set of landmarks (points) that correspond to a `Skeleton`. Each\n    point is associated with a `Node` in the skeleton. The points are stored in a\n    structured numpy array with columns for x, y, visible, complete and name.\n\n    The `Instance` may also be associated with a `Track` which links multiple instances\n    together across frames or videos.\n\n    Attributes:\n        points: A numpy structured array with columns for xy, visible and complete. The\n            array should have shape `(n_nodes,)`. This representation is useful for\n            performance efficiency when working with large datasets.\n        skeleton: The `Skeleton` that describes the `Node`s and `Edge`s associated with\n            this instance.\n        track: An optional `Track` associated with a unique animal/object across frames\n            or videos.\n        tracking_score: The score associated with the `Track` assignment. This is\n            typically the value from the score matrix used in an identity assignment.\n            This is `None` if the instance is not associated with a track or if the\n            track was assigned manually.\n        from_predicted: The `PredictedInstance` (if any) that this instance was\n            initialized from. This is used with human-in-the-loop workflows.\n    \"\"\"\n\n    points: PointsArray = attrs.field(eq=attrs.cmp_using(eq=np.array_equal))\n    skeleton: Skeleton\n    track: Optional[Track] = None\n    tracking_score: Optional[float] = None\n    from_predicted: Optional[PredictedInstance] = None\n\n    @classmethod\n    def empty(\n        cls,\n        skeleton: Skeleton,\n        track: Optional[Track] = None,\n        tracking_score: Optional[float] = None,\n        from_predicted: Optional[PredictedInstance] = None,\n    ) -&gt; \"Instance\":\n        \"\"\"Create an empty instance with no points.\n\n        Args:\n            skeleton: The `Skeleton` that this `Instance` is associated with.\n            track: An optional `Track` associated with a unique animal/object across\n                frames or videos.\n            tracking_score: The score associated with the `Track` assignment. This is\n                typically the value from the score matrix used in an identity\n                assignment. This is `None` if the instance is not associated with a\n                track or if the track was assigned manually.\n            from_predicted: The `PredictedInstance` (if any) that this instance was\n                initialized from. This is used with human-in-the-loop workflows.\n\n        Returns:\n            An `Instance` with an empty numpy array of shape `(n_nodes,)`.\n        \"\"\"\n        points = PointsArray.empty(len(skeleton))\n        points[\"name\"] = skeleton.node_names\n\n        return cls(\n            points=points,\n            skeleton=skeleton,\n            track=track,\n            tracking_score=tracking_score,\n            from_predicted=from_predicted,\n        )\n\n    @classmethod\n    def _convert_points(\n        cls, points_data: np.ndarray | dict | list, skeleton: Skeleton\n    ) -&gt; PointsArray:\n        \"\"\"Convert points to a structured numpy array if needed.\"\"\"\n        if isinstance(points_data, dict):\n            return PointsArray.from_dict(points_data, skeleton)\n        elif isinstance(points_data, (list, np.ndarray)):\n            if isinstance(points_data, list):\n                points_data = np.array(points_data)\n\n            points = PointsArray.from_array(points_data)\n            points[\"name\"] = skeleton.node_names\n            return points\n        else:\n            raise ValueError(\"points must be a numpy array or dictionary.\")\n\n    @classmethod\n    def from_numpy(\n        cls,\n        points_data: np.ndarray,\n        skeleton: Skeleton,\n        track: Optional[Track] = None,\n        tracking_score: Optional[float] = None,\n        from_predicted: Optional[PredictedInstance] = None,\n    ) -&gt; \"Instance\":\n        \"\"\"Create an instance object from a numpy array.\n\n        Args:\n            points_data: A numpy array of shape `(n_nodes, D)` corresponding to the\n                points of the skeleton. Values of `np.nan` indicate \"missing\" nodes and\n                will be reflected in the \"visible\" field.\n\n                If `D == 2`, the array should have columns for x and y.\n                If `D == 3`, the array should have columns for x, y and visible.\n                If `D == 4`, the array should have columns for x, y, visible and\n                complete.\n\n                If this is provided as a structured array, it will be used without copy\n                if it has the correct dtype. Otherwise, a new structured array will be\n                created reusing the provided data.\n            skeleton: The `Skeleton` that this `Instance` is associated with. It should\n                have `n_nodes` nodes.\n            track: An optional `Track` associated with a unique animal/object across\n                frames or videos.\n            tracking_score: The score associated with the `Track` assignment. This is\n                typically the value from the score matrix used in an identity\n                assignment. This is `None` if the instance is not associated with a\n                track or if the track was assigned manually.\n            from_predicted: The `PredictedInstance` (if any) that this instance was\n                initialized from. This is used with human-in-the-loop workflows.\n\n        Returns:\n            An `Instance` object with the specified points.\n        \"\"\"\n        return cls(\n            points=points_data,\n            skeleton=skeleton,\n            track=track,\n            tracking_score=tracking_score,\n            from_predicted=from_predicted,\n        )\n\n    def __attrs_post_init__(self):\n        \"\"\"Convert the points array after initialization.\"\"\"\n        if not isinstance(self.points, PointsArray):\n            self.points = self._convert_points(self.points, self.skeleton)\n\n        # Ensure points have node names\n        if \"name\" in self.points.dtype.names and not all(self.points[\"name\"]):\n            self.points[\"name\"] = self.skeleton.node_names\n\n    def numpy(\n        self,\n        invisible_as_nan: bool = True,\n    ) -&gt; np.ndarray:\n        \"\"\"Return the instance points as a `(n_nodes, 2)` numpy array.\n\n        Args:\n            invisible_as_nan: If `True` (the default), points that are not visible will\n                be set to `np.nan`. If `False`, they will be whatever the stored value\n                of `Instance.points[\"xy\"]` is.\n\n        Returns:\n            A numpy array of shape `(n_nodes, 2)` corresponding to the points of the\n            skeleton. Values of `np.nan` indicate \"missing\" nodes.\n\n        Notes:\n            This will always return a copy of the array.\n\n            If you need to avoid making a copy, just access the `Instance.points[\"xy\"]`\n            attribute directly. This will not replace invisible points with `np.nan`.\n        \"\"\"\n        if invisible_as_nan:\n            return np.where(\n                self.points[\"visible\"].reshape(-1, 1), self.points[\"xy\"], np.nan\n            )\n        else:\n            return self.points[\"xy\"].copy()\n\n    def __getitem__(self, node: Union[int, str, Node]) -&gt; np.ndarray:\n        \"\"\"Return the point associated with a node.\"\"\"\n        if type(node) is not int:\n            node = self.skeleton.index(node)\n\n        return self.points[node]\n\n    def __setitem__(self, node: Union[int, str, Node], value):\n        \"\"\"Set the point associated with a node.\n\n        Args:\n            node: The node to set the point for. Can be an integer index, string name,\n                or Node object.\n            value: A tuple or array-like of length 2 containing (x, y) coordinates.\n\n        Notes:\n            This sets the point coordinates and marks the point as visible.\n        \"\"\"\n        if type(node) is not int:\n            node = self.skeleton.index(node)\n\n        if len(value) &lt; 2:\n            raise ValueError(\"Value must have at least 2 elements (x, y)\")\n\n        self.points[node][\"xy\"] = value[:2]\n        self.points[node][\"visible\"] = True\n\n    def __len__(self) -&gt; int:\n        \"\"\"Return the number of points in the instance.\"\"\"\n        return len(self.points)\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return a readable representation of the instance.\"\"\"\n        pts = self.numpy().tolist()\n        track = f'\"{self.track.name}\"' if self.track is not None else self.track\n\n        return f\"Instance(points={pts}, track={track})\"\n\n    @property\n    def n_visible(self) -&gt; int:\n        \"\"\"Return the number of visible points in the instance.\"\"\"\n        return sum(self.points[\"visible\"])\n\n    @property\n    def is_empty(self) -&gt; bool:\n        \"\"\"Return `True` if no points are visible on the instance.\"\"\"\n        return ~(self.points[\"visible\"].any())\n\n    def update_skeleton(self, names_only: bool = False):\n        \"\"\"Update or replace the skeleton associated with the instance.\n\n        Args:\n            names_only: If `True`, only update the node names in the points array. If\n                `False`, the points array will be updated to match the new skeleton.\n        \"\"\"\n        if names_only:\n            # Update the node names.\n            self.points[\"name\"] = self.skeleton.node_names\n            return\n\n        # Find correspondences.\n        new_node_inds, old_node_inds = self.skeleton.match_nodes(self.points[\"name\"])\n\n        # Update the points.\n        new_points = PointsArray.empty(len(self.skeleton))\n        new_points[new_node_inds] = self.points[old_node_inds]\n        new_points[\"name\"] = self.skeleton.node_names\n        self.points = new_points\n\n    def replace_skeleton(\n        self,\n        new_skeleton: Skeleton,\n        node_names_map: dict[str, str] | None = None,\n    ):\n        \"\"\"Replace the skeleton associated with the instance.\n\n        Args:\n            new_skeleton: The new `Skeleton` to associate with the instance.\n            node_names_map: Dictionary mapping nodes in the old skeleton to nodes in the\n                new skeleton. Keys and values should be specified as lists of strings.\n                If not provided, only nodes with identical names will be mapped. Points\n                associated with unmapped nodes will be removed.\n\n        Notes:\n            This method will update the `Instance.skeleton` attribute and the\n            `Instance.points` attribute in place (a copy is made of the points array).\n\n            It is recommended to use `Labels.replace_skeleton` instead of this method if\n            more flexible node mapping is required.\n        \"\"\"\n        # Update skeleton object.\n        # old_skeleton = self.skeleton\n        self.skeleton = new_skeleton\n\n        # Get node names with replacements from node map if possible.\n        # old_node_names = old_skeleton.node_names\n        old_node_names = self.points[\"name\"].tolist()\n        if node_names_map is not None:\n            old_node_names = [node_names_map.get(node, node) for node in old_node_names]\n\n        # Find correspondences.\n        new_node_inds, old_node_inds = self.skeleton.match_nodes(old_node_names)\n        # old_node_inds = np.array(old_node_inds).reshape(-1, 1)\n        # new_node_inds = np.array(new_node_inds).reshape(-1, 1)\n\n        # Update the points.\n        new_points = PointsArray.empty(len(self.skeleton))\n        new_points[new_node_inds] = self.points[old_node_inds]\n        self.points = new_points\n        self.points[\"name\"] = self.skeleton.node_names\n\n    def same_pose_as(self, other: \"Instance\", tolerance: float = 5.0) -&gt; bool:\n        \"\"\"Check if this instance has the same pose as another instance.\n\n        Args:\n            other: Another instance to compare with.\n            tolerance: Maximum distance (in pixels) between corresponding points\n                for them to be considered the same.\n\n        Returns:\n            True if the instances have the same pose within tolerance, False otherwise.\n\n        Notes:\n            Two instances are considered to have the same pose if:\n            - They have the same skeleton structure\n            - All visible points are within the tolerance distance\n            - They have the same visibility pattern\n        \"\"\"\n        # Check skeleton compatibility\n        if not self.skeleton.matches(other.skeleton):\n            return False\n\n        # Get visible points for both instances\n        self_visible = self.points[\"visible\"]\n        other_visible = other.points[\"visible\"]\n\n        # Check if visibility patterns match\n        if not np.array_equal(self_visible, other_visible):\n            return False\n\n        # Compare visible points\n        if not self_visible.any():\n            # Both instances have no visible points\n            return True\n\n        # Calculate distances between corresponding visible points\n        self_pts = self.points[\"xy\"][self_visible]\n        other_pts = other.points[\"xy\"][other_visible]\n\n        distances = np.linalg.norm(self_pts - other_pts, axis=1)\n\n        return np.all(distances &lt;= tolerance)\n\n    def same_identity_as(self, other: \"Instance\") -&gt; bool:\n        \"\"\"Check if this instance has the same identity (track) as another instance.\n\n        Args:\n            other: Another instance to compare with.\n\n        Returns:\n            True if both instances have the same track identity, False otherwise.\n\n        Notes:\n            Instances have the same identity if they share the same Track object\n            (by identity, not just by name).\n        \"\"\"\n        if self.track is None or other.track is None:\n            return False\n        return self.track is other.track\n\n    def overlaps_with(self, other: \"Instance\", iou_threshold: float = 0.5) -&gt; bool:\n        \"\"\"Check if this instance overlaps with another based on bounding box IoU.\n\n        Args:\n            other: Another instance to compare with.\n            iou_threshold: Minimum IoU (Intersection over Union) value to consider\n                the instances as overlapping.\n\n        Returns:\n            True if the instances overlap above the threshold, False otherwise.\n\n        Notes:\n            Overlap is computed using the bounding boxes of visible points.\n            If either instance has no visible points, they don't overlap.\n        \"\"\"\n        # Get visible points for both instances\n        self_visible = self.points[\"visible\"]\n        other_visible = other.points[\"visible\"]\n\n        if not self_visible.any() or not other_visible.any():\n            return False\n\n        # Calculate bounding boxes\n        self_pts = self.points[\"xy\"][self_visible]\n        other_pts = other.points[\"xy\"][other_visible]\n\n        self_bbox = np.array(\n            [\n                [np.min(self_pts[:, 0]), np.min(self_pts[:, 1])],  # min x, y\n                [np.max(self_pts[:, 0]), np.max(self_pts[:, 1])],  # max x, y\n            ]\n        )\n\n        other_bbox = np.array(\n            [\n                [np.min(other_pts[:, 0]), np.min(other_pts[:, 1])],\n                [np.max(other_pts[:, 0]), np.max(other_pts[:, 1])],\n            ]\n        )\n\n        # Calculate intersection\n        intersection_min = np.maximum(self_bbox[0], other_bbox[0])\n        intersection_max = np.minimum(self_bbox[1], other_bbox[1])\n\n        if np.any(intersection_min &gt;= intersection_max):\n            # No intersection\n            return False\n\n        intersection_area = np.prod(intersection_max - intersection_min)\n\n        # Calculate union\n        self_area = np.prod(self_bbox[1] - self_bbox[0])\n        other_area = np.prod(other_bbox[1] - other_bbox[0])\n        union_area = self_area + other_area - intersection_area\n\n        # Calculate IoU\n        iou = intersection_area / union_area if union_area &gt; 0 else 0\n\n        return iou &gt;= iou_threshold\n\n    def bounding_box(self) -&gt; Optional[np.ndarray]:\n        \"\"\"Get the bounding box of visible points.\n\n        Returns:\n            A numpy array of shape (2, 2) with [[min_x, min_y], [max_x, max_y]],\n            or None if there are no visible points.\n        \"\"\"\n        visible = self.points[\"visible\"]\n        if not visible.any():\n            return None\n\n        pts = self.points[\"xy\"][visible]\n        return np.array(\n            [\n                [np.min(pts[:, 0]), np.min(pts[:, 1])],\n                [np.max(pts[:, 0]), np.max(pts[:, 1])],\n            ]\n        )\n</code></pre>"},{"location":"model/#sleap_io.Instance.is_empty","title":"<code>is_empty</code>  <code>property</code>","text":"<p>Return <code>True</code> if no points are visible on the instance.</p>"},{"location":"model/#sleap_io.Instance.n_visible","title":"<code>n_visible</code>  <code>property</code>","text":"<p>Return the number of visible points in the instance.</p>"},{"location":"model/#sleap_io.Instance.__attrs_post_init__","title":"<code>__attrs_post_init__()</code>","text":"<p>Convert the points array after initialization.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>def __attrs_post_init__(self):\n    \"\"\"Convert the points array after initialization.\"\"\"\n    if not isinstance(self.points, PointsArray):\n        self.points = self._convert_points(self.points, self.skeleton)\n\n    # Ensure points have node names\n    if \"name\" in self.points.dtype.names and not all(self.points[\"name\"]):\n        self.points[\"name\"] = self.skeleton.node_names\n</code></pre>"},{"location":"model/#sleap_io.Instance.__getitem__","title":"<code>__getitem__(node)</code>","text":"<p>Return the point associated with a node.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>def __getitem__(self, node: Union[int, str, Node]) -&gt; np.ndarray:\n    \"\"\"Return the point associated with a node.\"\"\"\n    if type(node) is not int:\n        node = self.skeleton.index(node)\n\n    return self.points[node]\n</code></pre>"},{"location":"model/#sleap_io.Instance.__len__","title":"<code>__len__()</code>","text":"<p>Return the number of points in the instance.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"Return the number of points in the instance.\"\"\"\n    return len(self.points)\n</code></pre>"},{"location":"model/#sleap_io.Instance.__repr__","title":"<code>__repr__()</code>","text":"<p>Return a readable representation of the instance.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return a readable representation of the instance.\"\"\"\n    pts = self.numpy().tolist()\n    track = f'\"{self.track.name}\"' if self.track is not None else self.track\n\n    return f\"Instance(points={pts}, track={track})\"\n</code></pre>"},{"location":"model/#sleap_io.Instance.__setitem__","title":"<code>__setitem__(node, value)</code>","text":"<p>Set the point associated with a node.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>Union[int, str, Node]</code> <p>The node to set the point for. Can be an integer index, string name, or Node object.</p> required <code>value</code> <p>A tuple or array-like of length 2 containing (x, y) coordinates.</p> required Notes <p>This sets the point coordinates and marks the point as visible.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>def __setitem__(self, node: Union[int, str, Node], value):\n    \"\"\"Set the point associated with a node.\n\n    Args:\n        node: The node to set the point for. Can be an integer index, string name,\n            or Node object.\n        value: A tuple or array-like of length 2 containing (x, y) coordinates.\n\n    Notes:\n        This sets the point coordinates and marks the point as visible.\n    \"\"\"\n    if type(node) is not int:\n        node = self.skeleton.index(node)\n\n    if len(value) &lt; 2:\n        raise ValueError(\"Value must have at least 2 elements (x, y)\")\n\n    self.points[node][\"xy\"] = value[:2]\n    self.points[node][\"visible\"] = True\n</code></pre>"},{"location":"model/#sleap_io.Instance.bounding_box","title":"<code>bounding_box()</code>","text":"<p>Get the bounding box of visible points.</p> <p>Returns:</p> Type Description <code>Optional[ndarray]</code> <p>A numpy array of shape (2, 2) with [[min_x, min_y], [max_x, max_y]], or None if there are no visible points.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>def bounding_box(self) -&gt; Optional[np.ndarray]:\n    \"\"\"Get the bounding box of visible points.\n\n    Returns:\n        A numpy array of shape (2, 2) with [[min_x, min_y], [max_x, max_y]],\n        or None if there are no visible points.\n    \"\"\"\n    visible = self.points[\"visible\"]\n    if not visible.any():\n        return None\n\n    pts = self.points[\"xy\"][visible]\n    return np.array(\n        [\n            [np.min(pts[:, 0]), np.min(pts[:, 1])],\n            [np.max(pts[:, 0]), np.max(pts[:, 1])],\n        ]\n    )\n</code></pre>"},{"location":"model/#sleap_io.Instance.empty","title":"<code>empty(skeleton, track=None, tracking_score=None, from_predicted=None)</code>  <code>classmethod</code>","text":"<p>Create an empty instance with no points.</p> <p>Parameters:</p> Name Type Description Default <code>skeleton</code> <code>Skeleton</code> <p>The <code>Skeleton</code> that this <code>Instance</code> is associated with.</p> required <code>track</code> <code>Optional[Track]</code> <p>An optional <code>Track</code> associated with a unique animal/object across frames or videos.</p> <code>None</code> <code>tracking_score</code> <code>Optional[float]</code> <p>The score associated with the <code>Track</code> assignment. This is typically the value from the score matrix used in an identity assignment. This is <code>None</code> if the instance is not associated with a track or if the track was assigned manually.</p> <code>None</code> <code>from_predicted</code> <code>Optional[PredictedInstance]</code> <p>The <code>PredictedInstance</code> (if any) that this instance was initialized from. This is used with human-in-the-loop workflows.</p> <code>None</code> <p>Returns:</p> Type Description <code>'Instance'</code> <p>An <code>Instance</code> with an empty numpy array of shape <code>(n_nodes,)</code>.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>@classmethod\ndef empty(\n    cls,\n    skeleton: Skeleton,\n    track: Optional[Track] = None,\n    tracking_score: Optional[float] = None,\n    from_predicted: Optional[PredictedInstance] = None,\n) -&gt; \"Instance\":\n    \"\"\"Create an empty instance with no points.\n\n    Args:\n        skeleton: The `Skeleton` that this `Instance` is associated with.\n        track: An optional `Track` associated with a unique animal/object across\n            frames or videos.\n        tracking_score: The score associated with the `Track` assignment. This is\n            typically the value from the score matrix used in an identity\n            assignment. This is `None` if the instance is not associated with a\n            track or if the track was assigned manually.\n        from_predicted: The `PredictedInstance` (if any) that this instance was\n            initialized from. This is used with human-in-the-loop workflows.\n\n    Returns:\n        An `Instance` with an empty numpy array of shape `(n_nodes,)`.\n    \"\"\"\n    points = PointsArray.empty(len(skeleton))\n    points[\"name\"] = skeleton.node_names\n\n    return cls(\n        points=points,\n        skeleton=skeleton,\n        track=track,\n        tracking_score=tracking_score,\n        from_predicted=from_predicted,\n    )\n</code></pre>"},{"location":"model/#sleap_io.Instance.from_numpy","title":"<code>from_numpy(points_data, skeleton, track=None, tracking_score=None, from_predicted=None)</code>  <code>classmethod</code>","text":"<p>Create an instance object from a numpy array.</p> <p>Parameters:</p> Name Type Description Default <code>points_data</code> <code>ndarray</code> <p>A numpy array of shape <code>(n_nodes, D)</code> corresponding to the points of the skeleton. Values of <code>np.nan</code> indicate \"missing\" nodes and will be reflected in the \"visible\" field.</p> <p>If <code>D == 2</code>, the array should have columns for x and y. If <code>D == 3</code>, the array should have columns for x, y and visible. If <code>D == 4</code>, the array should have columns for x, y, visible and complete.</p> <p>If this is provided as a structured array, it will be used without copy if it has the correct dtype. Otherwise, a new structured array will be created reusing the provided data.</p> required <code>skeleton</code> <code>Skeleton</code> <p>The <code>Skeleton</code> that this <code>Instance</code> is associated with. It should have <code>n_nodes</code> nodes.</p> required <code>track</code> <code>Optional[Track]</code> <p>An optional <code>Track</code> associated with a unique animal/object across frames or videos.</p> <code>None</code> <code>tracking_score</code> <code>Optional[float]</code> <p>The score associated with the <code>Track</code> assignment. This is typically the value from the score matrix used in an identity assignment. This is <code>None</code> if the instance is not associated with a track or if the track was assigned manually.</p> <code>None</code> <code>from_predicted</code> <code>Optional[PredictedInstance]</code> <p>The <code>PredictedInstance</code> (if any) that this instance was initialized from. This is used with human-in-the-loop workflows.</p> <code>None</code> <p>Returns:</p> Type Description <code>'Instance'</code> <p>An <code>Instance</code> object with the specified points.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>@classmethod\ndef from_numpy(\n    cls,\n    points_data: np.ndarray,\n    skeleton: Skeleton,\n    track: Optional[Track] = None,\n    tracking_score: Optional[float] = None,\n    from_predicted: Optional[PredictedInstance] = None,\n) -&gt; \"Instance\":\n    \"\"\"Create an instance object from a numpy array.\n\n    Args:\n        points_data: A numpy array of shape `(n_nodes, D)` corresponding to the\n            points of the skeleton. Values of `np.nan` indicate \"missing\" nodes and\n            will be reflected in the \"visible\" field.\n\n            If `D == 2`, the array should have columns for x and y.\n            If `D == 3`, the array should have columns for x, y and visible.\n            If `D == 4`, the array should have columns for x, y, visible and\n            complete.\n\n            If this is provided as a structured array, it will be used without copy\n            if it has the correct dtype. Otherwise, a new structured array will be\n            created reusing the provided data.\n        skeleton: The `Skeleton` that this `Instance` is associated with. It should\n            have `n_nodes` nodes.\n        track: An optional `Track` associated with a unique animal/object across\n            frames or videos.\n        tracking_score: The score associated with the `Track` assignment. This is\n            typically the value from the score matrix used in an identity\n            assignment. This is `None` if the instance is not associated with a\n            track or if the track was assigned manually.\n        from_predicted: The `PredictedInstance` (if any) that this instance was\n            initialized from. This is used with human-in-the-loop workflows.\n\n    Returns:\n        An `Instance` object with the specified points.\n    \"\"\"\n    return cls(\n        points=points_data,\n        skeleton=skeleton,\n        track=track,\n        tracking_score=tracking_score,\n        from_predicted=from_predicted,\n    )\n</code></pre>"},{"location":"model/#sleap_io.Instance.numpy","title":"<code>numpy(invisible_as_nan=True)</code>","text":"<p>Return the instance points as a <code>(n_nodes, 2)</code> numpy array.</p> <p>Parameters:</p> Name Type Description Default <code>invisible_as_nan</code> <code>bool</code> <p>If <code>True</code> (the default), points that are not visible will be set to <code>np.nan</code>. If <code>False</code>, they will be whatever the stored value of <code>Instance.points[\"xy\"]</code> is.</p> <code>True</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>A numpy array of shape <code>(n_nodes, 2)</code> corresponding to the points of the skeleton. Values of <code>np.nan</code> indicate \"missing\" nodes.</p> Notes <p>This will always return a copy of the array.</p> <p>If you need to avoid making a copy, just access the <code>Instance.points[\"xy\"]</code> attribute directly. This will not replace invisible points with <code>np.nan</code>.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>def numpy(\n    self,\n    invisible_as_nan: bool = True,\n) -&gt; np.ndarray:\n    \"\"\"Return the instance points as a `(n_nodes, 2)` numpy array.\n\n    Args:\n        invisible_as_nan: If `True` (the default), points that are not visible will\n            be set to `np.nan`. If `False`, they will be whatever the stored value\n            of `Instance.points[\"xy\"]` is.\n\n    Returns:\n        A numpy array of shape `(n_nodes, 2)` corresponding to the points of the\n        skeleton. Values of `np.nan` indicate \"missing\" nodes.\n\n    Notes:\n        This will always return a copy of the array.\n\n        If you need to avoid making a copy, just access the `Instance.points[\"xy\"]`\n        attribute directly. This will not replace invisible points with `np.nan`.\n    \"\"\"\n    if invisible_as_nan:\n        return np.where(\n            self.points[\"visible\"].reshape(-1, 1), self.points[\"xy\"], np.nan\n        )\n    else:\n        return self.points[\"xy\"].copy()\n</code></pre>"},{"location":"model/#sleap_io.Instance.overlaps_with","title":"<code>overlaps_with(other, iou_threshold=0.5)</code>","text":"<p>Check if this instance overlaps with another based on bounding box IoU.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>'Instance'</code> <p>Another instance to compare with.</p> required <code>iou_threshold</code> <code>float</code> <p>Minimum IoU (Intersection over Union) value to consider the instances as overlapping.</p> <code>0.5</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if the instances overlap above the threshold, False otherwise.</p> Notes <p>Overlap is computed using the bounding boxes of visible points. If either instance has no visible points, they don't overlap.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>def overlaps_with(self, other: \"Instance\", iou_threshold: float = 0.5) -&gt; bool:\n    \"\"\"Check if this instance overlaps with another based on bounding box IoU.\n\n    Args:\n        other: Another instance to compare with.\n        iou_threshold: Minimum IoU (Intersection over Union) value to consider\n            the instances as overlapping.\n\n    Returns:\n        True if the instances overlap above the threshold, False otherwise.\n\n    Notes:\n        Overlap is computed using the bounding boxes of visible points.\n        If either instance has no visible points, they don't overlap.\n    \"\"\"\n    # Get visible points for both instances\n    self_visible = self.points[\"visible\"]\n    other_visible = other.points[\"visible\"]\n\n    if not self_visible.any() or not other_visible.any():\n        return False\n\n    # Calculate bounding boxes\n    self_pts = self.points[\"xy\"][self_visible]\n    other_pts = other.points[\"xy\"][other_visible]\n\n    self_bbox = np.array(\n        [\n            [np.min(self_pts[:, 0]), np.min(self_pts[:, 1])],  # min x, y\n            [np.max(self_pts[:, 0]), np.max(self_pts[:, 1])],  # max x, y\n        ]\n    )\n\n    other_bbox = np.array(\n        [\n            [np.min(other_pts[:, 0]), np.min(other_pts[:, 1])],\n            [np.max(other_pts[:, 0]), np.max(other_pts[:, 1])],\n        ]\n    )\n\n    # Calculate intersection\n    intersection_min = np.maximum(self_bbox[0], other_bbox[0])\n    intersection_max = np.minimum(self_bbox[1], other_bbox[1])\n\n    if np.any(intersection_min &gt;= intersection_max):\n        # No intersection\n        return False\n\n    intersection_area = np.prod(intersection_max - intersection_min)\n\n    # Calculate union\n    self_area = np.prod(self_bbox[1] - self_bbox[0])\n    other_area = np.prod(other_bbox[1] - other_bbox[0])\n    union_area = self_area + other_area - intersection_area\n\n    # Calculate IoU\n    iou = intersection_area / union_area if union_area &gt; 0 else 0\n\n    return iou &gt;= iou_threshold\n</code></pre>"},{"location":"model/#sleap_io.Instance.replace_skeleton","title":"<code>replace_skeleton(new_skeleton, node_names_map=None)</code>","text":"<p>Replace the skeleton associated with the instance.</p> <p>Parameters:</p> Name Type Description Default <code>new_skeleton</code> <code>Skeleton</code> <p>The new <code>Skeleton</code> to associate with the instance.</p> required <code>node_names_map</code> <code>dict[str, str] | None</code> <p>Dictionary mapping nodes in the old skeleton to nodes in the new skeleton. Keys and values should be specified as lists of strings. If not provided, only nodes with identical names will be mapped. Points associated with unmapped nodes will be removed.</p> <code>None</code> Notes <p>This method will update the <code>Instance.skeleton</code> attribute and the <code>Instance.points</code> attribute in place (a copy is made of the points array).</p> <p>It is recommended to use <code>Labels.replace_skeleton</code> instead of this method if more flexible node mapping is required.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>def replace_skeleton(\n    self,\n    new_skeleton: Skeleton,\n    node_names_map: dict[str, str] | None = None,\n):\n    \"\"\"Replace the skeleton associated with the instance.\n\n    Args:\n        new_skeleton: The new `Skeleton` to associate with the instance.\n        node_names_map: Dictionary mapping nodes in the old skeleton to nodes in the\n            new skeleton. Keys and values should be specified as lists of strings.\n            If not provided, only nodes with identical names will be mapped. Points\n            associated with unmapped nodes will be removed.\n\n    Notes:\n        This method will update the `Instance.skeleton` attribute and the\n        `Instance.points` attribute in place (a copy is made of the points array).\n\n        It is recommended to use `Labels.replace_skeleton` instead of this method if\n        more flexible node mapping is required.\n    \"\"\"\n    # Update skeleton object.\n    # old_skeleton = self.skeleton\n    self.skeleton = new_skeleton\n\n    # Get node names with replacements from node map if possible.\n    # old_node_names = old_skeleton.node_names\n    old_node_names = self.points[\"name\"].tolist()\n    if node_names_map is not None:\n        old_node_names = [node_names_map.get(node, node) for node in old_node_names]\n\n    # Find correspondences.\n    new_node_inds, old_node_inds = self.skeleton.match_nodes(old_node_names)\n    # old_node_inds = np.array(old_node_inds).reshape(-1, 1)\n    # new_node_inds = np.array(new_node_inds).reshape(-1, 1)\n\n    # Update the points.\n    new_points = PointsArray.empty(len(self.skeleton))\n    new_points[new_node_inds] = self.points[old_node_inds]\n    self.points = new_points\n    self.points[\"name\"] = self.skeleton.node_names\n</code></pre>"},{"location":"model/#sleap_io.Instance.same_identity_as","title":"<code>same_identity_as(other)</code>","text":"<p>Check if this instance has the same identity (track) as another instance.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>'Instance'</code> <p>Another instance to compare with.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if both instances have the same track identity, False otherwise.</p> Notes <p>Instances have the same identity if they share the same Track object (by identity, not just by name).</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>def same_identity_as(self, other: \"Instance\") -&gt; bool:\n    \"\"\"Check if this instance has the same identity (track) as another instance.\n\n    Args:\n        other: Another instance to compare with.\n\n    Returns:\n        True if both instances have the same track identity, False otherwise.\n\n    Notes:\n        Instances have the same identity if they share the same Track object\n        (by identity, not just by name).\n    \"\"\"\n    if self.track is None or other.track is None:\n        return False\n    return self.track is other.track\n</code></pre>"},{"location":"model/#sleap_io.Instance.same_pose_as","title":"<code>same_pose_as(other, tolerance=5.0)</code>","text":"<p>Check if this instance has the same pose as another instance.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>'Instance'</code> <p>Another instance to compare with.</p> required <code>tolerance</code> <code>float</code> <p>Maximum distance (in pixels) between corresponding points for them to be considered the same.</p> <code>5.0</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if the instances have the same pose within tolerance, False otherwise.</p> Notes <p>Two instances are considered to have the same pose if: - They have the same skeleton structure - All visible points are within the tolerance distance - They have the same visibility pattern</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>def same_pose_as(self, other: \"Instance\", tolerance: float = 5.0) -&gt; bool:\n    \"\"\"Check if this instance has the same pose as another instance.\n\n    Args:\n        other: Another instance to compare with.\n        tolerance: Maximum distance (in pixels) between corresponding points\n            for them to be considered the same.\n\n    Returns:\n        True if the instances have the same pose within tolerance, False otherwise.\n\n    Notes:\n        Two instances are considered to have the same pose if:\n        - They have the same skeleton structure\n        - All visible points are within the tolerance distance\n        - They have the same visibility pattern\n    \"\"\"\n    # Check skeleton compatibility\n    if not self.skeleton.matches(other.skeleton):\n        return False\n\n    # Get visible points for both instances\n    self_visible = self.points[\"visible\"]\n    other_visible = other.points[\"visible\"]\n\n    # Check if visibility patterns match\n    if not np.array_equal(self_visible, other_visible):\n        return False\n\n    # Compare visible points\n    if not self_visible.any():\n        # Both instances have no visible points\n        return True\n\n    # Calculate distances between corresponding visible points\n    self_pts = self.points[\"xy\"][self_visible]\n    other_pts = other.points[\"xy\"][other_visible]\n\n    distances = np.linalg.norm(self_pts - other_pts, axis=1)\n\n    return np.all(distances &lt;= tolerance)\n</code></pre>"},{"location":"model/#sleap_io.Instance.update_skeleton","title":"<code>update_skeleton(names_only=False)</code>","text":"<p>Update or replace the skeleton associated with the instance.</p> <p>Parameters:</p> Name Type Description Default <code>names_only</code> <code>bool</code> <p>If <code>True</code>, only update the node names in the points array. If <code>False</code>, the points array will be updated to match the new skeleton.</p> <code>False</code> Source code in <code>sleap_io/model/instance.py</code> <pre><code>def update_skeleton(self, names_only: bool = False):\n    \"\"\"Update or replace the skeleton associated with the instance.\n\n    Args:\n        names_only: If `True`, only update the node names in the points array. If\n            `False`, the points array will be updated to match the new skeleton.\n    \"\"\"\n    if names_only:\n        # Update the node names.\n        self.points[\"name\"] = self.skeleton.node_names\n        return\n\n    # Find correspondences.\n    new_node_inds, old_node_inds = self.skeleton.match_nodes(self.points[\"name\"])\n\n    # Update the points.\n    new_points = PointsArray.empty(len(self.skeleton))\n    new_points[new_node_inds] = self.points[old_node_inds]\n    new_points[\"name\"] = self.skeleton.node_names\n    self.points = new_points\n</code></pre>"},{"location":"model/#sleap_io.PredictedInstance","title":"<code>sleap_io.PredictedInstance</code>","text":"<p>               Bases: <code>Instance</code></p> <p>A <code>PredictedInstance</code> is an <code>Instance</code> that was predicted using a model.</p> <p>Attributes:</p> Name Type Description <code>skeleton</code> <code>Skeleton</code> <p>The <code>Skeleton</code> that this <code>Instance</code> is associated with.</p> <code>points</code> <code>PredictedPointsArray</code> <p>A dictionary where keys are <code>Skeleton</code> nodes and values are <code>Point</code>s.</p> <code>track</code> <code>Optional[Track]</code> <p>An optional <code>Track</code> associated with a unique animal/object across frames or videos.</p> <code>from_predicted</code> <code>Optional[PredictedInstance]</code> <p>Not applicable in <code>PredictedInstance</code>s (must be set to <code>None</code>).</p> <code>score</code> <code>float</code> <p>The instance detection or part grouping prediction score. This is a scalar that represents the confidence with which this entire instance was predicted. This may not always be applicable depending on the model type.</p> <code>tracking_score</code> <code>Optional[float]</code> <p>The score associated with the <code>Track</code> assignment. This is typically the value from the score matrix used in an identity assignment.</p> <p>Methods:</p> Name Description <code>__getitem__</code> <p>Return the point associated with a node.</p> <code>__repr__</code> <p>Return a readable representation of the instance.</p> <code>__setitem__</code> <p>Set the point associated with a node.</p> <code>empty</code> <p>Create an empty instance with no points.</p> <code>from_numpy</code> <p>Create a predicted instance object from a numpy array.</p> <code>numpy</code> <p>Return the instance points as a <code>(n_nodes, 2)</code> numpy array.</p> <code>replace_skeleton</code> <p>Replace the skeleton associated with the instance.</p> <code>update_skeleton</code> <p>Update or replace the skeleton associated with the instance.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>@attrs.define(eq=False)\nclass PredictedInstance(Instance):\n    \"\"\"A `PredictedInstance` is an `Instance` that was predicted using a model.\n\n    Attributes:\n        skeleton: The `Skeleton` that this `Instance` is associated with.\n        points: A dictionary where keys are `Skeleton` nodes and values are `Point`s.\n        track: An optional `Track` associated with a unique animal/object across frames\n            or videos.\n        from_predicted: Not applicable in `PredictedInstance`s (must be set to `None`).\n        score: The instance detection or part grouping prediction score. This is a\n            scalar that represents the confidence with which this entire instance was\n            predicted. This may not always be applicable depending on the model type.\n        tracking_score: The score associated with the `Track` assignment. This is\n            typically the value from the score matrix used in an identity assignment.\n    \"\"\"\n\n    points: PredictedPointsArray = attrs.field(eq=attrs.cmp_using(eq=np.array_equal))\n    skeleton: Skeleton\n    score: float = 0.0\n    track: Optional[Track] = None\n    tracking_score: Optional[float] = 0\n    from_predicted: Optional[PredictedInstance] = None\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return a readable representation of the instance.\"\"\"\n        pts = self.numpy().tolist()\n        track = f'\"{self.track.name}\"' if self.track is not None else self.track\n\n        score = str(self.score) if self.score is None else f\"{self.score:.2f}\"\n        tracking_score = (\n            str(self.tracking_score)\n            if self.tracking_score is None\n            else f\"{self.tracking_score:.2f}\"\n        )\n        return (\n            f\"PredictedInstance(points={pts}, track={track}, \"\n            f\"score={score}, tracking_score={tracking_score})\"\n        )\n\n    @classmethod\n    def empty(\n        cls,\n        skeleton: Skeleton,\n        score: float = 0.0,\n        track: Optional[Track] = None,\n        tracking_score: Optional[float] = None,\n        from_predicted: Optional[PredictedInstance] = None,\n    ) -&gt; \"PredictedInstance\":\n        \"\"\"Create an empty instance with no points.\"\"\"\n        points = PredictedPointsArray.empty(len(skeleton))\n        points[\"name\"] = skeleton.node_names\n\n        return cls(\n            points=points,\n            skeleton=skeleton,\n            score=score,\n            track=track,\n            tracking_score=tracking_score,\n            from_predicted=from_predicted,\n        )\n\n    @classmethod\n    def _convert_points(\n        cls, points_data: np.ndarray | dict | list, skeleton: Skeleton\n    ) -&gt; PredictedPointsArray:\n        \"\"\"Convert points to a structured numpy array if needed.\"\"\"\n        if isinstance(points_data, dict):\n            return PredictedPointsArray.from_dict(points_data, skeleton)\n        elif isinstance(points_data, (list, np.ndarray)):\n            if isinstance(points_data, list):\n                points_data = np.array(points_data)\n\n            points = PredictedPointsArray.from_array(points_data)\n            points[\"name\"] = skeleton.node_names\n            return points\n        else:\n            raise ValueError(\"points must be a numpy array or dictionary.\")\n\n    @classmethod\n    def from_numpy(\n        cls,\n        points_data: np.ndarray,\n        skeleton: Skeleton,\n        point_scores: Optional[np.ndarray] = None,\n        score: float = 0.0,\n        track: Optional[Track] = None,\n        tracking_score: Optional[float] = None,\n        from_predicted: Optional[PredictedInstance] = None,\n    ) -&gt; \"PredictedInstance\":\n        \"\"\"Create a predicted instance object from a numpy array.\"\"\"\n        points = cls._convert_points(points_data, skeleton)\n        if point_scores is not None:\n            points[\"score\"] = point_scores\n\n        return cls(\n            points=points,\n            skeleton=skeleton,\n            score=score,\n            track=track,\n            tracking_score=tracking_score,\n            from_predicted=from_predicted,\n        )\n\n    def numpy(\n        self,\n        invisible_as_nan: bool = True,\n        scores: bool = False,\n    ) -&gt; np.ndarray:\n        \"\"\"Return the instance points as a `(n_nodes, 2)` numpy array.\n\n        Args:\n            invisible_as_nan: If `True` (the default), points that are not visible will\n                be set to `np.nan`. If `False`, they will be whatever the stored value\n                of `PredictedInstance.points[\"xy\"]` is.\n            scores: If `True`, the score associated with each point will be\n                included in the output.\n\n        Returns:\n            A numpy array of shape `(n_nodes, 2)` corresponding to the points of the\n            skeleton. Values of `np.nan` indicate \"missing\" nodes.\n\n            If `scores` is `True`, the array will have shape `(n_nodes, 3)` with the\n            third column containing the score associated with each point.\n\n        Notes:\n            This will always return a copy of the array.\n\n            If you need to avoid making a copy, just access the\n            `PredictedInstance.points[\"xy\"]` attribute directly. This will not replace\n            invisible points with `np.nan`.\n        \"\"\"\n        if invisible_as_nan:\n            pts = np.where(\n                self.points[\"visible\"].reshape(-1, 1), self.points[\"xy\"], np.nan\n            )\n        else:\n            pts = self.points[\"xy\"].copy()\n\n        if scores:\n            return np.column_stack((pts, self.points[\"score\"]))\n        else:\n            return pts\n\n    def update_skeleton(self, names_only: bool = False):\n        \"\"\"Update or replace the skeleton associated with the instance.\n\n        Args:\n            names_only: If `True`, only update the node names in the points array. If\n                `False`, the points array will be updated to match the new skeleton.\n        \"\"\"\n        if names_only:\n            # Update the node names.\n            self.points[\"name\"] = self.skeleton.node_names\n            return\n\n        # Find correspondences.\n        new_node_inds, old_node_inds = self.skeleton.match_nodes(self.points[\"name\"])\n\n        # Update the points.\n        new_points = PredictedPointsArray.empty(len(self.skeleton))\n        new_points[new_node_inds] = self.points[old_node_inds]\n        new_points[\"name\"] = self.skeleton.node_names\n        self.points = new_points\n\n    def replace_skeleton(\n        self,\n        new_skeleton: Skeleton,\n        node_names_map: dict[str, str] | None = None,\n    ):\n        \"\"\"Replace the skeleton associated with the instance.\n\n        Args:\n            new_skeleton: The new `Skeleton` to associate with the instance.\n            node_names_map: Dictionary mapping nodes in the old skeleton to nodes in the\n                new skeleton. Keys and values should be specified as lists of strings.\n                If not provided, only nodes with identical names will be mapped. Points\n                associated with unmapped nodes will be removed.\n\n        Notes:\n            This method will update the `PredictedInstance.skeleton` attribute and the\n            `PredictedInstance.points` attribute in place (a copy is made of the points\n            array).\n\n            It is recommended to use `Labels.replace_skeleton` instead of this method if\n            more flexible node mapping is required.\n        \"\"\"\n        # Update skeleton object.\n        self.skeleton = new_skeleton\n\n        # Get node names with replacements from node map if possible.\n        old_node_names = self.points[\"name\"].tolist()\n        if node_names_map is not None:\n            old_node_names = [node_names_map.get(node, node) for node in old_node_names]\n\n        # Find correspondences.\n        new_node_inds, old_node_inds = self.skeleton.match_nodes(old_node_names)\n\n        # Update the points.\n        new_points = PredictedPointsArray.empty(len(self.skeleton))\n        new_points[new_node_inds] = self.points[old_node_inds]\n        self.points = new_points\n        self.points[\"name\"] = self.skeleton.node_names\n\n    def __getitem__(self, node: Union[int, str, Node]) -&gt; np.ndarray:\n        \"\"\"Return the point associated with a node.\"\"\"\n        # Inherit from Instance.__getitem__\n        return super().__getitem__(node)\n\n    def __setitem__(self, node: Union[int, str, Node], value):\n        \"\"\"Set the point associated with a node.\n\n        Args:\n            node: The node to set the point for. Can be an integer index, string name,\n                or Node object.\n            value: A tuple or array-like of length 2 or 3 containing (x, y) coordinates\n                and optionally a confidence score. If the score is not provided, it\n                defaults to 1.0.\n\n        Notes:\n            This sets the point coordinates, score, and marks the point as visible.\n        \"\"\"\n        if type(node) is not int:\n            node = self.skeleton.index(node)\n\n        if len(value) &lt; 2:\n            raise ValueError(\"Value must have at least 2 elements (x, y)\")\n\n        self.points[node][\"xy\"] = value[:2]\n\n        # Set score if provided, otherwise default to 1.0\n        if len(value) &gt;= 3:\n            self.points[node][\"score\"] = value[2]\n        else:\n            self.points[node][\"score\"] = 1.0\n\n        self.points[node][\"visible\"] = True\n</code></pre>"},{"location":"model/#sleap_io.PredictedInstance.__getitem__","title":"<code>__getitem__(node)</code>","text":"<p>Return the point associated with a node.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>def __getitem__(self, node: Union[int, str, Node]) -&gt; np.ndarray:\n    \"\"\"Return the point associated with a node.\"\"\"\n    # Inherit from Instance.__getitem__\n    return super().__getitem__(node)\n</code></pre>"},{"location":"model/#sleap_io.PredictedInstance.__repr__","title":"<code>__repr__()</code>","text":"<p>Return a readable representation of the instance.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return a readable representation of the instance.\"\"\"\n    pts = self.numpy().tolist()\n    track = f'\"{self.track.name}\"' if self.track is not None else self.track\n\n    score = str(self.score) if self.score is None else f\"{self.score:.2f}\"\n    tracking_score = (\n        str(self.tracking_score)\n        if self.tracking_score is None\n        else f\"{self.tracking_score:.2f}\"\n    )\n    return (\n        f\"PredictedInstance(points={pts}, track={track}, \"\n        f\"score={score}, tracking_score={tracking_score})\"\n    )\n</code></pre>"},{"location":"model/#sleap_io.PredictedInstance.__setitem__","title":"<code>__setitem__(node, value)</code>","text":"<p>Set the point associated with a node.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>Union[int, str, Node]</code> <p>The node to set the point for. Can be an integer index, string name, or Node object.</p> required <code>value</code> <p>A tuple or array-like of length 2 or 3 containing (x, y) coordinates and optionally a confidence score. If the score is not provided, it defaults to 1.0.</p> required Notes <p>This sets the point coordinates, score, and marks the point as visible.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>def __setitem__(self, node: Union[int, str, Node], value):\n    \"\"\"Set the point associated with a node.\n\n    Args:\n        node: The node to set the point for. Can be an integer index, string name,\n            or Node object.\n        value: A tuple or array-like of length 2 or 3 containing (x, y) coordinates\n            and optionally a confidence score. If the score is not provided, it\n            defaults to 1.0.\n\n    Notes:\n        This sets the point coordinates, score, and marks the point as visible.\n    \"\"\"\n    if type(node) is not int:\n        node = self.skeleton.index(node)\n\n    if len(value) &lt; 2:\n        raise ValueError(\"Value must have at least 2 elements (x, y)\")\n\n    self.points[node][\"xy\"] = value[:2]\n\n    # Set score if provided, otherwise default to 1.0\n    if len(value) &gt;= 3:\n        self.points[node][\"score\"] = value[2]\n    else:\n        self.points[node][\"score\"] = 1.0\n\n    self.points[node][\"visible\"] = True\n</code></pre>"},{"location":"model/#sleap_io.PredictedInstance.empty","title":"<code>empty(skeleton, score=0.0, track=None, tracking_score=None, from_predicted=None)</code>  <code>classmethod</code>","text":"<p>Create an empty instance with no points.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>@classmethod\ndef empty(\n    cls,\n    skeleton: Skeleton,\n    score: float = 0.0,\n    track: Optional[Track] = None,\n    tracking_score: Optional[float] = None,\n    from_predicted: Optional[PredictedInstance] = None,\n) -&gt; \"PredictedInstance\":\n    \"\"\"Create an empty instance with no points.\"\"\"\n    points = PredictedPointsArray.empty(len(skeleton))\n    points[\"name\"] = skeleton.node_names\n\n    return cls(\n        points=points,\n        skeleton=skeleton,\n        score=score,\n        track=track,\n        tracking_score=tracking_score,\n        from_predicted=from_predicted,\n    )\n</code></pre>"},{"location":"model/#sleap_io.PredictedInstance.from_numpy","title":"<code>from_numpy(points_data, skeleton, point_scores=None, score=0.0, track=None, tracking_score=None, from_predicted=None)</code>  <code>classmethod</code>","text":"<p>Create a predicted instance object from a numpy array.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>@classmethod\ndef from_numpy(\n    cls,\n    points_data: np.ndarray,\n    skeleton: Skeleton,\n    point_scores: Optional[np.ndarray] = None,\n    score: float = 0.0,\n    track: Optional[Track] = None,\n    tracking_score: Optional[float] = None,\n    from_predicted: Optional[PredictedInstance] = None,\n) -&gt; \"PredictedInstance\":\n    \"\"\"Create a predicted instance object from a numpy array.\"\"\"\n    points = cls._convert_points(points_data, skeleton)\n    if point_scores is not None:\n        points[\"score\"] = point_scores\n\n    return cls(\n        points=points,\n        skeleton=skeleton,\n        score=score,\n        track=track,\n        tracking_score=tracking_score,\n        from_predicted=from_predicted,\n    )\n</code></pre>"},{"location":"model/#sleap_io.PredictedInstance.numpy","title":"<code>numpy(invisible_as_nan=True, scores=False)</code>","text":"<p>Return the instance points as a <code>(n_nodes, 2)</code> numpy array.</p> <p>Parameters:</p> Name Type Description Default <code>invisible_as_nan</code> <code>bool</code> <p>If <code>True</code> (the default), points that are not visible will be set to <code>np.nan</code>. If <code>False</code>, they will be whatever the stored value of <code>PredictedInstance.points[\"xy\"]</code> is.</p> <code>True</code> <code>scores</code> <code>bool</code> <p>If <code>True</code>, the score associated with each point will be included in the output.</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>A numpy array of shape <code>(n_nodes, 2)</code> corresponding to the points of the skeleton. Values of <code>np.nan</code> indicate \"missing\" nodes.</p> <p>If <code>scores</code> is <code>True</code>, the array will have shape <code>(n_nodes, 3)</code> with the third column containing the score associated with each point.</p> Notes <p>This will always return a copy of the array.</p> <p>If you need to avoid making a copy, just access the <code>PredictedInstance.points[\"xy\"]</code> attribute directly. This will not replace invisible points with <code>np.nan</code>.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>def numpy(\n    self,\n    invisible_as_nan: bool = True,\n    scores: bool = False,\n) -&gt; np.ndarray:\n    \"\"\"Return the instance points as a `(n_nodes, 2)` numpy array.\n\n    Args:\n        invisible_as_nan: If `True` (the default), points that are not visible will\n            be set to `np.nan`. If `False`, they will be whatever the stored value\n            of `PredictedInstance.points[\"xy\"]` is.\n        scores: If `True`, the score associated with each point will be\n            included in the output.\n\n    Returns:\n        A numpy array of shape `(n_nodes, 2)` corresponding to the points of the\n        skeleton. Values of `np.nan` indicate \"missing\" nodes.\n\n        If `scores` is `True`, the array will have shape `(n_nodes, 3)` with the\n        third column containing the score associated with each point.\n\n    Notes:\n        This will always return a copy of the array.\n\n        If you need to avoid making a copy, just access the\n        `PredictedInstance.points[\"xy\"]` attribute directly. This will not replace\n        invisible points with `np.nan`.\n    \"\"\"\n    if invisible_as_nan:\n        pts = np.where(\n            self.points[\"visible\"].reshape(-1, 1), self.points[\"xy\"], np.nan\n        )\n    else:\n        pts = self.points[\"xy\"].copy()\n\n    if scores:\n        return np.column_stack((pts, self.points[\"score\"]))\n    else:\n        return pts\n</code></pre>"},{"location":"model/#sleap_io.PredictedInstance.replace_skeleton","title":"<code>replace_skeleton(new_skeleton, node_names_map=None)</code>","text":"<p>Replace the skeleton associated with the instance.</p> <p>Parameters:</p> Name Type Description Default <code>new_skeleton</code> <code>Skeleton</code> <p>The new <code>Skeleton</code> to associate with the instance.</p> required <code>node_names_map</code> <code>dict[str, str] | None</code> <p>Dictionary mapping nodes in the old skeleton to nodes in the new skeleton. Keys and values should be specified as lists of strings. If not provided, only nodes with identical names will be mapped. Points associated with unmapped nodes will be removed.</p> <code>None</code> Notes <p>This method will update the <code>PredictedInstance.skeleton</code> attribute and the <code>PredictedInstance.points</code> attribute in place (a copy is made of the points array).</p> <p>It is recommended to use <code>Labels.replace_skeleton</code> instead of this method if more flexible node mapping is required.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>def replace_skeleton(\n    self,\n    new_skeleton: Skeleton,\n    node_names_map: dict[str, str] | None = None,\n):\n    \"\"\"Replace the skeleton associated with the instance.\n\n    Args:\n        new_skeleton: The new `Skeleton` to associate with the instance.\n        node_names_map: Dictionary mapping nodes in the old skeleton to nodes in the\n            new skeleton. Keys and values should be specified as lists of strings.\n            If not provided, only nodes with identical names will be mapped. Points\n            associated with unmapped nodes will be removed.\n\n    Notes:\n        This method will update the `PredictedInstance.skeleton` attribute and the\n        `PredictedInstance.points` attribute in place (a copy is made of the points\n        array).\n\n        It is recommended to use `Labels.replace_skeleton` instead of this method if\n        more flexible node mapping is required.\n    \"\"\"\n    # Update skeleton object.\n    self.skeleton = new_skeleton\n\n    # Get node names with replacements from node map if possible.\n    old_node_names = self.points[\"name\"].tolist()\n    if node_names_map is not None:\n        old_node_names = [node_names_map.get(node, node) for node in old_node_names]\n\n    # Find correspondences.\n    new_node_inds, old_node_inds = self.skeleton.match_nodes(old_node_names)\n\n    # Update the points.\n    new_points = PredictedPointsArray.empty(len(self.skeleton))\n    new_points[new_node_inds] = self.points[old_node_inds]\n    self.points = new_points\n    self.points[\"name\"] = self.skeleton.node_names\n</code></pre>"},{"location":"model/#sleap_io.PredictedInstance.update_skeleton","title":"<code>update_skeleton(names_only=False)</code>","text":"<p>Update or replace the skeleton associated with the instance.</p> <p>Parameters:</p> Name Type Description Default <code>names_only</code> <code>bool</code> <p>If <code>True</code>, only update the node names in the points array. If <code>False</code>, the points array will be updated to match the new skeleton.</p> <code>False</code> Source code in <code>sleap_io/model/instance.py</code> <pre><code>def update_skeleton(self, names_only: bool = False):\n    \"\"\"Update or replace the skeleton associated with the instance.\n\n    Args:\n        names_only: If `True`, only update the node names in the points array. If\n            `False`, the points array will be updated to match the new skeleton.\n    \"\"\"\n    if names_only:\n        # Update the node names.\n        self.points[\"name\"] = self.skeleton.node_names\n        return\n\n    # Find correspondences.\n    new_node_inds, old_node_inds = self.skeleton.match_nodes(self.points[\"name\"])\n\n    # Update the points.\n    new_points = PredictedPointsArray.empty(len(self.skeleton))\n    new_points[new_node_inds] = self.points[old_node_inds]\n    new_points[\"name\"] = self.skeleton.node_names\n    self.points = new_points\n</code></pre>"},{"location":"model/#sleap_io.Skeleton","title":"<code>sleap_io.Skeleton</code>","text":"<p>A description of a set of landmark types and connections between them.</p> <p>Skeletons are represented by a directed graph composed of a set of <code>Node</code>s (landmark types such as body parts) and <code>Edge</code>s (connections between parts).</p> <p>Attributes:</p> Name Type Description <code>nodes</code> <code>list[Node]</code> <p>A list of <code>Node</code>s. May be specified as a list of strings to create new nodes from their names.</p> <code>edges</code> <code>list[Edge]</code> <p>A list of <code>Edge</code>s. May be specified as a list of 2-tuples of string names or integer indices of <code>nodes</code>. Each edge corresponds to a pair of source and destination nodes forming a directed edge.</p> <code>symmetries</code> <code>list[Symmetry]</code> <p>A list of <code>Symmetry</code>s. Each symmetry corresponds to symmetric body parts, such as <code>\"left eye\", \"right eye\"</code>. This is used when applying flip (reflection) augmentation to images in order to appropriately swap the indices of symmetric landmarks.</p> <code>name</code> <code>str | None</code> <p>A descriptive name for the <code>Skeleton</code>.</p> <p>Methods:</p> Name Description <code>__attrs_post_init__</code> <p>Ensure nodes are <code>Node</code>s, edges are <code>Edge</code>s, and <code>Node</code> map is updated.</p> <code>__contains__</code> <p>Check if a node is in the skeleton.</p> <code>__getitem__</code> <p>Return a <code>Node</code> when indexing by name or integer.</p> <code>__len__</code> <p>Return the number of nodes in the skeleton.</p> <code>__repr__</code> <p>Return a readable representation of the skeleton.</p> <code>add_edge</code> <p>Add an <code>Edge</code> to the skeleton.</p> <code>add_edges</code> <p>Add multiple <code>Edge</code>s to the skeleton.</p> <code>add_node</code> <p>Add a <code>Node</code> to the skeleton.</p> <code>add_nodes</code> <p>Add multiple <code>Node</code>s to the skeleton.</p> <code>add_symmetries</code> <p>Add multiple <code>Symmetry</code> relationships to the skeleton.</p> <code>add_symmetry</code> <p>Add a symmetry relationship to the skeleton.</p> <code>get_flipped_node_inds</code> <p>Returns node indices that should be switched when horizontally flipping.</p> <code>index</code> <p>Return the index of a node specified as a <code>Node</code> or string name.</p> <code>match_nodes</code> <p>Return the order of nodes in the skeleton.</p> <code>matches</code> <p>Check if this skeleton matches another skeleton's structure.</p> <code>node_similarities</code> <p>Calculate node overlap metrics with another skeleton.</p> <code>rebuild_cache</code> <p>Rebuild the node name/index to <code>Node</code> map caches.</p> <code>remove_node</code> <p>Remove a single node from the skeleton.</p> <code>remove_nodes</code> <p>Remove nodes from the skeleton.</p> <code>rename_node</code> <p>Rename a single node in the skeleton.</p> <code>rename_nodes</code> <p>Rename nodes in the skeleton.</p> <code>reorder_nodes</code> <p>Reorder nodes in the skeleton.</p> <code>require_node</code> <p>Return a <code>Node</code> object, handling indexing and adding missing nodes.</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>@define(eq=False)\nclass Skeleton:\n    \"\"\"A description of a set of landmark types and connections between them.\n\n    Skeletons are represented by a directed graph composed of a set of `Node`s (landmark\n    types such as body parts) and `Edge`s (connections between parts).\n\n    Attributes:\n        nodes: A list of `Node`s. May be specified as a list of strings to create new\n            nodes from their names.\n        edges: A list of `Edge`s. May be specified as a list of 2-tuples of string names\n            or integer indices of `nodes`. Each edge corresponds to a pair of source and\n            destination nodes forming a directed edge.\n        symmetries: A list of `Symmetry`s. Each symmetry corresponds to symmetric body\n            parts, such as `\"left eye\", \"right eye\"`. This is used when applying flip\n            (reflection) augmentation to images in order to appropriately swap the\n            indices of symmetric landmarks.\n        name: A descriptive name for the `Skeleton`.\n    \"\"\"\n\n    def _nodes_on_setattr(self, attr, new_nodes):\n        \"\"\"Callback to update caches when nodes are set.\"\"\"\n        self.rebuild_cache(nodes=new_nodes)\n        return new_nodes\n\n    nodes: list[Node] = field(\n        factory=list,\n        on_setattr=_nodes_on_setattr,\n    )\n    edges: list[Edge] = field(factory=list)\n    symmetries: list[Symmetry] = field(factory=list)\n    name: str | None = None\n    _name_to_node_cache: dict[str, Node] = field(init=False, repr=False, eq=False)\n    _node_to_ind_cache: dict[Node, int] = field(init=False, repr=False, eq=False)\n\n    def __attrs_post_init__(self):\n        \"\"\"Ensure nodes are `Node`s, edges are `Edge`s, and `Node` map is updated.\"\"\"\n        self._convert_nodes()\n        self._convert_edges()\n        self._convert_symmetries()\n        self.rebuild_cache()\n\n    def _convert_nodes(self):\n        \"\"\"Convert nodes to `Node` objects if needed.\"\"\"\n        if isinstance(self.nodes, np.ndarray):\n            object.__setattr__(self, \"nodes\", self.nodes.tolist())\n        for i, node in enumerate(self.nodes):\n            if type(node) is str:\n                self.nodes[i] = Node(node)\n\n    def _convert_edges(self):\n        \"\"\"Convert list of edge names or integers to `Edge` objects if needed.\"\"\"\n        if isinstance(self.edges, np.ndarray):\n            self.edges = self.edges.tolist()\n        node_names = self.node_names\n        for i, edge in enumerate(self.edges):\n            if type(edge) is Edge:\n                continue\n            src, dst = edge\n            if type(src) is str:\n                try:\n                    src = node_names.index(src)\n                except ValueError:\n                    raise ValueError(\n                        f\"Node '{src}' specified in the edge list is not in the nodes.\"\n                    )\n            if type(src) is int or (\n                np.isscalar(src) and np.issubdtype(src.dtype, np.integer)\n            ):\n                src = self.nodes[src]\n\n            if type(dst) is str:\n                try:\n                    dst = node_names.index(dst)\n                except ValueError:\n                    raise ValueError(\n                        f\"Node '{dst}' specified in the edge list is not in the nodes.\"\n                    )\n            if type(dst) is int or (\n                np.isscalar(dst) and np.issubdtype(dst.dtype, np.integer)\n            ):\n                dst = self.nodes[dst]\n\n            self.edges[i] = Edge(src, dst)\n\n    def _convert_symmetries(self):\n        \"\"\"Convert list of symmetric node names or integers to `Symmetry` objects.\"\"\"\n        if isinstance(self.symmetries, np.ndarray):\n            self.symmetries = self.symmetries.tolist()\n\n        node_names = self.node_names\n        for i, symmetry in enumerate(self.symmetries):\n            if type(symmetry) is Symmetry:\n                continue\n            node1, node2 = symmetry\n            if type(node1) is str:\n                try:\n                    node1 = node_names.index(node1)\n                except ValueError:\n                    raise ValueError(\n                        f\"Node '{node1}' specified in the symmetry list is not in the \"\n                        \"nodes.\"\n                    )\n            if type(node1) is int or (\n                np.isscalar(node1) and np.issubdtype(node1.dtype, np.integer)\n            ):\n                node1 = self.nodes[node1]\n\n            if type(node2) is str:\n                try:\n                    node2 = node_names.index(node2)\n                except ValueError:\n                    raise ValueError(\n                        f\"Node '{node2}' specified in the symmetry list is not in the \"\n                        \"nodes.\"\n                    )\n            if type(node2) is int or (\n                np.isscalar(node2) and np.issubdtype(node2.dtype, np.integer)\n            ):\n                node2 = self.nodes[node2]\n\n            self.symmetries[i] = Symmetry({node1, node2})\n\n    def rebuild_cache(self, nodes: list[Node] | None = None):\n        \"\"\"Rebuild the node name/index to `Node` map caches.\n\n        Args:\n            nodes: A list of `Node` objects to update the cache with. If not provided,\n                the cache will be updated with the current nodes in the skeleton. If\n                nodes are provided, the cache will be updated with the provided nodes,\n                but the current nodes in the skeleton will not be updated. Default is\n                `None`.\n\n        Notes:\n            This function should be called when nodes or node list is mutated to update\n            the lookup caches for indexing nodes by name or `Node` object.\n\n            This is done automatically when nodes are added or removed from the skeleton\n            using the convenience methods in this class.\n\n            This method only needs to be used when manually mutating nodes or the node\n            list directly.\n        \"\"\"\n        if nodes is None:\n            nodes = self.nodes\n        self._name_to_node_cache = {node.name: node for node in nodes}\n        self._node_to_ind_cache = {node: i for i, node in enumerate(nodes)}\n\n    @property\n    def node_names(self) -&gt; list[str]:\n        \"\"\"Names of the nodes associated with this skeleton as a list of strings.\"\"\"\n        return [node.name for node in self.nodes]\n\n    @property\n    def edge_inds(self) -&gt; list[tuple[int, int]]:\n        \"\"\"Edges indices as a list of 2-tuples.\"\"\"\n        return [\n            (self.nodes.index(edge.source), self.nodes.index(edge.destination))\n            for edge in self.edges\n        ]\n\n    @property\n    def edge_names(self) -&gt; list[str, str]:\n        \"\"\"Edge names as a list of 2-tuples with string node names.\"\"\"\n        return [(edge.source.name, edge.destination.name) for edge in self.edges]\n\n    @property\n    def symmetry_inds(self) -&gt; list[tuple[int, int]]:\n        \"\"\"Symmetry indices as a list of 2-tuples.\"\"\"\n        return [\n            tuple(sorted((self.index(symmetry[0]), self.index(symmetry[1]))))\n            for symmetry in self.symmetries\n        ]\n\n    @property\n    def symmetry_names(self) -&gt; list[str, str]:\n        \"\"\"Symmetry names as a list of 2-tuples with string node names.\"\"\"\n        return [\n            (self.nodes[i].name, self.nodes[j].name) for (i, j) in self.symmetry_inds\n        ]\n\n    def get_flipped_node_inds(self) -&gt; list[int]:\n        \"\"\"Returns node indices that should be switched when horizontally flipping.\n\n        This is useful as a lookup table for flipping the landmark coordinates when\n        doing data augmentation.\n\n        Example:\n            &gt;&gt;&gt; skel = Skeleton([\"A\", \"B_left\", \"B_right\", \"C\", \"D_left\", \"D_right\"])\n            &gt;&gt;&gt; skel.add_symmetry(\"B_left\", \"B_right\")\n            &gt;&gt;&gt; skel.add_symmetry(\"D_left\", \"D_right\")\n            &gt;&gt;&gt; skel.flipped_node_inds\n            [0, 2, 1, 3, 5, 4]\n            &gt;&gt;&gt; pose = np.array([[0, 0], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5]])\n            &gt;&gt;&gt; pose[skel.flipped_node_inds]\n            array([[0, 0],\n                   [2, 2],\n                   [1, 1],\n                   [3, 3],\n                   [5, 5],\n                   [4, 4]])\n        \"\"\"\n        flip_idx = np.arange(len(self.nodes))\n        if len(self.symmetries) &gt; 0:\n            symmetry_inds = np.array(\n                [(self.index(a), self.index(b)) for a, b in self.symmetries]\n            )\n            flip_idx[symmetry_inds[:, 0]] = symmetry_inds[:, 1]\n            flip_idx[symmetry_inds[:, 1]] = symmetry_inds[:, 0]\n\n        flip_idx = flip_idx.tolist()\n        return flip_idx\n\n    def __len__(self) -&gt; int:\n        \"\"\"Return the number of nodes in the skeleton.\"\"\"\n        return len(self.nodes)\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return a readable representation of the skeleton.\"\"\"\n        nodes = \", \".join([f'\"{node}\"' for node in self.node_names])\n        return f\"Skeleton(nodes=[{nodes}], edges={self.edge_inds})\"\n\n    def index(self, node: Node | str) -&gt; int:\n        \"\"\"Return the index of a node specified as a `Node` or string name.\"\"\"\n        if type(node) is str:\n            return self.index(self._name_to_node_cache[node])\n        elif type(node) is Node:\n            return self._node_to_ind_cache[node]\n        else:\n            raise IndexError(f\"Invalid indexing argument for skeleton: {node}\")\n\n    def __getitem__(self, idx: NodeOrIndex) -&gt; Node:\n        \"\"\"Return a `Node` when indexing by name or integer.\"\"\"\n        if type(idx) is int:\n            return self.nodes[idx]\n        elif type(idx) is str:\n            return self._name_to_node_cache[idx]\n        else:\n            raise IndexError(f\"Invalid indexing argument for skeleton: {idx}\")\n\n    def __contains__(self, node: NodeOrIndex) -&gt; bool:\n        \"\"\"Check if a node is in the skeleton.\"\"\"\n        if type(node) is str:\n            return node in self._name_to_node_cache\n        elif type(node) is Node:\n            return node in self.nodes\n        elif type(node) is int:\n            return 0 &lt;= node &lt; len(self.nodes)\n        else:\n            raise ValueError(f\"Invalid node type for skeleton: {node}\")\n\n    def add_node(self, node: Node | str):\n        \"\"\"Add a `Node` to the skeleton.\n\n        Args:\n            node: A `Node` object or a string name to create a new node.\n\n        Raises:\n            ValueError: If the node already exists in the skeleton or if the node is\n                not specified as a `Node` or string.\n        \"\"\"\n        if node in self:\n            raise ValueError(f\"Node '{node}' already exists in the skeleton.\")\n\n        if type(node) is str:\n            node = Node(node)\n\n        if type(node) is not Node:\n            raise ValueError(f\"Invalid node type: {node} ({type(node)})\")\n\n        self.nodes.append(node)\n\n        # Atomic update of the cache.\n        self._name_to_node_cache[node.name] = node\n        self._node_to_ind_cache[node] = len(self.nodes) - 1\n\n    def add_nodes(self, nodes: list[Node | str]):\n        \"\"\"Add multiple `Node`s to the skeleton.\n\n        Args:\n            nodes: A list of `Node` objects or string names to create new nodes.\n        \"\"\"\n        for node in nodes:\n            self.add_node(node)\n\n    def require_node(self, node: NodeOrIndex, add_missing: bool = True) -&gt; Node:\n        \"\"\"Return a `Node` object, handling indexing and adding missing nodes.\n\n        Args:\n            node: A `Node` object, name or index.\n            add_missing: If `True`, missing nodes will be added to the skeleton. If\n                `False`, an error will be raised if the node is not found. Default is\n                `True`.\n\n        Returns:\n            The `Node` object.\n\n        Raises:\n            IndexError: If the node is not found in the skeleton and `add_missing` is\n                `False`.\n        \"\"\"\n        if node not in self:\n            if add_missing:\n                self.add_node(node)\n            else:\n                raise IndexError(f\"Node '{node}' not found in the skeleton.\")\n\n        if type(node) is Node:\n            return node\n\n        return self[node]\n\n    def add_edge(\n        self,\n        src: NodeOrIndex | Edge | tuple[NodeOrIndex, NodeOrIndex],\n        dst: NodeOrIndex | None = None,\n    ):\n        \"\"\"Add an `Edge` to the skeleton.\n\n        Args:\n            src: The source node specified as a `Node`, name or index.\n            dst: The destination node specified as a `Node`, name or index.\n        \"\"\"\n        edge = None\n        if type(src) is tuple:\n            src, dst = src\n\n        if is_node_or_index(src):\n            if not is_node_or_index(dst):\n                raise ValueError(\"Destination node must be specified.\")\n\n            src = self.require_node(src)\n            dst = self.require_node(dst)\n            edge = Edge(src, dst)\n\n        if type(src) is Edge:\n            edge = src\n\n        if edge not in self.edges:\n            self.edges.append(edge)\n\n    def add_edges(self, edges: list[Edge | tuple[NodeOrIndex, NodeOrIndex]]):\n        \"\"\"Add multiple `Edge`s to the skeleton.\n\n        Args:\n            edges: A list of `Edge` objects or 2-tuples of source and destination nodes.\n        \"\"\"\n        for edge in edges:\n            self.add_edge(edge)\n\n    def add_symmetry(\n        self, node1: Symmetry | NodeOrIndex = None, node2: NodeOrIndex | None = None\n    ):\n        \"\"\"Add a symmetry relationship to the skeleton.\n\n        Args:\n            node1: The first node specified as a `Node`, name or index. If a `Symmetry`\n                object is provided, it will be added directly to the skeleton.\n            node2: The second node specified as a `Node`, name or index.\n        \"\"\"\n        symmetry = None\n        if type(node1) is Symmetry:\n            symmetry = node1\n            node1, node2 = symmetry\n\n        node1 = self.require_node(node1)\n        node2 = self.require_node(node2)\n\n        if symmetry is None:\n            symmetry = Symmetry({node1, node2})\n\n        if symmetry not in self.symmetries:\n            self.symmetries.append(symmetry)\n\n    def add_symmetries(\n        self, symmetries: list[Symmetry | tuple[NodeOrIndex, NodeOrIndex]]\n    ):\n        \"\"\"Add multiple `Symmetry` relationships to the skeleton.\n\n        Args:\n            symmetries: A list of `Symmetry` objects or 2-tuples of symmetric nodes.\n        \"\"\"\n        for symmetry in symmetries:\n            self.add_symmetry(*symmetry)\n\n    def rename_nodes(self, name_map: dict[NodeOrIndex, str] | list[str]):\n        \"\"\"Rename nodes in the skeleton.\n\n        Args:\n            name_map: A dictionary mapping old node names to new node names. Keys can be\n                specified as `Node` objects, integer indices, or string names. Values\n                must be specified as string names.\n\n                If a list of strings is provided of the same length as the current\n                nodes, the nodes will be renamed to the names in the list in order.\n\n        Raises:\n            ValueError: If the new node names exist in the skeleton or if the old node\n                names are not found in the skeleton.\n\n        Notes:\n            This method should always be used when renaming nodes in the skeleton as it\n            handles updating the lookup caches necessary for indexing nodes by name.\n\n            After renaming, instances using this skeleton **do NOT need to be updated**\n            as the nodes are stored by reference in the skeleton, so changes are\n            reflected automatically.\n\n        Example:\n            &gt;&gt;&gt; skel = Skeleton([\"A\", \"B\", \"C\"], edges=[(\"A\", \"B\"), (\"B\", \"C\")])\n            &gt;&gt;&gt; skel.rename_nodes({\"A\": \"X\", \"B\": \"Y\", \"C\": \"Z\"})\n            &gt;&gt;&gt; skel.node_names\n            [\"X\", \"Y\", \"Z\"]\n            &gt;&gt;&gt; skel.rename_nodes([\"a\", \"b\", \"c\"])\n            &gt;&gt;&gt; skel.node_names\n            [\"a\", \"b\", \"c\"]\n        \"\"\"\n        if type(name_map) is list:\n            if len(name_map) != len(self.nodes):\n                raise ValueError(\n                    \"List of new node names must be the same length as the current \"\n                    \"nodes.\"\n                )\n            name_map = {node: name for node, name in zip(self.nodes, name_map)}\n\n        for old_name, new_name in name_map.items():\n            if type(old_name) is Node:\n                old_name = old_name.name\n            if type(old_name) is int:\n                old_name = self.nodes[old_name].name\n\n            if old_name not in self._name_to_node_cache:\n                raise ValueError(f\"Node '{old_name}' not found in the skeleton.\")\n            if new_name in self._name_to_node_cache:\n                raise ValueError(f\"Node '{new_name}' already exists in the skeleton.\")\n\n            node = self._name_to_node_cache[old_name]\n            node.name = new_name\n            self._name_to_node_cache[new_name] = node\n            del self._name_to_node_cache[old_name]\n\n    def rename_node(self, old_name: NodeOrIndex, new_name: str):\n        \"\"\"Rename a single node in the skeleton.\n\n        Args:\n            old_name: The name of the node to rename. Can also be specified as an\n                integer index or `Node` object.\n            new_name: The new name for the node.\n        \"\"\"\n        self.rename_nodes({old_name: new_name})\n\n    def remove_nodes(self, nodes: list[NodeOrIndex]):\n        \"\"\"Remove nodes from the skeleton.\n\n        Args:\n            nodes: A list of node names, indices, or `Node` objects to remove.\n\n        Notes:\n            This method handles updating the lookup caches necessary for indexing nodes\n            by name.\n\n            Any edges and symmetries that are connected to the removed nodes will also\n            be removed.\n\n        Warning:\n            **This method does NOT update instances** that use this skeleton to reflect\n            changes.\n\n            It is recommended to use the `Labels.remove_nodes()` method which will\n            update all contained to reflect the changes made to the skeleton.\n\n            To manually update instances after this method is called, call\n            `instance.update_nodes()` on each instance that uses this skeleton.\n        \"\"\"\n        # Standardize input and make a pre-mutation copy before keys are changed.\n        rm_node_objs = [self.require_node(node, add_missing=False) for node in nodes]\n\n        # Remove nodes from the skeleton.\n        for node in rm_node_objs:\n            self.nodes.remove(node)\n            del self._name_to_node_cache[node.name]\n\n        # Remove edges connected to the removed nodes.\n        self.edges = [\n            edge\n            for edge in self.edges\n            if edge.source not in rm_node_objs and edge.destination not in rm_node_objs\n        ]\n\n        # Remove symmetries connected to the removed nodes.\n        self.symmetries = [\n            symmetry\n            for symmetry in self.symmetries\n            if symmetry.nodes.isdisjoint(rm_node_objs)\n        ]\n\n        # Update node index map.\n        self.rebuild_cache()\n\n    def remove_node(self, node: NodeOrIndex):\n        \"\"\"Remove a single node from the skeleton.\n\n        Args:\n            node: The node to remove. Can be specified as a string name, integer index,\n                or `Node` object.\n\n        Notes:\n            This method handles updating the lookup caches necessary for indexing nodes\n            by name.\n\n            Any edges and symmetries that are connected to the removed node will also be\n            removed.\n\n        Warning:\n            **This method does NOT update instances** that use this skeleton to reflect\n            changes.\n\n            It is recommended to use the `Labels.remove_nodes()` method which will\n            update all contained instances to reflect the changes made to the skeleton.\n\n            To manually update instances after this method is called, call\n            `Instance.update_skeleton()` on each instance that uses this skeleton.\n        \"\"\"\n        self.remove_nodes([node])\n\n    def reorder_nodes(self, new_order: list[NodeOrIndex]):\n        \"\"\"Reorder nodes in the skeleton.\n\n        Args:\n            new_order: A list of node names, indices, or `Node` objects specifying the\n                new order of the nodes.\n\n        Raises:\n            ValueError: If the new order of nodes is not the same length as the current\n                nodes.\n\n        Notes:\n            This method handles updating the lookup caches necessary for indexing nodes\n            by name.\n\n        Warning:\n            After reordering, instances using this skeleton do not need to be updated as\n            the nodes are stored by reference in the skeleton.\n\n            However, the order that points are stored in the instances will not be\n            updated to match the new order of the nodes in the skeleton. This should not\n            matter unless the ordering of the keys in the `Instance.points` dictionary\n            is used instead of relying on the skeleton node order.\n\n            To make sure these are aligned, it is recommended to use the\n            `Labels.reorder_nodes()` method which will update all contained instances to\n            reflect the changes made to the skeleton.\n\n            To manually update instances after this method is called, call\n            `Instance.update_skeleton()` on each instance that uses this skeleton.\n        \"\"\"\n        if len(new_order) != len(self.nodes):\n            raise ValueError(\n                \"New order of nodes must be the same length as the current nodes.\"\n            )\n\n        new_nodes = [self.require_node(node, add_missing=False) for node in new_order]\n        self.nodes = new_nodes\n\n    def match_nodes(self, other_nodes: list[str, Node]) -&gt; tuple[list[int], list[int]]:\n        \"\"\"Return the order of nodes in the skeleton.\n\n        Args:\n            other_nodes: A list of node names or `Node` objects.\n\n        Returns:\n            A tuple of `skeleton_inds, `other_inds`.\n\n            `skeleton_inds` contains the indices of the nodes in the skeleton that match\n            the input nodes.\n\n            `other_inds` contains the indices of the input nodes that match the nodes in\n            the skeleton.\n\n            These can be used to reorder point data to match the order of nodes in the\n            skeleton.\n\n        See also: match_nodes_cached\n        \"\"\"\n        if isinstance(other_nodes, np.ndarray):\n            other_nodes = other_nodes.tolist()\n        if type(other_nodes) is not tuple:\n            other_nodes = [x.name if type(x) is Node else x for x in other_nodes]\n\n        skeleton_inds, other_inds = match_nodes_cached(\n            tuple(self.node_names), tuple(other_nodes)\n        )\n\n        return list(skeleton_inds), list(other_inds)\n\n    def matches(self, other: \"Skeleton\", require_same_order: bool = False) -&gt; bool:\n        \"\"\"Check if this skeleton matches another skeleton's structure.\n\n        Args:\n            other: Another skeleton to compare with.\n            require_same_order: If True, nodes must be in the same order.\n                If False, only the node names and edges need to match.\n\n        Returns:\n            True if the skeletons match, False otherwise.\n\n        Notes:\n            Two skeletons match if they have the same nodes (by name) and edges.\n            If require_same_order is True, the nodes must also be in the same order.\n        \"\"\"\n        # Check if we have the same number of nodes\n        if len(self.nodes) != len(other.nodes):\n            return False\n\n        # Check node names\n        if require_same_order:\n            if self.node_names != other.node_names:\n                return False\n        else:\n            if set(self.node_names) != set(other.node_names):\n                return False\n\n        # Check edges (considering node name mapping if order differs)\n        if len(self.edges) != len(other.edges):\n            return False\n\n        # Create edge sets for comparison\n        self_edge_set = {\n            (edge.source.name, edge.destination.name) for edge in self.edges\n        }\n        other_edge_set = {\n            (edge.source.name, edge.destination.name) for edge in other.edges\n        }\n\n        if self_edge_set != other_edge_set:\n            return False\n\n        # Check symmetries\n        if len(self.symmetries) != len(other.symmetries):\n            return False\n\n        self_sym_set = {\n            frozenset(node.name for node in sym.nodes) for sym in self.symmetries\n        }\n        other_sym_set = {\n            frozenset(node.name for node in sym.nodes) for sym in other.symmetries\n        }\n\n        return self_sym_set == other_sym_set\n\n    def node_similarities(self, other: \"Skeleton\") -&gt; dict[str, float]:\n        \"\"\"Calculate node overlap metrics with another skeleton.\n\n        Args:\n            other: Another skeleton to compare with.\n\n        Returns:\n            A dictionary with similarity metrics:\n            - 'n_common': Number of nodes in common\n            - 'n_self_only': Number of nodes only in this skeleton\n            - 'n_other_only': Number of nodes only in the other skeleton\n            - 'jaccard': Jaccard similarity (intersection/union)\n            - 'dice': Dice coefficient (2*intersection/(n_self + n_other))\n        \"\"\"\n        self_nodes = set(self.node_names)\n        other_nodes = set(other.node_names)\n\n        n_common = len(self_nodes &amp; other_nodes)\n        n_self_only = len(self_nodes - other_nodes)\n        n_other_only = len(other_nodes - self_nodes)\n        n_union = len(self_nodes | other_nodes)\n\n        jaccard = n_common / n_union if n_union &gt; 0 else 0\n        dice = (\n            2 * n_common / (len(self_nodes) + len(other_nodes))\n            if (len(self_nodes) + len(other_nodes)) &gt; 0\n            else 0\n        )\n\n        return {\n            \"n_common\": n_common,\n            \"n_self_only\": n_self_only,\n            \"n_other_only\": n_other_only,\n            \"jaccard\": jaccard,\n            \"dice\": dice,\n        }\n</code></pre>"},{"location":"model/#sleap_io.Skeleton.edge_inds","title":"<code>edge_inds</code>  <code>property</code>","text":"<p>Edges indices as a list of 2-tuples.</p>"},{"location":"model/#sleap_io.Skeleton.edge_names","title":"<code>edge_names</code>  <code>property</code>","text":"<p>Edge names as a list of 2-tuples with string node names.</p>"},{"location":"model/#sleap_io.Skeleton.node_names","title":"<code>node_names</code>  <code>property</code>","text":"<p>Names of the nodes associated with this skeleton as a list of strings.</p>"},{"location":"model/#sleap_io.Skeleton.symmetry_inds","title":"<code>symmetry_inds</code>  <code>property</code>","text":"<p>Symmetry indices as a list of 2-tuples.</p>"},{"location":"model/#sleap_io.Skeleton.symmetry_names","title":"<code>symmetry_names</code>  <code>property</code>","text":"<p>Symmetry names as a list of 2-tuples with string node names.</p>"},{"location":"model/#sleap_io.Skeleton.__attrs_post_init__","title":"<code>__attrs_post_init__()</code>","text":"<p>Ensure nodes are <code>Node</code>s, edges are <code>Edge</code>s, and <code>Node</code> map is updated.</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def __attrs_post_init__(self):\n    \"\"\"Ensure nodes are `Node`s, edges are `Edge`s, and `Node` map is updated.\"\"\"\n    self._convert_nodes()\n    self._convert_edges()\n    self._convert_symmetries()\n    self.rebuild_cache()\n</code></pre>"},{"location":"model/#sleap_io.Skeleton.__contains__","title":"<code>__contains__(node)</code>","text":"<p>Check if a node is in the skeleton.</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def __contains__(self, node: NodeOrIndex) -&gt; bool:\n    \"\"\"Check if a node is in the skeleton.\"\"\"\n    if type(node) is str:\n        return node in self._name_to_node_cache\n    elif type(node) is Node:\n        return node in self.nodes\n    elif type(node) is int:\n        return 0 &lt;= node &lt; len(self.nodes)\n    else:\n        raise ValueError(f\"Invalid node type for skeleton: {node}\")\n</code></pre>"},{"location":"model/#sleap_io.Skeleton.__getitem__","title":"<code>__getitem__(idx)</code>","text":"<p>Return a <code>Node</code> when indexing by name or integer.</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def __getitem__(self, idx: NodeOrIndex) -&gt; Node:\n    \"\"\"Return a `Node` when indexing by name or integer.\"\"\"\n    if type(idx) is int:\n        return self.nodes[idx]\n    elif type(idx) is str:\n        return self._name_to_node_cache[idx]\n    else:\n        raise IndexError(f\"Invalid indexing argument for skeleton: {idx}\")\n</code></pre>"},{"location":"model/#sleap_io.Skeleton.__len__","title":"<code>__len__()</code>","text":"<p>Return the number of nodes in the skeleton.</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"Return the number of nodes in the skeleton.\"\"\"\n    return len(self.nodes)\n</code></pre>"},{"location":"model/#sleap_io.Skeleton.__repr__","title":"<code>__repr__()</code>","text":"<p>Return a readable representation of the skeleton.</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return a readable representation of the skeleton.\"\"\"\n    nodes = \", \".join([f'\"{node}\"' for node in self.node_names])\n    return f\"Skeleton(nodes=[{nodes}], edges={self.edge_inds})\"\n</code></pre>"},{"location":"model/#sleap_io.Skeleton.add_edge","title":"<code>add_edge(src, dst=None)</code>","text":"<p>Add an <code>Edge</code> to the skeleton.</p> <p>Parameters:</p> Name Type Description Default <code>src</code> <code>NodeOrIndex | Edge | tuple[NodeOrIndex, NodeOrIndex]</code> <p>The source node specified as a <code>Node</code>, name or index.</p> required <code>dst</code> <code>NodeOrIndex | None</code> <p>The destination node specified as a <code>Node</code>, name or index.</p> <code>None</code> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def add_edge(\n    self,\n    src: NodeOrIndex | Edge | tuple[NodeOrIndex, NodeOrIndex],\n    dst: NodeOrIndex | None = None,\n):\n    \"\"\"Add an `Edge` to the skeleton.\n\n    Args:\n        src: The source node specified as a `Node`, name or index.\n        dst: The destination node specified as a `Node`, name or index.\n    \"\"\"\n    edge = None\n    if type(src) is tuple:\n        src, dst = src\n\n    if is_node_or_index(src):\n        if not is_node_or_index(dst):\n            raise ValueError(\"Destination node must be specified.\")\n\n        src = self.require_node(src)\n        dst = self.require_node(dst)\n        edge = Edge(src, dst)\n\n    if type(src) is Edge:\n        edge = src\n\n    if edge not in self.edges:\n        self.edges.append(edge)\n</code></pre>"},{"location":"model/#sleap_io.Skeleton.add_edges","title":"<code>add_edges(edges)</code>","text":"<p>Add multiple <code>Edge</code>s to the skeleton.</p> <p>Parameters:</p> Name Type Description Default <code>edges</code> <code>list[Edge | tuple[NodeOrIndex, NodeOrIndex]]</code> <p>A list of <code>Edge</code> objects or 2-tuples of source and destination nodes.</p> required Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def add_edges(self, edges: list[Edge | tuple[NodeOrIndex, NodeOrIndex]]):\n    \"\"\"Add multiple `Edge`s to the skeleton.\n\n    Args:\n        edges: A list of `Edge` objects or 2-tuples of source and destination nodes.\n    \"\"\"\n    for edge in edges:\n        self.add_edge(edge)\n</code></pre>"},{"location":"model/#sleap_io.Skeleton.add_node","title":"<code>add_node(node)</code>","text":"<p>Add a <code>Node</code> to the skeleton.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>Node | str</code> <p>A <code>Node</code> object or a string name to create a new node.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If the node already exists in the skeleton or if the node is not specified as a <code>Node</code> or string.</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def add_node(self, node: Node | str):\n    \"\"\"Add a `Node` to the skeleton.\n\n    Args:\n        node: A `Node` object or a string name to create a new node.\n\n    Raises:\n        ValueError: If the node already exists in the skeleton or if the node is\n            not specified as a `Node` or string.\n    \"\"\"\n    if node in self:\n        raise ValueError(f\"Node '{node}' already exists in the skeleton.\")\n\n    if type(node) is str:\n        node = Node(node)\n\n    if type(node) is not Node:\n        raise ValueError(f\"Invalid node type: {node} ({type(node)})\")\n\n    self.nodes.append(node)\n\n    # Atomic update of the cache.\n    self._name_to_node_cache[node.name] = node\n    self._node_to_ind_cache[node] = len(self.nodes) - 1\n</code></pre>"},{"location":"model/#sleap_io.Skeleton.add_nodes","title":"<code>add_nodes(nodes)</code>","text":"<p>Add multiple <code>Node</code>s to the skeleton.</p> <p>Parameters:</p> Name Type Description Default <code>nodes</code> <code>list[Node | str]</code> <p>A list of <code>Node</code> objects or string names to create new nodes.</p> required Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def add_nodes(self, nodes: list[Node | str]):\n    \"\"\"Add multiple `Node`s to the skeleton.\n\n    Args:\n        nodes: A list of `Node` objects or string names to create new nodes.\n    \"\"\"\n    for node in nodes:\n        self.add_node(node)\n</code></pre>"},{"location":"model/#sleap_io.Skeleton.add_symmetries","title":"<code>add_symmetries(symmetries)</code>","text":"<p>Add multiple <code>Symmetry</code> relationships to the skeleton.</p> <p>Parameters:</p> Name Type Description Default <code>symmetries</code> <code>list[Symmetry | tuple[NodeOrIndex, NodeOrIndex]]</code> <p>A list of <code>Symmetry</code> objects or 2-tuples of symmetric nodes.</p> required Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def add_symmetries(\n    self, symmetries: list[Symmetry | tuple[NodeOrIndex, NodeOrIndex]]\n):\n    \"\"\"Add multiple `Symmetry` relationships to the skeleton.\n\n    Args:\n        symmetries: A list of `Symmetry` objects or 2-tuples of symmetric nodes.\n    \"\"\"\n    for symmetry in symmetries:\n        self.add_symmetry(*symmetry)\n</code></pre>"},{"location":"model/#sleap_io.Skeleton.add_symmetry","title":"<code>add_symmetry(node1=None, node2=None)</code>","text":"<p>Add a symmetry relationship to the skeleton.</p> <p>Parameters:</p> Name Type Description Default <code>node1</code> <code>Symmetry | NodeOrIndex</code> <p>The first node specified as a <code>Node</code>, name or index. If a <code>Symmetry</code> object is provided, it will be added directly to the skeleton.</p> <code>None</code> <code>node2</code> <code>NodeOrIndex | None</code> <p>The second node specified as a <code>Node</code>, name or index.</p> <code>None</code> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def add_symmetry(\n    self, node1: Symmetry | NodeOrIndex = None, node2: NodeOrIndex | None = None\n):\n    \"\"\"Add a symmetry relationship to the skeleton.\n\n    Args:\n        node1: The first node specified as a `Node`, name or index. If a `Symmetry`\n            object is provided, it will be added directly to the skeleton.\n        node2: The second node specified as a `Node`, name or index.\n    \"\"\"\n    symmetry = None\n    if type(node1) is Symmetry:\n        symmetry = node1\n        node1, node2 = symmetry\n\n    node1 = self.require_node(node1)\n    node2 = self.require_node(node2)\n\n    if symmetry is None:\n        symmetry = Symmetry({node1, node2})\n\n    if symmetry not in self.symmetries:\n        self.symmetries.append(symmetry)\n</code></pre>"},{"location":"model/#sleap_io.Skeleton.get_flipped_node_inds","title":"<code>get_flipped_node_inds()</code>","text":"<p>Returns node indices that should be switched when horizontally flipping.</p> <p>This is useful as a lookup table for flipping the landmark coordinates when doing data augmentation.</p> Example <p>skel = Skeleton([\"A\", \"B_left\", \"B_right\", \"C\", \"D_left\", \"D_right\"]) skel.add_symmetry(\"B_left\", \"B_right\") skel.add_symmetry(\"D_left\", \"D_right\") skel.flipped_node_inds [0, 2, 1, 3, 5, 4] pose = np.array([[0, 0], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5]]) pose[skel.flipped_node_inds] array([[0, 0],        [2, 2],        [1, 1],        [3, 3],        [5, 5],        [4, 4]])</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def get_flipped_node_inds(self) -&gt; list[int]:\n    \"\"\"Returns node indices that should be switched when horizontally flipping.\n\n    This is useful as a lookup table for flipping the landmark coordinates when\n    doing data augmentation.\n\n    Example:\n        &gt;&gt;&gt; skel = Skeleton([\"A\", \"B_left\", \"B_right\", \"C\", \"D_left\", \"D_right\"])\n        &gt;&gt;&gt; skel.add_symmetry(\"B_left\", \"B_right\")\n        &gt;&gt;&gt; skel.add_symmetry(\"D_left\", \"D_right\")\n        &gt;&gt;&gt; skel.flipped_node_inds\n        [0, 2, 1, 3, 5, 4]\n        &gt;&gt;&gt; pose = np.array([[0, 0], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5]])\n        &gt;&gt;&gt; pose[skel.flipped_node_inds]\n        array([[0, 0],\n               [2, 2],\n               [1, 1],\n               [3, 3],\n               [5, 5],\n               [4, 4]])\n    \"\"\"\n    flip_idx = np.arange(len(self.nodes))\n    if len(self.symmetries) &gt; 0:\n        symmetry_inds = np.array(\n            [(self.index(a), self.index(b)) for a, b in self.symmetries]\n        )\n        flip_idx[symmetry_inds[:, 0]] = symmetry_inds[:, 1]\n        flip_idx[symmetry_inds[:, 1]] = symmetry_inds[:, 0]\n\n    flip_idx = flip_idx.tolist()\n    return flip_idx\n</code></pre>"},{"location":"model/#sleap_io.Skeleton.index","title":"<code>index(node)</code>","text":"<p>Return the index of a node specified as a <code>Node</code> or string name.</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def index(self, node: Node | str) -&gt; int:\n    \"\"\"Return the index of a node specified as a `Node` or string name.\"\"\"\n    if type(node) is str:\n        return self.index(self._name_to_node_cache[node])\n    elif type(node) is Node:\n        return self._node_to_ind_cache[node]\n    else:\n        raise IndexError(f\"Invalid indexing argument for skeleton: {node}\")\n</code></pre>"},{"location":"model/#sleap_io.Skeleton.match_nodes","title":"<code>match_nodes(other_nodes)</code>","text":"<p>Return the order of nodes in the skeleton.</p> <p>Parameters:</p> Name Type Description Default <code>other_nodes</code> <code>list[str, Node]</code> <p>A list of node names or <code>Node</code> objects.</p> required <p>Returns:</p> Type Description <code>tuple[list[int], list[int]]</code> <p>A tuple of <code>skeleton_inds,</code>other_inds`.</p> <p><code>skeleton_inds</code> contains the indices of the nodes in the skeleton that match the input nodes.</p> <p><code>other_inds</code> contains the indices of the input nodes that match the nodes in the skeleton.</p> <p>These can be used to reorder point data to match the order of nodes in the skeleton.</p> <p>See also: match_nodes_cached</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def match_nodes(self, other_nodes: list[str, Node]) -&gt; tuple[list[int], list[int]]:\n    \"\"\"Return the order of nodes in the skeleton.\n\n    Args:\n        other_nodes: A list of node names or `Node` objects.\n\n    Returns:\n        A tuple of `skeleton_inds, `other_inds`.\n\n        `skeleton_inds` contains the indices of the nodes in the skeleton that match\n        the input nodes.\n\n        `other_inds` contains the indices of the input nodes that match the nodes in\n        the skeleton.\n\n        These can be used to reorder point data to match the order of nodes in the\n        skeleton.\n\n    See also: match_nodes_cached\n    \"\"\"\n    if isinstance(other_nodes, np.ndarray):\n        other_nodes = other_nodes.tolist()\n    if type(other_nodes) is not tuple:\n        other_nodes = [x.name if type(x) is Node else x for x in other_nodes]\n\n    skeleton_inds, other_inds = match_nodes_cached(\n        tuple(self.node_names), tuple(other_nodes)\n    )\n\n    return list(skeleton_inds), list(other_inds)\n</code></pre>"},{"location":"model/#sleap_io.Skeleton.matches","title":"<code>matches(other, require_same_order=False)</code>","text":"<p>Check if this skeleton matches another skeleton's structure.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>'Skeleton'</code> <p>Another skeleton to compare with.</p> required <code>require_same_order</code> <code>bool</code> <p>If True, nodes must be in the same order. If False, only the node names and edges need to match.</p> <code>False</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if the skeletons match, False otherwise.</p> Notes <p>Two skeletons match if they have the same nodes (by name) and edges. If require_same_order is True, the nodes must also be in the same order.</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def matches(self, other: \"Skeleton\", require_same_order: bool = False) -&gt; bool:\n    \"\"\"Check if this skeleton matches another skeleton's structure.\n\n    Args:\n        other: Another skeleton to compare with.\n        require_same_order: If True, nodes must be in the same order.\n            If False, only the node names and edges need to match.\n\n    Returns:\n        True if the skeletons match, False otherwise.\n\n    Notes:\n        Two skeletons match if they have the same nodes (by name) and edges.\n        If require_same_order is True, the nodes must also be in the same order.\n    \"\"\"\n    # Check if we have the same number of nodes\n    if len(self.nodes) != len(other.nodes):\n        return False\n\n    # Check node names\n    if require_same_order:\n        if self.node_names != other.node_names:\n            return False\n    else:\n        if set(self.node_names) != set(other.node_names):\n            return False\n\n    # Check edges (considering node name mapping if order differs)\n    if len(self.edges) != len(other.edges):\n        return False\n\n    # Create edge sets for comparison\n    self_edge_set = {\n        (edge.source.name, edge.destination.name) for edge in self.edges\n    }\n    other_edge_set = {\n        (edge.source.name, edge.destination.name) for edge in other.edges\n    }\n\n    if self_edge_set != other_edge_set:\n        return False\n\n    # Check symmetries\n    if len(self.symmetries) != len(other.symmetries):\n        return False\n\n    self_sym_set = {\n        frozenset(node.name for node in sym.nodes) for sym in self.symmetries\n    }\n    other_sym_set = {\n        frozenset(node.name for node in sym.nodes) for sym in other.symmetries\n    }\n\n    return self_sym_set == other_sym_set\n</code></pre>"},{"location":"model/#sleap_io.Skeleton.node_similarities","title":"<code>node_similarities(other)</code>","text":"<p>Calculate node overlap metrics with another skeleton.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>'Skeleton'</code> <p>Another skeleton to compare with.</p> required <p>Returns:</p> Type Description <code>dict[str, float]</code> <p>A dictionary with similarity metrics: - 'n_common': Number of nodes in common - 'n_self_only': Number of nodes only in this skeleton - 'n_other_only': Number of nodes only in the other skeleton - 'jaccard': Jaccard similarity (intersection/union) - 'dice': Dice coefficient (2*intersection/(n_self + n_other))</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def node_similarities(self, other: \"Skeleton\") -&gt; dict[str, float]:\n    \"\"\"Calculate node overlap metrics with another skeleton.\n\n    Args:\n        other: Another skeleton to compare with.\n\n    Returns:\n        A dictionary with similarity metrics:\n        - 'n_common': Number of nodes in common\n        - 'n_self_only': Number of nodes only in this skeleton\n        - 'n_other_only': Number of nodes only in the other skeleton\n        - 'jaccard': Jaccard similarity (intersection/union)\n        - 'dice': Dice coefficient (2*intersection/(n_self + n_other))\n    \"\"\"\n    self_nodes = set(self.node_names)\n    other_nodes = set(other.node_names)\n\n    n_common = len(self_nodes &amp; other_nodes)\n    n_self_only = len(self_nodes - other_nodes)\n    n_other_only = len(other_nodes - self_nodes)\n    n_union = len(self_nodes | other_nodes)\n\n    jaccard = n_common / n_union if n_union &gt; 0 else 0\n    dice = (\n        2 * n_common / (len(self_nodes) + len(other_nodes))\n        if (len(self_nodes) + len(other_nodes)) &gt; 0\n        else 0\n    )\n\n    return {\n        \"n_common\": n_common,\n        \"n_self_only\": n_self_only,\n        \"n_other_only\": n_other_only,\n        \"jaccard\": jaccard,\n        \"dice\": dice,\n    }\n</code></pre>"},{"location":"model/#sleap_io.Skeleton.rebuild_cache","title":"<code>rebuild_cache(nodes=None)</code>","text":"<p>Rebuild the node name/index to <code>Node</code> map caches.</p> <p>Parameters:</p> Name Type Description Default <code>nodes</code> <code>list[Node] | None</code> <p>A list of <code>Node</code> objects to update the cache with. If not provided, the cache will be updated with the current nodes in the skeleton. If nodes are provided, the cache will be updated with the provided nodes, but the current nodes in the skeleton will not be updated. Default is <code>None</code>.</p> <code>None</code> Notes <p>This function should be called when nodes or node list is mutated to update the lookup caches for indexing nodes by name or <code>Node</code> object.</p> <p>This is done automatically when nodes are added or removed from the skeleton using the convenience methods in this class.</p> <p>This method only needs to be used when manually mutating nodes or the node list directly.</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def rebuild_cache(self, nodes: list[Node] | None = None):\n    \"\"\"Rebuild the node name/index to `Node` map caches.\n\n    Args:\n        nodes: A list of `Node` objects to update the cache with. If not provided,\n            the cache will be updated with the current nodes in the skeleton. If\n            nodes are provided, the cache will be updated with the provided nodes,\n            but the current nodes in the skeleton will not be updated. Default is\n            `None`.\n\n    Notes:\n        This function should be called when nodes or node list is mutated to update\n        the lookup caches for indexing nodes by name or `Node` object.\n\n        This is done automatically when nodes are added or removed from the skeleton\n        using the convenience methods in this class.\n\n        This method only needs to be used when manually mutating nodes or the node\n        list directly.\n    \"\"\"\n    if nodes is None:\n        nodes = self.nodes\n    self._name_to_node_cache = {node.name: node for node in nodes}\n    self._node_to_ind_cache = {node: i for i, node in enumerate(nodes)}\n</code></pre>"},{"location":"model/#sleap_io.Skeleton.remove_node","title":"<code>remove_node(node)</code>","text":"<p>Remove a single node from the skeleton.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>NodeOrIndex</code> <p>The node to remove. Can be specified as a string name, integer index, or <code>Node</code> object.</p> required Notes <p>This method handles updating the lookup caches necessary for indexing nodes by name.</p> <p>Any edges and symmetries that are connected to the removed node will also be removed.</p> Warning <p>This method does NOT update instances that use this skeleton to reflect changes.</p> <p>It is recommended to use the <code>Labels.remove_nodes()</code> method which will update all contained instances to reflect the changes made to the skeleton.</p> <p>To manually update instances after this method is called, call <code>Instance.update_skeleton()</code> on each instance that uses this skeleton.</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def remove_node(self, node: NodeOrIndex):\n    \"\"\"Remove a single node from the skeleton.\n\n    Args:\n        node: The node to remove. Can be specified as a string name, integer index,\n            or `Node` object.\n\n    Notes:\n        This method handles updating the lookup caches necessary for indexing nodes\n        by name.\n\n        Any edges and symmetries that are connected to the removed node will also be\n        removed.\n\n    Warning:\n        **This method does NOT update instances** that use this skeleton to reflect\n        changes.\n\n        It is recommended to use the `Labels.remove_nodes()` method which will\n        update all contained instances to reflect the changes made to the skeleton.\n\n        To manually update instances after this method is called, call\n        `Instance.update_skeleton()` on each instance that uses this skeleton.\n    \"\"\"\n    self.remove_nodes([node])\n</code></pre>"},{"location":"model/#sleap_io.Skeleton.remove_nodes","title":"<code>remove_nodes(nodes)</code>","text":"<p>Remove nodes from the skeleton.</p> <p>Parameters:</p> Name Type Description Default <code>nodes</code> <code>list[NodeOrIndex]</code> <p>A list of node names, indices, or <code>Node</code> objects to remove.</p> required Notes <p>This method handles updating the lookup caches necessary for indexing nodes by name.</p> <p>Any edges and symmetries that are connected to the removed nodes will also be removed.</p> Warning <p>This method does NOT update instances that use this skeleton to reflect changes.</p> <p>It is recommended to use the <code>Labels.remove_nodes()</code> method which will update all contained to reflect the changes made to the skeleton.</p> <p>To manually update instances after this method is called, call <code>instance.update_nodes()</code> on each instance that uses this skeleton.</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def remove_nodes(self, nodes: list[NodeOrIndex]):\n    \"\"\"Remove nodes from the skeleton.\n\n    Args:\n        nodes: A list of node names, indices, or `Node` objects to remove.\n\n    Notes:\n        This method handles updating the lookup caches necessary for indexing nodes\n        by name.\n\n        Any edges and symmetries that are connected to the removed nodes will also\n        be removed.\n\n    Warning:\n        **This method does NOT update instances** that use this skeleton to reflect\n        changes.\n\n        It is recommended to use the `Labels.remove_nodes()` method which will\n        update all contained to reflect the changes made to the skeleton.\n\n        To manually update instances after this method is called, call\n        `instance.update_nodes()` on each instance that uses this skeleton.\n    \"\"\"\n    # Standardize input and make a pre-mutation copy before keys are changed.\n    rm_node_objs = [self.require_node(node, add_missing=False) for node in nodes]\n\n    # Remove nodes from the skeleton.\n    for node in rm_node_objs:\n        self.nodes.remove(node)\n        del self._name_to_node_cache[node.name]\n\n    # Remove edges connected to the removed nodes.\n    self.edges = [\n        edge\n        for edge in self.edges\n        if edge.source not in rm_node_objs and edge.destination not in rm_node_objs\n    ]\n\n    # Remove symmetries connected to the removed nodes.\n    self.symmetries = [\n        symmetry\n        for symmetry in self.symmetries\n        if symmetry.nodes.isdisjoint(rm_node_objs)\n    ]\n\n    # Update node index map.\n    self.rebuild_cache()\n</code></pre>"},{"location":"model/#sleap_io.Skeleton.rename_node","title":"<code>rename_node(old_name, new_name)</code>","text":"<p>Rename a single node in the skeleton.</p> <p>Parameters:</p> Name Type Description Default <code>old_name</code> <code>NodeOrIndex</code> <p>The name of the node to rename. Can also be specified as an integer index or <code>Node</code> object.</p> required <code>new_name</code> <code>str</code> <p>The new name for the node.</p> required Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def rename_node(self, old_name: NodeOrIndex, new_name: str):\n    \"\"\"Rename a single node in the skeleton.\n\n    Args:\n        old_name: The name of the node to rename. Can also be specified as an\n            integer index or `Node` object.\n        new_name: The new name for the node.\n    \"\"\"\n    self.rename_nodes({old_name: new_name})\n</code></pre>"},{"location":"model/#sleap_io.Skeleton.rename_nodes","title":"<code>rename_nodes(name_map)</code>","text":"<p>Rename nodes in the skeleton.</p> <p>Parameters:</p> Name Type Description Default <code>name_map</code> <code>dict[NodeOrIndex, str] | list[str]</code> <p>A dictionary mapping old node names to new node names. Keys can be specified as <code>Node</code> objects, integer indices, or string names. Values must be specified as string names.</p> <p>If a list of strings is provided of the same length as the current nodes, the nodes will be renamed to the names in the list in order.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If the new node names exist in the skeleton or if the old node names are not found in the skeleton.</p> Notes <p>This method should always be used when renaming nodes in the skeleton as it handles updating the lookup caches necessary for indexing nodes by name.</p> <p>After renaming, instances using this skeleton do NOT need to be updated as the nodes are stored by reference in the skeleton, so changes are reflected automatically.</p> Example <p>skel = Skeleton([\"A\", \"B\", \"C\"], edges=[(\"A\", \"B\"), (\"B\", \"C\")]) skel.rename_nodes({\"A\": \"X\", \"B\": \"Y\", \"C\": \"Z\"}) skel.node_names [\"X\", \"Y\", \"Z\"] skel.rename_nodes([\"a\", \"b\", \"c\"]) skel.node_names [\"a\", \"b\", \"c\"]</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def rename_nodes(self, name_map: dict[NodeOrIndex, str] | list[str]):\n    \"\"\"Rename nodes in the skeleton.\n\n    Args:\n        name_map: A dictionary mapping old node names to new node names. Keys can be\n            specified as `Node` objects, integer indices, or string names. Values\n            must be specified as string names.\n\n            If a list of strings is provided of the same length as the current\n            nodes, the nodes will be renamed to the names in the list in order.\n\n    Raises:\n        ValueError: If the new node names exist in the skeleton or if the old node\n            names are not found in the skeleton.\n\n    Notes:\n        This method should always be used when renaming nodes in the skeleton as it\n        handles updating the lookup caches necessary for indexing nodes by name.\n\n        After renaming, instances using this skeleton **do NOT need to be updated**\n        as the nodes are stored by reference in the skeleton, so changes are\n        reflected automatically.\n\n    Example:\n        &gt;&gt;&gt; skel = Skeleton([\"A\", \"B\", \"C\"], edges=[(\"A\", \"B\"), (\"B\", \"C\")])\n        &gt;&gt;&gt; skel.rename_nodes({\"A\": \"X\", \"B\": \"Y\", \"C\": \"Z\"})\n        &gt;&gt;&gt; skel.node_names\n        [\"X\", \"Y\", \"Z\"]\n        &gt;&gt;&gt; skel.rename_nodes([\"a\", \"b\", \"c\"])\n        &gt;&gt;&gt; skel.node_names\n        [\"a\", \"b\", \"c\"]\n    \"\"\"\n    if type(name_map) is list:\n        if len(name_map) != len(self.nodes):\n            raise ValueError(\n                \"List of new node names must be the same length as the current \"\n                \"nodes.\"\n            )\n        name_map = {node: name for node, name in zip(self.nodes, name_map)}\n\n    for old_name, new_name in name_map.items():\n        if type(old_name) is Node:\n            old_name = old_name.name\n        if type(old_name) is int:\n            old_name = self.nodes[old_name].name\n\n        if old_name not in self._name_to_node_cache:\n            raise ValueError(f\"Node '{old_name}' not found in the skeleton.\")\n        if new_name in self._name_to_node_cache:\n            raise ValueError(f\"Node '{new_name}' already exists in the skeleton.\")\n\n        node = self._name_to_node_cache[old_name]\n        node.name = new_name\n        self._name_to_node_cache[new_name] = node\n        del self._name_to_node_cache[old_name]\n</code></pre>"},{"location":"model/#sleap_io.Skeleton.reorder_nodes","title":"<code>reorder_nodes(new_order)</code>","text":"<p>Reorder nodes in the skeleton.</p> <p>Parameters:</p> Name Type Description Default <code>new_order</code> <code>list[NodeOrIndex]</code> <p>A list of node names, indices, or <code>Node</code> objects specifying the new order of the nodes.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If the new order of nodes is not the same length as the current nodes.</p> Notes <p>This method handles updating the lookup caches necessary for indexing nodes by name.</p> Warning <p>After reordering, instances using this skeleton do not need to be updated as the nodes are stored by reference in the skeleton.</p> <p>However, the order that points are stored in the instances will not be updated to match the new order of the nodes in the skeleton. This should not matter unless the ordering of the keys in the <code>Instance.points</code> dictionary is used instead of relying on the skeleton node order.</p> <p>To make sure these are aligned, it is recommended to use the <code>Labels.reorder_nodes()</code> method which will update all contained instances to reflect the changes made to the skeleton.</p> <p>To manually update instances after this method is called, call <code>Instance.update_skeleton()</code> on each instance that uses this skeleton.</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def reorder_nodes(self, new_order: list[NodeOrIndex]):\n    \"\"\"Reorder nodes in the skeleton.\n\n    Args:\n        new_order: A list of node names, indices, or `Node` objects specifying the\n            new order of the nodes.\n\n    Raises:\n        ValueError: If the new order of nodes is not the same length as the current\n            nodes.\n\n    Notes:\n        This method handles updating the lookup caches necessary for indexing nodes\n        by name.\n\n    Warning:\n        After reordering, instances using this skeleton do not need to be updated as\n        the nodes are stored by reference in the skeleton.\n\n        However, the order that points are stored in the instances will not be\n        updated to match the new order of the nodes in the skeleton. This should not\n        matter unless the ordering of the keys in the `Instance.points` dictionary\n        is used instead of relying on the skeleton node order.\n\n        To make sure these are aligned, it is recommended to use the\n        `Labels.reorder_nodes()` method which will update all contained instances to\n        reflect the changes made to the skeleton.\n\n        To manually update instances after this method is called, call\n        `Instance.update_skeleton()` on each instance that uses this skeleton.\n    \"\"\"\n    if len(new_order) != len(self.nodes):\n        raise ValueError(\n            \"New order of nodes must be the same length as the current nodes.\"\n        )\n\n    new_nodes = [self.require_node(node, add_missing=False) for node in new_order]\n    self.nodes = new_nodes\n</code></pre>"},{"location":"model/#sleap_io.Skeleton.require_node","title":"<code>require_node(node, add_missing=True)</code>","text":"<p>Return a <code>Node</code> object, handling indexing and adding missing nodes.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>NodeOrIndex</code> <p>A <code>Node</code> object, name or index.</p> required <code>add_missing</code> <code>bool</code> <p>If <code>True</code>, missing nodes will be added to the skeleton. If <code>False</code>, an error will be raised if the node is not found. Default is <code>True</code>.</p> <code>True</code> <p>Returns:</p> Type Description <code>Node</code> <p>The <code>Node</code> object.</p> <p>Raises:</p> Type Description <code>IndexError</code> <p>If the node is not found in the skeleton and <code>add_missing</code> is <code>False</code>.</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def require_node(self, node: NodeOrIndex, add_missing: bool = True) -&gt; Node:\n    \"\"\"Return a `Node` object, handling indexing and adding missing nodes.\n\n    Args:\n        node: A `Node` object, name or index.\n        add_missing: If `True`, missing nodes will be added to the skeleton. If\n            `False`, an error will be raised if the node is not found. Default is\n            `True`.\n\n    Returns:\n        The `Node` object.\n\n    Raises:\n        IndexError: If the node is not found in the skeleton and `add_missing` is\n            `False`.\n    \"\"\"\n    if node not in self:\n        if add_missing:\n            self.add_node(node)\n        else:\n            raise IndexError(f\"Node '{node}' not found in the skeleton.\")\n\n    if type(node) is Node:\n        return node\n\n    return self[node]\n</code></pre>"},{"location":"model/#sleap_io.Node","title":"<code>sleap_io.Node</code>","text":"<p>A landmark type within a <code>Skeleton</code>.</p> <p>This typically corresponds to a unique landmark within a skeleton, such as the \"left eye\".</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>Descriptive label for the landmark.</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>@define(eq=False)\nclass Node:\n    \"\"\"A landmark type within a `Skeleton`.\n\n    This typically corresponds to a unique landmark within a skeleton, such as the \"left\n    eye\".\n\n    Attributes:\n        name: Descriptive label for the landmark.\n    \"\"\"\n\n    name: str\n</code></pre>"},{"location":"model/#sleap_io.Edge","title":"<code>sleap_io.Edge</code>","text":"<p>A connection between two <code>Node</code> objects within a <code>Skeleton</code>.</p> <p>This is a directed edge, representing the ordering of <code>Node</code>s in the <code>Skeleton</code> tree.</p> <p>Attributes:</p> Name Type Description <code>source</code> <code>Node</code> <p>The origin <code>Node</code>.</p> <code>destination</code> <code>Node</code> <p>The destination <code>Node</code>.</p> <p>Methods:</p> Name Description <code>__getitem__</code> <p>Return the source <code>Node</code> (<code>idx</code> is 0) or destination <code>Node</code> (<code>idx</code> is 1).</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>@define(frozen=True)\nclass Edge:\n    \"\"\"A connection between two `Node` objects within a `Skeleton`.\n\n    This is a directed edge, representing the ordering of `Node`s in the `Skeleton`\n    tree.\n\n    Attributes:\n        source: The origin `Node`.\n        destination: The destination `Node`.\n    \"\"\"\n\n    source: Node\n    destination: Node\n\n    def __getitem__(self, idx) -&gt; Node:\n        \"\"\"Return the source `Node` (`idx` is 0) or destination `Node` (`idx` is 1).\"\"\"\n        if idx == 0:\n            return self.source\n        elif idx == 1:\n            return self.destination\n        else:\n            raise IndexError(\"Edge only has 2 nodes (source and destination).\")\n</code></pre>"},{"location":"model/#sleap_io.Edge.__getitem__","title":"<code>__getitem__(idx)</code>","text":"<p>Return the source <code>Node</code> (<code>idx</code> is 0) or destination <code>Node</code> (<code>idx</code> is 1).</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def __getitem__(self, idx) -&gt; Node:\n    \"\"\"Return the source `Node` (`idx` is 0) or destination `Node` (`idx` is 1).\"\"\"\n    if idx == 0:\n        return self.source\n    elif idx == 1:\n        return self.destination\n    else:\n        raise IndexError(\"Edge only has 2 nodes (source and destination).\")\n</code></pre>"},{"location":"model/#sleap_io.Symmetry","title":"<code>sleap_io.Symmetry</code>","text":"<p>A relationship between a pair of nodes denoting their left/right pairing.</p> <p>Attributes:</p> Name Type Description <code>nodes</code> <code>set[Node]</code> <p>A set of two <code>Node</code>s.</p> <p>Methods:</p> Name Description <code>__getitem__</code> <p>Return the first node.</p> <code>__iter__</code> <p>Iterate over the symmetric nodes.</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>@define\nclass Symmetry:\n    \"\"\"A relationship between a pair of nodes denoting their left/right pairing.\n\n    Attributes:\n        nodes: A set of two `Node`s.\n    \"\"\"\n\n    nodes: set[Node] = field(converter=set, validator=lambda _, __, val: len(val) == 2)\n\n    def __iter__(self):\n        \"\"\"Iterate over the symmetric nodes.\"\"\"\n        return iter(self.nodes)\n\n    def __getitem__(self, idx) -&gt; Node:\n        \"\"\"Return the first node.\"\"\"\n        for i, node in enumerate(self.nodes):\n            if i == idx:\n                return node\n</code></pre>"},{"location":"model/#sleap_io.Symmetry.__getitem__","title":"<code>__getitem__(idx)</code>","text":"<p>Return the first node.</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def __getitem__(self, idx) -&gt; Node:\n    \"\"\"Return the first node.\"\"\"\n    for i, node in enumerate(self.nodes):\n        if i == idx:\n            return node\n</code></pre>"},{"location":"model/#sleap_io.Symmetry.__iter__","title":"<code>__iter__()</code>","text":"<p>Iterate over the symmetric nodes.</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def __iter__(self):\n    \"\"\"Iterate over the symmetric nodes.\"\"\"\n    return iter(self.nodes)\n</code></pre>"},{"location":"model/#sleap_io.Track","title":"<code>sleap_io.Track</code>","text":"<p>An object that represents the same animal/object across multiple detections.</p> <p>This allows tracking of unique entities in the video over time and space.</p> <p>A <code>Track</code> may also be used to refer to unique identity classes that span multiple videos, such as <code>\"female mouse\"</code>.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>A name given to this track for identification purposes.</p> Notes <p><code>Track</code>s are compared by identity. This means that unique track objects with the same name are considered to be different.</p> <p>Methods:</p> Name Description <code>matches</code> <p>Check if this track matches another track.</p> <code>similarity_to</code> <p>Calculate similarity metrics with another track.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>@attrs.define(eq=False)\nclass Track:\n    \"\"\"An object that represents the same animal/object across multiple detections.\n\n    This allows tracking of unique entities in the video over time and space.\n\n    A `Track` may also be used to refer to unique identity classes that span multiple\n    videos, such as `\"female mouse\"`.\n\n    Attributes:\n        name: A name given to this track for identification purposes.\n\n    Notes:\n        `Track`s are compared by identity. This means that unique track objects with the\n        same name are considered to be different.\n    \"\"\"\n\n    name: str = \"\"\n\n    def matches(self, other: \"Track\", method: str = \"name\") -&gt; bool:\n        \"\"\"Check if this track matches another track.\n\n        Args:\n            other: Another track to compare with.\n            method: Matching method - \"name\" (match by name) or \"identity\"\n                (match by object identity).\n\n        Returns:\n            True if the tracks match according to the specified method.\n        \"\"\"\n        if method == \"name\":\n            return self.name == other.name\n        elif method == \"identity\":\n            return self is other\n        else:\n            raise ValueError(f\"Unknown matching method: {method}\")\n\n    def similarity_to(self, other: \"Track\") -&gt; dict[str, any]:\n        \"\"\"Calculate similarity metrics with another track.\n\n        Args:\n            other: Another track to compare with.\n\n        Returns:\n            A dictionary with similarity metrics:\n            - 'same_name': Whether the tracks have the same name\n            - 'same_identity': Whether the tracks are the same object\n            - 'name_similarity': Simple string similarity score (0-1)\n        \"\"\"\n        # Calculate simple string similarity\n        if self.name and other.name:\n            # Simple character overlap similarity\n            common_chars = set(self.name.lower()) &amp; set(other.name.lower())\n            all_chars = set(self.name.lower()) | set(other.name.lower())\n            name_similarity = len(common_chars) / len(all_chars) if all_chars else 0\n        else:\n            name_similarity = 1.0 if self.name == other.name else 0.0\n\n        return {\n            \"same_name\": self.name == other.name,\n            \"same_identity\": self is other,\n            \"name_similarity\": name_similarity,\n        }\n</code></pre>"},{"location":"model/#sleap_io.Track.matches","title":"<code>matches(other, method='name')</code>","text":"<p>Check if this track matches another track.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>'Track'</code> <p>Another track to compare with.</p> required <code>method</code> <code>str</code> <p>Matching method - \"name\" (match by name) or \"identity\" (match by object identity).</p> <code>'name'</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if the tracks match according to the specified method.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>def matches(self, other: \"Track\", method: str = \"name\") -&gt; bool:\n    \"\"\"Check if this track matches another track.\n\n    Args:\n        other: Another track to compare with.\n        method: Matching method - \"name\" (match by name) or \"identity\"\n            (match by object identity).\n\n    Returns:\n        True if the tracks match according to the specified method.\n    \"\"\"\n    if method == \"name\":\n        return self.name == other.name\n    elif method == \"identity\":\n        return self is other\n    else:\n        raise ValueError(f\"Unknown matching method: {method}\")\n</code></pre>"},{"location":"model/#sleap_io.Track.similarity_to","title":"<code>similarity_to(other)</code>","text":"<p>Calculate similarity metrics with another track.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>'Track'</code> <p>Another track to compare with.</p> required <p>Returns:</p> Type Description <code>dict[str, any]</code> <p>A dictionary with similarity metrics: - 'same_name': Whether the tracks have the same name - 'same_identity': Whether the tracks are the same object - 'name_similarity': Simple string similarity score (0-1)</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>def similarity_to(self, other: \"Track\") -&gt; dict[str, any]:\n    \"\"\"Calculate similarity metrics with another track.\n\n    Args:\n        other: Another track to compare with.\n\n    Returns:\n        A dictionary with similarity metrics:\n        - 'same_name': Whether the tracks have the same name\n        - 'same_identity': Whether the tracks are the same object\n        - 'name_similarity': Simple string similarity score (0-1)\n    \"\"\"\n    # Calculate simple string similarity\n    if self.name and other.name:\n        # Simple character overlap similarity\n        common_chars = set(self.name.lower()) &amp; set(other.name.lower())\n        all_chars = set(self.name.lower()) | set(other.name.lower())\n        name_similarity = len(common_chars) / len(all_chars) if all_chars else 0\n    else:\n        name_similarity = 1.0 if self.name == other.name else 0.0\n\n    return {\n        \"same_name\": self.name == other.name,\n        \"same_identity\": self is other,\n        \"name_similarity\": name_similarity,\n    }\n</code></pre>"},{"location":"model/#sleap_io.Video","title":"<code>sleap_io.Video</code>","text":"<p><code>Video</code> class used by sleap to represent videos and data associated with them.</p> <p>This class is used to store information regarding a video and its components. It is used to store the video's <code>filename</code>, <code>shape</code>, and the video's <code>backend</code>.</p> <p>To create a <code>Video</code> object, use the <code>from_filename</code> method which will select the backend appropriately.</p> <p>Attributes:</p> Name Type Description <code>filename</code> <code>str | list[str]</code> <p>The filename(s) of the video. Supported extensions: \"mp4\", \"avi\", \"mov\", \"mj2\", \"mkv\", \"h5\", \"hdf5\", \"slp\", \"png\", \"jpg\", \"jpeg\", \"tif\", \"tiff\", \"bmp\". If the filename is a list, a list of image filenames are expected. If filename is a folder, it will be searched for images.</p> <code>backend</code> <code>Optional[VideoBackend]</code> <p>An object that implements the basic methods for reading and manipulating frames of a specific video type.</p> <code>backend_metadata</code> <code>dict[str, any]</code> <p>A dictionary of metadata specific to the backend. This is useful for storing metadata that requires an open backend (e.g., shape information) without having access to the video file itself.</p> <code>source_video</code> <code>Optional[Video]</code> <p>The source video object if this is a proxy video. This is present when the video contains an embedded subset of frames from another video.</p> <code>open_backend</code> <code>bool</code> <p>Whether to open the backend when the video is available. If <code>True</code> (the default), the backend will be automatically opened if the video exists. Set this to <code>False</code> when you want to manually open the backend, or when the you know the video file does not exist and you want to avoid trying to open the file.</p> Notes <p>Instances of this class are hashed by identity, not by value. This means that two <code>Video</code> instances with the same attributes will NOT be considered equal in a set or dict.</p> Media Video Plugin Support <p>For media files (mp4, avi, etc.), the following plugins are supported: - \"opencv\": Uses OpenCV (cv2) for video reading - \"FFMPEG\": Uses imageio-ffmpeg for video reading - \"pyav\": Uses PyAV for video reading</p> <p>Plugin aliases (case-insensitive): - opencv: \"opencv\", \"cv\", \"cv2\", \"ocv\" - FFMPEG: \"FFMPEG\", \"ffmpeg\", \"imageio-ffmpeg\", \"imageio_ffmpeg\" - pyav: \"pyav\", \"av\"</p> <p>Plugin selection priority: 1. Explicitly specified plugin parameter 2. Backend metadata plugin value 3. Global default (set via sio.set_default_video_plugin) 4. Auto-detection based on available packages</p> See Also <p>VideoBackend: The backend interface for reading video data. sleap_io.set_default_video_plugin: Set global default plugin. sleap_io.get_default_video_plugin: Get current default plugin.</p> <p>Methods:</p> Name Description <code>__attrs_post_init__</code> <p>Post init syntactic sugar.</p> <code>__deepcopy__</code> <p>Deep copy the video object.</p> <code>__getitem__</code> <p>Return the frames of the video at the given indices.</p> <code>__len__</code> <p>Return the length of the video as the number of frames.</p> <code>__repr__</code> <p>Informal string representation (for print or format).</p> <code>__str__</code> <p>Informal string representation (for print or format).</p> <code>close</code> <p>Close the video backend.</p> <code>deduplicate_with</code> <p>Create a new video with duplicate images removed.</p> <code>exists</code> <p>Check if the video file exists and is accessible.</p> <code>from_filename</code> <p>Create a Video from a filename.</p> <code>has_overlapping_images</code> <p>Check if this video has overlapping images with another video.</p> <code>matches_content</code> <p>Check if this video has the same content as another video.</p> <code>matches_path</code> <p>Check if this video has the same path as another video.</p> <code>matches_shape</code> <p>Check if this video has the same shape as another video.</p> <code>merge_with</code> <p>Merge another video's images into this one.</p> <code>open</code> <p>Open the video backend for reading.</p> <code>replace_filename</code> <p>Update the filename of the video, optionally opening the backend.</p> <code>save</code> <p>Save video frames to a new video file.</p> <code>set_video_plugin</code> <p>Set the video plugin and reopen the video.</p> Source code in <code>sleap_io/model/video.py</code> <pre><code>@attrs.define(eq=False)\nclass Video:\n    \"\"\"`Video` class used by sleap to represent videos and data associated with them.\n\n    This class is used to store information regarding a video and its components.\n    It is used to store the video's `filename`, `shape`, and the video's `backend`.\n\n    To create a `Video` object, use the `from_filename` method which will select the\n    backend appropriately.\n\n    Attributes:\n        filename: The filename(s) of the video. Supported extensions: \"mp4\", \"avi\",\n            \"mov\", \"mj2\", \"mkv\", \"h5\", \"hdf5\", \"slp\", \"png\", \"jpg\", \"jpeg\", \"tif\",\n            \"tiff\", \"bmp\". If the filename is a list, a list of image filenames are\n            expected. If filename is a folder, it will be searched for images.\n        backend: An object that implements the basic methods for reading and\n            manipulating frames of a specific video type.\n        backend_metadata: A dictionary of metadata specific to the backend. This is\n            useful for storing metadata that requires an open backend (e.g., shape\n            information) without having access to the video file itself.\n        source_video: The source video object if this is a proxy video. This is present\n            when the video contains an embedded subset of frames from another video.\n        open_backend: Whether to open the backend when the video is available. If `True`\n            (the default), the backend will be automatically opened if the video exists.\n            Set this to `False` when you want to manually open the backend, or when the\n            you know the video file does not exist and you want to avoid trying to open\n            the file.\n\n    Notes:\n        Instances of this class are hashed by identity, not by value. This means that\n        two `Video` instances with the same attributes will NOT be considered equal in a\n        set or dict.\n\n    Media Video Plugin Support:\n        For media files (mp4, avi, etc.), the following plugins are supported:\n        - \"opencv\": Uses OpenCV (cv2) for video reading\n        - \"FFMPEG\": Uses imageio-ffmpeg for video reading\n        - \"pyav\": Uses PyAV for video reading\n\n        Plugin aliases (case-insensitive):\n        - opencv: \"opencv\", \"cv\", \"cv2\", \"ocv\"\n        - FFMPEG: \"FFMPEG\", \"ffmpeg\", \"imageio-ffmpeg\", \"imageio_ffmpeg\"\n        - pyav: \"pyav\", \"av\"\n\n        Plugin selection priority:\n        1. Explicitly specified plugin parameter\n        2. Backend metadata plugin value\n        3. Global default (set via sio.set_default_video_plugin)\n        4. Auto-detection based on available packages\n\n    See Also:\n        VideoBackend: The backend interface for reading video data.\n        sleap_io.set_default_video_plugin: Set global default plugin.\n        sleap_io.get_default_video_plugin: Get current default plugin.\n    \"\"\"\n\n    filename: str | list[str]\n    backend: Optional[VideoBackend] = None\n    backend_metadata: dict[str, any] = attrs.field(factory=dict)\n    source_video: Optional[Video] = None\n    original_video: Optional[Video] = None\n    open_backend: bool = True\n\n    EXTS = MediaVideo.EXTS + HDF5Video.EXTS + ImageVideo.EXTS\n\n    def __attrs_post_init__(self):\n        \"\"\"Post init syntactic sugar.\"\"\"\n        if self.open_backend and self.backend is None and self.exists():\n            try:\n                self.open()\n            except Exception:\n                # If we can't open the backend, just ignore it for now so we don't\n                # prevent the user from building the Video object entirely.\n                pass\n\n    def __deepcopy__(self, memo):\n        \"\"\"Deep copy the video object.\"\"\"\n        if id(self) in memo:\n            return memo[id(self)]\n\n        reopen = False\n        if self.is_open:\n            reopen = True\n            self.close()\n\n        new_video = Video(\n            filename=self.filename,\n            backend=None,\n            backend_metadata=self.backend_metadata,\n            source_video=self.source_video,\n            open_backend=self.open_backend,\n        )\n\n        memo[id(self)] = new_video\n\n        if reopen:\n            self.open()\n\n        return new_video\n\n    @classmethod\n    def from_filename(\n        cls,\n        filename: str | list[str],\n        dataset: Optional[str] = None,\n        grayscale: Optional[bool] = None,\n        keep_open: bool = True,\n        source_video: Optional[Video] = None,\n        **kwargs,\n    ) -&gt; VideoBackend:\n        \"\"\"Create a Video from a filename.\n\n        Args:\n            filename: The filename(s) of the video. Supported extensions: \"mp4\", \"avi\",\n                \"mov\", \"mj2\", \"mkv\", \"h5\", \"hdf5\", \"slp\", \"png\", \"jpg\", \"jpeg\", \"tif\",\n                \"tiff\", \"bmp\". If the filename is a list, a list of image filenames are\n                expected. If filename is a folder, it will be searched for images.\n            dataset: Name of dataset in HDF5 file.\n            grayscale: Whether to force grayscale. If None, autodetect on first frame\n                load.\n            keep_open: Whether to keep the video reader open between calls to read\n                frames. If False, will close the reader after each call. If True (the\n                default), it will keep the reader open and cache it for subsequent calls\n                which may enhance the performance of reading multiple frames.\n            source_video: The source video object if this is a proxy video. This is\n                present when the video contains an embedded subset of frames from\n                another video.\n            **kwargs: Additional backend-specific arguments passed to\n                VideoBackend.from_filename. See VideoBackend.from_filename for supported\n                arguments.\n\n        Returns:\n            Video instance with the appropriate backend instantiated.\n        \"\"\"\n        return cls(\n            filename=filename,\n            backend=VideoBackend.from_filename(\n                filename,\n                dataset=dataset,\n                grayscale=grayscale,\n                keep_open=keep_open,\n                **kwargs,\n            ),\n            source_video=source_video,\n        )\n\n    @property\n    def shape(self) -&gt; Tuple[int, int, int, int] | None:\n        \"\"\"Return the shape of the video as (num_frames, height, width, channels).\n\n        If the video backend is not set or it cannot determine the shape of the video,\n        this will return None.\n        \"\"\"\n        return self._get_shape()\n\n    def _get_shape(self) -&gt; Tuple[int, int, int, int] | None:\n        \"\"\"Return the shape of the video as (num_frames, height, width, channels).\n\n        This suppresses errors related to querying the backend for the video shape, such\n        as when it has not been set or when the video file is not found.\n        \"\"\"\n        try:\n            return self.backend.shape\n        except Exception:\n            if \"shape\" in self.backend_metadata:\n                return self.backend_metadata[\"shape\"]\n            return None\n\n    @property\n    def grayscale(self) -&gt; bool | None:\n        \"\"\"Return whether the video is grayscale.\n\n        If the video backend is not set or it cannot determine whether the video is\n        grayscale, this will return None.\n        \"\"\"\n        shape = self.shape\n        if shape is not None:\n            return shape[-1] == 1\n        else:\n            grayscale = None\n            if \"grayscale\" in self.backend_metadata:\n                grayscale = self.backend_metadata[\"grayscale\"]\n            return grayscale\n\n    @grayscale.setter\n    def grayscale(self, value: bool):\n        \"\"\"Set the grayscale value and adjust the backend.\"\"\"\n        if self.backend is not None:\n            self.backend.grayscale = value\n            self.backend._cached_shape = None\n\n        self.backend_metadata[\"grayscale\"] = value\n\n    def __len__(self) -&gt; int:\n        \"\"\"Return the length of the video as the number of frames.\"\"\"\n        shape = self.shape\n        return 0 if shape is None else shape[0]\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Informal string representation (for print or format).\"\"\"\n        dataset = (\n            f\"dataset={self.backend.dataset}, \"\n            if getattr(self.backend, \"dataset\", \"\")\n            else \"\"\n        )\n        return (\n            \"Video(\"\n            f'filename=\"{self.filename}\", '\n            f\"shape={self.shape}, \"\n            f\"{dataset}\"\n            f\"backend={type(self.backend).__name__}\"\n            \")\"\n        )\n\n    def __str__(self) -&gt; str:\n        \"\"\"Informal string representation (for print or format).\"\"\"\n        return self.__repr__()\n\n    def __getitem__(self, inds: int | list[int] | slice) -&gt; np.ndarray:\n        \"\"\"Return the frames of the video at the given indices.\n\n        Args:\n            inds: Index or list of indices of frames to read.\n\n        Returns:\n            Frame or frames as a numpy array of shape `(height, width, channels)` if a\n            scalar index is provided, or `(frames, height, width, channels)` if a list\n            of indices is provided.\n\n        See also: VideoBackend.get_frame, VideoBackend.get_frames\n        \"\"\"\n        if not self.is_open:\n            if self.open_backend:\n                self.open()\n            else:\n                raise ValueError(\n                    \"Video backend is not open. Call video.open() or set \"\n                    \"video.open_backend to True to do automatically on frame read.\"\n                )\n        return self.backend[inds]\n\n    def exists(self, check_all: bool = False, dataset: str | None = None) -&gt; bool:\n        \"\"\"Check if the video file exists and is accessible.\n\n        Args:\n            check_all: If `True`, check that all filenames in a list exist. If `False`\n                (the default), check that the first filename exists.\n            dataset: Name of dataset in HDF5 file. If specified, this will function will\n                return `False` if the dataset does not exist.\n\n        Returns:\n            `True` if the file exists and is accessible, `False` otherwise.\n        \"\"\"\n        if isinstance(self.filename, list):\n            if check_all:\n                for f in self.filename:\n                    if not is_file_accessible(f):\n                        return False\n                return True\n            else:\n                return is_file_accessible(self.filename[0])\n\n        file_is_accessible = is_file_accessible(self.filename)\n        if not file_is_accessible:\n            return False\n\n        if dataset is None or dataset == \"\":\n            dataset = self.backend_metadata.get(\"dataset\", None)\n\n        if dataset is not None and dataset != \"\":\n            has_dataset = False\n            if (\n                self.backend is not None\n                and type(self.backend) is HDF5Video\n                and self.backend._open_reader is not None\n            ):\n                has_dataset = dataset in self.backend._open_reader\n            else:\n                with h5py.File(self.filename, \"r\") as f:\n                    has_dataset = dataset in f\n            return has_dataset\n\n        return True\n\n    @property\n    def is_open(self) -&gt; bool:\n        \"\"\"Check if the video backend is open.\"\"\"\n        return self.exists() and self.backend is not None\n\n    def open(\n        self,\n        filename: Optional[str] = None,\n        dataset: Optional[str] = None,\n        grayscale: Optional[str] = None,\n        keep_open: bool = True,\n        plugin: Optional[str] = None,\n    ):\n        \"\"\"Open the video backend for reading.\n\n        Args:\n            filename: Filename to open. If not specified, will use the filename set on\n                the video object.\n            dataset: Name of dataset in HDF5 file.\n            grayscale: Whether to force grayscale. If None, autodetect on first frame\n                load.\n            keep_open: Whether to keep the video reader open between calls to read\n                frames. If False, will close the reader after each call. If True (the\n                default), it will keep the reader open and cache it for subsequent calls\n                which may enhance the performance of reading multiple frames.\n            plugin: Video plugin to use for MediaVideo files. One of \"opencv\",\n                \"FFMPEG\", or \"pyav\". Also accepts aliases (case-insensitive).\n                If not specified, uses the backend metadata, global default,\n                or auto-detection in that order.\n\n        Notes:\n            This is useful for opening the video backend to read frames and then closing\n            it after reading all the necessary frames.\n\n            If the backend was already open, it will be closed before opening a new one.\n            Values for the HDF5 dataset and grayscale will be remembered if not\n            specified.\n        \"\"\"\n        if filename is not None:\n            self.replace_filename(filename, open=False)\n\n        # Try to remember values from previous backend if available and not specified.\n        if self.backend is not None:\n            if dataset is None:\n                dataset = getattr(self.backend, \"dataset\", None)\n            if grayscale is None:\n                grayscale = getattr(self.backend, \"grayscale\", None)\n\n        else:\n            if dataset is None and \"dataset\" in self.backend_metadata:\n                dataset = self.backend_metadata[\"dataset\"]\n            if grayscale is None:\n                if \"grayscale\" in self.backend_metadata:\n                    grayscale = self.backend_metadata[\"grayscale\"]\n                elif \"shape\" in self.backend_metadata:\n                    grayscale = self.backend_metadata[\"shape\"][-1] == 1\n\n        if not self.exists(dataset=dataset):\n            msg = (\n                f\"Video does not exist or cannot be opened for reading: {self.filename}\"\n            )\n            if dataset is not None:\n                msg += f\" (dataset: {dataset})\"\n            raise FileNotFoundError(msg)\n\n        # Close previous backend if open.\n        self.close()\n\n        # Handle plugin parameter\n        backend_kwargs = {}\n        if plugin is not None:\n            from sleap_io.io.video_reading import normalize_plugin_name\n\n            plugin = normalize_plugin_name(plugin)\n            self.backend_metadata[\"plugin\"] = plugin\n\n        if \"plugin\" in self.backend_metadata:\n            backend_kwargs[\"plugin\"] = self.backend_metadata[\"plugin\"]\n\n        # Create new backend.\n        self.backend = VideoBackend.from_filename(\n            self.filename,\n            dataset=dataset,\n            grayscale=grayscale,\n            keep_open=keep_open,\n            **backend_kwargs,\n        )\n\n    def close(self):\n        \"\"\"Close the video backend.\"\"\"\n        if self.backend is not None:\n            # Try to remember values from previous backend if available and not\n            # specified.\n            try:\n                self.backend_metadata[\"dataset\"] = getattr(\n                    self.backend, \"dataset\", None\n                )\n                self.backend_metadata[\"grayscale\"] = getattr(\n                    self.backend, \"grayscale\", None\n                )\n                self.backend_metadata[\"shape\"] = getattr(self.backend, \"shape\", None)\n            except Exception:\n                pass\n\n            del self.backend\n            self.backend = None\n\n    def replace_filename(\n        self, new_filename: str | Path | list[str] | list[Path], open: bool = True\n    ):\n        \"\"\"Update the filename of the video, optionally opening the backend.\n\n        Args:\n            new_filename: New filename to set for the video.\n            open: If `True` (the default), open the backend with the new filename. If\n                the new filename does not exist, no error is raised.\n        \"\"\"\n        if isinstance(new_filename, Path):\n            new_filename = new_filename.as_posix()\n\n        if isinstance(new_filename, list):\n            new_filename = [\n                p.as_posix() if isinstance(p, Path) else p for p in new_filename\n            ]\n\n        self.filename = new_filename\n        self.backend_metadata[\"filename\"] = new_filename\n\n        if open:\n            if self.exists():\n                self.open()\n            else:\n                self.close()\n\n    def matches_path(self, other: \"Video\", strict: bool = False) -&gt; bool:\n        \"\"\"Check if this video has the same path as another video.\n\n        Args:\n            other: Another video to compare with.\n            strict: If True, require exact path match. If False, consider videos\n                with the same filename (basename) as matching.\n\n        Returns:\n            True if the videos have matching paths, False otherwise.\n        \"\"\"\n        if isinstance(self.filename, list) and isinstance(other.filename, list):\n            # Both are image sequences\n            if strict:\n                return self.filename == other.filename\n            else:\n                # Compare basenames\n                self_basenames = [Path(f).name for f in self.filename]\n                other_basenames = [Path(f).name for f in other.filename]\n                return self_basenames == other_basenames\n        elif isinstance(self.filename, list) or isinstance(other.filename, list):\n            # One is image sequence, other is single file\n            return False\n        else:\n            # Both are single files\n            if strict:\n                return Path(self.filename).resolve() == Path(other.filename).resolve()\n            else:\n                return Path(self.filename).name == Path(other.filename).name\n\n    def matches_content(self, other: \"Video\") -&gt; bool:\n        \"\"\"Check if this video has the same content as another video.\n\n        Args:\n            other: Another video to compare with.\n\n        Returns:\n            True if the videos have the same shape and backend type.\n\n        Notes:\n            This compares metadata like shape and backend type, not actual frame data.\n        \"\"\"\n        # Compare shapes\n        self_shape = self.shape\n        other_shape = other.shape\n\n        if self_shape != other_shape:\n            return False\n\n        # Compare backend types\n        if self.backend is None and other.backend is None:\n            return True\n        elif self.backend is None or other.backend is None:\n            return False\n\n        return type(self.backend).__name__ == type(other.backend).__name__\n\n    def matches_shape(self, other: \"Video\") -&gt; bool:\n        \"\"\"Check if this video has the same shape as another video.\n\n        Args:\n            other: Another video to compare with.\n\n        Returns:\n            True if the videos have the same height, width, and channels.\n\n        Notes:\n            This only compares spatial dimensions, not the number of frames.\n        \"\"\"\n        # Try to get shape from backend metadata first if shape is not available\n        if self.backend is None and \"shape\" in self.backend_metadata:\n            self_shape = self.backend_metadata[\"shape\"]\n        else:\n            self_shape = self.shape\n\n        if other.backend is None and \"shape\" in other.backend_metadata:\n            other_shape = other.backend_metadata[\"shape\"]\n        else:\n            other_shape = other.shape\n\n        # Handle None shapes\n        if self_shape is None or other_shape is None:\n            return False\n\n        # Compare only height, width, channels (not frames)\n        return self_shape[1:] == other_shape[1:]\n\n    def has_overlapping_images(self, other: \"Video\") -&gt; bool:\n        \"\"\"Check if this video has overlapping images with another video.\n\n        This method is specifically for ImageVideo backends (image sequences).\n\n        Args:\n            other: Another video to compare with.\n\n        Returns:\n            True if both are ImageVideo instances with overlapping image files.\n            False if either video is not an ImageVideo or no overlap exists.\n\n        Notes:\n            Only works with ImageVideo backends where filename is a list.\n            Compares individual image filenames (basenames only).\n        \"\"\"\n        # Both must be image sequences\n        if not (isinstance(self.filename, list) and isinstance(other.filename, list)):\n            return False\n\n        # Get basenames for comparison\n        self_basenames = set(Path(f).name for f in self.filename)\n        other_basenames = set(Path(f).name for f in other.filename)\n\n        # Check if there's any overlap\n        return len(self_basenames &amp; other_basenames) &gt; 0\n\n    def deduplicate_with(self, other: \"Video\") -&gt; \"Video\":\n        \"\"\"Create a new video with duplicate images removed.\n\n        This method is specifically for ImageVideo backends (image sequences).\n\n        Args:\n            other: Another video to deduplicate against. Must also be ImageVideo.\n\n        Returns:\n            A new Video object with duplicate images removed from this video,\n            or None if all images were duplicates.\n\n        Raises:\n            ValueError: If either video is not an ImageVideo backend.\n\n        Notes:\n            Only works with ImageVideo backends where filename is a list.\n            Images are considered duplicates if they have the same basename.\n            The returned video contains only images from this video that are\n            not present in the other video.\n        \"\"\"\n        if not isinstance(self.filename, list):\n            raise ValueError(\"deduplicate_with only works with ImageVideo backends\")\n        if not isinstance(other.filename, list):\n            raise ValueError(\"Other video must also be ImageVideo backend\")\n\n        # Get basenames from other video\n        other_basenames = set(Path(f).name for f in other.filename)\n\n        # Keep only non-duplicate images\n        deduplicated_paths = [\n            f for f in self.filename if Path(f).name not in other_basenames\n        ]\n\n        if not deduplicated_paths:\n            # All images were duplicates\n            return None\n\n        # Create new video with deduplicated images\n        return Video.from_filename(deduplicated_paths, grayscale=self.grayscale)\n\n    def merge_with(self, other: \"Video\") -&gt; \"Video\":\n        \"\"\"Merge another video's images into this one.\n\n        This method is specifically for ImageVideo backends (image sequences).\n\n        Args:\n            other: Another video to merge with. Must also be ImageVideo.\n\n        Returns:\n            A new Video object with unique images from both videos.\n\n        Raises:\n            ValueError: If either video is not an ImageVideo backend.\n\n        Notes:\n            Only works with ImageVideo backends where filename is a list.\n            The merged video contains all unique images from both videos,\n            with automatic deduplication based on image basename.\n        \"\"\"\n        if not isinstance(self.filename, list):\n            raise ValueError(\"merge_with only works with ImageVideo backends\")\n        if not isinstance(other.filename, list):\n            raise ValueError(\"Other video must also be ImageVideo backend\")\n\n        # Get all unique images (by basename) preserving order\n        seen_basenames = set()\n        merged_paths = []\n\n        for path in self.filename:\n            basename = Path(path).name\n            if basename not in seen_basenames:\n                merged_paths.append(path)\n                seen_basenames.add(basename)\n\n        for path in other.filename:\n            basename = Path(path).name\n            if basename not in seen_basenames:\n                merged_paths.append(path)\n                seen_basenames.add(basename)\n\n        # Create new video with merged images\n        return Video.from_filename(merged_paths, grayscale=self.grayscale)\n\n    def save(\n        self,\n        save_path: str | Path,\n        frame_inds: list[int] | np.ndarray | None = None,\n        video_kwargs: dict[str, Any] | None = None,\n    ) -&gt; Video:\n        \"\"\"Save video frames to a new video file.\n\n        Args:\n            save_path: Path to the new video file. Should end in MP4.\n            frame_inds: Frame indices to save. Can be specified as a list or array of\n                frame integers. If not specified, saves all video frames.\n            video_kwargs: A dictionary of keyword arguments to provide to\n                `sio.save_video` for video compression.\n\n        Returns:\n            A new `Video` object pointing to the new video file.\n        \"\"\"\n        video_kwargs = {} if video_kwargs is None else video_kwargs\n        frame_inds = np.arange(len(self)) if frame_inds is None else frame_inds\n\n        with VideoWriter(save_path, **video_kwargs) as vw:\n            for frame_ind in frame_inds:\n                vw(self[frame_ind])\n\n        new_video = Video.from_filename(save_path, grayscale=self.grayscale)\n        return new_video\n\n    def set_video_plugin(self, plugin: str) -&gt; None:\n        \"\"\"Set the video plugin and reopen the video.\n\n        Args:\n            plugin: Video plugin to use. One of \"opencv\", \"FFMPEG\", or \"pyav\".\n                Also accepts aliases (case-insensitive).\n\n        Raises:\n            ValueError: If the video is not a MediaVideo type.\n\n        Examples:\n            &gt;&gt;&gt; video.set_video_plugin(\"opencv\")\n            &gt;&gt;&gt; video.set_video_plugin(\"CV2\")  # Same as \"opencv\"\n        \"\"\"\n        from sleap_io.io.video_reading import MediaVideo, normalize_plugin_name\n\n        if not self.filename.endswith(MediaVideo.EXTS):\n            raise ValueError(f\"Cannot set plugin for non-media video: {self.filename}\")\n\n        plugin = normalize_plugin_name(plugin)\n\n        # Close current backend if open\n        was_open = self.is_open\n        if was_open:\n            self.close()\n\n        # Update backend metadata\n        self.backend_metadata[\"plugin\"] = plugin\n\n        # Reopen with new plugin if it was open\n        if was_open:\n            self.open()\n</code></pre>"},{"location":"model/#sleap_io.Video.grayscale","title":"<code>grayscale</code>  <code>property</code> <code>writable</code>","text":"<p>Return whether the video is grayscale.</p> <p>If the video backend is not set or it cannot determine whether the video is grayscale, this will return None.</p>"},{"location":"model/#sleap_io.Video.is_open","title":"<code>is_open</code>  <code>property</code>","text":"<p>Check if the video backend is open.</p>"},{"location":"model/#sleap_io.Video.shape","title":"<code>shape</code>  <code>property</code>","text":"<p>Return the shape of the video as (num_frames, height, width, channels).</p> <p>If the video backend is not set or it cannot determine the shape of the video, this will return None.</p>"},{"location":"model/#sleap_io.Video.__attrs_post_init__","title":"<code>__attrs_post_init__()</code>","text":"<p>Post init syntactic sugar.</p> Source code in <code>sleap_io/model/video.py</code> <pre><code>def __attrs_post_init__(self):\n    \"\"\"Post init syntactic sugar.\"\"\"\n    if self.open_backend and self.backend is None and self.exists():\n        try:\n            self.open()\n        except Exception:\n            # If we can't open the backend, just ignore it for now so we don't\n            # prevent the user from building the Video object entirely.\n            pass\n</code></pre>"},{"location":"model/#sleap_io.Video.__deepcopy__","title":"<code>__deepcopy__(memo)</code>","text":"<p>Deep copy the video object.</p> Source code in <code>sleap_io/model/video.py</code> <pre><code>def __deepcopy__(self, memo):\n    \"\"\"Deep copy the video object.\"\"\"\n    if id(self) in memo:\n        return memo[id(self)]\n\n    reopen = False\n    if self.is_open:\n        reopen = True\n        self.close()\n\n    new_video = Video(\n        filename=self.filename,\n        backend=None,\n        backend_metadata=self.backend_metadata,\n        source_video=self.source_video,\n        open_backend=self.open_backend,\n    )\n\n    memo[id(self)] = new_video\n\n    if reopen:\n        self.open()\n\n    return new_video\n</code></pre>"},{"location":"model/#sleap_io.Video.__getitem__","title":"<code>__getitem__(inds)</code>","text":"<p>Return the frames of the video at the given indices.</p> <p>Parameters:</p> Name Type Description Default <code>inds</code> <code>int | list[int] | slice</code> <p>Index or list of indices of frames to read.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Frame or frames as a numpy array of shape <code>(height, width, channels)</code> if a scalar index is provided, or <code>(frames, height, width, channels)</code> if a list of indices is provided.</p> <p>See also: VideoBackend.get_frame, VideoBackend.get_frames</p> Source code in <code>sleap_io/model/video.py</code> <pre><code>def __getitem__(self, inds: int | list[int] | slice) -&gt; np.ndarray:\n    \"\"\"Return the frames of the video at the given indices.\n\n    Args:\n        inds: Index or list of indices of frames to read.\n\n    Returns:\n        Frame or frames as a numpy array of shape `(height, width, channels)` if a\n        scalar index is provided, or `(frames, height, width, channels)` if a list\n        of indices is provided.\n\n    See also: VideoBackend.get_frame, VideoBackend.get_frames\n    \"\"\"\n    if not self.is_open:\n        if self.open_backend:\n            self.open()\n        else:\n            raise ValueError(\n                \"Video backend is not open. Call video.open() or set \"\n                \"video.open_backend to True to do automatically on frame read.\"\n            )\n    return self.backend[inds]\n</code></pre>"},{"location":"model/#sleap_io.Video.__len__","title":"<code>__len__()</code>","text":"<p>Return the length of the video as the number of frames.</p> Source code in <code>sleap_io/model/video.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"Return the length of the video as the number of frames.\"\"\"\n    shape = self.shape\n    return 0 if shape is None else shape[0]\n</code></pre>"},{"location":"model/#sleap_io.Video.__repr__","title":"<code>__repr__()</code>","text":"<p>Informal string representation (for print or format).</p> Source code in <code>sleap_io/model/video.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Informal string representation (for print or format).\"\"\"\n    dataset = (\n        f\"dataset={self.backend.dataset}, \"\n        if getattr(self.backend, \"dataset\", \"\")\n        else \"\"\n    )\n    return (\n        \"Video(\"\n        f'filename=\"{self.filename}\", '\n        f\"shape={self.shape}, \"\n        f\"{dataset}\"\n        f\"backend={type(self.backend).__name__}\"\n        \")\"\n    )\n</code></pre>"},{"location":"model/#sleap_io.Video.__str__","title":"<code>__str__()</code>","text":"<p>Informal string representation (for print or format).</p> Source code in <code>sleap_io/model/video.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Informal string representation (for print or format).\"\"\"\n    return self.__repr__()\n</code></pre>"},{"location":"model/#sleap_io.Video.close","title":"<code>close()</code>","text":"<p>Close the video backend.</p> Source code in <code>sleap_io/model/video.py</code> <pre><code>def close(self):\n    \"\"\"Close the video backend.\"\"\"\n    if self.backend is not None:\n        # Try to remember values from previous backend if available and not\n        # specified.\n        try:\n            self.backend_metadata[\"dataset\"] = getattr(\n                self.backend, \"dataset\", None\n            )\n            self.backend_metadata[\"grayscale\"] = getattr(\n                self.backend, \"grayscale\", None\n            )\n            self.backend_metadata[\"shape\"] = getattr(self.backend, \"shape\", None)\n        except Exception:\n            pass\n\n        del self.backend\n        self.backend = None\n</code></pre>"},{"location":"model/#sleap_io.Video.deduplicate_with","title":"<code>deduplicate_with(other)</code>","text":"<p>Create a new video with duplicate images removed.</p> <p>This method is specifically for ImageVideo backends (image sequences).</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>'Video'</code> <p>Another video to deduplicate against. Must also be ImageVideo.</p> required <p>Returns:</p> Type Description <code>'Video'</code> <p>A new Video object with duplicate images removed from this video, or None if all images were duplicates.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If either video is not an ImageVideo backend.</p> Notes <p>Only works with ImageVideo backends where filename is a list. Images are considered duplicates if they have the same basename. The returned video contains only images from this video that are not present in the other video.</p> Source code in <code>sleap_io/model/video.py</code> <pre><code>def deduplicate_with(self, other: \"Video\") -&gt; \"Video\":\n    \"\"\"Create a new video with duplicate images removed.\n\n    This method is specifically for ImageVideo backends (image sequences).\n\n    Args:\n        other: Another video to deduplicate against. Must also be ImageVideo.\n\n    Returns:\n        A new Video object with duplicate images removed from this video,\n        or None if all images were duplicates.\n\n    Raises:\n        ValueError: If either video is not an ImageVideo backend.\n\n    Notes:\n        Only works with ImageVideo backends where filename is a list.\n        Images are considered duplicates if they have the same basename.\n        The returned video contains only images from this video that are\n        not present in the other video.\n    \"\"\"\n    if not isinstance(self.filename, list):\n        raise ValueError(\"deduplicate_with only works with ImageVideo backends\")\n    if not isinstance(other.filename, list):\n        raise ValueError(\"Other video must also be ImageVideo backend\")\n\n    # Get basenames from other video\n    other_basenames = set(Path(f).name for f in other.filename)\n\n    # Keep only non-duplicate images\n    deduplicated_paths = [\n        f for f in self.filename if Path(f).name not in other_basenames\n    ]\n\n    if not deduplicated_paths:\n        # All images were duplicates\n        return None\n\n    # Create new video with deduplicated images\n    return Video.from_filename(deduplicated_paths, grayscale=self.grayscale)\n</code></pre>"},{"location":"model/#sleap_io.Video.exists","title":"<code>exists(check_all=False, dataset=None)</code>","text":"<p>Check if the video file exists and is accessible.</p> <p>Parameters:</p> Name Type Description Default <code>check_all</code> <code>bool</code> <p>If <code>True</code>, check that all filenames in a list exist. If <code>False</code> (the default), check that the first filename exists.</p> <code>False</code> <code>dataset</code> <code>str | None</code> <p>Name of dataset in HDF5 file. If specified, this will function will return <code>False</code> if the dataset does not exist.</p> <code>None</code> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if the file exists and is accessible, <code>False</code> otherwise.</p> Source code in <code>sleap_io/model/video.py</code> <pre><code>def exists(self, check_all: bool = False, dataset: str | None = None) -&gt; bool:\n    \"\"\"Check if the video file exists and is accessible.\n\n    Args:\n        check_all: If `True`, check that all filenames in a list exist. If `False`\n            (the default), check that the first filename exists.\n        dataset: Name of dataset in HDF5 file. If specified, this will function will\n            return `False` if the dataset does not exist.\n\n    Returns:\n        `True` if the file exists and is accessible, `False` otherwise.\n    \"\"\"\n    if isinstance(self.filename, list):\n        if check_all:\n            for f in self.filename:\n                if not is_file_accessible(f):\n                    return False\n            return True\n        else:\n            return is_file_accessible(self.filename[0])\n\n    file_is_accessible = is_file_accessible(self.filename)\n    if not file_is_accessible:\n        return False\n\n    if dataset is None or dataset == \"\":\n        dataset = self.backend_metadata.get(\"dataset\", None)\n\n    if dataset is not None and dataset != \"\":\n        has_dataset = False\n        if (\n            self.backend is not None\n            and type(self.backend) is HDF5Video\n            and self.backend._open_reader is not None\n        ):\n            has_dataset = dataset in self.backend._open_reader\n        else:\n            with h5py.File(self.filename, \"r\") as f:\n                has_dataset = dataset in f\n        return has_dataset\n\n    return True\n</code></pre>"},{"location":"model/#sleap_io.Video.from_filename","title":"<code>from_filename(filename, dataset=None, grayscale=None, keep_open=True, source_video=None, **kwargs)</code>  <code>classmethod</code>","text":"<p>Create a Video from a filename.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str | list[str]</code> <p>The filename(s) of the video. Supported extensions: \"mp4\", \"avi\", \"mov\", \"mj2\", \"mkv\", \"h5\", \"hdf5\", \"slp\", \"png\", \"jpg\", \"jpeg\", \"tif\", \"tiff\", \"bmp\". If the filename is a list, a list of image filenames are expected. If filename is a folder, it will be searched for images.</p> required <code>dataset</code> <code>Optional[str]</code> <p>Name of dataset in HDF5 file.</p> <code>None</code> <code>grayscale</code> <code>Optional[bool]</code> <p>Whether to force grayscale. If None, autodetect on first frame load.</p> <code>None</code> <code>keep_open</code> <code>bool</code> <p>Whether to keep the video reader open between calls to read frames. If False, will close the reader after each call. If True (the default), it will keep the reader open and cache it for subsequent calls which may enhance the performance of reading multiple frames.</p> <code>True</code> <code>source_video</code> <code>Optional[Video]</code> <p>The source video object if this is a proxy video. This is present when the video contains an embedded subset of frames from another video.</p> <code>None</code> <code>**kwargs</code> <p>Additional backend-specific arguments passed to VideoBackend.from_filename. See VideoBackend.from_filename for supported arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>VideoBackend</code> <p>Video instance with the appropriate backend instantiated.</p> Source code in <code>sleap_io/model/video.py</code> <pre><code>@classmethod\ndef from_filename(\n    cls,\n    filename: str | list[str],\n    dataset: Optional[str] = None,\n    grayscale: Optional[bool] = None,\n    keep_open: bool = True,\n    source_video: Optional[Video] = None,\n    **kwargs,\n) -&gt; VideoBackend:\n    \"\"\"Create a Video from a filename.\n\n    Args:\n        filename: The filename(s) of the video. Supported extensions: \"mp4\", \"avi\",\n            \"mov\", \"mj2\", \"mkv\", \"h5\", \"hdf5\", \"slp\", \"png\", \"jpg\", \"jpeg\", \"tif\",\n            \"tiff\", \"bmp\". If the filename is a list, a list of image filenames are\n            expected. If filename is a folder, it will be searched for images.\n        dataset: Name of dataset in HDF5 file.\n        grayscale: Whether to force grayscale. If None, autodetect on first frame\n            load.\n        keep_open: Whether to keep the video reader open between calls to read\n            frames. If False, will close the reader after each call. If True (the\n            default), it will keep the reader open and cache it for subsequent calls\n            which may enhance the performance of reading multiple frames.\n        source_video: The source video object if this is a proxy video. This is\n            present when the video contains an embedded subset of frames from\n            another video.\n        **kwargs: Additional backend-specific arguments passed to\n            VideoBackend.from_filename. See VideoBackend.from_filename for supported\n            arguments.\n\n    Returns:\n        Video instance with the appropriate backend instantiated.\n    \"\"\"\n    return cls(\n        filename=filename,\n        backend=VideoBackend.from_filename(\n            filename,\n            dataset=dataset,\n            grayscale=grayscale,\n            keep_open=keep_open,\n            **kwargs,\n        ),\n        source_video=source_video,\n    )\n</code></pre>"},{"location":"model/#sleap_io.Video.has_overlapping_images","title":"<code>has_overlapping_images(other)</code>","text":"<p>Check if this video has overlapping images with another video.</p> <p>This method is specifically for ImageVideo backends (image sequences).</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>'Video'</code> <p>Another video to compare with.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if both are ImageVideo instances with overlapping image files. False if either video is not an ImageVideo or no overlap exists.</p> Notes <p>Only works with ImageVideo backends where filename is a list. Compares individual image filenames (basenames only).</p> Source code in <code>sleap_io/model/video.py</code> <pre><code>def has_overlapping_images(self, other: \"Video\") -&gt; bool:\n    \"\"\"Check if this video has overlapping images with another video.\n\n    This method is specifically for ImageVideo backends (image sequences).\n\n    Args:\n        other: Another video to compare with.\n\n    Returns:\n        True if both are ImageVideo instances with overlapping image files.\n        False if either video is not an ImageVideo or no overlap exists.\n\n    Notes:\n        Only works with ImageVideo backends where filename is a list.\n        Compares individual image filenames (basenames only).\n    \"\"\"\n    # Both must be image sequences\n    if not (isinstance(self.filename, list) and isinstance(other.filename, list)):\n        return False\n\n    # Get basenames for comparison\n    self_basenames = set(Path(f).name for f in self.filename)\n    other_basenames = set(Path(f).name for f in other.filename)\n\n    # Check if there's any overlap\n    return len(self_basenames &amp; other_basenames) &gt; 0\n</code></pre>"},{"location":"model/#sleap_io.Video.matches_content","title":"<code>matches_content(other)</code>","text":"<p>Check if this video has the same content as another video.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>'Video'</code> <p>Another video to compare with.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the videos have the same shape and backend type.</p> Notes <p>This compares metadata like shape and backend type, not actual frame data.</p> Source code in <code>sleap_io/model/video.py</code> <pre><code>def matches_content(self, other: \"Video\") -&gt; bool:\n    \"\"\"Check if this video has the same content as another video.\n\n    Args:\n        other: Another video to compare with.\n\n    Returns:\n        True if the videos have the same shape and backend type.\n\n    Notes:\n        This compares metadata like shape and backend type, not actual frame data.\n    \"\"\"\n    # Compare shapes\n    self_shape = self.shape\n    other_shape = other.shape\n\n    if self_shape != other_shape:\n        return False\n\n    # Compare backend types\n    if self.backend is None and other.backend is None:\n        return True\n    elif self.backend is None or other.backend is None:\n        return False\n\n    return type(self.backend).__name__ == type(other.backend).__name__\n</code></pre>"},{"location":"model/#sleap_io.Video.matches_path","title":"<code>matches_path(other, strict=False)</code>","text":"<p>Check if this video has the same path as another video.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>'Video'</code> <p>Another video to compare with.</p> required <code>strict</code> <code>bool</code> <p>If True, require exact path match. If False, consider videos with the same filename (basename) as matching.</p> <code>False</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if the videos have matching paths, False otherwise.</p> Source code in <code>sleap_io/model/video.py</code> <pre><code>def matches_path(self, other: \"Video\", strict: bool = False) -&gt; bool:\n    \"\"\"Check if this video has the same path as another video.\n\n    Args:\n        other: Another video to compare with.\n        strict: If True, require exact path match. If False, consider videos\n            with the same filename (basename) as matching.\n\n    Returns:\n        True if the videos have matching paths, False otherwise.\n    \"\"\"\n    if isinstance(self.filename, list) and isinstance(other.filename, list):\n        # Both are image sequences\n        if strict:\n            return self.filename == other.filename\n        else:\n            # Compare basenames\n            self_basenames = [Path(f).name for f in self.filename]\n            other_basenames = [Path(f).name for f in other.filename]\n            return self_basenames == other_basenames\n    elif isinstance(self.filename, list) or isinstance(other.filename, list):\n        # One is image sequence, other is single file\n        return False\n    else:\n        # Both are single files\n        if strict:\n            return Path(self.filename).resolve() == Path(other.filename).resolve()\n        else:\n            return Path(self.filename).name == Path(other.filename).name\n</code></pre>"},{"location":"model/#sleap_io.Video.matches_shape","title":"<code>matches_shape(other)</code>","text":"<p>Check if this video has the same shape as another video.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>'Video'</code> <p>Another video to compare with.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the videos have the same height, width, and channels.</p> Notes <p>This only compares spatial dimensions, not the number of frames.</p> Source code in <code>sleap_io/model/video.py</code> <pre><code>def matches_shape(self, other: \"Video\") -&gt; bool:\n    \"\"\"Check if this video has the same shape as another video.\n\n    Args:\n        other: Another video to compare with.\n\n    Returns:\n        True if the videos have the same height, width, and channels.\n\n    Notes:\n        This only compares spatial dimensions, not the number of frames.\n    \"\"\"\n    # Try to get shape from backend metadata first if shape is not available\n    if self.backend is None and \"shape\" in self.backend_metadata:\n        self_shape = self.backend_metadata[\"shape\"]\n    else:\n        self_shape = self.shape\n\n    if other.backend is None and \"shape\" in other.backend_metadata:\n        other_shape = other.backend_metadata[\"shape\"]\n    else:\n        other_shape = other.shape\n\n    # Handle None shapes\n    if self_shape is None or other_shape is None:\n        return False\n\n    # Compare only height, width, channels (not frames)\n    return self_shape[1:] == other_shape[1:]\n</code></pre>"},{"location":"model/#sleap_io.Video.merge_with","title":"<code>merge_with(other)</code>","text":"<p>Merge another video's images into this one.</p> <p>This method is specifically for ImageVideo backends (image sequences).</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>'Video'</code> <p>Another video to merge with. Must also be ImageVideo.</p> required <p>Returns:</p> Type Description <code>'Video'</code> <p>A new Video object with unique images from both videos.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If either video is not an ImageVideo backend.</p> Notes <p>Only works with ImageVideo backends where filename is a list. The merged video contains all unique images from both videos, with automatic deduplication based on image basename.</p> Source code in <code>sleap_io/model/video.py</code> <pre><code>def merge_with(self, other: \"Video\") -&gt; \"Video\":\n    \"\"\"Merge another video's images into this one.\n\n    This method is specifically for ImageVideo backends (image sequences).\n\n    Args:\n        other: Another video to merge with. Must also be ImageVideo.\n\n    Returns:\n        A new Video object with unique images from both videos.\n\n    Raises:\n        ValueError: If either video is not an ImageVideo backend.\n\n    Notes:\n        Only works with ImageVideo backends where filename is a list.\n        The merged video contains all unique images from both videos,\n        with automatic deduplication based on image basename.\n    \"\"\"\n    if not isinstance(self.filename, list):\n        raise ValueError(\"merge_with only works with ImageVideo backends\")\n    if not isinstance(other.filename, list):\n        raise ValueError(\"Other video must also be ImageVideo backend\")\n\n    # Get all unique images (by basename) preserving order\n    seen_basenames = set()\n    merged_paths = []\n\n    for path in self.filename:\n        basename = Path(path).name\n        if basename not in seen_basenames:\n            merged_paths.append(path)\n            seen_basenames.add(basename)\n\n    for path in other.filename:\n        basename = Path(path).name\n        if basename not in seen_basenames:\n            merged_paths.append(path)\n            seen_basenames.add(basename)\n\n    # Create new video with merged images\n    return Video.from_filename(merged_paths, grayscale=self.grayscale)\n</code></pre>"},{"location":"model/#sleap_io.Video.open","title":"<code>open(filename=None, dataset=None, grayscale=None, keep_open=True, plugin=None)</code>","text":"<p>Open the video backend for reading.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>Optional[str]</code> <p>Filename to open. If not specified, will use the filename set on the video object.</p> <code>None</code> <code>dataset</code> <code>Optional[str]</code> <p>Name of dataset in HDF5 file.</p> <code>None</code> <code>grayscale</code> <code>Optional[str]</code> <p>Whether to force grayscale. If None, autodetect on first frame load.</p> <code>None</code> <code>keep_open</code> <code>bool</code> <p>Whether to keep the video reader open between calls to read frames. If False, will close the reader after each call. If True (the default), it will keep the reader open and cache it for subsequent calls which may enhance the performance of reading multiple frames.</p> <code>True</code> <code>plugin</code> <code>Optional[str]</code> <p>Video plugin to use for MediaVideo files. One of \"opencv\", \"FFMPEG\", or \"pyav\". Also accepts aliases (case-insensitive). If not specified, uses the backend metadata, global default, or auto-detection in that order.</p> <code>None</code> Notes <p>This is useful for opening the video backend to read frames and then closing it after reading all the necessary frames.</p> <p>If the backend was already open, it will be closed before opening a new one. Values for the HDF5 dataset and grayscale will be remembered if not specified.</p> Source code in <code>sleap_io/model/video.py</code> <pre><code>def open(\n    self,\n    filename: Optional[str] = None,\n    dataset: Optional[str] = None,\n    grayscale: Optional[str] = None,\n    keep_open: bool = True,\n    plugin: Optional[str] = None,\n):\n    \"\"\"Open the video backend for reading.\n\n    Args:\n        filename: Filename to open. If not specified, will use the filename set on\n            the video object.\n        dataset: Name of dataset in HDF5 file.\n        grayscale: Whether to force grayscale. If None, autodetect on first frame\n            load.\n        keep_open: Whether to keep the video reader open between calls to read\n            frames. If False, will close the reader after each call. If True (the\n            default), it will keep the reader open and cache it for subsequent calls\n            which may enhance the performance of reading multiple frames.\n        plugin: Video plugin to use for MediaVideo files. One of \"opencv\",\n            \"FFMPEG\", or \"pyav\". Also accepts aliases (case-insensitive).\n            If not specified, uses the backend metadata, global default,\n            or auto-detection in that order.\n\n    Notes:\n        This is useful for opening the video backend to read frames and then closing\n        it after reading all the necessary frames.\n\n        If the backend was already open, it will be closed before opening a new one.\n        Values for the HDF5 dataset and grayscale will be remembered if not\n        specified.\n    \"\"\"\n    if filename is not None:\n        self.replace_filename(filename, open=False)\n\n    # Try to remember values from previous backend if available and not specified.\n    if self.backend is not None:\n        if dataset is None:\n            dataset = getattr(self.backend, \"dataset\", None)\n        if grayscale is None:\n            grayscale = getattr(self.backend, \"grayscale\", None)\n\n    else:\n        if dataset is None and \"dataset\" in self.backend_metadata:\n            dataset = self.backend_metadata[\"dataset\"]\n        if grayscale is None:\n            if \"grayscale\" in self.backend_metadata:\n                grayscale = self.backend_metadata[\"grayscale\"]\n            elif \"shape\" in self.backend_metadata:\n                grayscale = self.backend_metadata[\"shape\"][-1] == 1\n\n    if not self.exists(dataset=dataset):\n        msg = (\n            f\"Video does not exist or cannot be opened for reading: {self.filename}\"\n        )\n        if dataset is not None:\n            msg += f\" (dataset: {dataset})\"\n        raise FileNotFoundError(msg)\n\n    # Close previous backend if open.\n    self.close()\n\n    # Handle plugin parameter\n    backend_kwargs = {}\n    if plugin is not None:\n        from sleap_io.io.video_reading import normalize_plugin_name\n\n        plugin = normalize_plugin_name(plugin)\n        self.backend_metadata[\"plugin\"] = plugin\n\n    if \"plugin\" in self.backend_metadata:\n        backend_kwargs[\"plugin\"] = self.backend_metadata[\"plugin\"]\n\n    # Create new backend.\n    self.backend = VideoBackend.from_filename(\n        self.filename,\n        dataset=dataset,\n        grayscale=grayscale,\n        keep_open=keep_open,\n        **backend_kwargs,\n    )\n</code></pre>"},{"location":"model/#sleap_io.Video.replace_filename","title":"<code>replace_filename(new_filename, open=True)</code>","text":"<p>Update the filename of the video, optionally opening the backend.</p> <p>Parameters:</p> Name Type Description Default <code>new_filename</code> <code>str | Path | list[str] | list[Path]</code> <p>New filename to set for the video.</p> required <code>open</code> <code>bool</code> <p>If <code>True</code> (the default), open the backend with the new filename. If the new filename does not exist, no error is raised.</p> <code>True</code> Source code in <code>sleap_io/model/video.py</code> <pre><code>def replace_filename(\n    self, new_filename: str | Path | list[str] | list[Path], open: bool = True\n):\n    \"\"\"Update the filename of the video, optionally opening the backend.\n\n    Args:\n        new_filename: New filename to set for the video.\n        open: If `True` (the default), open the backend with the new filename. If\n            the new filename does not exist, no error is raised.\n    \"\"\"\n    if isinstance(new_filename, Path):\n        new_filename = new_filename.as_posix()\n\n    if isinstance(new_filename, list):\n        new_filename = [\n            p.as_posix() if isinstance(p, Path) else p for p in new_filename\n        ]\n\n    self.filename = new_filename\n    self.backend_metadata[\"filename\"] = new_filename\n\n    if open:\n        if self.exists():\n            self.open()\n        else:\n            self.close()\n</code></pre>"},{"location":"model/#sleap_io.Video.save","title":"<code>save(save_path, frame_inds=None, video_kwargs=None)</code>","text":"<p>Save video frames to a new video file.</p> <p>Parameters:</p> Name Type Description Default <code>save_path</code> <code>str | Path</code> <p>Path to the new video file. Should end in MP4.</p> required <code>frame_inds</code> <code>list[int] | ndarray | None</code> <p>Frame indices to save. Can be specified as a list or array of frame integers. If not specified, saves all video frames.</p> <code>None</code> <code>video_kwargs</code> <code>dict[str, Any] | None</code> <p>A dictionary of keyword arguments to provide to <code>sio.save_video</code> for video compression.</p> <code>None</code> <p>Returns:</p> Type Description <code>Video</code> <p>A new <code>Video</code> object pointing to the new video file.</p> Source code in <code>sleap_io/model/video.py</code> <pre><code>def save(\n    self,\n    save_path: str | Path,\n    frame_inds: list[int] | np.ndarray | None = None,\n    video_kwargs: dict[str, Any] | None = None,\n) -&gt; Video:\n    \"\"\"Save video frames to a new video file.\n\n    Args:\n        save_path: Path to the new video file. Should end in MP4.\n        frame_inds: Frame indices to save. Can be specified as a list or array of\n            frame integers. If not specified, saves all video frames.\n        video_kwargs: A dictionary of keyword arguments to provide to\n            `sio.save_video` for video compression.\n\n    Returns:\n        A new `Video` object pointing to the new video file.\n    \"\"\"\n    video_kwargs = {} if video_kwargs is None else video_kwargs\n    frame_inds = np.arange(len(self)) if frame_inds is None else frame_inds\n\n    with VideoWriter(save_path, **video_kwargs) as vw:\n        for frame_ind in frame_inds:\n            vw(self[frame_ind])\n\n    new_video = Video.from_filename(save_path, grayscale=self.grayscale)\n    return new_video\n</code></pre>"},{"location":"model/#sleap_io.Video.set_video_plugin","title":"<code>set_video_plugin(plugin)</code>","text":"<p>Set the video plugin and reopen the video.</p> <p>Parameters:</p> Name Type Description Default <code>plugin</code> <code>str</code> <p>Video plugin to use. One of \"opencv\", \"FFMPEG\", or \"pyav\". Also accepts aliases (case-insensitive).</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If the video is not a MediaVideo type.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; video.set_video_plugin(\"opencv\")\n&gt;&gt;&gt; video.set_video_plugin(\"CV2\")  # Same as \"opencv\"\n</code></pre> Source code in <code>sleap_io/model/video.py</code> <pre><code>def set_video_plugin(self, plugin: str) -&gt; None:\n    \"\"\"Set the video plugin and reopen the video.\n\n    Args:\n        plugin: Video plugin to use. One of \"opencv\", \"FFMPEG\", or \"pyav\".\n            Also accepts aliases (case-insensitive).\n\n    Raises:\n        ValueError: If the video is not a MediaVideo type.\n\n    Examples:\n        &gt;&gt;&gt; video.set_video_plugin(\"opencv\")\n        &gt;&gt;&gt; video.set_video_plugin(\"CV2\")  # Same as \"opencv\"\n    \"\"\"\n    from sleap_io.io.video_reading import MediaVideo, normalize_plugin_name\n\n    if not self.filename.endswith(MediaVideo.EXTS):\n        raise ValueError(f\"Cannot set plugin for non-media video: {self.filename}\")\n\n    plugin = normalize_plugin_name(plugin)\n\n    # Close current backend if open\n    was_open = self.is_open\n    if was_open:\n        self.close()\n\n    # Update backend metadata\n    self.backend_metadata[\"plugin\"] = plugin\n\n    # Reopen with new plugin if it was open\n    if was_open:\n        self.open()\n</code></pre>"},{"location":"model/#sleap_io.SuggestionFrame","title":"<code>sleap_io.SuggestionFrame</code>","text":"<p>Data structure for a single frame of suggestions.</p> <p>Attributes:</p> Name Type Description <code>video</code> <code>Video</code> <p>The video associated with the frame.</p> <code>frame_idx</code> <code>int</code> <p>The index of the frame in the video.</p> Source code in <code>sleap_io/model/suggestions.py</code> <pre><code>@attrs.define(auto_attribs=True)\nclass SuggestionFrame:\n    \"\"\"Data structure for a single frame of suggestions.\n\n    Attributes:\n        video: The video associated with the frame.\n        frame_idx: The index of the frame in the video.\n    \"\"\"\n\n    video: Video\n    frame_idx: int\n</code></pre>"},{"location":"model/#sleap_io.Camera","title":"<code>sleap_io.Camera</code>","text":"<p>A camera used to record in a multi-view <code>RecordingSession</code>.</p> <p>Attributes:</p> Name Type Description <code>matrix</code> <code>ndarray</code> <p>Intrinsic camera matrix of size (3, 3) and type float64.</p> <code>dist</code> <code>ndarray</code> <p>Radial-tangential distortion coefficients [k_1, k_2, p_1, p_2, k_3] of size (5,) and type float64.</p> <code>size</code> <code>tuple[int, int]</code> <p>Image size (width, height) of camera in pixels of size (2,) and type int.</p> <code>rvec</code> <code>ndarray</code> <p>Rotation vector in unnormalized axis-angle representation of size (3,) and type float64.</p> <code>tvec</code> <code>ndarray</code> <p>Translation vector of size (3,) and type float64.</p> <code>extrinsic_matrix</code> <code>ndarray</code> <p>Extrinsic matrix of camera of size (4, 4) and type float64.</p> <code>name</code> <code>str</code> <p>Camera name.</p> <code>metadata</code> <code>dict</code> <p>Dictionary of metadata.</p> <p>Methods:</p> Name Description <code>__attrs_post_init__</code> <p>Initialize extrinsic matrix from rotation and translation vectors.</p> <code>__repr__</code> <p>Return a readable representation of the camera.</p> <code>get_video</code> <p>Get video associated with recording session.</p> Source code in <code>sleap_io/model/camera.py</code> <pre><code>@define(eq=False)  # Set eq to false to make class hashable\nclass Camera:\n    \"\"\"A camera used to record in a multi-view `RecordingSession`.\n\n    Attributes:\n        matrix: Intrinsic camera matrix of size (3, 3) and type float64.\n        dist: Radial-tangential distortion coefficients [k_1, k_2, p_1, p_2, k_3] of\n            size (5,) and type float64.\n        size: Image size (width, height) of camera in pixels of size (2,) and type int.\n        rvec: Rotation vector in unnormalized axis-angle representation of size (3,) and\n            type float64.\n        tvec: Translation vector of size (3,) and type float64.\n        extrinsic_matrix: Extrinsic matrix of camera of size (4, 4) and type float64.\n        name: Camera name.\n        metadata: Dictionary of metadata.\n    \"\"\"\n\n    matrix: np.ndarray = field(\n        default=np.eye(3),\n        converter=lambda x: np.array(x, dtype=\"float64\"),\n    )\n    dist: np.ndarray = field(\n        default=np.zeros(5), converter=lambda x: np.array(x, dtype=\"float64\").ravel()\n    )\n    size: tuple[int, int] = field(\n        default=None, converter=attrs.converters.optional(tuple)\n    )\n    _rvec: np.ndarray = field(\n        default=np.zeros(3), converter=lambda x: np.array(x, dtype=\"float64\").ravel()\n    )\n    _tvec: np.ndarray = field(\n        default=np.zeros(3), converter=lambda x: np.array(x, dtype=\"float64\").ravel()\n    )\n    name: str = field(default=None, converter=attrs.converters.optional(str))\n    _extrinsic_matrix: np.ndarray = field(init=False)\n    metadata: dict = field(factory=dict, validator=instance_of(dict))\n\n    @matrix.validator\n    @dist.validator\n    @size.validator\n    @_rvec.validator\n    @_tvec.validator\n    @_extrinsic_matrix.validator\n    def _validate_shape(self, attribute: attrs.Attribute, value):\n        \"\"\"Validate shape of attribute based on metadata.\n\n        Args:\n            attribute: Attribute to validate.\n            value: Value of attribute to validate.\n\n        Raises:\n            ValueError: If attribute shape is not as expected.\n        \"\"\"\n        # Define metadata for each attribute\n        attr_metadata = {\n            \"matrix\": {\"shape\": (3, 3), \"type\": np.ndarray},\n            \"dist\": {\"shape\": (5,), \"type\": np.ndarray},\n            \"size\": {\"shape\": (2,), \"type\": tuple},\n            \"_rvec\": {\"shape\": (3,), \"type\": np.ndarray},\n            \"_tvec\": {\"shape\": (3,), \"type\": np.ndarray},\n            \"_extrinsic_matrix\": {\"shape\": (4, 4), \"type\": np.ndarray},\n        }\n        optional_attrs = [\"size\"]\n\n        # Skip validation if optional attribute is None\n        if attribute.name in optional_attrs and value is None:\n            return\n\n        # Validate shape of attribute\n        expected_shape = attr_metadata[attribute.name][\"shape\"]\n        expected_type = attr_metadata[attribute.name][\"type\"]\n        if np.shape(value) != expected_shape:\n            raise ValueError(\n                f\"{attribute.name} must be a {expected_type} of size {expected_shape}, \"\n                f\"but received shape: {np.shape(value)} and type: {type(value)} for \"\n                f\"value: {value}\"\n            )\n\n    def __attrs_post_init__(self):\n        \"\"\"Initialize extrinsic matrix from rotation and translation vectors.\"\"\"\n        self._extrinsic_matrix = np.eye(4, dtype=\"float64\")\n        self._extrinsic_matrix[:3, :3] = rodrigues_transformation(self._rvec)[0]\n        self._extrinsic_matrix[:3, 3] = self._tvec\n\n    @property\n    def rvec(self) -&gt; np.ndarray:\n        \"\"\"Get rotation vector of camera.\n\n        Returns:\n            Rotation vector of camera of size 3.\n        \"\"\"\n        return self._rvec\n\n    @rvec.setter\n    def rvec(self, value: np.ndarray):\n        \"\"\"Set rotation vector and update extrinsic matrix.\n\n        Args:\n            value: Rotation vector of size 3.\n        \"\"\"\n        self._rvec = value\n        self._extrinsic_matrix[:3, :3] = rodrigues_transformation(self._rvec)[0]\n\n    @property\n    def tvec(self) -&gt; np.ndarray:\n        \"\"\"Get translation vector of camera.\n\n        Returns:\n            Translation vector of camera of size 3.\n        \"\"\"\n        return self._tvec\n\n    @tvec.setter\n    def tvec(self, value: np.ndarray):\n        \"\"\"Set translation vector and update extrinsic matrix.\n\n        Args:\n            value: Translation vector of size 3.\n        \"\"\"\n        self._tvec = value\n\n        # Update extrinsic matrix\n        self._extrinsic_matrix[:3, 3] = self._tvec\n\n    @property\n    def extrinsic_matrix(self) -&gt; np.ndarray:\n        \"\"\"Get extrinsic matrix of camera.\n\n        Returns:\n            Extrinsic matrix of camera of size 4 x 4.\n        \"\"\"\n        return self._extrinsic_matrix\n\n    @extrinsic_matrix.setter\n    def extrinsic_matrix(self, value: np.ndarray):\n        \"\"\"Set extrinsic matrix and update rotation and translation vectors.\n\n        Args:\n            value: Extrinsic matrix of size 4 x 4.\n        \"\"\"\n        self._extrinsic_matrix = value\n\n        # Update rotation and translation vectors\n        self._rvec = rodrigues_transformation(self._extrinsic_matrix[:3, :3])[0].ravel()\n        self._tvec = self._extrinsic_matrix[:3, 3]\n\n    def get_video(self, session: RecordingSession) -&gt; Video | None:\n        \"\"\"Get video associated with recording session.\n\n        Args:\n            session: Recording session to get video for.\n\n        Returns:\n            Video associated with recording session or None if not found.\n        \"\"\"\n        return session.get_video(camera=self)\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return a readable representation of the camera.\"\"\"\n        matrix_str = (\n            \"identity\" if np.array_equal(self.matrix, np.eye(3)) else \"non-identity\"\n        )\n        dist_str = \"zero\" if np.array_equal(self.dist, np.zeros(5)) else \"non-zero\"\n        size_str = \"None\" if self.size is None else self.size\n        rvec_str = (\n            \"zero\"\n            if np.array_equal(self.rvec, np.zeros(3))\n            else np.array2string(self.rvec, precision=2, suppress_small=True)\n        )\n        tvec_str = (\n            \"zero\"\n            if np.array_equal(self.tvec, np.zeros(3))\n            else np.array2string(self.tvec, precision=2, suppress_small=True)\n        )\n        name_str = self.name if self.name is not None else \"None\"\n        return (\n            \"Camera(\"\n            f\"matrix={matrix_str}, \"\n            f\"dist={dist_str}, \"\n            f\"size={size_str}, \"\n            f\"rvec={rvec_str}, \"\n            f\"tvec={tvec_str}, \"\n            f\"name={name_str}\"\n            \")\"\n        )\n</code></pre>"},{"location":"model/#sleap_io.Camera.extrinsic_matrix","title":"<code>extrinsic_matrix</code>  <code>property</code> <code>writable</code>","text":"<p>Get extrinsic matrix of camera.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>Extrinsic matrix of camera of size 4 x 4.</p>"},{"location":"model/#sleap_io.Camera.rvec","title":"<code>rvec</code>  <code>property</code> <code>writable</code>","text":"<p>Get rotation vector of camera.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>Rotation vector of camera of size 3.</p>"},{"location":"model/#sleap_io.Camera.tvec","title":"<code>tvec</code>  <code>property</code> <code>writable</code>","text":"<p>Get translation vector of camera.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>Translation vector of camera of size 3.</p>"},{"location":"model/#sleap_io.Camera.__attrs_post_init__","title":"<code>__attrs_post_init__()</code>","text":"<p>Initialize extrinsic matrix from rotation and translation vectors.</p> Source code in <code>sleap_io/model/camera.py</code> <pre><code>def __attrs_post_init__(self):\n    \"\"\"Initialize extrinsic matrix from rotation and translation vectors.\"\"\"\n    self._extrinsic_matrix = np.eye(4, dtype=\"float64\")\n    self._extrinsic_matrix[:3, :3] = rodrigues_transformation(self._rvec)[0]\n    self._extrinsic_matrix[:3, 3] = self._tvec\n</code></pre>"},{"location":"model/#sleap_io.Camera.__repr__","title":"<code>__repr__()</code>","text":"<p>Return a readable representation of the camera.</p> Source code in <code>sleap_io/model/camera.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return a readable representation of the camera.\"\"\"\n    matrix_str = (\n        \"identity\" if np.array_equal(self.matrix, np.eye(3)) else \"non-identity\"\n    )\n    dist_str = \"zero\" if np.array_equal(self.dist, np.zeros(5)) else \"non-zero\"\n    size_str = \"None\" if self.size is None else self.size\n    rvec_str = (\n        \"zero\"\n        if np.array_equal(self.rvec, np.zeros(3))\n        else np.array2string(self.rvec, precision=2, suppress_small=True)\n    )\n    tvec_str = (\n        \"zero\"\n        if np.array_equal(self.tvec, np.zeros(3))\n        else np.array2string(self.tvec, precision=2, suppress_small=True)\n    )\n    name_str = self.name if self.name is not None else \"None\"\n    return (\n        \"Camera(\"\n        f\"matrix={matrix_str}, \"\n        f\"dist={dist_str}, \"\n        f\"size={size_str}, \"\n        f\"rvec={rvec_str}, \"\n        f\"tvec={tvec_str}, \"\n        f\"name={name_str}\"\n        \")\"\n    )\n</code></pre>"},{"location":"model/#sleap_io.Camera.get_video","title":"<code>get_video(session)</code>","text":"<p>Get video associated with recording session.</p> <p>Parameters:</p> Name Type Description Default <code>session</code> <code>RecordingSession</code> <p>Recording session to get video for.</p> required <p>Returns:</p> Type Description <code>Video | None</code> <p>Video associated with recording session or None if not found.</p> Source code in <code>sleap_io/model/camera.py</code> <pre><code>def get_video(self, session: RecordingSession) -&gt; Video | None:\n    \"\"\"Get video associated with recording session.\n\n    Args:\n        session: Recording session to get video for.\n\n    Returns:\n        Video associated with recording session or None if not found.\n    \"\"\"\n    return session.get_video(camera=self)\n</code></pre>"},{"location":"model/#sleap_io.CameraGroup","title":"<code>sleap_io.CameraGroup</code>","text":"<p>A group of cameras used to record a multi-view <code>RecordingSession</code>.</p> <p>Attributes:</p> Name Type Description <code>cameras</code> <code>list[Camera]</code> <p>List of <code>Camera</code> objects in the group.</p> <code>metadata</code> <code>dict</code> <p>Dictionary of metadata.</p> <p>Methods:</p> Name Description <code>__repr__</code> <p>Return a readable representation of the camera group.</p> Source code in <code>sleap_io/model/camera.py</code> <pre><code>@define\nclass CameraGroup:\n    \"\"\"A group of cameras used to record a multi-view `RecordingSession`.\n\n    Attributes:\n        cameras: List of `Camera` objects in the group.\n        metadata: Dictionary of metadata.\n    \"\"\"\n\n    cameras: list[Camera] = field(factory=list, validator=instance_of(list))\n    metadata: dict = field(factory=dict, validator=instance_of(dict))\n\n    def __repr__(self):\n        \"\"\"Return a readable representation of the camera group.\"\"\"\n        camera_names = \", \".join([c.name or \"None\" for c in self.cameras])\n        return f\"CameraGroup(cameras={len(self.cameras)}:[{camera_names}])\"\n</code></pre>"},{"location":"model/#sleap_io.CameraGroup.__repr__","title":"<code>__repr__()</code>","text":"<p>Return a readable representation of the camera group.</p> Source code in <code>sleap_io/model/camera.py</code> <pre><code>def __repr__(self):\n    \"\"\"Return a readable representation of the camera group.\"\"\"\n    camera_names = \", \".join([c.name or \"None\" for c in self.cameras])\n    return f\"CameraGroup(cameras={len(self.cameras)}:[{camera_names}])\"\n</code></pre>"},{"location":"model/#sleap_io.FrameGroup","title":"<code>sleap_io.FrameGroup</code>","text":"<p>Defines a group of <code>InstanceGroups</code> across views at the same frame index.</p> <p>Attributes:</p> Name Type Description <code>frame_idx</code> <code>int</code> <p>Frame index for the <code>FrameGroup</code>.</p> <code>instance_groups</code> <code>list[InstanceGroup]</code> <p>List of <code>InstanceGroup</code>s in the <code>FrameGroup</code>.</p> <code>cameras</code> <code>list[Camera]</code> <p>List of <code>Camera</code> objects linked to <code>LabeledFrame</code>s in the <code>FrameGroup</code>.</p> <code>labeled_frames</code> <code>list[LabeledFrame]</code> <p>List of <code>LabeledFrame</code>s in the <code>FrameGroup</code>.</p> <code>metadata</code> <code>dict</code> <p>Metadata for the <code>FrameGroup</code> that is provided but not deserialized.</p> <p>Methods:</p> Name Description <code>__repr__</code> <p>Return a readable representation of the frame group.</p> <code>get_frame</code> <p>Get <code>LabeledFrame</code> associated with <code>camera</code>.</p> Source code in <code>sleap_io/model/camera.py</code> <pre><code>@define(eq=False)  # Set eq to false to make class hashable\nclass FrameGroup:\n    \"\"\"Defines a group of `InstanceGroups` across views at the same frame index.\n\n    Attributes:\n        frame_idx: Frame index for the `FrameGroup`.\n        instance_groups: List of `InstanceGroup`s in the `FrameGroup`.\n        cameras: List of `Camera` objects linked to `LabeledFrame`s in the `FrameGroup`.\n        labeled_frames: List of `LabeledFrame`s in the `FrameGroup`.\n        metadata: Metadata for the `FrameGroup` that is provided but not deserialized.\n    \"\"\"\n\n    frame_idx: int = field(converter=int)\n    _instance_groups: list[InstanceGroup] = field(\n        factory=list, validator=instance_of(list)\n    )\n    _labeled_frame_by_camera: dict[Camera, LabeledFrame] = field(\n        factory=dict, validator=instance_of(dict)\n    )\n    metadata: dict = field(factory=dict, validator=instance_of(dict))\n\n    @property\n    def instance_groups(self) -&gt; list[InstanceGroup]:\n        \"\"\"List of `InstanceGroup`s.\"\"\"\n        return self._instance_groups\n\n    @property\n    def cameras(self) -&gt; list[Camera]:\n        \"\"\"List of `Camera` objects.\"\"\"\n        return list(self._labeled_frame_by_camera.keys())\n\n    @property\n    def labeled_frames(self) -&gt; list[LabeledFrame]:\n        \"\"\"List of `LabeledFrame`s.\"\"\"\n        return list(self._labeled_frame_by_camera.values())\n\n    def get_frame(self, camera: Camera) -&gt; LabeledFrame | None:\n        \"\"\"Get `LabeledFrame` associated with `camera`.\n\n        Args:\n            camera: `Camera` to get `LabeledFrame`.\n\n        Returns:\n            `LabeledFrame` associated with `camera` or None if not found.\n        \"\"\"\n        return self._labeled_frame_by_camera.get(camera, None)\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return a readable representation of the frame group.\"\"\"\n        cameras_str = \", \".join([c.name or \"None\" for c in self.cameras])\n        return (\n            f\"FrameGroup(\"\n            f\"frame_idx={self.frame_idx},\"\n            f\"instance_groups={len(self.instance_groups)},\"\n            f\"cameras={len(self.cameras)}:[{cameras_str}]\"\n            f\")\"\n        )\n</code></pre>"},{"location":"model/#sleap_io.FrameGroup.cameras","title":"<code>cameras</code>  <code>property</code>","text":"<p>List of <code>Camera</code> objects.</p>"},{"location":"model/#sleap_io.FrameGroup.instance_groups","title":"<code>instance_groups</code>  <code>property</code>","text":"<p>List of <code>InstanceGroup</code>s.</p>"},{"location":"model/#sleap_io.FrameGroup.labeled_frames","title":"<code>labeled_frames</code>  <code>property</code>","text":"<p>List of <code>LabeledFrame</code>s.</p>"},{"location":"model/#sleap_io.FrameGroup.__repr__","title":"<code>__repr__()</code>","text":"<p>Return a readable representation of the frame group.</p> Source code in <code>sleap_io/model/camera.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return a readable representation of the frame group.\"\"\"\n    cameras_str = \", \".join([c.name or \"None\" for c in self.cameras])\n    return (\n        f\"FrameGroup(\"\n        f\"frame_idx={self.frame_idx},\"\n        f\"instance_groups={len(self.instance_groups)},\"\n        f\"cameras={len(self.cameras)}:[{cameras_str}]\"\n        f\")\"\n    )\n</code></pre>"},{"location":"model/#sleap_io.FrameGroup.get_frame","title":"<code>get_frame(camera)</code>","text":"<p>Get <code>LabeledFrame</code> associated with <code>camera</code>.</p> <p>Parameters:</p> Name Type Description Default <code>camera</code> <code>Camera</code> <p><code>Camera</code> to get <code>LabeledFrame</code>.</p> required <p>Returns:</p> Type Description <code>LabeledFrame | None</code> <p><code>LabeledFrame</code> associated with <code>camera</code> or None if not found.</p> Source code in <code>sleap_io/model/camera.py</code> <pre><code>def get_frame(self, camera: Camera) -&gt; LabeledFrame | None:\n    \"\"\"Get `LabeledFrame` associated with `camera`.\n\n    Args:\n        camera: `Camera` to get `LabeledFrame`.\n\n    Returns:\n        `LabeledFrame` associated with `camera` or None if not found.\n    \"\"\"\n    return self._labeled_frame_by_camera.get(camera, None)\n</code></pre>"},{"location":"model/#sleap_io.InstanceGroup","title":"<code>sleap_io.InstanceGroup</code>","text":"<p>Defines a group of instances across the same frame index.</p> <p>Attributes:</p> Name Type Description <code>instances_by_camera</code> <p>Dictionary of <code>Instance</code> objects by <code>Camera</code>.</p> <code>instances</code> <code>list[Instance]</code> <p>List of <code>Instance</code> objects in the group.</p> <code>cameras</code> <code>list[Camera]</code> <p>List of <code>Camera</code> objects that have an <code>Instance</code> associated.</p> <code>score</code> <code>float | None</code> <p>Optional score for the <code>InstanceGroup</code>. Setting the score will also update the score for all <code>instances</code> already in the <code>InstanceGroup</code>. The score for <code>instances</code> will not be updated upon initialization.</p> <code>points</code> <code>ndarray | None</code> <p>Optional 3D points for the <code>InstanceGroup</code>.</p> <code>metadata</code> <code>dict</code> <p>Dictionary of metadata.</p> <p>Methods:</p> Name Description <code>__repr__</code> <p>Return a readable representation of the instance group.</p> <code>get_instance</code> <p>Get <code>Instance</code> associated with <code>camera</code>.</p> Source code in <code>sleap_io/model/camera.py</code> <pre><code>@define(eq=False)  # Set eq to false to make class hashable\nclass InstanceGroup:\n    \"\"\"Defines a group of instances across the same frame index.\n\n    Attributes:\n        instances_by_camera: Dictionary of `Instance` objects by `Camera`.\n        instances: List of `Instance` objects in the group.\n        cameras: List of `Camera` objects that have an `Instance` associated.\n        score: Optional score for the `InstanceGroup`. Setting the score will also\n            update the score for all `instances` already in the `InstanceGroup`. The\n            score for `instances` will not be updated upon initialization.\n        points: Optional 3D points for the `InstanceGroup`.\n        metadata: Dictionary of metadata.\n    \"\"\"\n\n    _instance_by_camera: dict[Camera, Instance] = field(\n        factory=dict, validator=instance_of(dict)\n    )\n    _score: float | None = field(\n        default=None, converter=attrs.converters.optional(float)\n    )\n    _points: np.ndarray | None = field(\n        default=None,\n        converter=attrs.converters.optional(lambda x: np.array(x, dtype=\"float64\")),\n    )\n    metadata: dict = field(factory=dict, validator=instance_of(dict))\n\n    @property\n    def instance_by_camera(self) -&gt; dict[Camera, Instance]:\n        \"\"\"Get dictionary of `Instance` objects by `Camera`.\"\"\"\n        return self._instance_by_camera\n\n    @property\n    def instances(self) -&gt; list[Instance]:\n        \"\"\"List of `Instance` objects.\"\"\"\n        return list(self._instance_by_camera.values())\n\n    @property\n    def cameras(self) -&gt; list[Camera]:\n        \"\"\"List of `Camera` objects.\"\"\"\n        return list(self._instance_by_camera.keys())\n\n    @property\n    def score(self) -&gt; float | None:\n        \"\"\"Get score for `InstanceGroup`.\"\"\"\n        return self._score\n\n    @property\n    def points(self) -&gt; np.ndarray | None:\n        \"\"\"Get 3D points for `InstanceGroup`.\"\"\"\n        return self._points\n\n    def get_instance(self, camera: Camera) -&gt; Instance | None:\n        \"\"\"Get `Instance` associated with `camera`.\n\n        Args:\n            camera: `Camera` to get `Instance`.\n\n        Returns:\n            `Instance` associated with `camera` or None if not found.\n        \"\"\"\n        return self._instance_by_camera.get(camera, None)\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return a readable representation of the instance group.\"\"\"\n        cameras_str = \", \".join([c.name or \"None\" for c in self.cameras])\n        return f\"InstanceGroup(cameras={len(self.cameras)}:[{cameras_str}])\"\n</code></pre>"},{"location":"model/#sleap_io.InstanceGroup.cameras","title":"<code>cameras</code>  <code>property</code>","text":"<p>List of <code>Camera</code> objects.</p>"},{"location":"model/#sleap_io.InstanceGroup.instance_by_camera","title":"<code>instance_by_camera</code>  <code>property</code>","text":"<p>Get dictionary of <code>Instance</code> objects by <code>Camera</code>.</p>"},{"location":"model/#sleap_io.InstanceGroup.instances","title":"<code>instances</code>  <code>property</code>","text":"<p>List of <code>Instance</code> objects.</p>"},{"location":"model/#sleap_io.InstanceGroup.points","title":"<code>points</code>  <code>property</code>","text":"<p>Get 3D points for <code>InstanceGroup</code>.</p>"},{"location":"model/#sleap_io.InstanceGroup.score","title":"<code>score</code>  <code>property</code>","text":"<p>Get score for <code>InstanceGroup</code>.</p>"},{"location":"model/#sleap_io.InstanceGroup.__repr__","title":"<code>__repr__()</code>","text":"<p>Return a readable representation of the instance group.</p> Source code in <code>sleap_io/model/camera.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return a readable representation of the instance group.\"\"\"\n    cameras_str = \", \".join([c.name or \"None\" for c in self.cameras])\n    return f\"InstanceGroup(cameras={len(self.cameras)}:[{cameras_str}])\"\n</code></pre>"},{"location":"model/#sleap_io.InstanceGroup.get_instance","title":"<code>get_instance(camera)</code>","text":"<p>Get <code>Instance</code> associated with <code>camera</code>.</p> <p>Parameters:</p> Name Type Description Default <code>camera</code> <code>Camera</code> <p><code>Camera</code> to get <code>Instance</code>.</p> required <p>Returns:</p> Type Description <code>Instance | None</code> <p><code>Instance</code> associated with <code>camera</code> or None if not found.</p> Source code in <code>sleap_io/model/camera.py</code> <pre><code>def get_instance(self, camera: Camera) -&gt; Instance | None:\n    \"\"\"Get `Instance` associated with `camera`.\n\n    Args:\n        camera: `Camera` to get `Instance`.\n\n    Returns:\n        `Instance` associated with `camera` or None if not found.\n    \"\"\"\n    return self._instance_by_camera.get(camera, None)\n</code></pre>"},{"location":"model/#sleap_io.RecordingSession","title":"<code>sleap_io.RecordingSession</code>","text":"<p>A recording session with multiple cameras.</p> <p>Attributes:</p> Name Type Description <code>camera_group</code> <code>CameraGroup</code> <p><code>CameraGroup</code> object containing cameras in the session.</p> <code>frame_groups</code> <code>dict[int, FrameGroup]</code> <p>Dictionary mapping frame index to <code>FrameGroup</code>.</p> <code>videos</code> <code>list[Video]</code> <p>List of <code>Video</code> objects linked to <code>Camera</code>s in the session.</p> <code>cameras</code> <code>list[Camera]</code> <p>List of <code>Camera</code> objects linked to <code>Video</code>s in the session.</p> <code>metadata</code> <code>dict</code> <p>Dictionary of metadata.</p> <p>Methods:</p> Name Description <code>__repr__</code> <p>Return a readable representation of the session.</p> <code>add_video</code> <p>Add <code>video</code> to <code>RecordingSession</code> and mapping to <code>camera</code>.</p> <code>get_camera</code> <p>Get <code>Camera</code> associated with <code>video</code>.</p> <code>get_video</code> <p>Get <code>Video</code> associated with <code>camera</code>.</p> <code>remove_video</code> <p>Remove <code>video</code> from <code>RecordingSession</code> and mapping to <code>Camera</code>.</p> Source code in <code>sleap_io/model/camera.py</code> <pre><code>@define(eq=False)  # Set eq to false to make class hashable\nclass RecordingSession:\n    \"\"\"A recording session with multiple cameras.\n\n    Attributes:\n        camera_group: `CameraGroup` object containing cameras in the session.\n        frame_groups: Dictionary mapping frame index to `FrameGroup`.\n        videos: List of `Video` objects linked to `Camera`s in the session.\n        cameras: List of `Camera` objects linked to `Video`s in the session.\n        metadata: Dictionary of metadata.\n    \"\"\"\n\n    camera_group: CameraGroup = field(\n        factory=CameraGroup, validator=instance_of(CameraGroup)\n    )\n    _video_by_camera: dict[Camera, Video] = field(\n        factory=dict, validator=instance_of(dict)\n    )\n    _camera_by_video: dict[Video, Camera] = field(\n        factory=dict, validator=instance_of(dict)\n    )\n    _frame_group_by_frame_idx: dict[int, FrameGroup] = field(\n        factory=dict, validator=instance_of(dict)\n    )\n    metadata: dict = field(factory=dict, validator=instance_of(dict))\n\n    @property\n    def frame_groups(self) -&gt; dict[int, FrameGroup]:\n        \"\"\"Get dictionary of `FrameGroup` objects by frame index.\n\n        Returns:\n            Dictionary of `FrameGroup` objects by frame index.\n        \"\"\"\n        return self._frame_group_by_frame_idx\n\n    @property\n    def videos(self) -&gt; list[Video]:\n        \"\"\"Get list of `Video` objects in the `RecordingSession`.\n\n        Returns:\n            List of `Video` objects in `RecordingSession`.\n        \"\"\"\n        return list(self._video_by_camera.values())\n\n    @property\n    def cameras(self) -&gt; list[Camera]:\n        \"\"\"Get list of `Camera` objects linked to `Video`s in the `RecordingSession`.\n\n        Returns:\n            List of `Camera` objects in `RecordingSession`.\n        \"\"\"\n        return list(self._video_by_camera.keys())\n\n    def get_camera(self, video: Video) -&gt; Camera | None:\n        \"\"\"Get `Camera` associated with `video`.\n\n        Args:\n            video: `Video` to get `Camera`\n\n        Returns:\n            `Camera` associated with `video` or None if not found\n        \"\"\"\n        return self._camera_by_video.get(video, None)\n\n    def get_video(self, camera: Camera) -&gt; Video | None:\n        \"\"\"Get `Video` associated with `camera`.\n\n        Args:\n            camera: `Camera` to get `Video`\n\n        Returns:\n            `Video` associated with `camera` or None if not found\n        \"\"\"\n        return self._video_by_camera.get(camera, None)\n\n    def add_video(self, video: Video, camera: Camera):\n        \"\"\"Add `video` to `RecordingSession` and mapping to `camera`.\n\n        Args:\n            video: `Video` object to add to `RecordingSession`.\n            camera: `Camera` object to associate with `video`.\n\n        Raises:\n            ValueError: If `camera` is not in associated `CameraGroup`.\n            ValueError: If `video` is not a `Video` object.\n        \"\"\"\n        # Raise ValueError if camera is not in associated camera group\n        self.camera_group.cameras.index(camera)\n\n        # Raise ValueError if `Video` is not a `Video` object\n        if not isinstance(video, Video):\n            raise ValueError(\n                f\"Expected `Video` object, but received {type(video)} object.\"\n            )\n\n        # Add camera to video mapping\n        self._video_by_camera[camera] = video\n\n        # Add video to camera mapping\n        self._camera_by_video[video] = camera\n\n    def remove_video(self, video: Video):\n        \"\"\"Remove `video` from `RecordingSession` and mapping to `Camera`.\n\n        Args:\n            video: `Video` object to remove from `RecordingSession`.\n\n        Raises:\n            ValueError: If `video` is not in associated `RecordingSession`.\n        \"\"\"\n        # Remove video from camera mapping\n        camera = self._camera_by_video.pop(video)\n\n        # Remove camera from video mapping\n        self._video_by_camera.pop(camera)\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return a readable representation of the session.\"\"\"\n        return (\n            \"RecordingSession(\"\n            f\"camera_group={len(self.camera_group.cameras)}cameras, \"\n            f\"videos={len(self.videos)}, \"\n            f\"frame_groups={len(self.frame_groups)}\"\n            \")\"\n        )\n</code></pre>"},{"location":"model/#sleap_io.RecordingSession.cameras","title":"<code>cameras</code>  <code>property</code>","text":"<p>Get list of <code>Camera</code> objects linked to <code>Video</code>s in the <code>RecordingSession</code>.</p> <p>Returns:</p> Type Description <code>list[Camera]</code> <p>List of <code>Camera</code> objects in <code>RecordingSession</code>.</p>"},{"location":"model/#sleap_io.RecordingSession.frame_groups","title":"<code>frame_groups</code>  <code>property</code>","text":"<p>Get dictionary of <code>FrameGroup</code> objects by frame index.</p> <p>Returns:</p> Type Description <code>dict[int, FrameGroup]</code> <p>Dictionary of <code>FrameGroup</code> objects by frame index.</p>"},{"location":"model/#sleap_io.RecordingSession.videos","title":"<code>videos</code>  <code>property</code>","text":"<p>Get list of <code>Video</code> objects in the <code>RecordingSession</code>.</p> <p>Returns:</p> Type Description <code>list[Video]</code> <p>List of <code>Video</code> objects in <code>RecordingSession</code>.</p>"},{"location":"model/#sleap_io.RecordingSession.__repr__","title":"<code>__repr__()</code>","text":"<p>Return a readable representation of the session.</p> Source code in <code>sleap_io/model/camera.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return a readable representation of the session.\"\"\"\n    return (\n        \"RecordingSession(\"\n        f\"camera_group={len(self.camera_group.cameras)}cameras, \"\n        f\"videos={len(self.videos)}, \"\n        f\"frame_groups={len(self.frame_groups)}\"\n        \")\"\n    )\n</code></pre>"},{"location":"model/#sleap_io.RecordingSession.add_video","title":"<code>add_video(video, camera)</code>","text":"<p>Add <code>video</code> to <code>RecordingSession</code> and mapping to <code>camera</code>.</p> <p>Parameters:</p> Name Type Description Default <code>video</code> <code>Video</code> <p><code>Video</code> object to add to <code>RecordingSession</code>.</p> required <code>camera</code> <code>Camera</code> <p><code>Camera</code> object to associate with <code>video</code>.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If <code>camera</code> is not in associated <code>CameraGroup</code>.</p> <code>ValueError</code> <p>If <code>video</code> is not a <code>Video</code> object.</p> Source code in <code>sleap_io/model/camera.py</code> <pre><code>def add_video(self, video: Video, camera: Camera):\n    \"\"\"Add `video` to `RecordingSession` and mapping to `camera`.\n\n    Args:\n        video: `Video` object to add to `RecordingSession`.\n        camera: `Camera` object to associate with `video`.\n\n    Raises:\n        ValueError: If `camera` is not in associated `CameraGroup`.\n        ValueError: If `video` is not a `Video` object.\n    \"\"\"\n    # Raise ValueError if camera is not in associated camera group\n    self.camera_group.cameras.index(camera)\n\n    # Raise ValueError if `Video` is not a `Video` object\n    if not isinstance(video, Video):\n        raise ValueError(\n            f\"Expected `Video` object, but received {type(video)} object.\"\n        )\n\n    # Add camera to video mapping\n    self._video_by_camera[camera] = video\n\n    # Add video to camera mapping\n    self._camera_by_video[video] = camera\n</code></pre>"},{"location":"model/#sleap_io.RecordingSession.get_camera","title":"<code>get_camera(video)</code>","text":"<p>Get <code>Camera</code> associated with <code>video</code>.</p> <p>Parameters:</p> Name Type Description Default <code>video</code> <code>Video</code> <p><code>Video</code> to get <code>Camera</code></p> required <p>Returns:</p> Type Description <code>Camera | None</code> <p><code>Camera</code> associated with <code>video</code> or None if not found</p> Source code in <code>sleap_io/model/camera.py</code> <pre><code>def get_camera(self, video: Video) -&gt; Camera | None:\n    \"\"\"Get `Camera` associated with `video`.\n\n    Args:\n        video: `Video` to get `Camera`\n\n    Returns:\n        `Camera` associated with `video` or None if not found\n    \"\"\"\n    return self._camera_by_video.get(video, None)\n</code></pre>"},{"location":"model/#sleap_io.RecordingSession.get_video","title":"<code>get_video(camera)</code>","text":"<p>Get <code>Video</code> associated with <code>camera</code>.</p> <p>Parameters:</p> Name Type Description Default <code>camera</code> <code>Camera</code> <p><code>Camera</code> to get <code>Video</code></p> required <p>Returns:</p> Type Description <code>Video | None</code> <p><code>Video</code> associated with <code>camera</code> or None if not found</p> Source code in <code>sleap_io/model/camera.py</code> <pre><code>def get_video(self, camera: Camera) -&gt; Video | None:\n    \"\"\"Get `Video` associated with `camera`.\n\n    Args:\n        camera: `Camera` to get `Video`\n\n    Returns:\n        `Video` associated with `camera` or None if not found\n    \"\"\"\n    return self._video_by_camera.get(camera, None)\n</code></pre>"},{"location":"model/#sleap_io.RecordingSession.remove_video","title":"<code>remove_video(video)</code>","text":"<p>Remove <code>video</code> from <code>RecordingSession</code> and mapping to <code>Camera</code>.</p> <p>Parameters:</p> Name Type Description Default <code>video</code> <code>Video</code> <p><code>Video</code> object to remove from <code>RecordingSession</code>.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If <code>video</code> is not in associated <code>RecordingSession</code>.</p> Source code in <code>sleap_io/model/camera.py</code> <pre><code>def remove_video(self, video: Video):\n    \"\"\"Remove `video` from `RecordingSession` and mapping to `Camera`.\n\n    Args:\n        video: `Video` object to remove from `RecordingSession`.\n\n    Raises:\n        ValueError: If `video` is not in associated `RecordingSession`.\n    \"\"\"\n    # Remove video from camera mapping\n    camera = self._camera_by_video.pop(video)\n\n    # Remove camera from video mapping\n    self._video_by_camera.pop(camera)\n</code></pre>"},{"location":"model/#sleap_io.LabelsSet","title":"<code>sleap_io.LabelsSet</code>","text":"<p>Container for multiple Labels objects with dictionary and tuple-like interface.</p> <p>This class provides a way to manage collections of Labels objects, such as train/val/test splits. It supports both dictionary-style access by name and tuple-style unpacking for backward compatibility.</p> <p>Attributes:</p> Name Type Description <code>labels</code> <code>Dict[str, Labels]</code> <p>Dictionary mapping names to Labels objects.</p> <p>Examples:</p> <p>Create from existing Labels objects:</p> <pre><code>&gt;&gt;&gt; labels_set = LabelsSet({\"train\": train_labels, \"val\": val_labels})\n</code></pre> <p>Access like a dictionary:</p> <pre><code>&gt;&gt;&gt; train = labels_set[\"train\"]\n&gt;&gt;&gt; for name, labels in labels_set.items():\n...     print(f\"{name}: {len(labels)} frames\")\n</code></pre> <p>Unpack like a tuple:</p> <pre><code>&gt;&gt;&gt; train, val = labels_set  # Order preserved from insertion\n</code></pre> <p>Add new Labels:</p> <pre><code>&gt;&gt;&gt; labels_set[\"test\"] = test_labels\n</code></pre> <p>Methods:</p> Name Description <code>__contains__</code> <p>Check if a named Labels object exists.</p> <code>__delitem__</code> <p>Remove a Labels object by name.</p> <code>__getitem__</code> <p>Get Labels by name (string) or index (int) for tuple-like access.</p> <code>__iter__</code> <p>Iterate over Labels objects (not keys) for tuple-like unpacking.</p> <code>__len__</code> <p>Return the number of Labels objects.</p> <code>__repr__</code> <p>Return a string representation of the LabelsSet.</p> <code>__setitem__</code> <p>Set a Labels object with a given name.</p> <code>from_labels_lists</code> <p>Create a LabelsSet from a list of Labels objects.</p> <code>get</code> <p>Get a Labels object by name with optional default.</p> <code>items</code> <p>Return a view of (name, Labels) pairs.</p> <code>keys</code> <p>Return a view of the Labels names.</p> <code>save</code> <p>Save all Labels objects to a directory.</p> <code>values</code> <p>Return a view of the Labels objects.</p> Source code in <code>sleap_io/model/labels_set.py</code> <pre><code>@attrs.define\nclass LabelsSet:\n    \"\"\"Container for multiple Labels objects with dictionary and tuple-like interface.\n\n    This class provides a way to manage collections of Labels objects, such as\n    train/val/test splits. It supports both dictionary-style access by name and\n    tuple-style unpacking for backward compatibility.\n\n    Attributes:\n        labels: Dictionary mapping names to Labels objects.\n\n    Examples:\n        Create from existing Labels objects:\n        &gt;&gt;&gt; labels_set = LabelsSet({\"train\": train_labels, \"val\": val_labels})\n\n        Access like a dictionary:\n        &gt;&gt;&gt; train = labels_set[\"train\"]\n        &gt;&gt;&gt; for name, labels in labels_set.items():\n        ...     print(f\"{name}: {len(labels)} frames\")\n\n        Unpack like a tuple:\n        &gt;&gt;&gt; train, val = labels_set  # Order preserved from insertion\n\n        Add new Labels:\n        &gt;&gt;&gt; labels_set[\"test\"] = test_labels\n    \"\"\"\n\n    labels: Dict[str, Labels] = attrs.field(factory=dict)\n\n    def __getitem__(self, key: Union[str, int]) -&gt; Labels:\n        \"\"\"Get Labels by name (string) or index (int) for tuple-like access.\n\n        Args:\n            key: Either a string name or integer index.\n\n        Returns:\n            The Labels object associated with the key.\n\n        Raises:\n            KeyError: If string key not found.\n            IndexError: If integer index out of range.\n        \"\"\"\n        if isinstance(key, int):\n            try:\n                return list(self.labels.values())[key]\n            except IndexError:\n                raise IndexError(\n                    f\"Index {key} out of range for LabelsSet with {len(self)} items\"\n                )\n        return self.labels[key]\n\n    def __setitem__(self, key: str, value: Labels) -&gt; None:\n        \"\"\"Set a Labels object with a given name.\n\n        Args:\n            key: Name for the Labels object.\n            value: Labels object to store.\n\n        Raises:\n            TypeError: If key is not a string or value is not a Labels object.\n        \"\"\"\n        if not isinstance(key, str):\n            raise TypeError(f\"Key must be a string, not {type(key).__name__}\")\n        if not isinstance(value, Labels):\n            raise TypeError(\n                f\"Value must be a Labels object, not {type(value).__name__}\"\n            )\n        self.labels[key] = value\n\n    def __delitem__(self, key: str) -&gt; None:\n        \"\"\"Remove a Labels object by name.\n\n        Args:\n            key: Name of the Labels object to remove.\n\n        Raises:\n            KeyError: If key not found.\n        \"\"\"\n        del self.labels[key]\n\n    def __iter__(self) -&gt; Iterator[Labels]:\n        \"\"\"Iterate over Labels objects (not keys) for tuple-like unpacking.\n\n        This allows LabelsSet to be unpacked like a tuple:\n        &gt;&gt;&gt; train, val = labels_set\n\n        Returns:\n            Iterator over Labels objects in insertion order.\n        \"\"\"\n        return iter(self.labels.values())\n\n    def __len__(self) -&gt; int:\n        \"\"\"Return the number of Labels objects.\"\"\"\n        return len(self.labels)\n\n    def __contains__(self, key: str) -&gt; bool:\n        \"\"\"Check if a named Labels object exists.\n\n        Args:\n            key: Name to check.\n\n        Returns:\n            True if the name exists in the set.\n        \"\"\"\n        return key in self.labels\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return a string representation of the LabelsSet.\"\"\"\n        items = []\n        for name, labels in self.labels.items():\n            items.append(f\"{name}: {len(labels)} labeled frames\")\n        items_str = \", \".join(items)\n        return f\"LabelsSet({items_str})\"\n\n    def keys(self) -&gt; KeysView[str]:\n        \"\"\"Return a view of the Labels names.\"\"\"\n        return self.labels.keys()\n\n    def values(self) -&gt; ValuesView[Labels]:\n        \"\"\"Return a view of the Labels objects.\"\"\"\n        return self.labels.values()\n\n    def items(self) -&gt; ItemsView[str, Labels]:\n        \"\"\"Return a view of (name, Labels) pairs.\"\"\"\n        return self.labels.items()\n\n    def get(self, key: str, default: Labels | None = None) -&gt; Labels | None:\n        \"\"\"Get a Labels object by name with optional default.\n\n        Args:\n            key: Name of the Labels to retrieve.\n            default: Default value if key not found.\n\n        Returns:\n            The Labels object or default if not found.\n        \"\"\"\n        return self.labels.get(key, default)\n\n    def save(\n        self,\n        save_dir: Union[str, Path],\n        embed: Union[bool, str] = True,\n        format: str = \"slp\",\n        **kwargs,\n    ) -&gt; None:\n        \"\"\"Save all Labels objects to a directory.\n\n        Args:\n            save_dir: Directory to save the files to. Will be created if it\n                doesn't exist.\n            embed: For SLP format: Whether to embed images in the saved files.\n                Can be True, False, \"user\", \"predictions\", or \"all\".\n                See Labels.save() for details.\n            format: Output format. Currently supports \"slp\" (default) and \"ultralytics\".\n            **kwargs: Additional format-specific arguments. For ultralytics format,\n                these might include skeleton, image_size, etc.\n\n        Examples:\n            Save as SLP files with embedded images:\n            &gt;&gt;&gt; labels_set.save(\"path/to/splits/\", embed=True)\n\n            Save as SLP files without embedding:\n            &gt;&gt;&gt; labels_set.save(\"path/to/splits/\", embed=False)\n\n            Save as Ultralytics dataset:\n            &gt;&gt;&gt; labels_set.save(\"path/to/dataset/\", format=\"ultralytics\")\n        \"\"\"\n        save_dir = Path(save_dir)\n        save_dir.mkdir(parents=True, exist_ok=True)\n\n        if format == \"slp\":\n            for name, labels in self.items():\n                if embed:\n                    filename = f\"{name}.pkg.slp\"\n                else:\n                    filename = f\"{name}.slp\"\n                labels.save(save_dir / filename, embed=embed)\n\n        elif format == \"ultralytics\":\n            # Import here to avoid circular imports\n            from sleap_io.io import ultralytics\n\n            # For ultralytics, we need to save each split in the proper structure\n            for name, labels in self.items():\n                # Map common split names\n                split_name = name\n                if name in [\"training\", \"train\"]:\n                    split_name = \"train\"\n                elif name in [\"validation\", \"val\", \"valid\"]:\n                    split_name = \"val\"\n                elif name in [\"testing\", \"test\"]:\n                    split_name = \"test\"\n\n                # Write this split\n                ultralytics.write_labels(\n                    labels, str(save_dir), split=split_name, **kwargs\n                )\n\n        else:\n            raise ValueError(\n                f\"Unknown format: {format}. Supported formats: 'slp', 'ultralytics'\"\n            )\n\n    @classmethod\n    def from_labels_lists(\n        cls, labels_list: list[Labels], names: list[str] | None = None\n    ) -&gt; LabelsSet:\n        \"\"\"Create a LabelsSet from a list of Labels objects.\n\n        Args:\n            labels_list: List of Labels objects.\n            names: Optional list of names for the Labels. If not provided,\n                will use generic names like \"split1\", \"split2\", etc.\n\n        Returns:\n            A new LabelsSet instance.\n\n        Raises:\n            ValueError: If names provided but length doesn't match labels_list.\n        \"\"\"\n        if names is None:\n            names = [f\"split{i + 1}\" for i in range(len(labels_list))]\n        elif len(names) != len(labels_list):\n            raise ValueError(\n                f\"Number of names ({len(names)}) must match number of Labels \"\n                f\"({len(labels_list)})\"\n            )\n\n        return cls(labels=dict(zip(names, labels_list)))\n</code></pre>"},{"location":"model/#sleap_io.LabelsSet.__contains__","title":"<code>__contains__(key)</code>","text":"<p>Check if a named Labels object exists.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>Name to check.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the name exists in the set.</p> Source code in <code>sleap_io/model/labels_set.py</code> <pre><code>def __contains__(self, key: str) -&gt; bool:\n    \"\"\"Check if a named Labels object exists.\n\n    Args:\n        key: Name to check.\n\n    Returns:\n        True if the name exists in the set.\n    \"\"\"\n    return key in self.labels\n</code></pre>"},{"location":"model/#sleap_io.LabelsSet.__delitem__","title":"<code>__delitem__(key)</code>","text":"<p>Remove a Labels object by name.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>Name of the Labels object to remove.</p> required <p>Raises:</p> Type Description <code>KeyError</code> <p>If key not found.</p> Source code in <code>sleap_io/model/labels_set.py</code> <pre><code>def __delitem__(self, key: str) -&gt; None:\n    \"\"\"Remove a Labels object by name.\n\n    Args:\n        key: Name of the Labels object to remove.\n\n    Raises:\n        KeyError: If key not found.\n    \"\"\"\n    del self.labels[key]\n</code></pre>"},{"location":"model/#sleap_io.LabelsSet.__getitem__","title":"<code>__getitem__(key)</code>","text":"<p>Get Labels by name (string) or index (int) for tuple-like access.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>Union[str, int]</code> <p>Either a string name or integer index.</p> required <p>Returns:</p> Type Description <code>Labels</code> <p>The Labels object associated with the key.</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>If string key not found.</p> <code>IndexError</code> <p>If integer index out of range.</p> Source code in <code>sleap_io/model/labels_set.py</code> <pre><code>def __getitem__(self, key: Union[str, int]) -&gt; Labels:\n    \"\"\"Get Labels by name (string) or index (int) for tuple-like access.\n\n    Args:\n        key: Either a string name or integer index.\n\n    Returns:\n        The Labels object associated with the key.\n\n    Raises:\n        KeyError: If string key not found.\n        IndexError: If integer index out of range.\n    \"\"\"\n    if isinstance(key, int):\n        try:\n            return list(self.labels.values())[key]\n        except IndexError:\n            raise IndexError(\n                f\"Index {key} out of range for LabelsSet with {len(self)} items\"\n            )\n    return self.labels[key]\n</code></pre>"},{"location":"model/#sleap_io.LabelsSet.__iter__","title":"<code>__iter__()</code>","text":"<p>Iterate over Labels objects (not keys) for tuple-like unpacking.</p> <p>This allows LabelsSet to be unpacked like a tuple:</p> <p>train, val = labels_set</p> <p>Returns:</p> Type Description <code>Iterator[Labels]</code> <p>Iterator over Labels objects in insertion order.</p> Source code in <code>sleap_io/model/labels_set.py</code> <pre><code>def __iter__(self) -&gt; Iterator[Labels]:\n    \"\"\"Iterate over Labels objects (not keys) for tuple-like unpacking.\n\n    This allows LabelsSet to be unpacked like a tuple:\n    &gt;&gt;&gt; train, val = labels_set\n\n    Returns:\n        Iterator over Labels objects in insertion order.\n    \"\"\"\n    return iter(self.labels.values())\n</code></pre>"},{"location":"model/#sleap_io.LabelsSet.__len__","title":"<code>__len__()</code>","text":"<p>Return the number of Labels objects.</p> Source code in <code>sleap_io/model/labels_set.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"Return the number of Labels objects.\"\"\"\n    return len(self.labels)\n</code></pre>"},{"location":"model/#sleap_io.LabelsSet.__repr__","title":"<code>__repr__()</code>","text":"<p>Return a string representation of the LabelsSet.</p> Source code in <code>sleap_io/model/labels_set.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return a string representation of the LabelsSet.\"\"\"\n    items = []\n    for name, labels in self.labels.items():\n        items.append(f\"{name}: {len(labels)} labeled frames\")\n    items_str = \", \".join(items)\n    return f\"LabelsSet({items_str})\"\n</code></pre>"},{"location":"model/#sleap_io.LabelsSet.__setitem__","title":"<code>__setitem__(key, value)</code>","text":"<p>Set a Labels object with a given name.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>Name for the Labels object.</p> required <code>value</code> <code>Labels</code> <p>Labels object to store.</p> required <p>Raises:</p> Type Description <code>TypeError</code> <p>If key is not a string or value is not a Labels object.</p> Source code in <code>sleap_io/model/labels_set.py</code> <pre><code>def __setitem__(self, key: str, value: Labels) -&gt; None:\n    \"\"\"Set a Labels object with a given name.\n\n    Args:\n        key: Name for the Labels object.\n        value: Labels object to store.\n\n    Raises:\n        TypeError: If key is not a string or value is not a Labels object.\n    \"\"\"\n    if not isinstance(key, str):\n        raise TypeError(f\"Key must be a string, not {type(key).__name__}\")\n    if not isinstance(value, Labels):\n        raise TypeError(\n            f\"Value must be a Labels object, not {type(value).__name__}\"\n        )\n    self.labels[key] = value\n</code></pre>"},{"location":"model/#sleap_io.LabelsSet.from_labels_lists","title":"<code>from_labels_lists(labels_list, names=None)</code>  <code>classmethod</code>","text":"<p>Create a LabelsSet from a list of Labels objects.</p> <p>Parameters:</p> Name Type Description Default <code>labels_list</code> <code>list[Labels]</code> <p>List of Labels objects.</p> required <code>names</code> <code>list[str] | None</code> <p>Optional list of names for the Labels. If not provided, will use generic names like \"split1\", \"split2\", etc.</p> <code>None</code> <p>Returns:</p> Type Description <code>LabelsSet</code> <p>A new LabelsSet instance.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If names provided but length doesn't match labels_list.</p> Source code in <code>sleap_io/model/labels_set.py</code> <pre><code>@classmethod\ndef from_labels_lists(\n    cls, labels_list: list[Labels], names: list[str] | None = None\n) -&gt; LabelsSet:\n    \"\"\"Create a LabelsSet from a list of Labels objects.\n\n    Args:\n        labels_list: List of Labels objects.\n        names: Optional list of names for the Labels. If not provided,\n            will use generic names like \"split1\", \"split2\", etc.\n\n    Returns:\n        A new LabelsSet instance.\n\n    Raises:\n        ValueError: If names provided but length doesn't match labels_list.\n    \"\"\"\n    if names is None:\n        names = [f\"split{i + 1}\" for i in range(len(labels_list))]\n    elif len(names) != len(labels_list):\n        raise ValueError(\n            f\"Number of names ({len(names)}) must match number of Labels \"\n            f\"({len(labels_list)})\"\n        )\n\n    return cls(labels=dict(zip(names, labels_list)))\n</code></pre>"},{"location":"model/#sleap_io.LabelsSet.get","title":"<code>get(key, default=None)</code>","text":"<p>Get a Labels object by name with optional default.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>Name of the Labels to retrieve.</p> required <code>default</code> <code>Labels | None</code> <p>Default value if key not found.</p> <code>None</code> <p>Returns:</p> Type Description <code>Labels | None</code> <p>The Labels object or default if not found.</p> Source code in <code>sleap_io/model/labels_set.py</code> <pre><code>def get(self, key: str, default: Labels | None = None) -&gt; Labels | None:\n    \"\"\"Get a Labels object by name with optional default.\n\n    Args:\n        key: Name of the Labels to retrieve.\n        default: Default value if key not found.\n\n    Returns:\n        The Labels object or default if not found.\n    \"\"\"\n    return self.labels.get(key, default)\n</code></pre>"},{"location":"model/#sleap_io.LabelsSet.items","title":"<code>items()</code>","text":"<p>Return a view of (name, Labels) pairs.</p> Source code in <code>sleap_io/model/labels_set.py</code> <pre><code>def items(self) -&gt; ItemsView[str, Labels]:\n    \"\"\"Return a view of (name, Labels) pairs.\"\"\"\n    return self.labels.items()\n</code></pre>"},{"location":"model/#sleap_io.LabelsSet.keys","title":"<code>keys()</code>","text":"<p>Return a view of the Labels names.</p> Source code in <code>sleap_io/model/labels_set.py</code> <pre><code>def keys(self) -&gt; KeysView[str]:\n    \"\"\"Return a view of the Labels names.\"\"\"\n    return self.labels.keys()\n</code></pre>"},{"location":"model/#sleap_io.LabelsSet.save","title":"<code>save(save_dir, embed=True, format='slp', **kwargs)</code>","text":"<p>Save all Labels objects to a directory.</p> <p>Parameters:</p> Name Type Description Default <code>save_dir</code> <code>Union[str, Path]</code> <p>Directory to save the files to. Will be created if it doesn't exist.</p> required <code>embed</code> <code>Union[bool, str]</code> <p>For SLP format: Whether to embed images in the saved files. Can be True, False, \"user\", \"predictions\", or \"all\". See Labels.save() for details.</p> <code>True</code> <code>format</code> <code>str</code> <p>Output format. Currently supports \"slp\" (default) and \"ultralytics\".</p> <code>'slp'</code> <code>**kwargs</code> <p>Additional format-specific arguments. For ultralytics format, these might include skeleton, image_size, etc.</p> <code>{}</code> <p>Examples:</p> <p>Save as SLP files with embedded images:</p> <pre><code>&gt;&gt;&gt; labels_set.save(\"path/to/splits/\", embed=True)\n</code></pre> <p>Save as SLP files without embedding:</p> <pre><code>&gt;&gt;&gt; labels_set.save(\"path/to/splits/\", embed=False)\n</code></pre> <p>Save as Ultralytics dataset:</p> <pre><code>&gt;&gt;&gt; labels_set.save(\"path/to/dataset/\", format=\"ultralytics\")\n</code></pre> Source code in <code>sleap_io/model/labels_set.py</code> <pre><code>def save(\n    self,\n    save_dir: Union[str, Path],\n    embed: Union[bool, str] = True,\n    format: str = \"slp\",\n    **kwargs,\n) -&gt; None:\n    \"\"\"Save all Labels objects to a directory.\n\n    Args:\n        save_dir: Directory to save the files to. Will be created if it\n            doesn't exist.\n        embed: For SLP format: Whether to embed images in the saved files.\n            Can be True, False, \"user\", \"predictions\", or \"all\".\n            See Labels.save() for details.\n        format: Output format. Currently supports \"slp\" (default) and \"ultralytics\".\n        **kwargs: Additional format-specific arguments. For ultralytics format,\n            these might include skeleton, image_size, etc.\n\n    Examples:\n        Save as SLP files with embedded images:\n        &gt;&gt;&gt; labels_set.save(\"path/to/splits/\", embed=True)\n\n        Save as SLP files without embedding:\n        &gt;&gt;&gt; labels_set.save(\"path/to/splits/\", embed=False)\n\n        Save as Ultralytics dataset:\n        &gt;&gt;&gt; labels_set.save(\"path/to/dataset/\", format=\"ultralytics\")\n    \"\"\"\n    save_dir = Path(save_dir)\n    save_dir.mkdir(parents=True, exist_ok=True)\n\n    if format == \"slp\":\n        for name, labels in self.items():\n            if embed:\n                filename = f\"{name}.pkg.slp\"\n            else:\n                filename = f\"{name}.slp\"\n            labels.save(save_dir / filename, embed=embed)\n\n    elif format == \"ultralytics\":\n        # Import here to avoid circular imports\n        from sleap_io.io import ultralytics\n\n        # For ultralytics, we need to save each split in the proper structure\n        for name, labels in self.items():\n            # Map common split names\n            split_name = name\n            if name in [\"training\", \"train\"]:\n                split_name = \"train\"\n            elif name in [\"validation\", \"val\", \"valid\"]:\n                split_name = \"val\"\n            elif name in [\"testing\", \"test\"]:\n                split_name = \"test\"\n\n            # Write this split\n            ultralytics.write_labels(\n                labels, str(save_dir), split=split_name, **kwargs\n            )\n\n    else:\n        raise ValueError(\n            f\"Unknown format: {format}. Supported formats: 'slp', 'ultralytics'\"\n        )\n</code></pre>"},{"location":"model/#sleap_io.LabelsSet.values","title":"<code>values()</code>","text":"<p>Return a view of the Labels objects.</p> Source code in <code>sleap_io/model/labels_set.py</code> <pre><code>def values(self) -&gt; ValuesView[Labels]:\n    \"\"\"Return a view of the Labels objects.\"\"\"\n    return self.labels.values()\n</code></pre>"},{"location":"reference/SUMMARY/","title":"SUMMARY","text":"<ul> <li>sleap_io<ul> <li>io<ul> <li>alphatracker</li> <li>coco</li> <li>dlc</li> <li>jabs</li> <li>labelstudio</li> <li>leap</li> <li>main</li> <li>nwb</li> <li>nwb_annotations</li> <li>nwb_predictions</li> <li>skeleton</li> <li>slp</li> <li>ultralytics</li> <li>utils</li> <li>video_reading</li> <li>video_writing</li> </ul> </li> <li>model<ul> <li>camera</li> <li>instance</li> <li>labeled_frame</li> <li>labels</li> <li>labels_set</li> <li>matching</li> <li>skeleton</li> <li>suggestions</li> <li>video</li> </ul> </li> <li>version</li> </ul> </li> </ul>"},{"location":"reference/sleap_io/","title":"sleap_io","text":""},{"location":"reference/sleap_io/#sleap_io","title":"<code>sleap_io</code>","text":"<p>This module exposes all high level APIs for sleap-io.</p> <p>Modules:</p> Name Description <code>io</code> <p>This sub-package contains I/O-related modules such as specific format backends.</p> <code>model</code> <p>This subpackage contains data model interfaces.</p> <code>version</code> <p>This module defines the package version.</p> <p>Classes:</p> Name Description <code>Camera</code> <p>A camera used to record in a multi-view <code>RecordingSession</code>.</p> <code>CameraGroup</code> <p>A group of cameras used to record a multi-view <code>RecordingSession</code>.</p> <code>Edge</code> <p>A connection between two <code>Node</code> objects within a <code>Skeleton</code>.</p> <code>FrameGroup</code> <p>Defines a group of <code>InstanceGroups</code> across views at the same frame index.</p> <code>Instance</code> <p>This class represents a ground truth instance such as an animal.</p> <code>InstanceGroup</code> <p>Defines a group of instances across the same frame index.</p> <code>LabeledFrame</code> <p>Labeled data for a single frame of a video.</p> <code>Labels</code> <p>Pose data for a set of videos that have user labels and/or predictions.</p> <code>LabelsSet</code> <p>Container for multiple Labels objects with dictionary and tuple-like interface.</p> <code>Node</code> <p>A landmark type within a <code>Skeleton</code>.</p> <code>PredictedInstance</code> <p>A <code>PredictedInstance</code> is an <code>Instance</code> that was predicted using a model.</p> <code>RecordingSession</code> <p>A recording session with multiple cameras.</p> <code>Skeleton</code> <p>A description of a set of landmark types and connections between them.</p> <code>SuggestionFrame</code> <p>Data structure for a single frame of suggestions.</p> <code>Symmetry</code> <p>A relationship between a pair of nodes denoting their left/right pairing.</p> <code>Track</code> <p>An object that represents the same animal/object across multiple detections.</p> <code>Video</code> <p><code>Video</code> class used by sleap to represent videos and data associated with them.</p> <code>VideoBackend</code> <p>Base class for video backends.</p> <code>VideoWriter</code> <p>Simple video writer using imageio and FFMPEG.</p> <p>Functions:</p> Name Description <code>get_default_video_plugin</code> <p>Get the current default video plugin.</p> <code>load_alphatracker</code> <p>Read AlphaTracker annotations from a file and return a <code>Labels</code> object.</p> <code>load_coco</code> <p>Load a COCO-style pose dataset and return a Labels object.</p> <code>load_dlc</code> <p>Read DeepLabCut annotations from a CSV file and return a <code>Labels</code> object.</p> <code>load_file</code> <p>Load a file and return the appropriate object.</p> <code>load_jabs</code> <p>Read JABS-style predictions from a file and return a <code>Labels</code> object.</p> <code>load_labels_set</code> <p>Load a LabelsSet from multiple files.</p> <code>load_labelstudio</code> <p>Read Label Studio-style annotations from a file and return a <code>Labels</code> object.</p> <code>load_leap</code> <p>Load a LEAP dataset from a .mat file.</p> <code>load_nwb</code> <p>Load an NWB dataset as a SLEAP <code>Labels</code> object.</p> <code>load_skeleton</code> <p>Load skeleton(s) from a JSON, YAML, or SLP file.</p> <code>load_slp</code> <p>Load a SLEAP dataset.</p> <code>load_ultralytics</code> <p>Load an Ultralytics YOLO pose dataset as a SLEAP <code>Labels</code> object.</p> <code>load_video</code> <p>Load a video file.</p> <code>save_file</code> <p>Save a file based on the extension.</p> <code>save_jabs</code> <p>Save a SLEAP dataset to JABS pose file format.</p> <code>save_labelstudio</code> <p>Save a SLEAP dataset to Label Studio format.</p> <code>save_nwb</code> <p>Save a SLEAP dataset to NWB format.</p> <code>save_skeleton</code> <p>Save skeleton(s) to a JSON or YAML file.</p> <code>save_slp</code> <p>Save a SLEAP dataset to a <code>.slp</code> file.</p> <code>save_ultralytics</code> <p>Save a SLEAP dataset to Ultralytics YOLO pose format.</p> <code>save_video</code> <p>Write a list of frames to a video file.</p> <code>set_default_video_plugin</code> <p>Set the default video plugin for all subsequently loaded videos.</p>"},{"location":"reference/sleap_io/#sleap_io.Camera","title":"<code>Camera</code>","text":"<p>A camera used to record in a multi-view <code>RecordingSession</code>.</p> <p>Attributes:</p> Name Type Description <code>matrix</code> <code>ndarray</code> <p>Intrinsic camera matrix of size (3, 3) and type float64.</p> <code>dist</code> <code>ndarray</code> <p>Radial-tangential distortion coefficients [k_1, k_2, p_1, p_2, k_3] of size (5,) and type float64.</p> <code>size</code> <code>tuple[int, int]</code> <p>Image size (width, height) of camera in pixels of size (2,) and type int.</p> <code>rvec</code> <code>ndarray</code> <p>Rotation vector in unnormalized axis-angle representation of size (3,) and type float64.</p> <code>tvec</code> <code>ndarray</code> <p>Translation vector of size (3,) and type float64.</p> <code>extrinsic_matrix</code> <code>ndarray</code> <p>Extrinsic matrix of camera of size (4, 4) and type float64.</p> <code>name</code> <code>str</code> <p>Camera name.</p> <code>metadata</code> <code>dict</code> <p>Dictionary of metadata.</p> <p>Methods:</p> Name Description <code>__attrs_post_init__</code> <p>Initialize extrinsic matrix from rotation and translation vectors.</p> <code>__repr__</code> <p>Return a readable representation of the camera.</p> <code>get_video</code> <p>Get video associated with recording session.</p> Source code in <code>sleap_io/model/camera.py</code> <pre><code>@define(eq=False)  # Set eq to false to make class hashable\nclass Camera:\n    \"\"\"A camera used to record in a multi-view `RecordingSession`.\n\n    Attributes:\n        matrix: Intrinsic camera matrix of size (3, 3) and type float64.\n        dist: Radial-tangential distortion coefficients [k_1, k_2, p_1, p_2, k_3] of\n            size (5,) and type float64.\n        size: Image size (width, height) of camera in pixels of size (2,) and type int.\n        rvec: Rotation vector in unnormalized axis-angle representation of size (3,) and\n            type float64.\n        tvec: Translation vector of size (3,) and type float64.\n        extrinsic_matrix: Extrinsic matrix of camera of size (4, 4) and type float64.\n        name: Camera name.\n        metadata: Dictionary of metadata.\n    \"\"\"\n\n    matrix: np.ndarray = field(\n        default=np.eye(3),\n        converter=lambda x: np.array(x, dtype=\"float64\"),\n    )\n    dist: np.ndarray = field(\n        default=np.zeros(5), converter=lambda x: np.array(x, dtype=\"float64\").ravel()\n    )\n    size: tuple[int, int] = field(\n        default=None, converter=attrs.converters.optional(tuple)\n    )\n    _rvec: np.ndarray = field(\n        default=np.zeros(3), converter=lambda x: np.array(x, dtype=\"float64\").ravel()\n    )\n    _tvec: np.ndarray = field(\n        default=np.zeros(3), converter=lambda x: np.array(x, dtype=\"float64\").ravel()\n    )\n    name: str = field(default=None, converter=attrs.converters.optional(str))\n    _extrinsic_matrix: np.ndarray = field(init=False)\n    metadata: dict = field(factory=dict, validator=instance_of(dict))\n\n    @matrix.validator\n    @dist.validator\n    @size.validator\n    @_rvec.validator\n    @_tvec.validator\n    @_extrinsic_matrix.validator\n    def _validate_shape(self, attribute: attrs.Attribute, value):\n        \"\"\"Validate shape of attribute based on metadata.\n\n        Args:\n            attribute: Attribute to validate.\n            value: Value of attribute to validate.\n\n        Raises:\n            ValueError: If attribute shape is not as expected.\n        \"\"\"\n        # Define metadata for each attribute\n        attr_metadata = {\n            \"matrix\": {\"shape\": (3, 3), \"type\": np.ndarray},\n            \"dist\": {\"shape\": (5,), \"type\": np.ndarray},\n            \"size\": {\"shape\": (2,), \"type\": tuple},\n            \"_rvec\": {\"shape\": (3,), \"type\": np.ndarray},\n            \"_tvec\": {\"shape\": (3,), \"type\": np.ndarray},\n            \"_extrinsic_matrix\": {\"shape\": (4, 4), \"type\": np.ndarray},\n        }\n        optional_attrs = [\"size\"]\n\n        # Skip validation if optional attribute is None\n        if attribute.name in optional_attrs and value is None:\n            return\n\n        # Validate shape of attribute\n        expected_shape = attr_metadata[attribute.name][\"shape\"]\n        expected_type = attr_metadata[attribute.name][\"type\"]\n        if np.shape(value) != expected_shape:\n            raise ValueError(\n                f\"{attribute.name} must be a {expected_type} of size {expected_shape}, \"\n                f\"but received shape: {np.shape(value)} and type: {type(value)} for \"\n                f\"value: {value}\"\n            )\n\n    def __attrs_post_init__(self):\n        \"\"\"Initialize extrinsic matrix from rotation and translation vectors.\"\"\"\n        self._extrinsic_matrix = np.eye(4, dtype=\"float64\")\n        self._extrinsic_matrix[:3, :3] = rodrigues_transformation(self._rvec)[0]\n        self._extrinsic_matrix[:3, 3] = self._tvec\n\n    @property\n    def rvec(self) -&gt; np.ndarray:\n        \"\"\"Get rotation vector of camera.\n\n        Returns:\n            Rotation vector of camera of size 3.\n        \"\"\"\n        return self._rvec\n\n    @rvec.setter\n    def rvec(self, value: np.ndarray):\n        \"\"\"Set rotation vector and update extrinsic matrix.\n\n        Args:\n            value: Rotation vector of size 3.\n        \"\"\"\n        self._rvec = value\n        self._extrinsic_matrix[:3, :3] = rodrigues_transformation(self._rvec)[0]\n\n    @property\n    def tvec(self) -&gt; np.ndarray:\n        \"\"\"Get translation vector of camera.\n\n        Returns:\n            Translation vector of camera of size 3.\n        \"\"\"\n        return self._tvec\n\n    @tvec.setter\n    def tvec(self, value: np.ndarray):\n        \"\"\"Set translation vector and update extrinsic matrix.\n\n        Args:\n            value: Translation vector of size 3.\n        \"\"\"\n        self._tvec = value\n\n        # Update extrinsic matrix\n        self._extrinsic_matrix[:3, 3] = self._tvec\n\n    @property\n    def extrinsic_matrix(self) -&gt; np.ndarray:\n        \"\"\"Get extrinsic matrix of camera.\n\n        Returns:\n            Extrinsic matrix of camera of size 4 x 4.\n        \"\"\"\n        return self._extrinsic_matrix\n\n    @extrinsic_matrix.setter\n    def extrinsic_matrix(self, value: np.ndarray):\n        \"\"\"Set extrinsic matrix and update rotation and translation vectors.\n\n        Args:\n            value: Extrinsic matrix of size 4 x 4.\n        \"\"\"\n        self._extrinsic_matrix = value\n\n        # Update rotation and translation vectors\n        self._rvec = rodrigues_transformation(self._extrinsic_matrix[:3, :3])[0].ravel()\n        self._tvec = self._extrinsic_matrix[:3, 3]\n\n    def get_video(self, session: RecordingSession) -&gt; Video | None:\n        \"\"\"Get video associated with recording session.\n\n        Args:\n            session: Recording session to get video for.\n\n        Returns:\n            Video associated with recording session or None if not found.\n        \"\"\"\n        return session.get_video(camera=self)\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return a readable representation of the camera.\"\"\"\n        matrix_str = (\n            \"identity\" if np.array_equal(self.matrix, np.eye(3)) else \"non-identity\"\n        )\n        dist_str = \"zero\" if np.array_equal(self.dist, np.zeros(5)) else \"non-zero\"\n        size_str = \"None\" if self.size is None else self.size\n        rvec_str = (\n            \"zero\"\n            if np.array_equal(self.rvec, np.zeros(3))\n            else np.array2string(self.rvec, precision=2, suppress_small=True)\n        )\n        tvec_str = (\n            \"zero\"\n            if np.array_equal(self.tvec, np.zeros(3))\n            else np.array2string(self.tvec, precision=2, suppress_small=True)\n        )\n        name_str = self.name if self.name is not None else \"None\"\n        return (\n            \"Camera(\"\n            f\"matrix={matrix_str}, \"\n            f\"dist={dist_str}, \"\n            f\"size={size_str}, \"\n            f\"rvec={rvec_str}, \"\n            f\"tvec={tvec_str}, \"\n            f\"name={name_str}\"\n            \")\"\n        )\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Camera.extrinsic_matrix","title":"<code>extrinsic_matrix</code>  <code>property</code> <code>writable</code>","text":"<p>Get extrinsic matrix of camera.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>Extrinsic matrix of camera of size 4 x 4.</p>"},{"location":"reference/sleap_io/#sleap_io.Camera.rvec","title":"<code>rvec</code>  <code>property</code> <code>writable</code>","text":"<p>Get rotation vector of camera.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>Rotation vector of camera of size 3.</p>"},{"location":"reference/sleap_io/#sleap_io.Camera.tvec","title":"<code>tvec</code>  <code>property</code> <code>writable</code>","text":"<p>Get translation vector of camera.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>Translation vector of camera of size 3.</p>"},{"location":"reference/sleap_io/#sleap_io.Camera.__attrs_post_init__","title":"<code>__attrs_post_init__()</code>","text":"<p>Initialize extrinsic matrix from rotation and translation vectors.</p> Source code in <code>sleap_io/model/camera.py</code> <pre><code>def __attrs_post_init__(self):\n    \"\"\"Initialize extrinsic matrix from rotation and translation vectors.\"\"\"\n    self._extrinsic_matrix = np.eye(4, dtype=\"float64\")\n    self._extrinsic_matrix[:3, :3] = rodrigues_transformation(self._rvec)[0]\n    self._extrinsic_matrix[:3, 3] = self._tvec\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Camera.__repr__","title":"<code>__repr__()</code>","text":"<p>Return a readable representation of the camera.</p> Source code in <code>sleap_io/model/camera.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return a readable representation of the camera.\"\"\"\n    matrix_str = (\n        \"identity\" if np.array_equal(self.matrix, np.eye(3)) else \"non-identity\"\n    )\n    dist_str = \"zero\" if np.array_equal(self.dist, np.zeros(5)) else \"non-zero\"\n    size_str = \"None\" if self.size is None else self.size\n    rvec_str = (\n        \"zero\"\n        if np.array_equal(self.rvec, np.zeros(3))\n        else np.array2string(self.rvec, precision=2, suppress_small=True)\n    )\n    tvec_str = (\n        \"zero\"\n        if np.array_equal(self.tvec, np.zeros(3))\n        else np.array2string(self.tvec, precision=2, suppress_small=True)\n    )\n    name_str = self.name if self.name is not None else \"None\"\n    return (\n        \"Camera(\"\n        f\"matrix={matrix_str}, \"\n        f\"dist={dist_str}, \"\n        f\"size={size_str}, \"\n        f\"rvec={rvec_str}, \"\n        f\"tvec={tvec_str}, \"\n        f\"name={name_str}\"\n        \")\"\n    )\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Camera.get_video","title":"<code>get_video(session)</code>","text":"<p>Get video associated with recording session.</p> <p>Parameters:</p> Name Type Description Default <code>session</code> <code>RecordingSession</code> <p>Recording session to get video for.</p> required <p>Returns:</p> Type Description <code>Video | None</code> <p>Video associated with recording session or None if not found.</p> Source code in <code>sleap_io/model/camera.py</code> <pre><code>def get_video(self, session: RecordingSession) -&gt; Video | None:\n    \"\"\"Get video associated with recording session.\n\n    Args:\n        session: Recording session to get video for.\n\n    Returns:\n        Video associated with recording session or None if not found.\n    \"\"\"\n    return session.get_video(camera=self)\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.CameraGroup","title":"<code>CameraGroup</code>","text":"<p>A group of cameras used to record a multi-view <code>RecordingSession</code>.</p> <p>Attributes:</p> Name Type Description <code>cameras</code> <code>list[Camera]</code> <p>List of <code>Camera</code> objects in the group.</p> <code>metadata</code> <code>dict</code> <p>Dictionary of metadata.</p> <p>Methods:</p> Name Description <code>__repr__</code> <p>Return a readable representation of the camera group.</p> Source code in <code>sleap_io/model/camera.py</code> <pre><code>@define\nclass CameraGroup:\n    \"\"\"A group of cameras used to record a multi-view `RecordingSession`.\n\n    Attributes:\n        cameras: List of `Camera` objects in the group.\n        metadata: Dictionary of metadata.\n    \"\"\"\n\n    cameras: list[Camera] = field(factory=list, validator=instance_of(list))\n    metadata: dict = field(factory=dict, validator=instance_of(dict))\n\n    def __repr__(self):\n        \"\"\"Return a readable representation of the camera group.\"\"\"\n        camera_names = \", \".join([c.name or \"None\" for c in self.cameras])\n        return f\"CameraGroup(cameras={len(self.cameras)}:[{camera_names}])\"\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.CameraGroup.__repr__","title":"<code>__repr__()</code>","text":"<p>Return a readable representation of the camera group.</p> Source code in <code>sleap_io/model/camera.py</code> <pre><code>def __repr__(self):\n    \"\"\"Return a readable representation of the camera group.\"\"\"\n    camera_names = \", \".join([c.name or \"None\" for c in self.cameras])\n    return f\"CameraGroup(cameras={len(self.cameras)}:[{camera_names}])\"\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Edge","title":"<code>Edge</code>","text":"<p>A connection between two <code>Node</code> objects within a <code>Skeleton</code>.</p> <p>This is a directed edge, representing the ordering of <code>Node</code>s in the <code>Skeleton</code> tree.</p> <p>Attributes:</p> Name Type Description <code>source</code> <code>Node</code> <p>The origin <code>Node</code>.</p> <code>destination</code> <code>Node</code> <p>The destination <code>Node</code>.</p> <p>Methods:</p> Name Description <code>__getitem__</code> <p>Return the source <code>Node</code> (<code>idx</code> is 0) or destination <code>Node</code> (<code>idx</code> is 1).</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>@define(frozen=True)\nclass Edge:\n    \"\"\"A connection between two `Node` objects within a `Skeleton`.\n\n    This is a directed edge, representing the ordering of `Node`s in the `Skeleton`\n    tree.\n\n    Attributes:\n        source: The origin `Node`.\n        destination: The destination `Node`.\n    \"\"\"\n\n    source: Node\n    destination: Node\n\n    def __getitem__(self, idx) -&gt; Node:\n        \"\"\"Return the source `Node` (`idx` is 0) or destination `Node` (`idx` is 1).\"\"\"\n        if idx == 0:\n            return self.source\n        elif idx == 1:\n            return self.destination\n        else:\n            raise IndexError(\"Edge only has 2 nodes (source and destination).\")\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Edge.__getitem__","title":"<code>__getitem__(idx)</code>","text":"<p>Return the source <code>Node</code> (<code>idx</code> is 0) or destination <code>Node</code> (<code>idx</code> is 1).</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def __getitem__(self, idx) -&gt; Node:\n    \"\"\"Return the source `Node` (`idx` is 0) or destination `Node` (`idx` is 1).\"\"\"\n    if idx == 0:\n        return self.source\n    elif idx == 1:\n        return self.destination\n    else:\n        raise IndexError(\"Edge only has 2 nodes (source and destination).\")\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.FrameGroup","title":"<code>FrameGroup</code>","text":"<p>Defines a group of <code>InstanceGroups</code> across views at the same frame index.</p> <p>Attributes:</p> Name Type Description <code>frame_idx</code> <code>int</code> <p>Frame index for the <code>FrameGroup</code>.</p> <code>instance_groups</code> <code>list[InstanceGroup]</code> <p>List of <code>InstanceGroup</code>s in the <code>FrameGroup</code>.</p> <code>cameras</code> <code>list[Camera]</code> <p>List of <code>Camera</code> objects linked to <code>LabeledFrame</code>s in the <code>FrameGroup</code>.</p> <code>labeled_frames</code> <code>list[LabeledFrame]</code> <p>List of <code>LabeledFrame</code>s in the <code>FrameGroup</code>.</p> <code>metadata</code> <code>dict</code> <p>Metadata for the <code>FrameGroup</code> that is provided but not deserialized.</p> <p>Methods:</p> Name Description <code>__repr__</code> <p>Return a readable representation of the frame group.</p> <code>get_frame</code> <p>Get <code>LabeledFrame</code> associated with <code>camera</code>.</p> Source code in <code>sleap_io/model/camera.py</code> <pre><code>@define(eq=False)  # Set eq to false to make class hashable\nclass FrameGroup:\n    \"\"\"Defines a group of `InstanceGroups` across views at the same frame index.\n\n    Attributes:\n        frame_idx: Frame index for the `FrameGroup`.\n        instance_groups: List of `InstanceGroup`s in the `FrameGroup`.\n        cameras: List of `Camera` objects linked to `LabeledFrame`s in the `FrameGroup`.\n        labeled_frames: List of `LabeledFrame`s in the `FrameGroup`.\n        metadata: Metadata for the `FrameGroup` that is provided but not deserialized.\n    \"\"\"\n\n    frame_idx: int = field(converter=int)\n    _instance_groups: list[InstanceGroup] = field(\n        factory=list, validator=instance_of(list)\n    )\n    _labeled_frame_by_camera: dict[Camera, LabeledFrame] = field(\n        factory=dict, validator=instance_of(dict)\n    )\n    metadata: dict = field(factory=dict, validator=instance_of(dict))\n\n    @property\n    def instance_groups(self) -&gt; list[InstanceGroup]:\n        \"\"\"List of `InstanceGroup`s.\"\"\"\n        return self._instance_groups\n\n    @property\n    def cameras(self) -&gt; list[Camera]:\n        \"\"\"List of `Camera` objects.\"\"\"\n        return list(self._labeled_frame_by_camera.keys())\n\n    @property\n    def labeled_frames(self) -&gt; list[LabeledFrame]:\n        \"\"\"List of `LabeledFrame`s.\"\"\"\n        return list(self._labeled_frame_by_camera.values())\n\n    def get_frame(self, camera: Camera) -&gt; LabeledFrame | None:\n        \"\"\"Get `LabeledFrame` associated with `camera`.\n\n        Args:\n            camera: `Camera` to get `LabeledFrame`.\n\n        Returns:\n            `LabeledFrame` associated with `camera` or None if not found.\n        \"\"\"\n        return self._labeled_frame_by_camera.get(camera, None)\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return a readable representation of the frame group.\"\"\"\n        cameras_str = \", \".join([c.name or \"None\" for c in self.cameras])\n        return (\n            f\"FrameGroup(\"\n            f\"frame_idx={self.frame_idx},\"\n            f\"instance_groups={len(self.instance_groups)},\"\n            f\"cameras={len(self.cameras)}:[{cameras_str}]\"\n            f\")\"\n        )\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.FrameGroup.cameras","title":"<code>cameras</code>  <code>property</code>","text":"<p>List of <code>Camera</code> objects.</p>"},{"location":"reference/sleap_io/#sleap_io.FrameGroup.instance_groups","title":"<code>instance_groups</code>  <code>property</code>","text":"<p>List of <code>InstanceGroup</code>s.</p>"},{"location":"reference/sleap_io/#sleap_io.FrameGroup.labeled_frames","title":"<code>labeled_frames</code>  <code>property</code>","text":"<p>List of <code>LabeledFrame</code>s.</p>"},{"location":"reference/sleap_io/#sleap_io.FrameGroup.__repr__","title":"<code>__repr__()</code>","text":"<p>Return a readable representation of the frame group.</p> Source code in <code>sleap_io/model/camera.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return a readable representation of the frame group.\"\"\"\n    cameras_str = \", \".join([c.name or \"None\" for c in self.cameras])\n    return (\n        f\"FrameGroup(\"\n        f\"frame_idx={self.frame_idx},\"\n        f\"instance_groups={len(self.instance_groups)},\"\n        f\"cameras={len(self.cameras)}:[{cameras_str}]\"\n        f\")\"\n    )\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.FrameGroup.get_frame","title":"<code>get_frame(camera)</code>","text":"<p>Get <code>LabeledFrame</code> associated with <code>camera</code>.</p> <p>Parameters:</p> Name Type Description Default <code>camera</code> <code>Camera</code> <p><code>Camera</code> to get <code>LabeledFrame</code>.</p> required <p>Returns:</p> Type Description <code>LabeledFrame | None</code> <p><code>LabeledFrame</code> associated with <code>camera</code> or None if not found.</p> Source code in <code>sleap_io/model/camera.py</code> <pre><code>def get_frame(self, camera: Camera) -&gt; LabeledFrame | None:\n    \"\"\"Get `LabeledFrame` associated with `camera`.\n\n    Args:\n        camera: `Camera` to get `LabeledFrame`.\n\n    Returns:\n        `LabeledFrame` associated with `camera` or None if not found.\n    \"\"\"\n    return self._labeled_frame_by_camera.get(camera, None)\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Instance","title":"<code>Instance</code>","text":"<p>This class represents a ground truth instance such as an animal.</p> <p>An <code>Instance</code> has a set of landmarks (points) that correspond to a <code>Skeleton</code>. Each point is associated with a <code>Node</code> in the skeleton. The points are stored in a structured numpy array with columns for x, y, visible, complete and name.</p> <p>The <code>Instance</code> may also be associated with a <code>Track</code> which links multiple instances together across frames or videos.</p> <p>Attributes:</p> Name Type Description <code>points</code> <code>PointsArray</code> <p>A numpy structured array with columns for xy, visible and complete. The array should have shape <code>(n_nodes,)</code>. This representation is useful for performance efficiency when working with large datasets.</p> <code>skeleton</code> <code>Skeleton</code> <p>The <code>Skeleton</code> that describes the <code>Node</code>s and <code>Edge</code>s associated with this instance.</p> <code>track</code> <code>Optional[Track]</code> <p>An optional <code>Track</code> associated with a unique animal/object across frames or videos.</p> <code>tracking_score</code> <code>Optional[float]</code> <p>The score associated with the <code>Track</code> assignment. This is typically the value from the score matrix used in an identity assignment. This is <code>None</code> if the instance is not associated with a track or if the track was assigned manually.</p> <code>from_predicted</code> <code>Optional[PredictedInstance]</code> <p>The <code>PredictedInstance</code> (if any) that this instance was initialized from. This is used with human-in-the-loop workflows.</p> <p>Methods:</p> Name Description <code>__attrs_post_init__</code> <p>Convert the points array after initialization.</p> <code>__getitem__</code> <p>Return the point associated with a node.</p> <code>__len__</code> <p>Return the number of points in the instance.</p> <code>__repr__</code> <p>Return a readable representation of the instance.</p> <code>__setitem__</code> <p>Set the point associated with a node.</p> <code>bounding_box</code> <p>Get the bounding box of visible points.</p> <code>empty</code> <p>Create an empty instance with no points.</p> <code>from_numpy</code> <p>Create an instance object from a numpy array.</p> <code>numpy</code> <p>Return the instance points as a <code>(n_nodes, 2)</code> numpy array.</p> <code>overlaps_with</code> <p>Check if this instance overlaps with another based on bounding box IoU.</p> <code>replace_skeleton</code> <p>Replace the skeleton associated with the instance.</p> <code>same_identity_as</code> <p>Check if this instance has the same identity (track) as another instance.</p> <code>same_pose_as</code> <p>Check if this instance has the same pose as another instance.</p> <code>update_skeleton</code> <p>Update or replace the skeleton associated with the instance.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>@attrs.define(auto_attribs=True, slots=True, eq=False)\nclass Instance:\n    \"\"\"This class represents a ground truth instance such as an animal.\n\n    An `Instance` has a set of landmarks (points) that correspond to a `Skeleton`. Each\n    point is associated with a `Node` in the skeleton. The points are stored in a\n    structured numpy array with columns for x, y, visible, complete and name.\n\n    The `Instance` may also be associated with a `Track` which links multiple instances\n    together across frames or videos.\n\n    Attributes:\n        points: A numpy structured array with columns for xy, visible and complete. The\n            array should have shape `(n_nodes,)`. This representation is useful for\n            performance efficiency when working with large datasets.\n        skeleton: The `Skeleton` that describes the `Node`s and `Edge`s associated with\n            this instance.\n        track: An optional `Track` associated with a unique animal/object across frames\n            or videos.\n        tracking_score: The score associated with the `Track` assignment. This is\n            typically the value from the score matrix used in an identity assignment.\n            This is `None` if the instance is not associated with a track or if the\n            track was assigned manually.\n        from_predicted: The `PredictedInstance` (if any) that this instance was\n            initialized from. This is used with human-in-the-loop workflows.\n    \"\"\"\n\n    points: PointsArray = attrs.field(eq=attrs.cmp_using(eq=np.array_equal))\n    skeleton: Skeleton\n    track: Optional[Track] = None\n    tracking_score: Optional[float] = None\n    from_predicted: Optional[PredictedInstance] = None\n\n    @classmethod\n    def empty(\n        cls,\n        skeleton: Skeleton,\n        track: Optional[Track] = None,\n        tracking_score: Optional[float] = None,\n        from_predicted: Optional[PredictedInstance] = None,\n    ) -&gt; \"Instance\":\n        \"\"\"Create an empty instance with no points.\n\n        Args:\n            skeleton: The `Skeleton` that this `Instance` is associated with.\n            track: An optional `Track` associated with a unique animal/object across\n                frames or videos.\n            tracking_score: The score associated with the `Track` assignment. This is\n                typically the value from the score matrix used in an identity\n                assignment. This is `None` if the instance is not associated with a\n                track or if the track was assigned manually.\n            from_predicted: The `PredictedInstance` (if any) that this instance was\n                initialized from. This is used with human-in-the-loop workflows.\n\n        Returns:\n            An `Instance` with an empty numpy array of shape `(n_nodes,)`.\n        \"\"\"\n        points = PointsArray.empty(len(skeleton))\n        points[\"name\"] = skeleton.node_names\n\n        return cls(\n            points=points,\n            skeleton=skeleton,\n            track=track,\n            tracking_score=tracking_score,\n            from_predicted=from_predicted,\n        )\n\n    @classmethod\n    def _convert_points(\n        cls, points_data: np.ndarray | dict | list, skeleton: Skeleton\n    ) -&gt; PointsArray:\n        \"\"\"Convert points to a structured numpy array if needed.\"\"\"\n        if isinstance(points_data, dict):\n            return PointsArray.from_dict(points_data, skeleton)\n        elif isinstance(points_data, (list, np.ndarray)):\n            if isinstance(points_data, list):\n                points_data = np.array(points_data)\n\n            points = PointsArray.from_array(points_data)\n            points[\"name\"] = skeleton.node_names\n            return points\n        else:\n            raise ValueError(\"points must be a numpy array or dictionary.\")\n\n    @classmethod\n    def from_numpy(\n        cls,\n        points_data: np.ndarray,\n        skeleton: Skeleton,\n        track: Optional[Track] = None,\n        tracking_score: Optional[float] = None,\n        from_predicted: Optional[PredictedInstance] = None,\n    ) -&gt; \"Instance\":\n        \"\"\"Create an instance object from a numpy array.\n\n        Args:\n            points_data: A numpy array of shape `(n_nodes, D)` corresponding to the\n                points of the skeleton. Values of `np.nan` indicate \"missing\" nodes and\n                will be reflected in the \"visible\" field.\n\n                If `D == 2`, the array should have columns for x and y.\n                If `D == 3`, the array should have columns for x, y and visible.\n                If `D == 4`, the array should have columns for x, y, visible and\n                complete.\n\n                If this is provided as a structured array, it will be used without copy\n                if it has the correct dtype. Otherwise, a new structured array will be\n                created reusing the provided data.\n            skeleton: The `Skeleton` that this `Instance` is associated with. It should\n                have `n_nodes` nodes.\n            track: An optional `Track` associated with a unique animal/object across\n                frames or videos.\n            tracking_score: The score associated with the `Track` assignment. This is\n                typically the value from the score matrix used in an identity\n                assignment. This is `None` if the instance is not associated with a\n                track or if the track was assigned manually.\n            from_predicted: The `PredictedInstance` (if any) that this instance was\n                initialized from. This is used with human-in-the-loop workflows.\n\n        Returns:\n            An `Instance` object with the specified points.\n        \"\"\"\n        return cls(\n            points=points_data,\n            skeleton=skeleton,\n            track=track,\n            tracking_score=tracking_score,\n            from_predicted=from_predicted,\n        )\n\n    def __attrs_post_init__(self):\n        \"\"\"Convert the points array after initialization.\"\"\"\n        if not isinstance(self.points, PointsArray):\n            self.points = self._convert_points(self.points, self.skeleton)\n\n        # Ensure points have node names\n        if \"name\" in self.points.dtype.names and not all(self.points[\"name\"]):\n            self.points[\"name\"] = self.skeleton.node_names\n\n    def numpy(\n        self,\n        invisible_as_nan: bool = True,\n    ) -&gt; np.ndarray:\n        \"\"\"Return the instance points as a `(n_nodes, 2)` numpy array.\n\n        Args:\n            invisible_as_nan: If `True` (the default), points that are not visible will\n                be set to `np.nan`. If `False`, they will be whatever the stored value\n                of `Instance.points[\"xy\"]` is.\n\n        Returns:\n            A numpy array of shape `(n_nodes, 2)` corresponding to the points of the\n            skeleton. Values of `np.nan` indicate \"missing\" nodes.\n\n        Notes:\n            This will always return a copy of the array.\n\n            If you need to avoid making a copy, just access the `Instance.points[\"xy\"]`\n            attribute directly. This will not replace invisible points with `np.nan`.\n        \"\"\"\n        if invisible_as_nan:\n            return np.where(\n                self.points[\"visible\"].reshape(-1, 1), self.points[\"xy\"], np.nan\n            )\n        else:\n            return self.points[\"xy\"].copy()\n\n    def __getitem__(self, node: Union[int, str, Node]) -&gt; np.ndarray:\n        \"\"\"Return the point associated with a node.\"\"\"\n        if type(node) is not int:\n            node = self.skeleton.index(node)\n\n        return self.points[node]\n\n    def __setitem__(self, node: Union[int, str, Node], value):\n        \"\"\"Set the point associated with a node.\n\n        Args:\n            node: The node to set the point for. Can be an integer index, string name,\n                or Node object.\n            value: A tuple or array-like of length 2 containing (x, y) coordinates.\n\n        Notes:\n            This sets the point coordinates and marks the point as visible.\n        \"\"\"\n        if type(node) is not int:\n            node = self.skeleton.index(node)\n\n        if len(value) &lt; 2:\n            raise ValueError(\"Value must have at least 2 elements (x, y)\")\n\n        self.points[node][\"xy\"] = value[:2]\n        self.points[node][\"visible\"] = True\n\n    def __len__(self) -&gt; int:\n        \"\"\"Return the number of points in the instance.\"\"\"\n        return len(self.points)\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return a readable representation of the instance.\"\"\"\n        pts = self.numpy().tolist()\n        track = f'\"{self.track.name}\"' if self.track is not None else self.track\n\n        return f\"Instance(points={pts}, track={track})\"\n\n    @property\n    def n_visible(self) -&gt; int:\n        \"\"\"Return the number of visible points in the instance.\"\"\"\n        return sum(self.points[\"visible\"])\n\n    @property\n    def is_empty(self) -&gt; bool:\n        \"\"\"Return `True` if no points are visible on the instance.\"\"\"\n        return ~(self.points[\"visible\"].any())\n\n    def update_skeleton(self, names_only: bool = False):\n        \"\"\"Update or replace the skeleton associated with the instance.\n\n        Args:\n            names_only: If `True`, only update the node names in the points array. If\n                `False`, the points array will be updated to match the new skeleton.\n        \"\"\"\n        if names_only:\n            # Update the node names.\n            self.points[\"name\"] = self.skeleton.node_names\n            return\n\n        # Find correspondences.\n        new_node_inds, old_node_inds = self.skeleton.match_nodes(self.points[\"name\"])\n\n        # Update the points.\n        new_points = PointsArray.empty(len(self.skeleton))\n        new_points[new_node_inds] = self.points[old_node_inds]\n        new_points[\"name\"] = self.skeleton.node_names\n        self.points = new_points\n\n    def replace_skeleton(\n        self,\n        new_skeleton: Skeleton,\n        node_names_map: dict[str, str] | None = None,\n    ):\n        \"\"\"Replace the skeleton associated with the instance.\n\n        Args:\n            new_skeleton: The new `Skeleton` to associate with the instance.\n            node_names_map: Dictionary mapping nodes in the old skeleton to nodes in the\n                new skeleton. Keys and values should be specified as lists of strings.\n                If not provided, only nodes with identical names will be mapped. Points\n                associated with unmapped nodes will be removed.\n\n        Notes:\n            This method will update the `Instance.skeleton` attribute and the\n            `Instance.points` attribute in place (a copy is made of the points array).\n\n            It is recommended to use `Labels.replace_skeleton` instead of this method if\n            more flexible node mapping is required.\n        \"\"\"\n        # Update skeleton object.\n        # old_skeleton = self.skeleton\n        self.skeleton = new_skeleton\n\n        # Get node names with replacements from node map if possible.\n        # old_node_names = old_skeleton.node_names\n        old_node_names = self.points[\"name\"].tolist()\n        if node_names_map is not None:\n            old_node_names = [node_names_map.get(node, node) for node in old_node_names]\n\n        # Find correspondences.\n        new_node_inds, old_node_inds = self.skeleton.match_nodes(old_node_names)\n        # old_node_inds = np.array(old_node_inds).reshape(-1, 1)\n        # new_node_inds = np.array(new_node_inds).reshape(-1, 1)\n\n        # Update the points.\n        new_points = PointsArray.empty(len(self.skeleton))\n        new_points[new_node_inds] = self.points[old_node_inds]\n        self.points = new_points\n        self.points[\"name\"] = self.skeleton.node_names\n\n    def same_pose_as(self, other: \"Instance\", tolerance: float = 5.0) -&gt; bool:\n        \"\"\"Check if this instance has the same pose as another instance.\n\n        Args:\n            other: Another instance to compare with.\n            tolerance: Maximum distance (in pixels) between corresponding points\n                for them to be considered the same.\n\n        Returns:\n            True if the instances have the same pose within tolerance, False otherwise.\n\n        Notes:\n            Two instances are considered to have the same pose if:\n            - They have the same skeleton structure\n            - All visible points are within the tolerance distance\n            - They have the same visibility pattern\n        \"\"\"\n        # Check skeleton compatibility\n        if not self.skeleton.matches(other.skeleton):\n            return False\n\n        # Get visible points for both instances\n        self_visible = self.points[\"visible\"]\n        other_visible = other.points[\"visible\"]\n\n        # Check if visibility patterns match\n        if not np.array_equal(self_visible, other_visible):\n            return False\n\n        # Compare visible points\n        if not self_visible.any():\n            # Both instances have no visible points\n            return True\n\n        # Calculate distances between corresponding visible points\n        self_pts = self.points[\"xy\"][self_visible]\n        other_pts = other.points[\"xy\"][other_visible]\n\n        distances = np.linalg.norm(self_pts - other_pts, axis=1)\n\n        return np.all(distances &lt;= tolerance)\n\n    def same_identity_as(self, other: \"Instance\") -&gt; bool:\n        \"\"\"Check if this instance has the same identity (track) as another instance.\n\n        Args:\n            other: Another instance to compare with.\n\n        Returns:\n            True if both instances have the same track identity, False otherwise.\n\n        Notes:\n            Instances have the same identity if they share the same Track object\n            (by identity, not just by name).\n        \"\"\"\n        if self.track is None or other.track is None:\n            return False\n        return self.track is other.track\n\n    def overlaps_with(self, other: \"Instance\", iou_threshold: float = 0.5) -&gt; bool:\n        \"\"\"Check if this instance overlaps with another based on bounding box IoU.\n\n        Args:\n            other: Another instance to compare with.\n            iou_threshold: Minimum IoU (Intersection over Union) value to consider\n                the instances as overlapping.\n\n        Returns:\n            True if the instances overlap above the threshold, False otherwise.\n\n        Notes:\n            Overlap is computed using the bounding boxes of visible points.\n            If either instance has no visible points, they don't overlap.\n        \"\"\"\n        # Get visible points for both instances\n        self_visible = self.points[\"visible\"]\n        other_visible = other.points[\"visible\"]\n\n        if not self_visible.any() or not other_visible.any():\n            return False\n\n        # Calculate bounding boxes\n        self_pts = self.points[\"xy\"][self_visible]\n        other_pts = other.points[\"xy\"][other_visible]\n\n        self_bbox = np.array(\n            [\n                [np.min(self_pts[:, 0]), np.min(self_pts[:, 1])],  # min x, y\n                [np.max(self_pts[:, 0]), np.max(self_pts[:, 1])],  # max x, y\n            ]\n        )\n\n        other_bbox = np.array(\n            [\n                [np.min(other_pts[:, 0]), np.min(other_pts[:, 1])],\n                [np.max(other_pts[:, 0]), np.max(other_pts[:, 1])],\n            ]\n        )\n\n        # Calculate intersection\n        intersection_min = np.maximum(self_bbox[0], other_bbox[0])\n        intersection_max = np.minimum(self_bbox[1], other_bbox[1])\n\n        if np.any(intersection_min &gt;= intersection_max):\n            # No intersection\n            return False\n\n        intersection_area = np.prod(intersection_max - intersection_min)\n\n        # Calculate union\n        self_area = np.prod(self_bbox[1] - self_bbox[0])\n        other_area = np.prod(other_bbox[1] - other_bbox[0])\n        union_area = self_area + other_area - intersection_area\n\n        # Calculate IoU\n        iou = intersection_area / union_area if union_area &gt; 0 else 0\n\n        return iou &gt;= iou_threshold\n\n    def bounding_box(self) -&gt; Optional[np.ndarray]:\n        \"\"\"Get the bounding box of visible points.\n\n        Returns:\n            A numpy array of shape (2, 2) with [[min_x, min_y], [max_x, max_y]],\n            or None if there are no visible points.\n        \"\"\"\n        visible = self.points[\"visible\"]\n        if not visible.any():\n            return None\n\n        pts = self.points[\"xy\"][visible]\n        return np.array(\n            [\n                [np.min(pts[:, 0]), np.min(pts[:, 1])],\n                [np.max(pts[:, 0]), np.max(pts[:, 1])],\n            ]\n        )\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Instance.is_empty","title":"<code>is_empty</code>  <code>property</code>","text":"<p>Return <code>True</code> if no points are visible on the instance.</p>"},{"location":"reference/sleap_io/#sleap_io.Instance.n_visible","title":"<code>n_visible</code>  <code>property</code>","text":"<p>Return the number of visible points in the instance.</p>"},{"location":"reference/sleap_io/#sleap_io.Instance.__attrs_post_init__","title":"<code>__attrs_post_init__()</code>","text":"<p>Convert the points array after initialization.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>def __attrs_post_init__(self):\n    \"\"\"Convert the points array after initialization.\"\"\"\n    if not isinstance(self.points, PointsArray):\n        self.points = self._convert_points(self.points, self.skeleton)\n\n    # Ensure points have node names\n    if \"name\" in self.points.dtype.names and not all(self.points[\"name\"]):\n        self.points[\"name\"] = self.skeleton.node_names\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Instance.__getitem__","title":"<code>__getitem__(node)</code>","text":"<p>Return the point associated with a node.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>def __getitem__(self, node: Union[int, str, Node]) -&gt; np.ndarray:\n    \"\"\"Return the point associated with a node.\"\"\"\n    if type(node) is not int:\n        node = self.skeleton.index(node)\n\n    return self.points[node]\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Instance.__len__","title":"<code>__len__()</code>","text":"<p>Return the number of points in the instance.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"Return the number of points in the instance.\"\"\"\n    return len(self.points)\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Instance.__repr__","title":"<code>__repr__()</code>","text":"<p>Return a readable representation of the instance.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return a readable representation of the instance.\"\"\"\n    pts = self.numpy().tolist()\n    track = f'\"{self.track.name}\"' if self.track is not None else self.track\n\n    return f\"Instance(points={pts}, track={track})\"\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Instance.__setitem__","title":"<code>__setitem__(node, value)</code>","text":"<p>Set the point associated with a node.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>Union[int, str, Node]</code> <p>The node to set the point for. Can be an integer index, string name, or Node object.</p> required <code>value</code> <p>A tuple or array-like of length 2 containing (x, y) coordinates.</p> required Notes <p>This sets the point coordinates and marks the point as visible.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>def __setitem__(self, node: Union[int, str, Node], value):\n    \"\"\"Set the point associated with a node.\n\n    Args:\n        node: The node to set the point for. Can be an integer index, string name,\n            or Node object.\n        value: A tuple or array-like of length 2 containing (x, y) coordinates.\n\n    Notes:\n        This sets the point coordinates and marks the point as visible.\n    \"\"\"\n    if type(node) is not int:\n        node = self.skeleton.index(node)\n\n    if len(value) &lt; 2:\n        raise ValueError(\"Value must have at least 2 elements (x, y)\")\n\n    self.points[node][\"xy\"] = value[:2]\n    self.points[node][\"visible\"] = True\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Instance.bounding_box","title":"<code>bounding_box()</code>","text":"<p>Get the bounding box of visible points.</p> <p>Returns:</p> Type Description <code>Optional[ndarray]</code> <p>A numpy array of shape (2, 2) with [[min_x, min_y], [max_x, max_y]], or None if there are no visible points.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>def bounding_box(self) -&gt; Optional[np.ndarray]:\n    \"\"\"Get the bounding box of visible points.\n\n    Returns:\n        A numpy array of shape (2, 2) with [[min_x, min_y], [max_x, max_y]],\n        or None if there are no visible points.\n    \"\"\"\n    visible = self.points[\"visible\"]\n    if not visible.any():\n        return None\n\n    pts = self.points[\"xy\"][visible]\n    return np.array(\n        [\n            [np.min(pts[:, 0]), np.min(pts[:, 1])],\n            [np.max(pts[:, 0]), np.max(pts[:, 1])],\n        ]\n    )\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Instance.empty","title":"<code>empty(skeleton, track=None, tracking_score=None, from_predicted=None)</code>  <code>classmethod</code>","text":"<p>Create an empty instance with no points.</p> <p>Parameters:</p> Name Type Description Default <code>skeleton</code> <code>Skeleton</code> <p>The <code>Skeleton</code> that this <code>Instance</code> is associated with.</p> required <code>track</code> <code>Optional[Track]</code> <p>An optional <code>Track</code> associated with a unique animal/object across frames or videos.</p> <code>None</code> <code>tracking_score</code> <code>Optional[float]</code> <p>The score associated with the <code>Track</code> assignment. This is typically the value from the score matrix used in an identity assignment. This is <code>None</code> if the instance is not associated with a track or if the track was assigned manually.</p> <code>None</code> <code>from_predicted</code> <code>Optional[PredictedInstance]</code> <p>The <code>PredictedInstance</code> (if any) that this instance was initialized from. This is used with human-in-the-loop workflows.</p> <code>None</code> <p>Returns:</p> Type Description <code>'Instance'</code> <p>An <code>Instance</code> with an empty numpy array of shape <code>(n_nodes,)</code>.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>@classmethod\ndef empty(\n    cls,\n    skeleton: Skeleton,\n    track: Optional[Track] = None,\n    tracking_score: Optional[float] = None,\n    from_predicted: Optional[PredictedInstance] = None,\n) -&gt; \"Instance\":\n    \"\"\"Create an empty instance with no points.\n\n    Args:\n        skeleton: The `Skeleton` that this `Instance` is associated with.\n        track: An optional `Track` associated with a unique animal/object across\n            frames or videos.\n        tracking_score: The score associated with the `Track` assignment. This is\n            typically the value from the score matrix used in an identity\n            assignment. This is `None` if the instance is not associated with a\n            track or if the track was assigned manually.\n        from_predicted: The `PredictedInstance` (if any) that this instance was\n            initialized from. This is used with human-in-the-loop workflows.\n\n    Returns:\n        An `Instance` with an empty numpy array of shape `(n_nodes,)`.\n    \"\"\"\n    points = PointsArray.empty(len(skeleton))\n    points[\"name\"] = skeleton.node_names\n\n    return cls(\n        points=points,\n        skeleton=skeleton,\n        track=track,\n        tracking_score=tracking_score,\n        from_predicted=from_predicted,\n    )\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Instance.from_numpy","title":"<code>from_numpy(points_data, skeleton, track=None, tracking_score=None, from_predicted=None)</code>  <code>classmethod</code>","text":"<p>Create an instance object from a numpy array.</p> <p>Parameters:</p> Name Type Description Default <code>points_data</code> <code>ndarray</code> <p>A numpy array of shape <code>(n_nodes, D)</code> corresponding to the points of the skeleton. Values of <code>np.nan</code> indicate \"missing\" nodes and will be reflected in the \"visible\" field.</p> <p>If <code>D == 2</code>, the array should have columns for x and y. If <code>D == 3</code>, the array should have columns for x, y and visible. If <code>D == 4</code>, the array should have columns for x, y, visible and complete.</p> <p>If this is provided as a structured array, it will be used without copy if it has the correct dtype. Otherwise, a new structured array will be created reusing the provided data.</p> required <code>skeleton</code> <code>Skeleton</code> <p>The <code>Skeleton</code> that this <code>Instance</code> is associated with. It should have <code>n_nodes</code> nodes.</p> required <code>track</code> <code>Optional[Track]</code> <p>An optional <code>Track</code> associated with a unique animal/object across frames or videos.</p> <code>None</code> <code>tracking_score</code> <code>Optional[float]</code> <p>The score associated with the <code>Track</code> assignment. This is typically the value from the score matrix used in an identity assignment. This is <code>None</code> if the instance is not associated with a track or if the track was assigned manually.</p> <code>None</code> <code>from_predicted</code> <code>Optional[PredictedInstance]</code> <p>The <code>PredictedInstance</code> (if any) that this instance was initialized from. This is used with human-in-the-loop workflows.</p> <code>None</code> <p>Returns:</p> Type Description <code>'Instance'</code> <p>An <code>Instance</code> object with the specified points.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>@classmethod\ndef from_numpy(\n    cls,\n    points_data: np.ndarray,\n    skeleton: Skeleton,\n    track: Optional[Track] = None,\n    tracking_score: Optional[float] = None,\n    from_predicted: Optional[PredictedInstance] = None,\n) -&gt; \"Instance\":\n    \"\"\"Create an instance object from a numpy array.\n\n    Args:\n        points_data: A numpy array of shape `(n_nodes, D)` corresponding to the\n            points of the skeleton. Values of `np.nan` indicate \"missing\" nodes and\n            will be reflected in the \"visible\" field.\n\n            If `D == 2`, the array should have columns for x and y.\n            If `D == 3`, the array should have columns for x, y and visible.\n            If `D == 4`, the array should have columns for x, y, visible and\n            complete.\n\n            If this is provided as a structured array, it will be used without copy\n            if it has the correct dtype. Otherwise, a new structured array will be\n            created reusing the provided data.\n        skeleton: The `Skeleton` that this `Instance` is associated with. It should\n            have `n_nodes` nodes.\n        track: An optional `Track` associated with a unique animal/object across\n            frames or videos.\n        tracking_score: The score associated with the `Track` assignment. This is\n            typically the value from the score matrix used in an identity\n            assignment. This is `None` if the instance is not associated with a\n            track or if the track was assigned manually.\n        from_predicted: The `PredictedInstance` (if any) that this instance was\n            initialized from. This is used with human-in-the-loop workflows.\n\n    Returns:\n        An `Instance` object with the specified points.\n    \"\"\"\n    return cls(\n        points=points_data,\n        skeleton=skeleton,\n        track=track,\n        tracking_score=tracking_score,\n        from_predicted=from_predicted,\n    )\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Instance.numpy","title":"<code>numpy(invisible_as_nan=True)</code>","text":"<p>Return the instance points as a <code>(n_nodes, 2)</code> numpy array.</p> <p>Parameters:</p> Name Type Description Default <code>invisible_as_nan</code> <code>bool</code> <p>If <code>True</code> (the default), points that are not visible will be set to <code>np.nan</code>. If <code>False</code>, they will be whatever the stored value of <code>Instance.points[\"xy\"]</code> is.</p> <code>True</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>A numpy array of shape <code>(n_nodes, 2)</code> corresponding to the points of the skeleton. Values of <code>np.nan</code> indicate \"missing\" nodes.</p> Notes <p>This will always return a copy of the array.</p> <p>If you need to avoid making a copy, just access the <code>Instance.points[\"xy\"]</code> attribute directly. This will not replace invisible points with <code>np.nan</code>.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>def numpy(\n    self,\n    invisible_as_nan: bool = True,\n) -&gt; np.ndarray:\n    \"\"\"Return the instance points as a `(n_nodes, 2)` numpy array.\n\n    Args:\n        invisible_as_nan: If `True` (the default), points that are not visible will\n            be set to `np.nan`. If `False`, they will be whatever the stored value\n            of `Instance.points[\"xy\"]` is.\n\n    Returns:\n        A numpy array of shape `(n_nodes, 2)` corresponding to the points of the\n        skeleton. Values of `np.nan` indicate \"missing\" nodes.\n\n    Notes:\n        This will always return a copy of the array.\n\n        If you need to avoid making a copy, just access the `Instance.points[\"xy\"]`\n        attribute directly. This will not replace invisible points with `np.nan`.\n    \"\"\"\n    if invisible_as_nan:\n        return np.where(\n            self.points[\"visible\"].reshape(-1, 1), self.points[\"xy\"], np.nan\n        )\n    else:\n        return self.points[\"xy\"].copy()\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Instance.overlaps_with","title":"<code>overlaps_with(other, iou_threshold=0.5)</code>","text":"<p>Check if this instance overlaps with another based on bounding box IoU.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>'Instance'</code> <p>Another instance to compare with.</p> required <code>iou_threshold</code> <code>float</code> <p>Minimum IoU (Intersection over Union) value to consider the instances as overlapping.</p> <code>0.5</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if the instances overlap above the threshold, False otherwise.</p> Notes <p>Overlap is computed using the bounding boxes of visible points. If either instance has no visible points, they don't overlap.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>def overlaps_with(self, other: \"Instance\", iou_threshold: float = 0.5) -&gt; bool:\n    \"\"\"Check if this instance overlaps with another based on bounding box IoU.\n\n    Args:\n        other: Another instance to compare with.\n        iou_threshold: Minimum IoU (Intersection over Union) value to consider\n            the instances as overlapping.\n\n    Returns:\n        True if the instances overlap above the threshold, False otherwise.\n\n    Notes:\n        Overlap is computed using the bounding boxes of visible points.\n        If either instance has no visible points, they don't overlap.\n    \"\"\"\n    # Get visible points for both instances\n    self_visible = self.points[\"visible\"]\n    other_visible = other.points[\"visible\"]\n\n    if not self_visible.any() or not other_visible.any():\n        return False\n\n    # Calculate bounding boxes\n    self_pts = self.points[\"xy\"][self_visible]\n    other_pts = other.points[\"xy\"][other_visible]\n\n    self_bbox = np.array(\n        [\n            [np.min(self_pts[:, 0]), np.min(self_pts[:, 1])],  # min x, y\n            [np.max(self_pts[:, 0]), np.max(self_pts[:, 1])],  # max x, y\n        ]\n    )\n\n    other_bbox = np.array(\n        [\n            [np.min(other_pts[:, 0]), np.min(other_pts[:, 1])],\n            [np.max(other_pts[:, 0]), np.max(other_pts[:, 1])],\n        ]\n    )\n\n    # Calculate intersection\n    intersection_min = np.maximum(self_bbox[0], other_bbox[0])\n    intersection_max = np.minimum(self_bbox[1], other_bbox[1])\n\n    if np.any(intersection_min &gt;= intersection_max):\n        # No intersection\n        return False\n\n    intersection_area = np.prod(intersection_max - intersection_min)\n\n    # Calculate union\n    self_area = np.prod(self_bbox[1] - self_bbox[0])\n    other_area = np.prod(other_bbox[1] - other_bbox[0])\n    union_area = self_area + other_area - intersection_area\n\n    # Calculate IoU\n    iou = intersection_area / union_area if union_area &gt; 0 else 0\n\n    return iou &gt;= iou_threshold\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Instance.replace_skeleton","title":"<code>replace_skeleton(new_skeleton, node_names_map=None)</code>","text":"<p>Replace the skeleton associated with the instance.</p> <p>Parameters:</p> Name Type Description Default <code>new_skeleton</code> <code>Skeleton</code> <p>The new <code>Skeleton</code> to associate with the instance.</p> required <code>node_names_map</code> <code>dict[str, str] | None</code> <p>Dictionary mapping nodes in the old skeleton to nodes in the new skeleton. Keys and values should be specified as lists of strings. If not provided, only nodes with identical names will be mapped. Points associated with unmapped nodes will be removed.</p> <code>None</code> Notes <p>This method will update the <code>Instance.skeleton</code> attribute and the <code>Instance.points</code> attribute in place (a copy is made of the points array).</p> <p>It is recommended to use <code>Labels.replace_skeleton</code> instead of this method if more flexible node mapping is required.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>def replace_skeleton(\n    self,\n    new_skeleton: Skeleton,\n    node_names_map: dict[str, str] | None = None,\n):\n    \"\"\"Replace the skeleton associated with the instance.\n\n    Args:\n        new_skeleton: The new `Skeleton` to associate with the instance.\n        node_names_map: Dictionary mapping nodes in the old skeleton to nodes in the\n            new skeleton. Keys and values should be specified as lists of strings.\n            If not provided, only nodes with identical names will be mapped. Points\n            associated with unmapped nodes will be removed.\n\n    Notes:\n        This method will update the `Instance.skeleton` attribute and the\n        `Instance.points` attribute in place (a copy is made of the points array).\n\n        It is recommended to use `Labels.replace_skeleton` instead of this method if\n        more flexible node mapping is required.\n    \"\"\"\n    # Update skeleton object.\n    # old_skeleton = self.skeleton\n    self.skeleton = new_skeleton\n\n    # Get node names with replacements from node map if possible.\n    # old_node_names = old_skeleton.node_names\n    old_node_names = self.points[\"name\"].tolist()\n    if node_names_map is not None:\n        old_node_names = [node_names_map.get(node, node) for node in old_node_names]\n\n    # Find correspondences.\n    new_node_inds, old_node_inds = self.skeleton.match_nodes(old_node_names)\n    # old_node_inds = np.array(old_node_inds).reshape(-1, 1)\n    # new_node_inds = np.array(new_node_inds).reshape(-1, 1)\n\n    # Update the points.\n    new_points = PointsArray.empty(len(self.skeleton))\n    new_points[new_node_inds] = self.points[old_node_inds]\n    self.points = new_points\n    self.points[\"name\"] = self.skeleton.node_names\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Instance.same_identity_as","title":"<code>same_identity_as(other)</code>","text":"<p>Check if this instance has the same identity (track) as another instance.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>'Instance'</code> <p>Another instance to compare with.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if both instances have the same track identity, False otherwise.</p> Notes <p>Instances have the same identity if they share the same Track object (by identity, not just by name).</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>def same_identity_as(self, other: \"Instance\") -&gt; bool:\n    \"\"\"Check if this instance has the same identity (track) as another instance.\n\n    Args:\n        other: Another instance to compare with.\n\n    Returns:\n        True if both instances have the same track identity, False otherwise.\n\n    Notes:\n        Instances have the same identity if they share the same Track object\n        (by identity, not just by name).\n    \"\"\"\n    if self.track is None or other.track is None:\n        return False\n    return self.track is other.track\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Instance.same_pose_as","title":"<code>same_pose_as(other, tolerance=5.0)</code>","text":"<p>Check if this instance has the same pose as another instance.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>'Instance'</code> <p>Another instance to compare with.</p> required <code>tolerance</code> <code>float</code> <p>Maximum distance (in pixels) between corresponding points for them to be considered the same.</p> <code>5.0</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if the instances have the same pose within tolerance, False otherwise.</p> Notes <p>Two instances are considered to have the same pose if: - They have the same skeleton structure - All visible points are within the tolerance distance - They have the same visibility pattern</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>def same_pose_as(self, other: \"Instance\", tolerance: float = 5.0) -&gt; bool:\n    \"\"\"Check if this instance has the same pose as another instance.\n\n    Args:\n        other: Another instance to compare with.\n        tolerance: Maximum distance (in pixels) between corresponding points\n            for them to be considered the same.\n\n    Returns:\n        True if the instances have the same pose within tolerance, False otherwise.\n\n    Notes:\n        Two instances are considered to have the same pose if:\n        - They have the same skeleton structure\n        - All visible points are within the tolerance distance\n        - They have the same visibility pattern\n    \"\"\"\n    # Check skeleton compatibility\n    if not self.skeleton.matches(other.skeleton):\n        return False\n\n    # Get visible points for both instances\n    self_visible = self.points[\"visible\"]\n    other_visible = other.points[\"visible\"]\n\n    # Check if visibility patterns match\n    if not np.array_equal(self_visible, other_visible):\n        return False\n\n    # Compare visible points\n    if not self_visible.any():\n        # Both instances have no visible points\n        return True\n\n    # Calculate distances between corresponding visible points\n    self_pts = self.points[\"xy\"][self_visible]\n    other_pts = other.points[\"xy\"][other_visible]\n\n    distances = np.linalg.norm(self_pts - other_pts, axis=1)\n\n    return np.all(distances &lt;= tolerance)\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Instance.update_skeleton","title":"<code>update_skeleton(names_only=False)</code>","text":"<p>Update or replace the skeleton associated with the instance.</p> <p>Parameters:</p> Name Type Description Default <code>names_only</code> <code>bool</code> <p>If <code>True</code>, only update the node names in the points array. If <code>False</code>, the points array will be updated to match the new skeleton.</p> <code>False</code> Source code in <code>sleap_io/model/instance.py</code> <pre><code>def update_skeleton(self, names_only: bool = False):\n    \"\"\"Update or replace the skeleton associated with the instance.\n\n    Args:\n        names_only: If `True`, only update the node names in the points array. If\n            `False`, the points array will be updated to match the new skeleton.\n    \"\"\"\n    if names_only:\n        # Update the node names.\n        self.points[\"name\"] = self.skeleton.node_names\n        return\n\n    # Find correspondences.\n    new_node_inds, old_node_inds = self.skeleton.match_nodes(self.points[\"name\"])\n\n    # Update the points.\n    new_points = PointsArray.empty(len(self.skeleton))\n    new_points[new_node_inds] = self.points[old_node_inds]\n    new_points[\"name\"] = self.skeleton.node_names\n    self.points = new_points\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.InstanceGroup","title":"<code>InstanceGroup</code>","text":"<p>Defines a group of instances across the same frame index.</p> <p>Attributes:</p> Name Type Description <code>instances_by_camera</code> <p>Dictionary of <code>Instance</code> objects by <code>Camera</code>.</p> <code>instances</code> <code>list[Instance]</code> <p>List of <code>Instance</code> objects in the group.</p> <code>cameras</code> <code>list[Camera]</code> <p>List of <code>Camera</code> objects that have an <code>Instance</code> associated.</p> <code>score</code> <code>float | None</code> <p>Optional score for the <code>InstanceGroup</code>. Setting the score will also update the score for all <code>instances</code> already in the <code>InstanceGroup</code>. The score for <code>instances</code> will not be updated upon initialization.</p> <code>points</code> <code>ndarray | None</code> <p>Optional 3D points for the <code>InstanceGroup</code>.</p> <code>metadata</code> <code>dict</code> <p>Dictionary of metadata.</p> <p>Methods:</p> Name Description <code>__repr__</code> <p>Return a readable representation of the instance group.</p> <code>get_instance</code> <p>Get <code>Instance</code> associated with <code>camera</code>.</p> Source code in <code>sleap_io/model/camera.py</code> <pre><code>@define(eq=False)  # Set eq to false to make class hashable\nclass InstanceGroup:\n    \"\"\"Defines a group of instances across the same frame index.\n\n    Attributes:\n        instances_by_camera: Dictionary of `Instance` objects by `Camera`.\n        instances: List of `Instance` objects in the group.\n        cameras: List of `Camera` objects that have an `Instance` associated.\n        score: Optional score for the `InstanceGroup`. Setting the score will also\n            update the score for all `instances` already in the `InstanceGroup`. The\n            score for `instances` will not be updated upon initialization.\n        points: Optional 3D points for the `InstanceGroup`.\n        metadata: Dictionary of metadata.\n    \"\"\"\n\n    _instance_by_camera: dict[Camera, Instance] = field(\n        factory=dict, validator=instance_of(dict)\n    )\n    _score: float | None = field(\n        default=None, converter=attrs.converters.optional(float)\n    )\n    _points: np.ndarray | None = field(\n        default=None,\n        converter=attrs.converters.optional(lambda x: np.array(x, dtype=\"float64\")),\n    )\n    metadata: dict = field(factory=dict, validator=instance_of(dict))\n\n    @property\n    def instance_by_camera(self) -&gt; dict[Camera, Instance]:\n        \"\"\"Get dictionary of `Instance` objects by `Camera`.\"\"\"\n        return self._instance_by_camera\n\n    @property\n    def instances(self) -&gt; list[Instance]:\n        \"\"\"List of `Instance` objects.\"\"\"\n        return list(self._instance_by_camera.values())\n\n    @property\n    def cameras(self) -&gt; list[Camera]:\n        \"\"\"List of `Camera` objects.\"\"\"\n        return list(self._instance_by_camera.keys())\n\n    @property\n    def score(self) -&gt; float | None:\n        \"\"\"Get score for `InstanceGroup`.\"\"\"\n        return self._score\n\n    @property\n    def points(self) -&gt; np.ndarray | None:\n        \"\"\"Get 3D points for `InstanceGroup`.\"\"\"\n        return self._points\n\n    def get_instance(self, camera: Camera) -&gt; Instance | None:\n        \"\"\"Get `Instance` associated with `camera`.\n\n        Args:\n            camera: `Camera` to get `Instance`.\n\n        Returns:\n            `Instance` associated with `camera` or None if not found.\n        \"\"\"\n        return self._instance_by_camera.get(camera, None)\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return a readable representation of the instance group.\"\"\"\n        cameras_str = \", \".join([c.name or \"None\" for c in self.cameras])\n        return f\"InstanceGroup(cameras={len(self.cameras)}:[{cameras_str}])\"\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.InstanceGroup.cameras","title":"<code>cameras</code>  <code>property</code>","text":"<p>List of <code>Camera</code> objects.</p>"},{"location":"reference/sleap_io/#sleap_io.InstanceGroup.instance_by_camera","title":"<code>instance_by_camera</code>  <code>property</code>","text":"<p>Get dictionary of <code>Instance</code> objects by <code>Camera</code>.</p>"},{"location":"reference/sleap_io/#sleap_io.InstanceGroup.instances","title":"<code>instances</code>  <code>property</code>","text":"<p>List of <code>Instance</code> objects.</p>"},{"location":"reference/sleap_io/#sleap_io.InstanceGroup.points","title":"<code>points</code>  <code>property</code>","text":"<p>Get 3D points for <code>InstanceGroup</code>.</p>"},{"location":"reference/sleap_io/#sleap_io.InstanceGroup.score","title":"<code>score</code>  <code>property</code>","text":"<p>Get score for <code>InstanceGroup</code>.</p>"},{"location":"reference/sleap_io/#sleap_io.InstanceGroup.__repr__","title":"<code>__repr__()</code>","text":"<p>Return a readable representation of the instance group.</p> Source code in <code>sleap_io/model/camera.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return a readable representation of the instance group.\"\"\"\n    cameras_str = \", \".join([c.name or \"None\" for c in self.cameras])\n    return f\"InstanceGroup(cameras={len(self.cameras)}:[{cameras_str}])\"\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.InstanceGroup.get_instance","title":"<code>get_instance(camera)</code>","text":"<p>Get <code>Instance</code> associated with <code>camera</code>.</p> <p>Parameters:</p> Name Type Description Default <code>camera</code> <code>Camera</code> <p><code>Camera</code> to get <code>Instance</code>.</p> required <p>Returns:</p> Type Description <code>Instance | None</code> <p><code>Instance</code> associated with <code>camera</code> or None if not found.</p> Source code in <code>sleap_io/model/camera.py</code> <pre><code>def get_instance(self, camera: Camera) -&gt; Instance | None:\n    \"\"\"Get `Instance` associated with `camera`.\n\n    Args:\n        camera: `Camera` to get `Instance`.\n\n    Returns:\n        `Instance` associated with `camera` or None if not found.\n    \"\"\"\n    return self._instance_by_camera.get(camera, None)\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.LabeledFrame","title":"<code>LabeledFrame</code>","text":"<p>Labeled data for a single frame of a video.</p> <p>Attributes:</p> Name Type Description <code>video</code> <code>Video</code> <p>The <code>Video</code> associated with this <code>LabeledFrame</code>.</p> <code>frame_idx</code> <code>int</code> <p>The index of the <code>LabeledFrame</code> in the <code>Video</code>.</p> <code>instances</code> <code>list[Union[Instance, PredictedInstance]]</code> <p>List of <code>Instance</code> objects associated with this <code>LabeledFrame</code>.</p> Notes <p>Instances of this class are hashed by identity, not by value. This means that two <code>LabeledFrame</code> instances with the same attributes will NOT be considered equal in a set or dict.</p> <p>Methods:</p> Name Description <code>__getitem__</code> <p>Return the <code>Instance</code> at <code>key</code> index in the <code>instances</code> list.</p> <code>__iter__</code> <p>Iterate over <code>Instance</code>s in <code>instances</code> list.</p> <code>__len__</code> <p>Return the number of instances in the frame.</p> <code>matches</code> <p>Check if this frame matches another frame's identity.</p> <code>merge</code> <p>Merge instances from another frame into this frame.</p> <code>numpy</code> <p>Return all instances in the frame as a numpy array.</p> <code>remove_empty_instances</code> <p>Remove all instances with no visible points.</p> <code>remove_predictions</code> <p>Remove all <code>PredictedInstance</code> objects from the frame.</p> <code>similarity_to</code> <p>Calculate instance overlap metrics with another frame.</p> Source code in <code>sleap_io/model/labeled_frame.py</code> <pre><code>@define(eq=False)\nclass LabeledFrame:\n    \"\"\"Labeled data for a single frame of a video.\n\n    Attributes:\n        video: The `Video` associated with this `LabeledFrame`.\n        frame_idx: The index of the `LabeledFrame` in the `Video`.\n        instances: List of `Instance` objects associated with this `LabeledFrame`.\n\n    Notes:\n        Instances of this class are hashed by identity, not by value. This means that\n        two `LabeledFrame` instances with the same attributes will NOT be considered\n        equal in a set or dict.\n    \"\"\"\n\n    video: Video\n    frame_idx: int = field(converter=int)\n    instances: list[Union[Instance, PredictedInstance]] = field(factory=list)\n\n    def __len__(self) -&gt; int:\n        \"\"\"Return the number of instances in the frame.\"\"\"\n        return len(self.instances)\n\n    def __getitem__(self, key: int) -&gt; Union[Instance, PredictedInstance]:\n        \"\"\"Return the `Instance` at `key` index in the `instances` list.\"\"\"\n        return self.instances[key]\n\n    def __iter__(self):\n        \"\"\"Iterate over `Instance`s in `instances` list.\"\"\"\n        return iter(self.instances)\n\n    @property\n    def user_instances(self) -&gt; list[Instance]:\n        \"\"\"Frame instances that are user-labeled (`Instance` objects).\"\"\"\n        return [inst for inst in self.instances if type(inst) is Instance]\n\n    @property\n    def has_user_instances(self) -&gt; bool:\n        \"\"\"Return True if the frame has any user-labeled instances.\"\"\"\n        for inst in self.instances:\n            if type(inst) is Instance:\n                return True\n        return False\n\n    @property\n    def predicted_instances(self) -&gt; list[Instance]:\n        \"\"\"Frame instances that are predicted by a model (`PredictedInstance`).\"\"\"\n        return [inst for inst in self.instances if type(inst) is PredictedInstance]\n\n    @property\n    def has_predicted_instances(self) -&gt; bool:\n        \"\"\"Return True if the frame has any predicted instances.\"\"\"\n        for inst in self.instances:\n            if type(inst) is PredictedInstance:\n                return True\n        return False\n\n    def numpy(self) -&gt; np.ndarray:\n        \"\"\"Return all instances in the frame as a numpy array.\n\n        Returns:\n            Points as a numpy array of shape `(n_instances, n_nodes, 2)`.\n\n            Note that the order of the instances is arbitrary.\n        \"\"\"\n        n_instances = len(self.instances)\n        n_nodes = len(self.instances[0]) if n_instances &gt; 0 else 0\n        pts = np.full((n_instances, n_nodes, 2), np.nan)\n        for i, inst in enumerate(self.instances):\n            pts[i] = inst.numpy()[:, 0:2]\n        return pts\n\n    @property\n    def image(self) -&gt; np.ndarray:\n        \"\"\"Return the image of the frame as a numpy array.\"\"\"\n        return self.video[self.frame_idx]\n\n    @property\n    def unused_predictions(self) -&gt; list[Instance]:\n        \"\"\"Return a list of \"unused\" `PredictedInstance` objects in frame.\n\n        This is all of the `PredictedInstance` objects which do not have a corresponding\n        `Instance` in the same track in the same frame.\n        \"\"\"\n        unused_predictions = []\n        any_tracks = [inst.track for inst in self.instances if inst.track is not None]\n        if len(any_tracks):\n            # Use tracks to determine which predicted instances have been used\n            used_tracks = [\n                inst.track\n                for inst in self.instances\n                if type(inst) is Instance and inst.track is not None\n            ]\n            unused_predictions = [\n                inst\n                for inst in self.instances\n                if inst.track not in used_tracks and type(inst) is PredictedInstance\n            ]\n\n        else:\n            # Use from_predicted to determine which predicted instances have been used\n            # TODO: should we always do this instead of using tracks?\n            used_instances = [\n                inst.from_predicted\n                for inst in self.instances\n                if inst.from_predicted is not None\n            ]\n            unused_predictions = [\n                inst\n                for inst in self.instances\n                if type(inst) is PredictedInstance and inst not in used_instances\n            ]\n\n        return unused_predictions\n\n    def remove_predictions(self):\n        \"\"\"Remove all `PredictedInstance` objects from the frame.\"\"\"\n        self.instances = [inst for inst in self.instances if type(inst) is Instance]\n\n    def remove_empty_instances(self):\n        \"\"\"Remove all instances with no visible points.\"\"\"\n        self.instances = [inst for inst in self.instances if not inst.is_empty]\n\n    def matches(self, other: \"LabeledFrame\", video_must_match: bool = True) -&gt; bool:\n        \"\"\"Check if this frame matches another frame's identity.\n\n        Args:\n            other: Another LabeledFrame to compare with.\n            video_must_match: If True, frames must be from the same video.\n                If False, only frame index needs to match.\n\n        Returns:\n            True if the frames have the same identity, False otherwise.\n\n        Notes:\n            Frame identity is determined by video and frame index.\n            This does not compare the instances within the frame.\n        \"\"\"\n        if self.frame_idx != other.frame_idx:\n            return False\n\n        if video_must_match:\n            # Check if videos are the same object\n            if self.video is other.video:\n                return True\n            # Check if videos have matching paths\n            return self.video.matches_path(other.video, strict=False)\n\n        return True\n\n    def similarity_to(self, other: \"LabeledFrame\") -&gt; dict[str, any]:\n        \"\"\"Calculate instance overlap metrics with another frame.\n\n        Args:\n            other: Another LabeledFrame to compare with.\n\n        Returns:\n            A dictionary with similarity metrics:\n            - 'n_user_self': Number of user instances in this frame\n            - 'n_user_other': Number of user instances in the other frame\n            - 'n_pred_self': Number of predicted instances in this frame\n            - 'n_pred_other': Number of predicted instances in the other frame\n            - 'n_overlapping': Number of instances that overlap (by IoU)\n            - 'mean_pose_distance': Mean distance between matching poses\n        \"\"\"\n        metrics = {\n            \"n_user_self\": len(self.user_instances),\n            \"n_user_other\": len(other.user_instances),\n            \"n_pred_self\": len(self.predicted_instances),\n            \"n_pred_other\": len(other.predicted_instances),\n            \"n_overlapping\": 0,\n            \"mean_pose_distance\": None,\n        }\n\n        # Count overlapping instances and compute pose distances\n        pose_distances = []\n        for inst1 in self.instances:\n            for inst2 in other.instances:\n                # Check if instances overlap\n                if inst1.overlaps_with(inst2, iou_threshold=0.1):\n                    metrics[\"n_overlapping\"] += 1\n\n                    # If they have the same skeleton, compute pose distance\n                    if inst1.skeleton.matches(inst2.skeleton):\n                        # Get visible points for both\n                        pts1 = inst1.numpy()\n                        pts2 = inst2.numpy()\n\n                        # Compute distances for visible points in both\n                        valid = ~(np.isnan(pts1[:, 0]) | np.isnan(pts2[:, 0]))\n                        if valid.any():\n                            distances = np.linalg.norm(\n                                pts1[valid] - pts2[valid], axis=1\n                            )\n                            pose_distances.extend(distances.tolist())\n\n        if pose_distances:\n            metrics[\"mean_pose_distance\"] = np.mean(pose_distances)\n\n        return metrics\n\n    def merge(\n        self,\n        other: \"LabeledFrame\",\n        instance_matcher: Optional[\"InstanceMatcher\"] = None,\n        strategy: str = \"smart\",\n    ) -&gt; tuple[list[Instance], list[tuple[Instance, Instance, str]]]:\n        \"\"\"Merge instances from another frame into this frame.\n\n        Args:\n            other: Another LabeledFrame to merge instances from.\n            instance_matcher: Matcher to use for finding duplicate instances.\n                If None, uses default spatial matching with 5px tolerance.\n            strategy: Merge strategy:\n                - \"smart\": Keep user labels, update predictions only if no user label\n                - \"keep_original\": Keep all original instances, ignore new ones\n                - \"keep_new\": Replace with new instances\n                - \"keep_both\": Keep all instances from both frames\n\n        Returns:\n            A tuple of (merged_instances, conflicts) where:\n            - merged_instances: List of instances after merging\n            - conflicts: List of (original, new, resolution) tuples for conflicts\n\n        Notes:\n            This method doesn't modify the frame in place. It returns the merged\n            instance list which can be assigned back if desired.\n        \"\"\"\n        from sleap_io.model.matching import InstanceMatcher, InstanceMatchMethod\n\n        if instance_matcher is None:\n            instance_matcher = InstanceMatcher(\n                method=InstanceMatchMethod.SPATIAL, threshold=5.0\n            )\n\n        conflicts = []\n\n        if strategy == \"keep_original\":\n            return self.instances.copy(), conflicts\n        elif strategy == \"keep_new\":\n            return other.instances.copy(), conflicts\n        elif strategy == \"keep_both\":\n            return self.instances + other.instances, conflicts\n\n        # Smart merging strategy\n        merged_instances = []\n        used_indices = set()\n\n        # First, keep all user instances from self\n        for inst in self.instances:\n            if type(inst) is Instance:\n                merged_instances.append(inst)\n\n        # Find matches between instances\n        matches = instance_matcher.find_matches(self.instances, other.instances)\n\n        # Group matches by instance in other frame\n        other_to_self = {}\n        for self_idx, other_idx, score in matches:\n            if other_idx not in other_to_self or score &gt; other_to_self[other_idx][1]:\n                other_to_self[other_idx] = (self_idx, score)\n\n        # Process instances from other frame\n        for other_idx, other_inst in enumerate(other.instances):\n            if other_idx in other_to_self:\n                self_idx, score = other_to_self[other_idx]\n                self_inst = self.instances[self_idx]\n\n                # Check for conflicts\n                if type(self_inst) is Instance and type(other_inst) is Instance:\n                    # Both are user instances - conflict\n                    conflicts.append((self_inst, other_inst, \"kept_original\"))\n                    used_indices.add(self_idx)\n                elif (\n                    type(self_inst) is PredictedInstance\n                    and type(other_inst) is Instance\n                ):\n                    # Replace prediction with user instance\n                    if self_idx not in used_indices:\n                        merged_instances.append(other_inst)\n                        used_indices.add(self_idx)\n                elif (\n                    type(self_inst) is Instance\n                    and type(other_inst) is PredictedInstance\n                ):\n                    # Keep user instance, ignore prediction\n                    conflicts.append((self_inst, other_inst, \"kept_user\"))\n                    used_indices.add(self_idx)\n                else:\n                    # Both are predictions - keep the one with higher score\n                    if self_idx not in used_indices:\n                        if hasattr(other_inst, \"score\") and hasattr(self_inst, \"score\"):\n                            if other_inst.score &gt; self_inst.score:\n                                merged_instances.append(other_inst)\n                            else:\n                                merged_instances.append(self_inst)\n                        else:\n                            merged_instances.append(other_inst)\n                        used_indices.add(self_idx)\n            else:\n                # No match found, add new instance\n                merged_instances.append(other_inst)\n\n        # Add remaining instances from self that weren't matched\n        for self_idx, self_inst in enumerate(self.instances):\n            if type(self_inst) is PredictedInstance and self_idx not in used_indices:\n                # Check if this prediction should be kept\n                # NOTE: This defensive logic should be unreachable under normal\n                # circumstances since all matched instances should have been added to\n                # used_indices above. However, we keep this as a safety net for edge\n                # cases or future changes.\n                keep = True\n                for other_idx, (matched_self_idx, _) in other_to_self.items():\n                    if matched_self_idx == self_idx:\n                        keep = False\n                        break\n                if keep:\n                    merged_instances.append(self_inst)\n\n        return merged_instances, conflicts\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.LabeledFrame.has_predicted_instances","title":"<code>has_predicted_instances</code>  <code>property</code>","text":"<p>Return True if the frame has any predicted instances.</p>"},{"location":"reference/sleap_io/#sleap_io.LabeledFrame.has_user_instances","title":"<code>has_user_instances</code>  <code>property</code>","text":"<p>Return True if the frame has any user-labeled instances.</p>"},{"location":"reference/sleap_io/#sleap_io.LabeledFrame.image","title":"<code>image</code>  <code>property</code>","text":"<p>Return the image of the frame as a numpy array.</p>"},{"location":"reference/sleap_io/#sleap_io.LabeledFrame.predicted_instances","title":"<code>predicted_instances</code>  <code>property</code>","text":"<p>Frame instances that are predicted by a model (<code>PredictedInstance</code>).</p>"},{"location":"reference/sleap_io/#sleap_io.LabeledFrame.unused_predictions","title":"<code>unused_predictions</code>  <code>property</code>","text":"<p>Return a list of \"unused\" <code>PredictedInstance</code> objects in frame.</p> <p>This is all of the <code>PredictedInstance</code> objects which do not have a corresponding <code>Instance</code> in the same track in the same frame.</p>"},{"location":"reference/sleap_io/#sleap_io.LabeledFrame.user_instances","title":"<code>user_instances</code>  <code>property</code>","text":"<p>Frame instances that are user-labeled (<code>Instance</code> objects).</p>"},{"location":"reference/sleap_io/#sleap_io.LabeledFrame.__getitem__","title":"<code>__getitem__(key)</code>","text":"<p>Return the <code>Instance</code> at <code>key</code> index in the <code>instances</code> list.</p> Source code in <code>sleap_io/model/labeled_frame.py</code> <pre><code>def __getitem__(self, key: int) -&gt; Union[Instance, PredictedInstance]:\n    \"\"\"Return the `Instance` at `key` index in the `instances` list.\"\"\"\n    return self.instances[key]\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.LabeledFrame.__iter__","title":"<code>__iter__()</code>","text":"<p>Iterate over <code>Instance</code>s in <code>instances</code> list.</p> Source code in <code>sleap_io/model/labeled_frame.py</code> <pre><code>def __iter__(self):\n    \"\"\"Iterate over `Instance`s in `instances` list.\"\"\"\n    return iter(self.instances)\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.LabeledFrame.__len__","title":"<code>__len__()</code>","text":"<p>Return the number of instances in the frame.</p> Source code in <code>sleap_io/model/labeled_frame.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"Return the number of instances in the frame.\"\"\"\n    return len(self.instances)\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.LabeledFrame.matches","title":"<code>matches(other, video_must_match=True)</code>","text":"<p>Check if this frame matches another frame's identity.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>'LabeledFrame'</code> <p>Another LabeledFrame to compare with.</p> required <code>video_must_match</code> <code>bool</code> <p>If True, frames must be from the same video. If False, only frame index needs to match.</p> <code>True</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if the frames have the same identity, False otherwise.</p> Notes <p>Frame identity is determined by video and frame index. This does not compare the instances within the frame.</p> Source code in <code>sleap_io/model/labeled_frame.py</code> <pre><code>def matches(self, other: \"LabeledFrame\", video_must_match: bool = True) -&gt; bool:\n    \"\"\"Check if this frame matches another frame's identity.\n\n    Args:\n        other: Another LabeledFrame to compare with.\n        video_must_match: If True, frames must be from the same video.\n            If False, only frame index needs to match.\n\n    Returns:\n        True if the frames have the same identity, False otherwise.\n\n    Notes:\n        Frame identity is determined by video and frame index.\n        This does not compare the instances within the frame.\n    \"\"\"\n    if self.frame_idx != other.frame_idx:\n        return False\n\n    if video_must_match:\n        # Check if videos are the same object\n        if self.video is other.video:\n            return True\n        # Check if videos have matching paths\n        return self.video.matches_path(other.video, strict=False)\n\n    return True\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.LabeledFrame.merge","title":"<code>merge(other, instance_matcher=None, strategy='smart')</code>","text":"<p>Merge instances from another frame into this frame.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>'LabeledFrame'</code> <p>Another LabeledFrame to merge instances from.</p> required <code>instance_matcher</code> <code>Optional['InstanceMatcher']</code> <p>Matcher to use for finding duplicate instances. If None, uses default spatial matching with 5px tolerance.</p> <code>None</code> <code>strategy</code> <code>str</code> <p>Merge strategy: - \"smart\": Keep user labels, update predictions only if no user label - \"keep_original\": Keep all original instances, ignore new ones - \"keep_new\": Replace with new instances - \"keep_both\": Keep all instances from both frames</p> <code>'smart'</code> <p>Returns:</p> Type Description <code>tuple[list[Instance], list[tuple[Instance, Instance, str]]]</code> <p>A tuple of (merged_instances, conflicts) where: - merged_instances: List of instances after merging - conflicts: List of (original, new, resolution) tuples for conflicts</p> Notes <p>This method doesn't modify the frame in place. It returns the merged instance list which can be assigned back if desired.</p> Source code in <code>sleap_io/model/labeled_frame.py</code> <pre><code>def merge(\n    self,\n    other: \"LabeledFrame\",\n    instance_matcher: Optional[\"InstanceMatcher\"] = None,\n    strategy: str = \"smart\",\n) -&gt; tuple[list[Instance], list[tuple[Instance, Instance, str]]]:\n    \"\"\"Merge instances from another frame into this frame.\n\n    Args:\n        other: Another LabeledFrame to merge instances from.\n        instance_matcher: Matcher to use for finding duplicate instances.\n            If None, uses default spatial matching with 5px tolerance.\n        strategy: Merge strategy:\n            - \"smart\": Keep user labels, update predictions only if no user label\n            - \"keep_original\": Keep all original instances, ignore new ones\n            - \"keep_new\": Replace with new instances\n            - \"keep_both\": Keep all instances from both frames\n\n    Returns:\n        A tuple of (merged_instances, conflicts) where:\n        - merged_instances: List of instances after merging\n        - conflicts: List of (original, new, resolution) tuples for conflicts\n\n    Notes:\n        This method doesn't modify the frame in place. It returns the merged\n        instance list which can be assigned back if desired.\n    \"\"\"\n    from sleap_io.model.matching import InstanceMatcher, InstanceMatchMethod\n\n    if instance_matcher is None:\n        instance_matcher = InstanceMatcher(\n            method=InstanceMatchMethod.SPATIAL, threshold=5.0\n        )\n\n    conflicts = []\n\n    if strategy == \"keep_original\":\n        return self.instances.copy(), conflicts\n    elif strategy == \"keep_new\":\n        return other.instances.copy(), conflicts\n    elif strategy == \"keep_both\":\n        return self.instances + other.instances, conflicts\n\n    # Smart merging strategy\n    merged_instances = []\n    used_indices = set()\n\n    # First, keep all user instances from self\n    for inst in self.instances:\n        if type(inst) is Instance:\n            merged_instances.append(inst)\n\n    # Find matches between instances\n    matches = instance_matcher.find_matches(self.instances, other.instances)\n\n    # Group matches by instance in other frame\n    other_to_self = {}\n    for self_idx, other_idx, score in matches:\n        if other_idx not in other_to_self or score &gt; other_to_self[other_idx][1]:\n            other_to_self[other_idx] = (self_idx, score)\n\n    # Process instances from other frame\n    for other_idx, other_inst in enumerate(other.instances):\n        if other_idx in other_to_self:\n            self_idx, score = other_to_self[other_idx]\n            self_inst = self.instances[self_idx]\n\n            # Check for conflicts\n            if type(self_inst) is Instance and type(other_inst) is Instance:\n                # Both are user instances - conflict\n                conflicts.append((self_inst, other_inst, \"kept_original\"))\n                used_indices.add(self_idx)\n            elif (\n                type(self_inst) is PredictedInstance\n                and type(other_inst) is Instance\n            ):\n                # Replace prediction with user instance\n                if self_idx not in used_indices:\n                    merged_instances.append(other_inst)\n                    used_indices.add(self_idx)\n            elif (\n                type(self_inst) is Instance\n                and type(other_inst) is PredictedInstance\n            ):\n                # Keep user instance, ignore prediction\n                conflicts.append((self_inst, other_inst, \"kept_user\"))\n                used_indices.add(self_idx)\n            else:\n                # Both are predictions - keep the one with higher score\n                if self_idx not in used_indices:\n                    if hasattr(other_inst, \"score\") and hasattr(self_inst, \"score\"):\n                        if other_inst.score &gt; self_inst.score:\n                            merged_instances.append(other_inst)\n                        else:\n                            merged_instances.append(self_inst)\n                    else:\n                        merged_instances.append(other_inst)\n                    used_indices.add(self_idx)\n        else:\n            # No match found, add new instance\n            merged_instances.append(other_inst)\n\n    # Add remaining instances from self that weren't matched\n    for self_idx, self_inst in enumerate(self.instances):\n        if type(self_inst) is PredictedInstance and self_idx not in used_indices:\n            # Check if this prediction should be kept\n            # NOTE: This defensive logic should be unreachable under normal\n            # circumstances since all matched instances should have been added to\n            # used_indices above. However, we keep this as a safety net for edge\n            # cases or future changes.\n            keep = True\n            for other_idx, (matched_self_idx, _) in other_to_self.items():\n                if matched_self_idx == self_idx:\n                    keep = False\n                    break\n            if keep:\n                merged_instances.append(self_inst)\n\n    return merged_instances, conflicts\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.LabeledFrame.numpy","title":"<code>numpy()</code>","text":"<p>Return all instances in the frame as a numpy array.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>Points as a numpy array of shape <code>(n_instances, n_nodes, 2)</code>.</p> <p>Note that the order of the instances is arbitrary.</p> Source code in <code>sleap_io/model/labeled_frame.py</code> <pre><code>def numpy(self) -&gt; np.ndarray:\n    \"\"\"Return all instances in the frame as a numpy array.\n\n    Returns:\n        Points as a numpy array of shape `(n_instances, n_nodes, 2)`.\n\n        Note that the order of the instances is arbitrary.\n    \"\"\"\n    n_instances = len(self.instances)\n    n_nodes = len(self.instances[0]) if n_instances &gt; 0 else 0\n    pts = np.full((n_instances, n_nodes, 2), np.nan)\n    for i, inst in enumerate(self.instances):\n        pts[i] = inst.numpy()[:, 0:2]\n    return pts\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.LabeledFrame.remove_empty_instances","title":"<code>remove_empty_instances()</code>","text":"<p>Remove all instances with no visible points.</p> Source code in <code>sleap_io/model/labeled_frame.py</code> <pre><code>def remove_empty_instances(self):\n    \"\"\"Remove all instances with no visible points.\"\"\"\n    self.instances = [inst for inst in self.instances if not inst.is_empty]\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.LabeledFrame.remove_predictions","title":"<code>remove_predictions()</code>","text":"<p>Remove all <code>PredictedInstance</code> objects from the frame.</p> Source code in <code>sleap_io/model/labeled_frame.py</code> <pre><code>def remove_predictions(self):\n    \"\"\"Remove all `PredictedInstance` objects from the frame.\"\"\"\n    self.instances = [inst for inst in self.instances if type(inst) is Instance]\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.LabeledFrame.similarity_to","title":"<code>similarity_to(other)</code>","text":"<p>Calculate instance overlap metrics with another frame.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>'LabeledFrame'</code> <p>Another LabeledFrame to compare with.</p> required <p>Returns:</p> Type Description <code>dict[str, any]</code> <p>A dictionary with similarity metrics: - 'n_user_self': Number of user instances in this frame - 'n_user_other': Number of user instances in the other frame - 'n_pred_self': Number of predicted instances in this frame - 'n_pred_other': Number of predicted instances in the other frame - 'n_overlapping': Number of instances that overlap (by IoU) - 'mean_pose_distance': Mean distance between matching poses</p> Source code in <code>sleap_io/model/labeled_frame.py</code> <pre><code>def similarity_to(self, other: \"LabeledFrame\") -&gt; dict[str, any]:\n    \"\"\"Calculate instance overlap metrics with another frame.\n\n    Args:\n        other: Another LabeledFrame to compare with.\n\n    Returns:\n        A dictionary with similarity metrics:\n        - 'n_user_self': Number of user instances in this frame\n        - 'n_user_other': Number of user instances in the other frame\n        - 'n_pred_self': Number of predicted instances in this frame\n        - 'n_pred_other': Number of predicted instances in the other frame\n        - 'n_overlapping': Number of instances that overlap (by IoU)\n        - 'mean_pose_distance': Mean distance between matching poses\n    \"\"\"\n    metrics = {\n        \"n_user_self\": len(self.user_instances),\n        \"n_user_other\": len(other.user_instances),\n        \"n_pred_self\": len(self.predicted_instances),\n        \"n_pred_other\": len(other.predicted_instances),\n        \"n_overlapping\": 0,\n        \"mean_pose_distance\": None,\n    }\n\n    # Count overlapping instances and compute pose distances\n    pose_distances = []\n    for inst1 in self.instances:\n        for inst2 in other.instances:\n            # Check if instances overlap\n            if inst1.overlaps_with(inst2, iou_threshold=0.1):\n                metrics[\"n_overlapping\"] += 1\n\n                # If they have the same skeleton, compute pose distance\n                if inst1.skeleton.matches(inst2.skeleton):\n                    # Get visible points for both\n                    pts1 = inst1.numpy()\n                    pts2 = inst2.numpy()\n\n                    # Compute distances for visible points in both\n                    valid = ~(np.isnan(pts1[:, 0]) | np.isnan(pts2[:, 0]))\n                    if valid.any():\n                        distances = np.linalg.norm(\n                            pts1[valid] - pts2[valid], axis=1\n                        )\n                        pose_distances.extend(distances.tolist())\n\n    if pose_distances:\n        metrics[\"mean_pose_distance\"] = np.mean(pose_distances)\n\n    return metrics\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Labels","title":"<code>Labels</code>","text":"<p>Pose data for a set of videos that have user labels and/or predictions.</p> <p>Attributes:</p> Name Type Description <code>labeled_frames</code> <code>list[LabeledFrame]</code> <p>A list of <code>LabeledFrame</code>s that are associated with this dataset.</p> <code>videos</code> <code>list[Video]</code> <p>A list of <code>Video</code>s that are associated with this dataset. Videos do not need to have corresponding <code>LabeledFrame</code>s if they do not have any labels or predictions yet.</p> <code>skeletons</code> <code>list[Skeleton]</code> <p>A list of <code>Skeleton</code>s that are associated with this dataset. This should generally only contain a single skeleton.</p> <code>tracks</code> <code>list[Track]</code> <p>A list of <code>Track</code>s that are associated with this dataset.</p> <code>suggestions</code> <code>list[SuggestionFrame]</code> <p>A list of <code>SuggestionFrame</code>s that are associated with this dataset.</p> <code>sessions</code> <code>list[RecordingSession]</code> <p>A list of <code>RecordingSession</code>s that are associated with this dataset.</p> <code>provenance</code> <code>dict[str, Any]</code> <p>Dictionary of arbitrary metadata providing additional information about where the dataset came from.</p> Notes <p><code>Video</code>s in contain <code>LabeledFrame</code>s, and <code>Skeleton</code>s and <code>Track</code>s in contained <code>Instance</code>s are added to the respective lists automatically.</p> <p>Methods:</p> Name Description <code>__attrs_post_init__</code> <p>Append videos, skeletons, and tracks seen in <code>labeled_frames</code> to <code>Labels</code>.</p> <code>__getitem__</code> <p>Return one or more labeled frames based on indexing criteria.</p> <code>__iter__</code> <p>Iterate over <code>labeled_frames</code> list when calling iter method on <code>Labels</code>.</p> <code>__len__</code> <p>Return number of labeled frames.</p> <code>__repr__</code> <p>Return a readable representation of the labels.</p> <code>__str__</code> <p>Return a readable representation of the labels.</p> <code>append</code> <p>Append a labeled frame to the labels.</p> <code>clean</code> <p>Remove empty frames, unused skeletons, tracks and videos.</p> <code>extend</code> <p>Append a labeled frame to the labels.</p> <code>extract</code> <p>Extract a set of frames into a new Labels object.</p> <code>find</code> <p>Search for labeled frames given video and/or frame index.</p> <code>from_numpy</code> <p>Create a new Labels object from a numpy array of tracks.</p> <code>make_training_splits</code> <p>Make splits for training with embedded images.</p> <code>merge</code> <p>Merge another Labels object into this one.</p> <code>numpy</code> <p>Construct a numpy array from instance points.</p> <code>remove_nodes</code> <p>Remove nodes from the skeleton.</p> <code>remove_predictions</code> <p>Remove all predicted instances from the labels.</p> <code>rename_nodes</code> <p>Rename nodes in the skeleton.</p> <code>reorder_nodes</code> <p>Reorder nodes in the skeleton.</p> <code>replace_filenames</code> <p>Replace video filenames.</p> <code>replace_skeleton</code> <p>Replace the skeleton in the labels.</p> <code>replace_videos</code> <p>Replace videos and update all references.</p> <code>save</code> <p>Save labels to file in specified format.</p> <code>set_video_plugin</code> <p>Reopen all media videos with the specified plugin.</p> <code>split</code> <p>Separate the labels into random splits.</p> <code>trim</code> <p>Trim the labels to a subset of frames and videos accordingly.</p> <code>update</code> <p>Update data structures based on contents.</p> <code>update_from_numpy</code> <p>Update instances from a numpy array of tracks.</p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>@define\nclass Labels:\n    \"\"\"Pose data for a set of videos that have user labels and/or predictions.\n\n    Attributes:\n        labeled_frames: A list of `LabeledFrame`s that are associated with this dataset.\n        videos: A list of `Video`s that are associated with this dataset. Videos do not\n            need to have corresponding `LabeledFrame`s if they do not have any\n            labels or predictions yet.\n        skeletons: A list of `Skeleton`s that are associated with this dataset. This\n            should generally only contain a single skeleton.\n        tracks: A list of `Track`s that are associated with this dataset.\n        suggestions: A list of `SuggestionFrame`s that are associated with this dataset.\n        sessions: A list of `RecordingSession`s that are associated with this dataset.\n        provenance: Dictionary of arbitrary metadata providing additional information\n            about where the dataset came from.\n\n    Notes:\n        `Video`s in contain `LabeledFrame`s, and `Skeleton`s and `Track`s in contained\n        `Instance`s are added to the respective lists automatically.\n    \"\"\"\n\n    labeled_frames: list[LabeledFrame] = field(factory=list)\n    videos: list[Video] = field(factory=list)\n    skeletons: list[Skeleton] = field(factory=list)\n    tracks: list[Track] = field(factory=list)\n    suggestions: list[SuggestionFrame] = field(factory=list)\n    sessions: list[RecordingSession] = field(factory=list)\n    provenance: dict[str, Any] = field(factory=dict)\n\n    def __attrs_post_init__(self):\n        \"\"\"Append videos, skeletons, and tracks seen in `labeled_frames` to `Labels`.\"\"\"\n        self.update()\n\n    def update(self):\n        \"\"\"Update data structures based on contents.\n\n        This function will update the list of skeletons, videos and tracks from the\n        labeled frames, instances and suggestions.\n        \"\"\"\n        for lf in self.labeled_frames:\n            if lf.video not in self.videos:\n                self.videos.append(lf.video)\n\n            for inst in lf:\n                if inst.skeleton not in self.skeletons:\n                    self.skeletons.append(inst.skeleton)\n\n                if inst.track is not None and inst.track not in self.tracks:\n                    self.tracks.append(inst.track)\n\n        for sf in self.suggestions:\n            if sf.video not in self.videos:\n                self.videos.append(sf.video)\n\n    def __getitem__(\n        self, key: int | slice | list[int] | np.ndarray | tuple[Video, int]\n    ) -&gt; list[LabeledFrame] | LabeledFrame:\n        \"\"\"Return one or more labeled frames based on indexing criteria.\"\"\"\n        if type(key) is int:\n            return self.labeled_frames[key]\n        elif type(key) is slice:\n            return [self.labeled_frames[i] for i in range(*key.indices(len(self)))]\n        elif type(key) is list:\n            return [self.labeled_frames[i] for i in key]\n        elif isinstance(key, np.ndarray):\n            return [self.labeled_frames[i] for i in key.tolist()]\n        elif type(key) is tuple and len(key) == 2:\n            video, frame_idx = key\n            res = self.find(video, frame_idx)\n            if len(res) == 1:\n                return res[0]\n            elif len(res) == 0:\n                raise IndexError(\n                    f\"No labeled frames found for video {video} and \"\n                    f\"frame index {frame_idx}.\"\n                )\n        elif type(key) is Video:\n            res = self.find(key)\n            if len(res) == 0:\n                raise IndexError(f\"No labeled frames found for video {key}.\")\n            return res\n        else:\n            raise IndexError(f\"Invalid indexing argument for labels: {key}\")\n\n    def __iter__(self):\n        \"\"\"Iterate over `labeled_frames` list when calling iter method on `Labels`.\"\"\"\n        return iter(self.labeled_frames)\n\n    def __len__(self) -&gt; int:\n        \"\"\"Return number of labeled frames.\"\"\"\n        return len(self.labeled_frames)\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return a readable representation of the labels.\"\"\"\n        return (\n            \"Labels(\"\n            f\"labeled_frames={len(self.labeled_frames)}, \"\n            f\"videos={len(self.videos)}, \"\n            f\"skeletons={len(self.skeletons)}, \"\n            f\"tracks={len(self.tracks)}, \"\n            f\"suggestions={len(self.suggestions)}, \"\n            f\"sessions={len(self.sessions)}\"\n            \")\"\n        )\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return a readable representation of the labels.\"\"\"\n        return self.__repr__()\n\n    def append(self, lf: LabeledFrame, update: bool = True):\n        \"\"\"Append a labeled frame to the labels.\n\n        Args:\n            lf: A labeled frame to add to the labels.\n            update: If `True` (the default), update list of videos, tracks and\n                skeletons from the contents.\n        \"\"\"\n        self.labeled_frames.append(lf)\n\n        if update:\n            if lf.video not in self.videos:\n                self.videos.append(lf.video)\n\n            for inst in lf:\n                if inst.skeleton not in self.skeletons:\n                    self.skeletons.append(inst.skeleton)\n\n                if inst.track is not None and inst.track not in self.tracks:\n                    self.tracks.append(inst.track)\n\n    def extend(self, lfs: list[LabeledFrame], update: bool = True):\n        \"\"\"Append a labeled frame to the labels.\n\n        Args:\n            lfs: A list of labeled frames to add to the labels.\n            update: If `True` (the default), update list of videos, tracks and\n                skeletons from the contents.\n        \"\"\"\n        self.labeled_frames.extend(lfs)\n\n        if update:\n            for lf in lfs:\n                if lf.video not in self.videos:\n                    self.videos.append(lf.video)\n\n                for inst in lf:\n                    if inst.skeleton not in self.skeletons:\n                        self.skeletons.append(inst.skeleton)\n\n                    if inst.track is not None and inst.track not in self.tracks:\n                        self.tracks.append(inst.track)\n\n    def numpy(\n        self,\n        video: Optional[Union[Video, int]] = None,\n        untracked: bool = False,\n        return_confidence: bool = False,\n        user_instances: bool = True,\n    ) -&gt; np.ndarray:\n        \"\"\"Construct a numpy array from instance points.\n\n        Args:\n            video: Video or video index to convert to numpy arrays. If `None` (the\n                default), uses the first video.\n            untracked: If `False` (the default), include only instances that have a\n                track assignment. If `True`, includes all instances in each frame in\n                arbitrary order.\n            return_confidence: If `False` (the default), only return points of nodes. If\n                `True`, return the points and scores of nodes.\n            user_instances: If `True` (the default), include user instances when\n                available, preferring them over predicted instances with the same track.\n                If `False`,\n                only include predicted instances.\n\n        Returns:\n            An array of tracks of shape `(n_frames, n_tracks, n_nodes, 2)` if\n            `return_confidence` is `False`. Otherwise returned shape is\n            `(n_frames, n_tracks, n_nodes, 3)` if `return_confidence` is `True`.\n\n            Missing data will be replaced with `np.nan`.\n\n            If this is a single instance project, a track does not need to be assigned.\n\n            When `user_instances=False`, only predicted instances will be returned.\n            When `user_instances=True`, user instances will be preferred over predicted\n            instances with the same track or if linked via `from_predicted`.\n\n        Notes:\n            This method assumes that instances have tracks assigned and is intended to\n            function primarily for single-video prediction results.\n        \"\"\"\n        # Get labeled frames for specified video.\n        if video is None:\n            video = 0\n        if type(video) is int:\n            video = self.videos[video]\n        lfs = [lf for lf in self.labeled_frames if lf.video == video]\n\n        # Figure out frame index range.\n        first_frame, last_frame = 0, 0\n        for lf in lfs:\n            first_frame = min(first_frame, lf.frame_idx)\n            last_frame = max(last_frame, lf.frame_idx)\n\n        # Figure out the number of tracks based on number of instances in each frame.\n        # Check the max number of instances (predicted or user, depending on settings)\n        n_instances = 0\n        for lf in lfs:\n            if user_instances:\n                # Count max of either user or predicted instances per frame (not sum)\n                n_frame_instances = max(\n                    len(lf.user_instances), len(lf.predicted_instances)\n                )\n            else:\n                n_frame_instances = len(lf.predicted_instances)\n            n_instances = max(n_instances, n_frame_instances)\n\n        # Case 1: We don't care about order because there's only 1 instance per frame,\n        # or we're considering untracked instances.\n        is_single_instance = n_instances == 1\n        untracked = untracked or is_single_instance\n        if untracked:\n            n_tracks = n_instances\n        else:\n            # Case 2: We're considering only tracked instances.\n            n_tracks = len(self.tracks)\n\n        n_frames = int(last_frame - first_frame + 1)\n        skeleton = self.skeletons[-1]  # Assume project only uses last skeleton\n        n_nodes = len(skeleton.nodes)\n\n        if return_confidence:\n            tracks = np.full((n_frames, n_tracks, n_nodes, 3), np.nan, dtype=\"float32\")\n        else:\n            tracks = np.full((n_frames, n_tracks, n_nodes, 2), np.nan, dtype=\"float32\")\n\n        for lf in lfs:\n            i = int(lf.frame_idx - first_frame)\n\n            if untracked:\n                # For untracked instances, fill them in arbitrary order\n                j = 0\n                instances_to_include = []\n\n                # If user instances are preferred, add them first\n                if user_instances and lf.has_user_instances:\n                    # First collect all user instances\n                    for inst in lf.user_instances:\n                        instances_to_include.append(inst)\n\n                    # For the trivial case (single instance per frame), if we found\n                    # user instances, we shouldn't include any predicted instances\n                    if is_single_instance and len(instances_to_include) &gt; 0:\n                        pass  # Skip adding predicted instances\n                    else:\n                        # Add predicted instances that don't have a corresponding\n                        # user instance\n                        for inst in lf.predicted_instances:\n                            skip = False\n                            for user_inst in lf.user_instances:\n                                # Skip if this predicted instance is linked to a user\n                                # instance via from_predicted\n                                if (\n                                    hasattr(user_inst, \"from_predicted\")\n                                    and user_inst.from_predicted == inst\n                                ):\n                                    skip = True\n                                    break\n                                # Skip if user and predicted instances share same track\n                                if (\n                                    user_inst.track is not None\n                                    and inst.track is not None\n                                    and user_inst.track == inst.track\n                                ):\n                                    skip = True\n                                    break\n                            if not skip:\n                                instances_to_include.append(inst)\n                else:\n                    # If user_instances=False, only include predicted instances\n                    instances_to_include = lf.predicted_instances\n\n                # Now process all the instances we want to include\n                for inst in instances_to_include:\n                    if j &lt; n_tracks:\n                        if return_confidence:\n                            if isinstance(inst, PredictedInstance):\n                                tracks[i, j] = inst.numpy(scores=True)\n                            else:\n                                # For user instances, set confidence to 1.0\n                                points_data = inst.numpy()\n                                confidence = np.ones(\n                                    (points_data.shape[0], 1), dtype=\"float32\"\n                                )\n                                tracks[i, j] = np.hstack((points_data, confidence))\n                        else:\n                            tracks[i, j] = inst.numpy()\n                        j += 1\n            else:  # untracked is False\n                # For tracked instances, organize by track ID\n\n                # Create mapping from track to best instance for this frame\n                track_to_instance = {}\n\n                # First, add predicted instances to the mapping\n                for inst in lf.predicted_instances:\n                    if inst.track is not None:\n                        track_to_instance[inst.track] = inst\n\n                # Then, add user instances to the mapping (if user_instances=True)\n                if user_instances:\n                    for inst in lf.user_instances:\n                        if inst.track is not None:\n                            track_to_instance[inst.track] = inst\n\n                # Process the preferred instances for each track\n                for track in track_to_instance:\n                    inst = track_to_instance[track]\n                    j = self.tracks.index(track)\n\n                    if type(inst) is PredictedInstance:\n                        tracks[i, j] = inst.numpy(scores=return_confidence)\n                    elif type(inst) is Instance:\n                        tracks[i, j, :, :2] = inst.numpy()\n\n                        # If return_confidence is True, add dummy confidence scores\n                        if return_confidence:\n                            tracks[i, j, :, 2] = 1.0\n\n        return tracks\n\n    @classmethod\n    def from_numpy(\n        cls,\n        tracks_arr: np.ndarray,\n        videos: list[Video],\n        skeletons: list[Skeleton] | Skeleton | None = None,\n        tracks: list[Track] | None = None,\n        first_frame: int = 0,\n        return_confidence: bool = False,\n    ) -&gt; \"Labels\":\n        \"\"\"Create a new Labels object from a numpy array of tracks.\n\n        This factory method creates a new Labels object with instances constructed from\n        the provided numpy array. It is the inverse operation of `Labels.numpy()`.\n\n        Args:\n            tracks_arr: A numpy array of tracks, with shape\n                `(n_frames, n_tracks, n_nodes, 2)` or\n                `(n_frames, n_tracks, n_nodes, 3)`,\n                where the last dimension contains the x,y coordinates (and optionally\n                confidence scores).\n            videos: List of Video objects to associate with the labels. At least one\n                video\n                is required.\n            skeletons: Skeleton or list of Skeleton objects to use for the instances.\n                At least one skeleton is required.\n            tracks: List of Track objects corresponding to the second dimension of the\n                array. If not specified, new tracks will be created automatically.\n            first_frame: Frame index to start the labeled frames from. Default is 0.\n            return_confidence: Whether the tracks_arr contains confidence scores in the\n                last dimension. If True, tracks_arr.shape[-1] should be 3.\n\n        Returns:\n            A new Labels object with instances constructed from the numpy array.\n\n        Raises:\n            ValueError: If the array dimensions are invalid, or if no videos or\n                skeletons are provided.\n\n        Examples:\n            &gt;&gt;&gt; import numpy as np\n            &gt;&gt;&gt; from sleap_io import Labels, Video, Skeleton\n            &gt;&gt;&gt; # Create a simple tracking array for 2 frames, 1 track, 2 nodes\n            &gt;&gt;&gt; arr = np.zeros((2, 1, 2, 2))\n            &gt;&gt;&gt; arr[0, 0] = [[10, 20], [30, 40]]  # Frame 0\n            &gt;&gt;&gt; arr[1, 0] = [[15, 25], [35, 45]]  # Frame 1\n            &gt;&gt;&gt; # Create a video and skeleton\n            &gt;&gt;&gt; video = Video(filename=\"example.mp4\")\n            &gt;&gt;&gt; skeleton = Skeleton([\"head\", \"tail\"])\n            &gt;&gt;&gt; # Create labels from the array\n            &gt;&gt;&gt; labels = Labels.from_numpy(arr, videos=[video], skeletons=[skeleton])\n        \"\"\"\n        # Check dimensions\n        if len(tracks_arr.shape) != 4:\n            raise ValueError(\n                f\"Array must have 4 dimensions (n_frames, n_tracks, n_nodes, 2 or 3), \"\n                f\"but got {tracks_arr.shape}\"\n            )\n\n        # Validate videos\n        if not videos:\n            raise ValueError(\"At least one video must be provided\")\n        video = videos[0]  # Use the first video for creating labeled frames\n\n        # Process skeletons input\n        if skeletons is None:\n            raise ValueError(\"At least one skeleton must be provided\")\n        elif isinstance(skeletons, Skeleton):\n            skeletons = [skeletons]\n        elif not skeletons:  # Check for empty list\n            raise ValueError(\"At least one skeleton must be provided\")\n\n        skeleton = skeletons[0]  # Use the first skeleton for creating instances\n        n_nodes = len(skeleton.nodes)\n\n        # Check if tracks_arr contains confidence scores\n        has_confidence = tracks_arr.shape[-1] == 3 or return_confidence\n\n        # Get dimensions\n        n_frames, n_tracks_arr, _ = tracks_arr.shape[:3]\n\n        # Create or validate tracks\n        if tracks is None:\n            # Auto-create tracks if not provided\n            tracks = [Track(f\"track_{i}\") for i in range(n_tracks_arr)]\n        elif len(tracks) &lt; n_tracks_arr:\n            # Add missing tracks if needed\n            original_len = len(tracks)\n            for i in range(n_tracks_arr - original_len):\n                tracks.append(Track(f\"track_{i}\"))\n\n        # Create a new empty Labels object\n        labels = cls()\n        labels.videos = list(videos)\n        labels.skeletons = list(skeletons)\n        labels.tracks = list(tracks)\n\n        # Create labeled frames and instances from the array data\n        for i in range(n_frames):\n            frame_idx = i + first_frame\n\n            # Check if this frame has any valid data across all tracks\n            frame_has_valid_data = False\n            for j in range(n_tracks_arr):\n                track_data = tracks_arr[i, j]\n                # Check if at least one node in this track has valid xy coordinates\n                if np.any(~np.isnan(track_data[:, 0])):\n                    frame_has_valid_data = True\n                    break\n\n            # Skip creating a frame if there's no valid data\n            if not frame_has_valid_data:\n                continue\n\n            # Create a new labeled frame\n            labeled_frame = LabeledFrame(video=video, frame_idx=frame_idx)\n            frame_has_valid_instances = False\n\n            # Process each track in this frame\n            for j in range(n_tracks_arr):\n                track = tracks[j]\n                track_data = tracks_arr[i, j]\n\n                # Check if there's any valid data for this track at this frame\n                valid_points = ~np.isnan(track_data[:, 0])\n                if not np.any(valid_points):\n                    continue\n\n                # Create points from numpy data\n                points = track_data[:, :2].copy()\n\n                # Create new instance\n                if has_confidence:\n                    # Get confidence scores\n                    if tracks_arr.shape[-1] == 3:\n                        scores = track_data[:, 2].copy()\n                    else:\n                        scores = np.ones(n_nodes)\n\n                    # Fix NaN scores\n                    scores = np.where(np.isnan(scores), 1.0, scores)\n\n                    # Create instance with confidence scores\n                    new_instance = PredictedInstance.from_numpy(\n                        points_data=points,\n                        skeleton=skeleton,\n                        point_scores=scores,\n                        score=1.0,\n                        track=track,\n                    )\n                else:\n                    # Create instance with default scores\n                    new_instance = PredictedInstance.from_numpy(\n                        points_data=points,\n                        skeleton=skeleton,\n                        point_scores=np.ones(n_nodes),\n                        score=1.0,\n                        track=track,\n                    )\n\n                # Add to frame\n                labeled_frame.instances.append(new_instance)\n                frame_has_valid_instances = True\n\n            # Only add frames that have instances\n            if frame_has_valid_instances:\n                labels.append(labeled_frame, update=False)\n\n        # Update internal references\n        labels.update()\n\n        return labels\n\n    @property\n    def video(self) -&gt; Video:\n        \"\"\"Return the video if there is only a single video in the labels.\"\"\"\n        if len(self.videos) == 0:\n            raise ValueError(\"There are no videos in the labels.\")\n        elif len(self.videos) == 1:\n            return self.videos[0]\n        else:\n            raise ValueError(\n                \"Labels.video can only be used when there is only a single video saved \"\n                \"in the labels. Use Labels.videos instead.\"\n            )\n\n    @property\n    def skeleton(self) -&gt; Skeleton:\n        \"\"\"Return the skeleton if there is only a single skeleton in the labels.\"\"\"\n        if len(self.skeletons) == 0:\n            raise ValueError(\"There are no skeletons in the labels.\")\n        elif len(self.skeletons) == 1:\n            return self.skeletons[0]\n        else:\n            raise ValueError(\n                \"Labels.skeleton can only be used when there is only a single skeleton \"\n                \"saved in the labels. Use Labels.skeletons instead.\"\n            )\n\n    def find(\n        self,\n        video: Video,\n        frame_idx: int | list[int] | None = None,\n        return_new: bool = False,\n    ) -&gt; list[LabeledFrame]:\n        \"\"\"Search for labeled frames given video and/or frame index.\n\n        Args:\n            video: A `Video` that is associated with the project.\n            frame_idx: The frame index (or indices) which we want to find in the video.\n                If a range is specified, we'll return all frames with indices in that\n                range. If not specific, then we'll return all labeled frames for video.\n            return_new: Whether to return singleton of new and empty `LabeledFrame` if\n                none are found in project.\n\n        Returns:\n            List of `LabeledFrame` objects that match the criteria.\n\n            The list will be empty if no matches found, unless return_new is True, in\n            which case it contains new (empty) `LabeledFrame` objects with `video` and\n            `frame_index` set.\n        \"\"\"\n        results = []\n\n        if frame_idx is None:\n            for lf in self.labeled_frames:\n                if lf.video == video:\n                    results.append(lf)\n            return results\n\n        if np.isscalar(frame_idx):\n            frame_idx = np.array(frame_idx).reshape(-1)\n\n        for frame_ind in frame_idx:\n            result = None\n            for lf in self.labeled_frames:\n                if lf.video == video and lf.frame_idx == frame_ind:\n                    result = lf\n                    results.append(result)\n                    break\n            if result is None and return_new:\n                results.append(LabeledFrame(video=video, frame_idx=frame_ind))\n\n        return results\n\n    def save(\n        self,\n        filename: str,\n        format: Optional[str] = None,\n        embed: bool | str | list[tuple[Video, int]] | None = False,\n        restore_original_videos: bool = True,\n        verbose: bool = True,\n        **kwargs,\n    ):\n        \"\"\"Save labels to file in specified format.\n\n        Args:\n            filename: Path to save labels to.\n            format: The format to save the labels in. If `None`, the format will be\n                inferred from the file extension. Available formats are `\"slp\"`,\n                `\"nwb\"`, `\"labelstudio\"`, and `\"jabs\"`.\n            embed: Frames to embed in the saved labels file. One of `None`, `True`,\n                `\"all\"`, `\"user\"`, `\"suggestions\"`, `\"user+suggestions\"`, `\"source\"` or\n                list of tuples of `(video, frame_idx)`.\n\n                If `False` is specified (the default), the source video will be\n                restored if available, otherwise the embedded frames will be re-saved.\n\n                If `True` or `\"all\"`, all labeled frames and suggested frames will be\n                embedded.\n\n                If `\"source\"` is specified, no images will be embedded and the source\n                video will be restored if available.\n\n                This argument is only valid for the SLP backend.\n            restore_original_videos: If `True` (default) and `embed=False`, use original\n                video files. If `False` and `embed=False`, keep references to source\n                `.pkg.slp` files. Only applies when `embed=False`.\n            verbose: If `True` (the default), display a progress bar when embedding\n                frames.\n            **kwargs: Additional format-specific arguments passed to the save function.\n                See `save_file` for format-specific options.\n        \"\"\"\n        from pathlib import Path\n\n        from sleap_io import save_file\n        from sleap_io.io.slp import sanitize_filename\n\n        # Check for self-referential save when embed=False\n        if embed is False and (format == \"slp\" or str(filename).endswith(\".slp\")):\n            # Check if any videos have embedded images and would be self-referential\n            sanitized_save_path = Path(sanitize_filename(filename)).resolve()\n            for video in self.videos:\n                if (\n                    hasattr(video.backend, \"has_embedded_images\")\n                    and video.backend.has_embedded_images\n                    and video.source_video is None\n                ):\n                    sanitized_video_path = Path(\n                        sanitize_filename(video.filename)\n                    ).resolve()\n                    if sanitized_video_path == sanitized_save_path:\n                        raise ValueError(\n                            f\"Cannot save with embed=False when overwriting a file \"\n                            f\"that contains embedded videos. Use \"\n                            f\"labels.save('{filename}', embed=True) to re-embed the \"\n                            f\"frames, or save to a different filename.\"\n                        )\n\n        save_file(\n            self,\n            filename,\n            format=format,\n            embed=embed,\n            restore_original_videos=restore_original_videos,\n            verbose=verbose,\n            **kwargs,\n        )\n\n    def clean(\n        self,\n        frames: bool = True,\n        empty_instances: bool = False,\n        skeletons: bool = True,\n        tracks: bool = True,\n        videos: bool = False,\n    ):\n        \"\"\"Remove empty frames, unused skeletons, tracks and videos.\n\n        Args:\n            frames: If `True` (the default), remove empty frames.\n            empty_instances: If `True` (NOT default), remove instances that have no\n                visible points.\n            skeletons: If `True` (the default), remove unused skeletons.\n            tracks: If `True` (the default), remove unused tracks.\n            videos: If `True` (NOT default), remove videos that have no labeled frames.\n        \"\"\"\n        used_skeletons = []\n        used_tracks = []\n        used_videos = []\n        kept_frames = []\n        for lf in self.labeled_frames:\n            if empty_instances:\n                lf.remove_empty_instances()\n\n            if frames and len(lf) == 0:\n                continue\n\n            if videos and lf.video not in used_videos:\n                used_videos.append(lf.video)\n\n            if skeletons or tracks:\n                for inst in lf:\n                    if skeletons and inst.skeleton not in used_skeletons:\n                        used_skeletons.append(inst.skeleton)\n                    if (\n                        tracks\n                        and inst.track is not None\n                        and inst.track not in used_tracks\n                    ):\n                        used_tracks.append(inst.track)\n\n            if frames:\n                kept_frames.append(lf)\n\n        if videos:\n            self.videos = [video for video in self.videos if video in used_videos]\n\n        if skeletons:\n            self.skeletons = [\n                skeleton for skeleton in self.skeletons if skeleton in used_skeletons\n            ]\n\n        if tracks:\n            self.tracks = [track for track in self.tracks if track in used_tracks]\n\n        if frames:\n            self.labeled_frames = kept_frames\n\n    def remove_predictions(self, clean: bool = True):\n        \"\"\"Remove all predicted instances from the labels.\n\n        Args:\n            clean: If `True` (the default), also remove any empty frames and unused\n                tracks and skeletons. It does NOT remove videos that have no labeled\n                frames or instances with no visible points.\n\n        See also: `Labels.clean`\n        \"\"\"\n        for lf in self.labeled_frames:\n            lf.remove_predictions()\n\n        if clean:\n            self.clean(\n                frames=True,\n                empty_instances=False,\n                skeletons=True,\n                tracks=True,\n                videos=False,\n            )\n\n    @property\n    def user_labeled_frames(self) -&gt; list[LabeledFrame]:\n        \"\"\"Return all labeled frames with user (non-predicted) instances.\"\"\"\n        return [lf for lf in self.labeled_frames if lf.has_user_instances]\n\n    @property\n    def instances(self) -&gt; Iterator[Instance]:\n        \"\"\"Return an iterator over all instances within all labeled frames.\"\"\"\n        return (instance for lf in self.labeled_frames for instance in lf.instances)\n\n    def rename_nodes(\n        self,\n        name_map: dict[NodeOrIndex, str] | list[str],\n        skeleton: Skeleton | None = None,\n    ):\n        \"\"\"Rename nodes in the skeleton.\n\n        Args:\n            name_map: A dictionary mapping old node names to new node names. Keys can be\n                specified as `Node` objects, integer indices, or string names. Values\n                must be specified as string names.\n\n                If a list of strings is provided of the same length as the current\n                nodes, the nodes will be renamed to the names in the list in order.\n            skeleton: `Skeleton` to update. If `None` (the default), assumes there is\n                only one skeleton in the labels and raises `ValueError` otherwise.\n\n        Raises:\n            ValueError: If the new node names exist in the skeleton, if the old node\n                names are not found in the skeleton, or if there is more than one\n                skeleton in the `Labels` but it is not specified.\n\n        Notes:\n            This method is recommended over `Skeleton.rename_nodes` as it will update\n            all instances in the labels to reflect the new node names.\n\n        Example:\n            &gt;&gt;&gt; labels = Labels(skeletons=[Skeleton([\"A\", \"B\", \"C\"])])\n            &gt;&gt;&gt; labels.rename_nodes({\"A\": \"X\", \"B\": \"Y\", \"C\": \"Z\"})\n            &gt;&gt;&gt; labels.skeleton.node_names\n            [\"X\", \"Y\", \"Z\"]\n            &gt;&gt;&gt; labels.rename_nodes([\"a\", \"b\", \"c\"])\n            &gt;&gt;&gt; labels.skeleton.node_names\n            [\"a\", \"b\", \"c\"]\n        \"\"\"\n        if skeleton is None:\n            if len(self.skeletons) != 1:\n                raise ValueError(\n                    \"Skeleton must be specified when there is more than one skeleton \"\n                    \"in the labels.\"\n                )\n            skeleton = self.skeleton\n\n        skeleton.rename_nodes(name_map)\n\n        # Update instances.\n        for inst in self.instances:\n            if inst.skeleton == skeleton:\n                inst.points[\"name\"] = inst.skeleton.node_names\n\n    def remove_nodes(self, nodes: list[NodeOrIndex], skeleton: Skeleton | None = None):\n        \"\"\"Remove nodes from the skeleton.\n\n        Args:\n            nodes: A list of node names, indices, or `Node` objects to remove.\n            skeleton: `Skeleton` to update. If `None` (the default), assumes there is\n                only one skeleton in the labels and raises `ValueError` otherwise.\n\n        Raises:\n            ValueError: If the nodes are not found in the skeleton, or if there is more\n                than one skeleton in the labels and it is not specified.\n\n        Notes:\n            This method should always be used when removing nodes from the skeleton as\n            it handles updating the lookup caches necessary for indexing nodes by name,\n            and updating instances to reflect the changes made to the skeleton.\n\n            Any edges and symmetries that are connected to the removed nodes will also\n            be removed.\n        \"\"\"\n        if skeleton is None:\n            if len(self.skeletons) != 1:\n                raise ValueError(\n                    \"Skeleton must be specified when there is more than one skeleton \"\n                    \"in the labels.\"\n                )\n            skeleton = self.skeleton\n\n        skeleton.remove_nodes(nodes)\n\n        for inst in self.instances:\n            if inst.skeleton == skeleton:\n                inst.update_skeleton()\n\n    def reorder_nodes(\n        self, new_order: list[NodeOrIndex], skeleton: Skeleton | None = None\n    ):\n        \"\"\"Reorder nodes in the skeleton.\n\n        Args:\n            new_order: A list of node names, indices, or `Node` objects specifying the\n                new order of the nodes.\n            skeleton: `Skeleton` to update. If `None` (the default), assumes there is\n                only one skeleton in the labels and raises `ValueError` otherwise.\n\n        Raises:\n            ValueError: If the new order of nodes is not the same length as the current\n                nodes, or if there is more than one skeleton in the `Labels` but it is\n                not specified.\n\n        Notes:\n            This method handles updating the lookup caches necessary for indexing nodes\n            by name, as well as updating instances to reflect the changes made to the\n            skeleton.\n        \"\"\"\n        if skeleton is None:\n            if len(self.skeletons) != 1:\n                raise ValueError(\n                    \"Skeleton must be specified when there is more than one skeleton \"\n                    \"in the labels.\"\n                )\n            skeleton = self.skeleton\n\n        skeleton.reorder_nodes(new_order)\n\n        for inst in self.instances:\n            if inst.skeleton == skeleton:\n                inst.update_skeleton()\n\n    def replace_skeleton(\n        self,\n        new_skeleton: Skeleton,\n        old_skeleton: Skeleton | None = None,\n        node_map: dict[NodeOrIndex, NodeOrIndex] | None = None,\n    ):\n        \"\"\"Replace the skeleton in the labels.\n\n        Args:\n            new_skeleton: The new `Skeleton` to replace the old skeleton with.\n            old_skeleton: The old `Skeleton` to replace. If `None` (the default),\n                assumes there is only one skeleton in the labels and raises `ValueError`\n                otherwise.\n            node_map: Dictionary mapping nodes in the old skeleton to nodes in the new\n                skeleton. Keys and values can be specified as `Node` objects, integer\n                indices, or string names. If not provided, only nodes with identical\n                names will be mapped. Points associated with unmapped nodes will be\n                removed.\n\n        Raises:\n            ValueError: If there is more than one skeleton in the `Labels` but it is not\n                specified.\n\n        Warning:\n            This method will replace the skeleton in all instances in the labels that\n            have the old skeleton. **All point data associated with nodes not in the\n            `node_map` will be lost.**\n        \"\"\"\n        if old_skeleton is None:\n            if len(self.skeletons) != 1:\n                raise ValueError(\n                    \"Old skeleton must be specified when there is more than one \"\n                    \"skeleton in the labels.\"\n                )\n            old_skeleton = self.skeleton\n\n        if node_map is None:\n            node_map = {}\n            for old_node in old_skeleton.nodes:\n                for new_node in new_skeleton.nodes:\n                    if old_node.name == new_node.name:\n                        node_map[old_node] = new_node\n                        break\n        else:\n            node_map = {\n                old_skeleton.require_node(\n                    old, add_missing=False\n                ): new_skeleton.require_node(new, add_missing=False)\n                for old, new in node_map.items()\n            }\n\n        # Create node name map.\n        node_names_map = {old.name: new.name for old, new in node_map.items()}\n\n        # Replace the skeleton in the instances.\n        for inst in self.instances:\n            if inst.skeleton == old_skeleton:\n                inst.replace_skeleton(\n                    new_skeleton=new_skeleton, node_names_map=node_names_map\n                )\n\n        # Replace the skeleton in the labels.\n        self.skeletons[self.skeletons.index(old_skeleton)] = new_skeleton\n\n    def replace_videos(\n        self,\n        old_videos: list[Video] | None = None,\n        new_videos: list[Video] | None = None,\n        video_map: dict[Video, Video] | None = None,\n    ):\n        \"\"\"Replace videos and update all references.\n\n        Args:\n            old_videos: List of videos to be replaced.\n            new_videos: List of videos to replace with.\n            video_map: Alternative input of dictionary where keys are the old videos and\n                values are the new videos.\n        \"\"\"\n        if (\n            old_videos is None\n            and new_videos is not None\n            and len(new_videos) == len(self.videos)\n        ):\n            old_videos = self.videos\n\n        if video_map is None:\n            video_map = {o: n for o, n in zip(old_videos, new_videos)}\n\n        # Update the labeled frames with the new videos.\n        for lf in self.labeled_frames:\n            if lf.video in video_map:\n                lf.video = video_map[lf.video]\n\n        # Update suggestions with the new videos.\n        for sf in self.suggestions:\n            if sf.video in video_map:\n                sf.video = video_map[sf.video]\n\n        # Update the list of videos.\n        self.videos = [video_map.get(video, video) for video in self.videos]\n\n    def replace_filenames(\n        self,\n        new_filenames: list[str | Path] | None = None,\n        filename_map: dict[str | Path, str | Path] | None = None,\n        prefix_map: dict[str | Path, str | Path] | None = None,\n        open_videos: bool = True,\n    ):\n        \"\"\"Replace video filenames.\n\n        Args:\n            new_filenames: List of new filenames. Must have the same length as the\n                number of videos in the labels.\n            filename_map: Dictionary mapping old filenames (keys) to new filenames\n                (values).\n            prefix_map: Dictionary mapping old prefixes (keys) to new prefixes (values).\n            open_videos: If `True` (the default), attempt to open the video backend for\n                I/O after replacing the filename. If `False`, the backend will not be\n                opened (useful for operations with costly file existence checks).\n\n        Notes:\n            Only one of the argument types can be provided.\n        \"\"\"\n        n = 0\n        if new_filenames is not None:\n            n += 1\n        if filename_map is not None:\n            n += 1\n        if prefix_map is not None:\n            n += 1\n        if n != 1:\n            raise ValueError(\n                \"Exactly one input method must be provided to replace filenames.\"\n            )\n\n        if new_filenames is not None:\n            if len(self.videos) != len(new_filenames):\n                raise ValueError(\n                    f\"Number of new filenames ({len(new_filenames)}) does not match \"\n                    f\"the number of videos ({len(self.videos)}).\"\n                )\n\n            for video, new_filename in zip(self.videos, new_filenames):\n                video.replace_filename(new_filename, open=open_videos)\n\n        elif filename_map is not None:\n            for video in self.videos:\n                for old_fn, new_fn in filename_map.items():\n                    if type(video.filename) is list:\n                        new_fns = []\n                        for fn in video.filename:\n                            if Path(fn) == Path(old_fn):\n                                new_fns.append(new_fn)\n                            else:\n                                new_fns.append(fn)\n                        video.replace_filename(new_fns, open=open_videos)\n                    else:\n                        if Path(video.filename) == Path(old_fn):\n                            video.replace_filename(new_fn, open=open_videos)\n\n        elif prefix_map is not None:\n            for video in self.videos:\n                for old_prefix, new_prefix in prefix_map.items():\n                    # Sanitize old_prefix for cross-platform matching\n                    old_prefix_sanitized = sanitize_filename(old_prefix)\n\n                    # Check if old prefix ends with a separator\n                    old_ends_with_sep = old_prefix_sanitized.endswith(\"/\")\n\n                    if type(video.filename) is list:\n                        new_fns = []\n                        for fn in video.filename:\n                            # Sanitize filename for matching\n                            fn_sanitized = sanitize_filename(fn)\n\n                            if fn_sanitized.startswith(old_prefix_sanitized):\n                                # Calculate the remainder after removing the prefix\n                                remainder = fn_sanitized[len(old_prefix_sanitized) :]\n\n                                # Build the new filename\n                                if remainder.startswith(\"/\"):\n                                    # Remainder has separator, remove it to avoid double\n                                    # slash\n                                    remainder = remainder[1:]\n                                    # Always add separator between prefix and remainder\n                                    if new_prefix and not new_prefix.endswith(\n                                        (\"/\", \"\\\\\")\n                                    ):\n                                        new_fn = new_prefix + \"/\" + remainder\n                                    else:\n                                        new_fn = new_prefix + remainder\n                                elif old_ends_with_sep:\n                                    # Old prefix had separator, preserve it in the new\n                                    # one\n                                    if new_prefix and not new_prefix.endswith(\n                                        (\"/\", \"\\\\\")\n                                    ):\n                                        new_fn = new_prefix + \"/\" + remainder\n                                    else:\n                                        new_fn = new_prefix + remainder\n                                else:\n                                    # No separator in old prefix, don't add one\n                                    new_fn = new_prefix + remainder\n\n                                new_fns.append(new_fn)\n                            else:\n                                new_fns.append(fn)\n                        video.replace_filename(new_fns, open=open_videos)\n                    else:\n                        # Sanitize filename for matching\n                        fn_sanitized = sanitize_filename(video.filename)\n\n                        if fn_sanitized.startswith(old_prefix_sanitized):\n                            # Calculate the remainder after removing the prefix\n                            remainder = fn_sanitized[len(old_prefix_sanitized) :]\n\n                            # Build the new filename\n                            if remainder.startswith(\"/\"):\n                                # Remainder has separator, remove it to avoid double\n                                # slash\n                                remainder = remainder[1:]\n                                # Always add separator between prefix and remainder\n                                if new_prefix and not new_prefix.endswith((\"/\", \"\\\\\")):\n                                    new_fn = new_prefix + \"/\" + remainder\n                                else:\n                                    new_fn = new_prefix + remainder\n                            elif old_ends_with_sep:\n                                # Old prefix had separator, preserve it in the new one\n                                if new_prefix and not new_prefix.endswith((\"/\", \"\\\\\")):\n                                    new_fn = new_prefix + \"/\" + remainder\n                                else:\n                                    new_fn = new_prefix + remainder\n                            else:\n                                # No separator in old prefix, don't add one\n                                new_fn = new_prefix + remainder\n\n                            video.replace_filename(new_fn, open=open_videos)\n\n    def extract(\n        self, inds: list[int] | list[tuple[Video, int]] | np.ndarray, copy: bool = True\n    ) -&gt; Labels:\n        \"\"\"Extract a set of frames into a new Labels object.\n\n        Args:\n            inds: Indices of labeled frames. Can be specified as a list of array of\n                integer indices of labeled frames or tuples of Video and frame indices.\n            copy: If `True` (the default), return a copy of the frames and containing\n                objects. Otherwise, return a reference to the data.\n\n        Returns:\n            A new `Labels` object containing the selected labels.\n\n        Notes:\n            This copies the labeled frames and their associated data, including\n            skeletons and tracks, and tries to maintain the relative ordering.\n\n            This also copies the provenance and inserts an extra key: `\"source_labels\"`\n            with the path to the current labels, if available.\n\n            It does NOT copy suggested frames.\n        \"\"\"\n        lfs = self[inds]\n\n        if copy:\n            lfs = deepcopy(lfs)\n        labels = Labels(lfs)\n\n        # Try to keep the lists in the same order.\n        track_to_ind = {track.name: ind for ind, track in enumerate(self.tracks)}\n        labels.tracks = sorted(labels.tracks, key=lambda x: track_to_ind[x.name])\n\n        skel_to_ind = {skel.name: ind for ind, skel in enumerate(self.skeletons)}\n        labels.skeletons = sorted(labels.skeletons, key=lambda x: skel_to_ind[x.name])\n\n        labels.provenance = deepcopy(labels.provenance)\n        labels.provenance[\"source_labels\"] = self.provenance.get(\"filename\", None)\n\n        return labels\n\n    def split(self, n: int | float, seed: int | None = None):\n        \"\"\"Separate the labels into random splits.\n\n        Args:\n            n: Size of the first split. If integer &gt;= 1, assumes that this is the number\n                of labeled frames in the first split. If &lt; 1.0, this will be treated as\n                a fraction of the total labeled frames.\n            seed: Optional integer seed to use for reproducibility.\n\n        Returns:\n            A LabelsSet with keys \"split1\" and \"split2\".\n\n            If an integer was specified, `len(split1) == n`.\n\n            If a fraction was specified, `len(split1) == int(n * len(labels))`.\n\n            The second split contains the remainder, i.e.,\n            `len(split2) == len(labels) - len(split1)`.\n\n            If there are too few frames, a minimum of 1 frame will be kept in the second\n            split.\n\n            If there is exactly 1 labeled frame in the labels, the same frame will be\n            assigned to both splits.\n\n        Notes:\n            This method now returns a LabelsSet for easier management of splits.\n            For backward compatibility, the returned LabelsSet can be unpacked like\n            a tuple:\n            `split1, split2 = labels.split(0.8)`\n        \"\"\"\n        # Import here to avoid circular imports\n        from sleap_io.model.labels_set import LabelsSet\n\n        n0 = len(self)\n        if n0 == 0:\n            return LabelsSet({\"split1\": self, \"split2\": self})\n        n1 = n\n        if n &lt; 1.0:\n            n1 = max(int(n0 * float(n)), 1)\n        n2 = max(n0 - n1, 1)\n        n1, n2 = int(n1), int(n2)\n\n        rng = np.random.default_rng(seed=seed)\n        inds1 = rng.choice(n0, size=(n1,), replace=False)\n\n        if n0 == 1:\n            inds2 = np.array([0])\n        else:\n            inds2 = np.setdiff1d(np.arange(n0), inds1)\n\n        split1 = self.extract(inds1, copy=True)\n        split2 = self.extract(inds2, copy=True)\n\n        return LabelsSet({\"split1\": split1, \"split2\": split2})\n\n    def make_training_splits(\n        self,\n        n_train: int | float,\n        n_val: int | float | None = None,\n        n_test: int | float | None = None,\n        save_dir: str | Path | None = None,\n        seed: int | None = None,\n        embed: bool = True,\n    ) -&gt; LabelsSet:\n        \"\"\"Make splits for training with embedded images.\n\n        Args:\n            n_train: Size of the training split as integer or fraction.\n            n_val: Size of the validation split as integer or fraction. If `None`,\n                this will be inferred based on the values of `n_train` and `n_test`. If\n                `n_test` is `None`, this will be the remainder of the data after the\n                training split.\n            n_test: Size of the testing split as integer or fraction. If `None`, the\n                test split will not be saved.\n            save_dir: If specified, save splits to SLP files with embedded images.\n            seed: Optional integer seed to use for reproducibility.\n            embed: If `True` (the default), embed user labeled frame images in the saved\n                files, which is useful for portability but can be slow for large\n                projects. If `False`, labels are saved with references to the source\n                videos files.\n\n        Returns:\n            A `LabelsSet` containing \"train\", \"val\", and optionally \"test\" keys.\n            The `LabelsSet` can be unpacked for backward compatibility:\n            `train, val = labels.make_training_splits(0.8)`\n            `train, val, test = labels.make_training_splits(0.8, n_test=0.1)`\n\n        Notes:\n            Predictions and suggestions will be removed before saving, leaving only\n            frames with user labeled data (the source labels are not affected).\n\n            Frames with user labeled data will be embedded in the resulting files.\n\n            If `save_dir` is specified, this will save the randomly sampled splits to:\n\n            - `{save_dir}/train.pkg.slp`\n            - `{save_dir}/val.pkg.slp`\n            - `{save_dir}/test.pkg.slp` (if `n_test` is specified)\n\n            If `embed` is `False`, the files will be saved without embedded images to:\n\n            - `{save_dir}/train.slp`\n            - `{save_dir}/val.slp`\n            - `{save_dir}/test.slp` (if `n_test` is specified)\n\n        See also: `Labels.split`\n        \"\"\"\n        # Import here to avoid circular imports\n        from sleap_io.model.labels_set import LabelsSet\n\n        # Clean up labels.\n        labels = deepcopy(self)\n        labels.remove_predictions()\n        labels.suggestions = []\n        labels.clean()\n\n        # Make train split.\n        labels_train, labels_rest = labels.split(n_train, seed=seed)\n\n        # Make test split.\n        if n_test is not None:\n            if n_test &lt; 1:\n                n_test = (n_test * len(labels)) / len(labels_rest)\n            labels_test, labels_rest = labels_rest.split(n=n_test, seed=seed)\n\n        # Make val split.\n        if n_val is not None:\n            if n_val &lt; 1:\n                n_val = (n_val * len(labels)) / len(labels_rest)\n            if isinstance(n_val, float) and n_val == 1.0:\n                labels_val = labels_rest\n            else:\n                labels_val, _ = labels_rest.split(n=n_val, seed=seed)\n        else:\n            labels_val = labels_rest\n\n        # Update provenance.\n        source_labels = self.provenance.get(\"filename\", None)\n        labels_train.provenance[\"source_labels\"] = source_labels\n        if n_val is not None:\n            labels_val.provenance[\"source_labels\"] = source_labels\n        if n_test is not None:\n            labels_test.provenance[\"source_labels\"] = source_labels\n\n        # Create LabelsSet\n        if n_test is None:\n            labels_set = LabelsSet({\"train\": labels_train, \"val\": labels_val})\n        else:\n            labels_set = LabelsSet(\n                {\"train\": labels_train, \"val\": labels_val, \"test\": labels_test}\n            )\n\n        # Save.\n        if save_dir is not None:\n            labels_set.save(save_dir, embed=embed)\n\n        return labels_set\n\n    def trim(\n        self,\n        save_path: str | Path,\n        frame_inds: list[int] | np.ndarray,\n        video: Video | int | None = None,\n        video_kwargs: dict[str, Any] | None = None,\n    ) -&gt; Labels:\n        \"\"\"Trim the labels to a subset of frames and videos accordingly.\n\n        Args:\n            save_path: Path to the trimmed labels SLP file. Video will be saved with the\n                same base name but with .mp4 extension.\n            frame_inds: Frame indices to save. Can be specified as a list or array of\n                frame integers.\n            video: Video or integer index of the video to trim. Does not need to be\n                specified for single-video projects.\n            video_kwargs: A dictionary of keyword arguments to provide to\n                `sio.save_video` for video compression.\n\n        Returns:\n            The resulting labels object referencing the trimmed data.\n\n        Notes:\n            This will remove any data outside of the trimmed frames, save new videos,\n            and adjust the frame indices to match the newly trimmed videos.\n        \"\"\"\n        if video is None:\n            if len(self.videos) == 1:\n                video = self.video\n            else:\n                raise ValueError(\n                    \"Video needs to be specified when trimming multi-video projects.\"\n                )\n        if type(video) is int:\n            video = self.videos[video]\n\n        # Write trimmed clip.\n        save_path = Path(save_path)\n        video_path = save_path.with_suffix(\".mp4\")\n        fidx0, fidx1 = np.min(frame_inds), np.max(frame_inds)\n        new_video = video.save(\n            video_path,\n            frame_inds=np.arange(fidx0, fidx1 + 1),\n            video_kwargs=video_kwargs,\n        )\n\n        # Get frames in range.\n        # TODO: Create an optimized search function for this access pattern.\n        inds = []\n        for ind, lf in enumerate(self):\n            if lf.video == video and lf.frame_idx &gt;= fidx0 and lf.frame_idx &lt;= fidx1:\n                inds.append(ind)\n        trimmed_labels = self.extract(inds, copy=True)\n\n        # Adjust video and frame indices.\n        trimmed_labels.videos = [new_video]\n        for lf in trimmed_labels:\n            lf.video = new_video\n            lf.frame_idx = lf.frame_idx - fidx0\n\n        # Save.\n        trimmed_labels.save(save_path)\n\n        return trimmed_labels\n\n    def update_from_numpy(\n        self,\n        tracks_arr: np.ndarray,\n        video: Optional[Union[Video, int]] = None,\n        tracks: Optional[list[Track]] = None,\n        create_missing: bool = True,\n    ):\n        \"\"\"Update instances from a numpy array of tracks.\n\n        This function updates the points in existing instances, and creates new\n        instances for tracks that don't have a corresponding instance in a frame.\n\n        Args:\n            tracks_arr: A numpy array of tracks, with shape\n                `(n_frames, n_tracks, n_nodes, 2)` or\n                `(n_frames, n_tracks, n_nodes, 3)`,\n                where the last dimension contains the x,y coordinates (and optionally\n                confidence scores).\n            video: The video to update instances for. If not specified, the first video\n                in the labels will be used if there is only one video.\n            tracks: List of `Track` objects corresponding to the second dimension of the\n                array. If not specified, `self.tracks` will be used, and must have the\n                same length as the second dimension of the array.\n            create_missing: If `True` (the default), creates new `PredictedInstance`s\n                for tracks that don't have corresponding instances in a frame. If\n                `False`, only updates existing instances.\n\n        Raises:\n            ValueError: If the video cannot be determined, or if tracks are not\n                specified and the number of tracks in the array doesn't match the number\n                of tracks in the labels.\n\n        Notes:\n            This method is the inverse of `Labels.numpy()`, and can be used to update\n            instance points after modifying the numpy array.\n\n            If the array has a third dimension with shape 3 (tracks_arr.shape[-1] == 3),\n            the last channel is assumed to be confidence scores.\n        \"\"\"\n        # Check dimensions\n        if len(tracks_arr.shape) != 4:\n            raise ValueError(\n                f\"Array must have 4 dimensions (n_frames, n_tracks, n_nodes, 2 or 3), \"\n                f\"but got {tracks_arr.shape}\"\n            )\n\n        # Determine if confidence scores are included\n        has_confidence = tracks_arr.shape[3] == 3\n\n        # Determine the video to update\n        if video is None:\n            if len(self.videos) == 1:\n                video = self.videos[0]\n            else:\n                raise ValueError(\n                    \"Video must be specified when there is more than one video in the \"\n                    \"Labels.\"\n                )\n        elif isinstance(video, int):\n            video = self.videos[video]\n\n        # Get dimensions\n        n_frames, n_tracks_arr, n_nodes = tracks_arr.shape[:3]\n\n        # Get tracks to update\n        if tracks is None:\n            if len(self.tracks) != n_tracks_arr:\n                raise ValueError(\n                    f\"Number of tracks in array ({n_tracks_arr}) doesn't match \"\n                    f\"number of tracks in labels ({len(self.tracks)}). Please specify \"\n                    f\"the tracks corresponding to the second dimension of the array.\"\n                )\n            tracks = self.tracks\n\n        # Special case: Check if the array has more tracks than the provided tracks list\n        # This is for test_update_from_numpy where a new track is added\n        special_case = n_tracks_arr &gt; len(tracks)\n\n        # Get all labeled frames for the specified video\n        lfs = [lf for lf in self.labeled_frames if lf.video == video]\n\n        # Figure out frame index range from existing labeled frames\n        # Default to 0 if no labeled frames exist\n        first_frame = 0\n        if lfs:\n            first_frame = min(lf.frame_idx for lf in lfs)\n\n        # Ensure we have a skeleton\n        if not self.skeletons:\n            raise ValueError(\"No skeletons available in the labels.\")\n        skeleton = self.skeletons[-1]  # Use the same assumption as in numpy()\n\n        # Create a frame lookup dict for fast access\n        frame_lookup = {lf.frame_idx: lf for lf in lfs}\n\n        # Update or create instances for each frame in the array\n        for i in range(n_frames):\n            frame_idx = i + first_frame\n\n            # Find or create labeled frame\n            labeled_frame = None\n            if frame_idx in frame_lookup:\n                labeled_frame = frame_lookup[frame_idx]\n            else:\n                if create_missing:\n                    labeled_frame = LabeledFrame(video=video, frame_idx=frame_idx)\n                    self.append(labeled_frame, update=False)\n                    frame_lookup[frame_idx] = labeled_frame\n                else:\n                    continue\n\n            # First, handle regular tracks (up to len(tracks))\n            for j in range(min(n_tracks_arr, len(tracks))):\n                track = tracks[j]\n                track_data = tracks_arr[i, j]\n\n                # Check if there's any valid data for this track at this frame\n                valid_points = ~np.isnan(track_data[:, 0])\n                if not np.any(valid_points):\n                    continue\n\n                # Look for existing instance with this track\n                found_instance = None\n\n                # First check predicted instances\n                for inst in labeled_frame.predicted_instances:\n                    if inst.track and inst.track.name == track.name:\n                        found_instance = inst\n                        break\n\n                # Then check user instances if none found\n                if found_instance is None:\n                    for inst in labeled_frame.user_instances:\n                        if inst.track and inst.track.name == track.name:\n                            found_instance = inst\n                            break\n\n                # Create new instance if not found and create_missing is True\n                if found_instance is None and create_missing:\n                    # Create points from numpy data\n                    points = track_data[:, :2].copy()\n\n                    if has_confidence:\n                        # Get confidence scores\n                        scores = track_data[:, 2].copy()\n                        # Fix NaN scores\n                        scores = np.where(np.isnan(scores), 1.0, scores)\n\n                        # Create new instance\n                        new_instance = PredictedInstance.from_numpy(\n                            points_data=points,\n                            skeleton=skeleton,\n                            point_scores=scores,\n                            score=1.0,\n                            track=track,\n                        )\n                    else:\n                        # Create with default scores\n                        new_instance = PredictedInstance.from_numpy(\n                            points_data=points,\n                            skeleton=skeleton,\n                            point_scores=np.ones(n_nodes),\n                            score=1.0,\n                            track=track,\n                        )\n\n                    # Add to frame\n                    labeled_frame.instances.append(new_instance)\n                    found_instance = new_instance\n\n                # Update existing instance points\n                if found_instance is not None:\n                    points = track_data[:, :2]\n                    mask = ~np.isnan(points[:, 0])\n                    for node_idx in np.where(mask)[0]:\n                        found_instance.points[node_idx][\"xy\"] = points[node_idx]\n\n                    # Update confidence scores if available\n                    if has_confidence and isinstance(found_instance, PredictedInstance):\n                        scores = track_data[:, 2]\n                        score_mask = ~np.isnan(scores)\n                        for node_idx in np.where(score_mask)[0]:\n                            found_instance.points[node_idx][\"score\"] = float(\n                                scores[node_idx]\n                            )\n\n            # Special case: Handle any additional tracks in the array\n            # This is the fix for test_update_from_numpy where a new track is added\n            if special_case and create_missing and len(tracks) &gt; 0:\n                # In the test case, the last track in the tracks list is the new one\n                new_track = tracks[-1]\n\n                # Check if there's data for the new track in the current frame\n                # Use the last column in the array (new track)\n                new_track_data = tracks_arr[i, -1]\n\n                # Check if there's any valid data for this track at this frame\n                valid_points = ~np.isnan(new_track_data[:, 0])\n                if np.any(valid_points):\n                    # Create points from numpy data for the new track\n                    points = new_track_data[:, :2].copy()\n\n                    if has_confidence:\n                        # Get confidence scores\n                        scores = new_track_data[:, 2].copy()\n                        # Fix NaN scores\n                        scores = np.where(np.isnan(scores), 1.0, scores)\n\n                        # Create new instance for the new track\n                        new_instance = PredictedInstance.from_numpy(\n                            points_data=points,\n                            skeleton=skeleton,\n                            point_scores=scores,\n                            score=1.0,\n                            track=new_track,\n                        )\n                    else:\n                        # Create with default scores\n                        new_instance = PredictedInstance.from_numpy(\n                            points_data=points,\n                            skeleton=skeleton,\n                            point_scores=np.ones(n_nodes),\n                            score=1.0,\n                            track=new_track,\n                        )\n\n                    # Add the new instance directly to the frame's instances list\n                    labeled_frame.instances.append(new_instance)\n\n        # Make sure everything is properly linked\n        self.update()\n\n    def merge(\n        self,\n        other: \"Labels\",\n        instance_matcher: Optional[\"InstanceMatcher\"] = None,\n        skeleton_matcher: Optional[\"SkeletonMatcher\"] = None,\n        video_matcher: Optional[\"VideoMatcher\"] = None,\n        track_matcher: Optional[\"TrackMatcher\"] = None,\n        frame_strategy: str = \"smart\",\n        validate: bool = True,\n        progress_callback: Optional[Callable] = None,\n        error_mode: str = \"continue\",\n    ) -&gt; \"MergeResult\":\n        \"\"\"Merge another Labels object into this one.\n\n        Args:\n            other: Another Labels object to merge into this one.\n            instance_matcher: Matcher for comparing instances. If None, uses default\n                spatial matching with 5px tolerance.\n            skeleton_matcher: Matcher for comparing skeletons. If None, uses structure\n                matching.\n            video_matcher: Matcher for comparing videos. If None, uses auto matching.\n            track_matcher: Matcher for comparing tracks. If None, uses name matching.\n            frame_strategy: Strategy for merging frames:\n                - \"smart\": Keep user labels, update predictions\n                - \"keep_original\": Keep original frames\n                - \"keep_new\": Replace with new frames\n                - \"keep_both\": Keep all frames\n            validate: If True, validate for conflicts before merging.\n            progress_callback: Optional callback for progress updates.\n                Should accept (current, total, message) arguments.\n            error_mode: How to handle errors:\n                - \"continue\": Log errors but continue\n                - \"strict\": Raise exception on first error\n                - \"warn\": Print warnings but continue\n\n        Returns:\n            MergeResult object with statistics and any errors/conflicts.\n\n        Notes:\n            This method modifies the Labels object in place. The merge is designed to\n            handle common workflows like merging predictions back into a project.\n        \"\"\"\n        from datetime import datetime\n        from pathlib import Path\n\n        from sleap_io.model.matching import (\n            ConflictResolution,\n            ErrorMode,\n            InstanceMatcher,\n            MergeError,\n            MergeResult,\n            SkeletonMatcher,\n            SkeletonMatchMethod,\n            SkeletonMismatchError,\n            TrackMatcher,\n            VideoMatcher,\n            VideoMatchMethod,\n        )\n\n        # Initialize matchers with defaults if not provided\n        if instance_matcher is None:\n            instance_matcher = InstanceMatcher()\n        if skeleton_matcher is None:\n            skeleton_matcher = SkeletonMatcher(method=SkeletonMatchMethod.STRUCTURE)\n        if video_matcher is None:\n            video_matcher = VideoMatcher()\n        if track_matcher is None:\n            track_matcher = TrackMatcher()\n\n        # Parse error mode\n        error_mode_enum = ErrorMode(error_mode)\n\n        # Initialize result\n        result = MergeResult(successful=True)\n\n        # Track merge history in provenance\n        if \"merge_history\" not in self.provenance:\n            self.provenance[\"merge_history\"] = []\n\n        merge_record = {\n            \"timestamp\": datetime.now().isoformat(),\n            \"source_labels\": {\n                \"n_frames\": len(other.labeled_frames),\n                \"n_videos\": len(other.videos),\n                \"n_skeletons\": len(other.skeletons),\n                \"n_tracks\": len(other.tracks),\n            },\n            \"strategy\": frame_strategy,\n        }\n\n        try:\n            # Step 1: Match and merge skeletons\n            skeleton_map = {}\n            for other_skel in other.skeletons:\n                matched = False\n                for self_skel in self.skeletons:\n                    if skeleton_matcher.match(self_skel, other_skel):\n                        skeleton_map[other_skel] = self_skel\n                        matched = True\n                        break\n\n                if not matched:\n                    if validate and error_mode_enum == ErrorMode.STRICT:\n                        raise SkeletonMismatchError(\n                            message=f\"No matching skeleton found for {other_skel.name}\",\n                            details={\"skeleton\": other_skel},\n                        )\n                    elif error_mode_enum == ErrorMode.WARN:\n                        print(f\"Warning: No matching skeleton for {other_skel.name}\")\n\n                    # Add new skeleton if no match\n                    self.skeletons.append(other_skel)\n                    skeleton_map[other_skel] = other_skel\n\n            # Step 2: Match and merge videos\n            video_map = {}\n            frame_idx_map = {}  # Maps (old_video, old_idx) -&gt; (new_video, new_idx)\n\n            for other_video in other.videos:\n                matched = False\n                for self_video in self.videos:\n                    if video_matcher.match(self_video, other_video):\n                        # Special handling for different match methods\n                        if video_matcher.method == VideoMatchMethod.IMAGE_DEDUP:\n                            # Deduplicate images from other_video\n                            deduped_video = other_video.deduplicate_with(self_video)\n                            if deduped_video is None:\n                                # All images were duplicates, map to existing video\n                                video_map[other_video] = self_video\n                                # Build frame index mapping for deduplicated frames\n                                if isinstance(\n                                    other_video.filename, list\n                                ) and isinstance(self_video.filename, list):\n                                    other_basenames = [\n                                        Path(f).name for f in other_video.filename\n                                    ]\n                                    self_basenames = [\n                                        Path(f).name for f in self_video.filename\n                                    ]\n                                    for old_idx, basename in enumerate(other_basenames):\n                                        if basename in self_basenames:\n                                            new_idx = self_basenames.index(basename)\n                                            frame_idx_map[(other_video, old_idx)] = (\n                                                self_video,\n                                                new_idx,\n                                            )\n                            else:\n                                # Add deduplicated video as new\n                                self.videos.append(deduped_video)\n                                video_map[other_video] = deduped_video\n                                # Build frame index mapping for remaining frames\n                                if isinstance(\n                                    other_video.filename, list\n                                ) and isinstance(deduped_video.filename, list):\n                                    other_basenames = [\n                                        Path(f).name for f in other_video.filename\n                                    ]\n                                    deduped_basenames = [\n                                        Path(f).name for f in deduped_video.filename\n                                    ]\n                                    for old_idx, basename in enumerate(other_basenames):\n                                        if basename in deduped_basenames:\n                                            new_idx = deduped_basenames.index(basename)\n                                            frame_idx_map[(other_video, old_idx)] = (\n                                                deduped_video,\n                                                new_idx,\n                                            )\n                        elif video_matcher.method == VideoMatchMethod.SHAPE:\n                            # Merge videos with same shape\n                            merged_video = self_video.merge_with(other_video)\n                            # Replace self_video with merged version\n                            self_video_idx = self.videos.index(self_video)\n                            self.videos[self_video_idx] = merged_video\n                            video_map[other_video] = merged_video\n                            video_map[self_video] = (\n                                merged_video  # Update mapping for self too\n                            )\n                            # Build frame index mapping\n                            if isinstance(other_video.filename, list) and isinstance(\n                                merged_video.filename, list\n                            ):\n                                other_basenames = [\n                                    Path(f).name for f in other_video.filename\n                                ]\n                                merged_basenames = [\n                                    Path(f).name for f in merged_video.filename\n                                ]\n                                for old_idx, basename in enumerate(other_basenames):\n                                    if basename in merged_basenames:\n                                        new_idx = merged_basenames.index(basename)\n                                        frame_idx_map[(other_video, old_idx)] = (\n                                            merged_video,\n                                            new_idx,\n                                        )\n                        else:\n                            # Regular matching, no special handling\n                            video_map[other_video] = self_video\n                        matched = True\n                        break\n\n                if not matched:\n                    # Add new video if no match\n                    self.videos.append(other_video)\n                    video_map[other_video] = other_video\n\n            # Step 3: Match and merge tracks\n            track_map = {}\n            for other_track in other.tracks:\n                matched = False\n                for self_track in self.tracks:\n                    if track_matcher.match(self_track, other_track):\n                        track_map[other_track] = self_track\n                        matched = True\n                        break\n\n                if not matched:\n                    # Add new track if no match\n                    self.tracks.append(other_track)\n                    track_map[other_track] = other_track\n\n            # Step 4: Merge frames\n            total_frames = len(other.labeled_frames)\n\n            for frame_idx, other_frame in enumerate(other.labeled_frames):\n                if progress_callback:\n                    progress_callback(\n                        frame_idx,\n                        total_frames,\n                        f\"Merging frame {frame_idx + 1}/{total_frames}\",\n                    )\n\n                # Check if frame index needs remapping (for deduplicated/merged videos)\n                if (other_frame.video, other_frame.frame_idx) in frame_idx_map:\n                    mapped_video, mapped_frame_idx = frame_idx_map[\n                        (other_frame.video, other_frame.frame_idx)\n                    ]\n                else:\n                    # Map video to self\n                    mapped_video = video_map.get(other_frame.video, other_frame.video)\n                    mapped_frame_idx = other_frame.frame_idx\n\n                # Find matching frame in self\n                matching_frames = self.find(mapped_video, mapped_frame_idx)\n\n                if len(matching_frames) == 0:\n                    # No matching frame, create new one\n                    new_frame = LabeledFrame(\n                        video=mapped_video,\n                        frame_idx=mapped_frame_idx,\n                        instances=[],\n                    )\n\n                    # Map instances to new skeleton/track\n                    for inst in other_frame.instances:\n                        new_inst = self._map_instance(inst, skeleton_map, track_map)\n                        new_frame.instances.append(new_inst)\n                        result.instances_added += 1\n\n                    self.append(new_frame)\n                    result.frames_merged += 1\n\n                else:\n                    # Merge into existing frame\n                    self_frame = matching_frames[0]\n\n                    # Merge instances using frame-level merge\n                    merged_instances, conflicts = self_frame.merge(\n                        other_frame,\n                        instance_matcher=instance_matcher,\n                        strategy=frame_strategy,\n                    )\n\n                    # Remap skeleton and track references for instances from other frame\n                    remapped_instances = []\n                    for inst in merged_instances:\n                        # Check if instance needs remapping (from other_frame)\n                        if inst.skeleton in skeleton_map:\n                            # Instance needs remapping\n                            remapped_inst = self._map_instance(\n                                inst, skeleton_map, track_map\n                            )\n                            remapped_instances.append(remapped_inst)\n                        else:\n                            # Instance already has correct skeleton (from self_frame)\n                            remapped_instances.append(inst)\n                    merged_instances = remapped_instances\n\n                    # Count changes\n                    n_before = len(self_frame.instances)\n                    n_after = len(merged_instances)\n                    result.instances_added += max(0, n_after - n_before)\n\n                    # Record conflicts\n                    for orig, new, resolution in conflicts:\n                        result.conflicts.append(\n                            ConflictResolution(\n                                frame=self_frame,\n                                conflict_type=\"instance_conflict\",\n                                original_data=orig,\n                                new_data=new,\n                                resolution=resolution,\n                            )\n                        )\n\n                    # Update frame instances\n                    self_frame.instances = merged_instances\n                    result.frames_merged += 1\n\n            # Step 5: Merge suggestions\n            for other_suggestion in other.suggestions:\n                mapped_video = video_map.get(\n                    other_suggestion.video, other_suggestion.video\n                )\n                # Check if suggestion already exists\n                exists = False\n                for self_suggestion in self.suggestions:\n                    if (\n                        self_suggestion.video == mapped_video\n                        and self_suggestion.frame_idx == other_suggestion.frame_idx\n                    ):\n                        exists = True\n                        break\n                if not exists:\n                    # Create new suggestion with mapped video\n                    new_suggestion = SuggestionFrame(\n                        video=mapped_video, frame_idx=other_suggestion.frame_idx\n                    )\n                    self.suggestions.append(new_suggestion)\n\n            # Update merge record\n            merge_record[\"result\"] = {\n                \"frames_merged\": result.frames_merged,\n                \"instances_added\": result.instances_added,\n                \"conflicts\": len(result.conflicts),\n            }\n            self.provenance[\"merge_history\"].append(merge_record)\n\n        except MergeError as e:\n            result.successful = False\n            result.errors.append(e)\n            if error_mode_enum == ErrorMode.STRICT:\n                raise\n        except Exception as e:\n            result.successful = False\n            result.errors.append(\n                MergeError(message=str(e), details={\"exception\": type(e).__name__})\n            )\n            if error_mode_enum == ErrorMode.STRICT:\n                raise\n\n        if progress_callback:\n            progress_callback(total_frames, total_frames, \"Merge complete\")\n\n        return result\n\n    def _map_instance(\n        self,\n        instance: Union[Instance, PredictedInstance],\n        skeleton_map: dict[Skeleton, Skeleton],\n        track_map: dict[Track, Track],\n    ) -&gt; Union[Instance, PredictedInstance]:\n        \"\"\"Map an instance to use mapped skeleton and track.\n\n        Args:\n            instance: Instance to map.\n            skeleton_map: Dictionary mapping old skeletons to new ones.\n            track_map: Dictionary mapping old tracks to new ones.\n\n        Returns:\n            New instance with mapped skeleton and track.\n        \"\"\"\n        mapped_skeleton = skeleton_map.get(instance.skeleton, instance.skeleton)\n        mapped_track = (\n            track_map.get(instance.track, instance.track) if instance.track else None\n        )\n\n        if type(instance) is PredictedInstance:\n            return PredictedInstance(\n                points=instance.points.copy(),\n                skeleton=mapped_skeleton,\n                score=instance.score,\n                track=mapped_track,\n                tracking_score=instance.tracking_score,\n                from_predicted=instance.from_predicted,\n            )\n        else:\n            return Instance(\n                points=instance.points.copy(),\n                skeleton=mapped_skeleton,\n                track=mapped_track,\n                tracking_score=instance.tracking_score,\n                from_predicted=instance.from_predicted,\n            )\n\n    def set_video_plugin(self, plugin: str) -&gt; None:\n        \"\"\"Reopen all media videos with the specified plugin.\n\n        Args:\n            plugin: Video plugin to use. One of \"opencv\", \"FFMPEG\", or \"pyav\".\n                Also accepts aliases (case-insensitive).\n\n        Examples:\n            &gt;&gt;&gt; labels.set_video_plugin(\"opencv\")\n            &gt;&gt;&gt; labels.set_video_plugin(\"FFMPEG\")\n        \"\"\"\n        from sleap_io.io.video_reading import MediaVideo\n\n        for video in self.videos:\n            if video.filename.endswith(MediaVideo.EXTS):\n                video.set_video_plugin(plugin)\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Labels.instances","title":"<code>instances</code>  <code>property</code>","text":"<p>Return an iterator over all instances within all labeled frames.</p>"},{"location":"reference/sleap_io/#sleap_io.Labels.skeleton","title":"<code>skeleton</code>  <code>property</code>","text":"<p>Return the skeleton if there is only a single skeleton in the labels.</p>"},{"location":"reference/sleap_io/#sleap_io.Labels.user_labeled_frames","title":"<code>user_labeled_frames</code>  <code>property</code>","text":"<p>Return all labeled frames with user (non-predicted) instances.</p>"},{"location":"reference/sleap_io/#sleap_io.Labels.video","title":"<code>video</code>  <code>property</code>","text":"<p>Return the video if there is only a single video in the labels.</p>"},{"location":"reference/sleap_io/#sleap_io.Labels.__attrs_post_init__","title":"<code>__attrs_post_init__()</code>","text":"<p>Append videos, skeletons, and tracks seen in <code>labeled_frames</code> to <code>Labels</code>.</p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def __attrs_post_init__(self):\n    \"\"\"Append videos, skeletons, and tracks seen in `labeled_frames` to `Labels`.\"\"\"\n    self.update()\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Labels.__getitem__","title":"<code>__getitem__(key)</code>","text":"<p>Return one or more labeled frames based on indexing criteria.</p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def __getitem__(\n    self, key: int | slice | list[int] | np.ndarray | tuple[Video, int]\n) -&gt; list[LabeledFrame] | LabeledFrame:\n    \"\"\"Return one or more labeled frames based on indexing criteria.\"\"\"\n    if type(key) is int:\n        return self.labeled_frames[key]\n    elif type(key) is slice:\n        return [self.labeled_frames[i] for i in range(*key.indices(len(self)))]\n    elif type(key) is list:\n        return [self.labeled_frames[i] for i in key]\n    elif isinstance(key, np.ndarray):\n        return [self.labeled_frames[i] for i in key.tolist()]\n    elif type(key) is tuple and len(key) == 2:\n        video, frame_idx = key\n        res = self.find(video, frame_idx)\n        if len(res) == 1:\n            return res[0]\n        elif len(res) == 0:\n            raise IndexError(\n                f\"No labeled frames found for video {video} and \"\n                f\"frame index {frame_idx}.\"\n            )\n    elif type(key) is Video:\n        res = self.find(key)\n        if len(res) == 0:\n            raise IndexError(f\"No labeled frames found for video {key}.\")\n        return res\n    else:\n        raise IndexError(f\"Invalid indexing argument for labels: {key}\")\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Labels.__iter__","title":"<code>__iter__()</code>","text":"<p>Iterate over <code>labeled_frames</code> list when calling iter method on <code>Labels</code>.</p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def __iter__(self):\n    \"\"\"Iterate over `labeled_frames` list when calling iter method on `Labels`.\"\"\"\n    return iter(self.labeled_frames)\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Labels.__len__","title":"<code>__len__()</code>","text":"<p>Return number of labeled frames.</p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"Return number of labeled frames.\"\"\"\n    return len(self.labeled_frames)\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Labels.__repr__","title":"<code>__repr__()</code>","text":"<p>Return a readable representation of the labels.</p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return a readable representation of the labels.\"\"\"\n    return (\n        \"Labels(\"\n        f\"labeled_frames={len(self.labeled_frames)}, \"\n        f\"videos={len(self.videos)}, \"\n        f\"skeletons={len(self.skeletons)}, \"\n        f\"tracks={len(self.tracks)}, \"\n        f\"suggestions={len(self.suggestions)}, \"\n        f\"sessions={len(self.sessions)}\"\n        \")\"\n    )\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Labels.__str__","title":"<code>__str__()</code>","text":"<p>Return a readable representation of the labels.</p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return a readable representation of the labels.\"\"\"\n    return self.__repr__()\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Labels.append","title":"<code>append(lf, update=True)</code>","text":"<p>Append a labeled frame to the labels.</p> <p>Parameters:</p> Name Type Description Default <code>lf</code> <code>LabeledFrame</code> <p>A labeled frame to add to the labels.</p> required <code>update</code> <code>bool</code> <p>If <code>True</code> (the default), update list of videos, tracks and skeletons from the contents.</p> <code>True</code> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def append(self, lf: LabeledFrame, update: bool = True):\n    \"\"\"Append a labeled frame to the labels.\n\n    Args:\n        lf: A labeled frame to add to the labels.\n        update: If `True` (the default), update list of videos, tracks and\n            skeletons from the contents.\n    \"\"\"\n    self.labeled_frames.append(lf)\n\n    if update:\n        if lf.video not in self.videos:\n            self.videos.append(lf.video)\n\n        for inst in lf:\n            if inst.skeleton not in self.skeletons:\n                self.skeletons.append(inst.skeleton)\n\n            if inst.track is not None and inst.track not in self.tracks:\n                self.tracks.append(inst.track)\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Labels.clean","title":"<code>clean(frames=True, empty_instances=False, skeletons=True, tracks=True, videos=False)</code>","text":"<p>Remove empty frames, unused skeletons, tracks and videos.</p> <p>Parameters:</p> Name Type Description Default <code>frames</code> <code>bool</code> <p>If <code>True</code> (the default), remove empty frames.</p> <code>True</code> <code>empty_instances</code> <code>bool</code> <p>If <code>True</code> (NOT default), remove instances that have no visible points.</p> <code>False</code> <code>skeletons</code> <code>bool</code> <p>If <code>True</code> (the default), remove unused skeletons.</p> <code>True</code> <code>tracks</code> <code>bool</code> <p>If <code>True</code> (the default), remove unused tracks.</p> <code>True</code> <code>videos</code> <code>bool</code> <p>If <code>True</code> (NOT default), remove videos that have no labeled frames.</p> <code>False</code> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def clean(\n    self,\n    frames: bool = True,\n    empty_instances: bool = False,\n    skeletons: bool = True,\n    tracks: bool = True,\n    videos: bool = False,\n):\n    \"\"\"Remove empty frames, unused skeletons, tracks and videos.\n\n    Args:\n        frames: If `True` (the default), remove empty frames.\n        empty_instances: If `True` (NOT default), remove instances that have no\n            visible points.\n        skeletons: If `True` (the default), remove unused skeletons.\n        tracks: If `True` (the default), remove unused tracks.\n        videos: If `True` (NOT default), remove videos that have no labeled frames.\n    \"\"\"\n    used_skeletons = []\n    used_tracks = []\n    used_videos = []\n    kept_frames = []\n    for lf in self.labeled_frames:\n        if empty_instances:\n            lf.remove_empty_instances()\n\n        if frames and len(lf) == 0:\n            continue\n\n        if videos and lf.video not in used_videos:\n            used_videos.append(lf.video)\n\n        if skeletons or tracks:\n            for inst in lf:\n                if skeletons and inst.skeleton not in used_skeletons:\n                    used_skeletons.append(inst.skeleton)\n                if (\n                    tracks\n                    and inst.track is not None\n                    and inst.track not in used_tracks\n                ):\n                    used_tracks.append(inst.track)\n\n        if frames:\n            kept_frames.append(lf)\n\n    if videos:\n        self.videos = [video for video in self.videos if video in used_videos]\n\n    if skeletons:\n        self.skeletons = [\n            skeleton for skeleton in self.skeletons if skeleton in used_skeletons\n        ]\n\n    if tracks:\n        self.tracks = [track for track in self.tracks if track in used_tracks]\n\n    if frames:\n        self.labeled_frames = kept_frames\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Labels.extend","title":"<code>extend(lfs, update=True)</code>","text":"<p>Append a labeled frame to the labels.</p> <p>Parameters:</p> Name Type Description Default <code>lfs</code> <code>list[LabeledFrame]</code> <p>A list of labeled frames to add to the labels.</p> required <code>update</code> <code>bool</code> <p>If <code>True</code> (the default), update list of videos, tracks and skeletons from the contents.</p> <code>True</code> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def extend(self, lfs: list[LabeledFrame], update: bool = True):\n    \"\"\"Append a labeled frame to the labels.\n\n    Args:\n        lfs: A list of labeled frames to add to the labels.\n        update: If `True` (the default), update list of videos, tracks and\n            skeletons from the contents.\n    \"\"\"\n    self.labeled_frames.extend(lfs)\n\n    if update:\n        for lf in lfs:\n            if lf.video not in self.videos:\n                self.videos.append(lf.video)\n\n            for inst in lf:\n                if inst.skeleton not in self.skeletons:\n                    self.skeletons.append(inst.skeleton)\n\n                if inst.track is not None and inst.track not in self.tracks:\n                    self.tracks.append(inst.track)\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Labels.extract","title":"<code>extract(inds, copy=True)</code>","text":"<p>Extract a set of frames into a new Labels object.</p> <p>Parameters:</p> Name Type Description Default <code>inds</code> <code>list[int] | list[tuple[Video, int]] | ndarray</code> <p>Indices of labeled frames. Can be specified as a list of array of integer indices of labeled frames or tuples of Video and frame indices.</p> required <code>copy</code> <code>bool</code> <p>If <code>True</code> (the default), return a copy of the frames and containing objects. Otherwise, return a reference to the data.</p> <code>True</code> <p>Returns:</p> Type Description <code>Labels</code> <p>A new <code>Labels</code> object containing the selected labels.</p> Notes <p>This copies the labeled frames and their associated data, including skeletons and tracks, and tries to maintain the relative ordering.</p> <p>This also copies the provenance and inserts an extra key: <code>\"source_labels\"</code> with the path to the current labels, if available.</p> <p>It does NOT copy suggested frames.</p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def extract(\n    self, inds: list[int] | list[tuple[Video, int]] | np.ndarray, copy: bool = True\n) -&gt; Labels:\n    \"\"\"Extract a set of frames into a new Labels object.\n\n    Args:\n        inds: Indices of labeled frames. Can be specified as a list of array of\n            integer indices of labeled frames or tuples of Video and frame indices.\n        copy: If `True` (the default), return a copy of the frames and containing\n            objects. Otherwise, return a reference to the data.\n\n    Returns:\n        A new `Labels` object containing the selected labels.\n\n    Notes:\n        This copies the labeled frames and their associated data, including\n        skeletons and tracks, and tries to maintain the relative ordering.\n\n        This also copies the provenance and inserts an extra key: `\"source_labels\"`\n        with the path to the current labels, if available.\n\n        It does NOT copy suggested frames.\n    \"\"\"\n    lfs = self[inds]\n\n    if copy:\n        lfs = deepcopy(lfs)\n    labels = Labels(lfs)\n\n    # Try to keep the lists in the same order.\n    track_to_ind = {track.name: ind for ind, track in enumerate(self.tracks)}\n    labels.tracks = sorted(labels.tracks, key=lambda x: track_to_ind[x.name])\n\n    skel_to_ind = {skel.name: ind for ind, skel in enumerate(self.skeletons)}\n    labels.skeletons = sorted(labels.skeletons, key=lambda x: skel_to_ind[x.name])\n\n    labels.provenance = deepcopy(labels.provenance)\n    labels.provenance[\"source_labels\"] = self.provenance.get(\"filename\", None)\n\n    return labels\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Labels.find","title":"<code>find(video, frame_idx=None, return_new=False)</code>","text":"<p>Search for labeled frames given video and/or frame index.</p> <p>Parameters:</p> Name Type Description Default <code>video</code> <code>Video</code> <p>A <code>Video</code> that is associated with the project.</p> required <code>frame_idx</code> <code>int | list[int] | None</code> <p>The frame index (or indices) which we want to find in the video. If a range is specified, we'll return all frames with indices in that range. If not specific, then we'll return all labeled frames for video.</p> <code>None</code> <code>return_new</code> <code>bool</code> <p>Whether to return singleton of new and empty <code>LabeledFrame</code> if none are found in project.</p> <code>False</code> <p>Returns:</p> Type Description <code>list[LabeledFrame]</code> <p>List of <code>LabeledFrame</code> objects that match the criteria.</p> <p>The list will be empty if no matches found, unless return_new is True, in which case it contains new (empty) <code>LabeledFrame</code> objects with <code>video</code> and <code>frame_index</code> set.</p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def find(\n    self,\n    video: Video,\n    frame_idx: int | list[int] | None = None,\n    return_new: bool = False,\n) -&gt; list[LabeledFrame]:\n    \"\"\"Search for labeled frames given video and/or frame index.\n\n    Args:\n        video: A `Video` that is associated with the project.\n        frame_idx: The frame index (or indices) which we want to find in the video.\n            If a range is specified, we'll return all frames with indices in that\n            range. If not specific, then we'll return all labeled frames for video.\n        return_new: Whether to return singleton of new and empty `LabeledFrame` if\n            none are found in project.\n\n    Returns:\n        List of `LabeledFrame` objects that match the criteria.\n\n        The list will be empty if no matches found, unless return_new is True, in\n        which case it contains new (empty) `LabeledFrame` objects with `video` and\n        `frame_index` set.\n    \"\"\"\n    results = []\n\n    if frame_idx is None:\n        for lf in self.labeled_frames:\n            if lf.video == video:\n                results.append(lf)\n        return results\n\n    if np.isscalar(frame_idx):\n        frame_idx = np.array(frame_idx).reshape(-1)\n\n    for frame_ind in frame_idx:\n        result = None\n        for lf in self.labeled_frames:\n            if lf.video == video and lf.frame_idx == frame_ind:\n                result = lf\n                results.append(result)\n                break\n        if result is None and return_new:\n            results.append(LabeledFrame(video=video, frame_idx=frame_ind))\n\n    return results\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Labels.from_numpy","title":"<code>from_numpy(tracks_arr, videos, skeletons=None, tracks=None, first_frame=0, return_confidence=False)</code>  <code>classmethod</code>","text":"<p>Create a new Labels object from a numpy array of tracks.</p> <p>This factory method creates a new Labels object with instances constructed from the provided numpy array. It is the inverse operation of <code>Labels.numpy()</code>.</p> <p>Parameters:</p> Name Type Description Default <code>tracks_arr</code> <code>ndarray</code> <p>A numpy array of tracks, with shape <code>(n_frames, n_tracks, n_nodes, 2)</code> or <code>(n_frames, n_tracks, n_nodes, 3)</code>, where the last dimension contains the x,y coordinates (and optionally confidence scores).</p> required <code>videos</code> <code>list[Video]</code> <p>List of Video objects to associate with the labels. At least one video is required.</p> required <code>skeletons</code> <code>list[Skeleton] | Skeleton | None</code> <p>Skeleton or list of Skeleton objects to use for the instances. At least one skeleton is required.</p> <code>None</code> <code>tracks</code> <code>list[Track] | None</code> <p>List of Track objects corresponding to the second dimension of the array. If not specified, new tracks will be created automatically.</p> <code>None</code> <code>first_frame</code> <code>int</code> <p>Frame index to start the labeled frames from. Default is 0.</p> <code>0</code> <code>return_confidence</code> <code>bool</code> <p>Whether the tracks_arr contains confidence scores in the last dimension. If True, tracks_arr.shape[-1] should be 3.</p> <code>False</code> <p>Returns:</p> Type Description <code>'Labels'</code> <p>A new Labels object with instances constructed from the numpy array.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the array dimensions are invalid, or if no videos or skeletons are provided.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from sleap_io import Labels, Video, Skeleton\n&gt;&gt;&gt; # Create a simple tracking array for 2 frames, 1 track, 2 nodes\n&gt;&gt;&gt; arr = np.zeros((2, 1, 2, 2))\n&gt;&gt;&gt; arr[0, 0] = [[10, 20], [30, 40]]  # Frame 0\n&gt;&gt;&gt; arr[1, 0] = [[15, 25], [35, 45]]  # Frame 1\n&gt;&gt;&gt; # Create a video and skeleton\n&gt;&gt;&gt; video = Video(filename=\"example.mp4\")\n&gt;&gt;&gt; skeleton = Skeleton([\"head\", \"tail\"])\n&gt;&gt;&gt; # Create labels from the array\n&gt;&gt;&gt; labels = Labels.from_numpy(arr, videos=[video], skeletons=[skeleton])\n</code></pre> Source code in <code>sleap_io/model/labels.py</code> <pre><code>@classmethod\ndef from_numpy(\n    cls,\n    tracks_arr: np.ndarray,\n    videos: list[Video],\n    skeletons: list[Skeleton] | Skeleton | None = None,\n    tracks: list[Track] | None = None,\n    first_frame: int = 0,\n    return_confidence: bool = False,\n) -&gt; \"Labels\":\n    \"\"\"Create a new Labels object from a numpy array of tracks.\n\n    This factory method creates a new Labels object with instances constructed from\n    the provided numpy array. It is the inverse operation of `Labels.numpy()`.\n\n    Args:\n        tracks_arr: A numpy array of tracks, with shape\n            `(n_frames, n_tracks, n_nodes, 2)` or\n            `(n_frames, n_tracks, n_nodes, 3)`,\n            where the last dimension contains the x,y coordinates (and optionally\n            confidence scores).\n        videos: List of Video objects to associate with the labels. At least one\n            video\n            is required.\n        skeletons: Skeleton or list of Skeleton objects to use for the instances.\n            At least one skeleton is required.\n        tracks: List of Track objects corresponding to the second dimension of the\n            array. If not specified, new tracks will be created automatically.\n        first_frame: Frame index to start the labeled frames from. Default is 0.\n        return_confidence: Whether the tracks_arr contains confidence scores in the\n            last dimension. If True, tracks_arr.shape[-1] should be 3.\n\n    Returns:\n        A new Labels object with instances constructed from the numpy array.\n\n    Raises:\n        ValueError: If the array dimensions are invalid, or if no videos or\n            skeletons are provided.\n\n    Examples:\n        &gt;&gt;&gt; import numpy as np\n        &gt;&gt;&gt; from sleap_io import Labels, Video, Skeleton\n        &gt;&gt;&gt; # Create a simple tracking array for 2 frames, 1 track, 2 nodes\n        &gt;&gt;&gt; arr = np.zeros((2, 1, 2, 2))\n        &gt;&gt;&gt; arr[0, 0] = [[10, 20], [30, 40]]  # Frame 0\n        &gt;&gt;&gt; arr[1, 0] = [[15, 25], [35, 45]]  # Frame 1\n        &gt;&gt;&gt; # Create a video and skeleton\n        &gt;&gt;&gt; video = Video(filename=\"example.mp4\")\n        &gt;&gt;&gt; skeleton = Skeleton([\"head\", \"tail\"])\n        &gt;&gt;&gt; # Create labels from the array\n        &gt;&gt;&gt; labels = Labels.from_numpy(arr, videos=[video], skeletons=[skeleton])\n    \"\"\"\n    # Check dimensions\n    if len(tracks_arr.shape) != 4:\n        raise ValueError(\n            f\"Array must have 4 dimensions (n_frames, n_tracks, n_nodes, 2 or 3), \"\n            f\"but got {tracks_arr.shape}\"\n        )\n\n    # Validate videos\n    if not videos:\n        raise ValueError(\"At least one video must be provided\")\n    video = videos[0]  # Use the first video for creating labeled frames\n\n    # Process skeletons input\n    if skeletons is None:\n        raise ValueError(\"At least one skeleton must be provided\")\n    elif isinstance(skeletons, Skeleton):\n        skeletons = [skeletons]\n    elif not skeletons:  # Check for empty list\n        raise ValueError(\"At least one skeleton must be provided\")\n\n    skeleton = skeletons[0]  # Use the first skeleton for creating instances\n    n_nodes = len(skeleton.nodes)\n\n    # Check if tracks_arr contains confidence scores\n    has_confidence = tracks_arr.shape[-1] == 3 or return_confidence\n\n    # Get dimensions\n    n_frames, n_tracks_arr, _ = tracks_arr.shape[:3]\n\n    # Create or validate tracks\n    if tracks is None:\n        # Auto-create tracks if not provided\n        tracks = [Track(f\"track_{i}\") for i in range(n_tracks_arr)]\n    elif len(tracks) &lt; n_tracks_arr:\n        # Add missing tracks if needed\n        original_len = len(tracks)\n        for i in range(n_tracks_arr - original_len):\n            tracks.append(Track(f\"track_{i}\"))\n\n    # Create a new empty Labels object\n    labels = cls()\n    labels.videos = list(videos)\n    labels.skeletons = list(skeletons)\n    labels.tracks = list(tracks)\n\n    # Create labeled frames and instances from the array data\n    for i in range(n_frames):\n        frame_idx = i + first_frame\n\n        # Check if this frame has any valid data across all tracks\n        frame_has_valid_data = False\n        for j in range(n_tracks_arr):\n            track_data = tracks_arr[i, j]\n            # Check if at least one node in this track has valid xy coordinates\n            if np.any(~np.isnan(track_data[:, 0])):\n                frame_has_valid_data = True\n                break\n\n        # Skip creating a frame if there's no valid data\n        if not frame_has_valid_data:\n            continue\n\n        # Create a new labeled frame\n        labeled_frame = LabeledFrame(video=video, frame_idx=frame_idx)\n        frame_has_valid_instances = False\n\n        # Process each track in this frame\n        for j in range(n_tracks_arr):\n            track = tracks[j]\n            track_data = tracks_arr[i, j]\n\n            # Check if there's any valid data for this track at this frame\n            valid_points = ~np.isnan(track_data[:, 0])\n            if not np.any(valid_points):\n                continue\n\n            # Create points from numpy data\n            points = track_data[:, :2].copy()\n\n            # Create new instance\n            if has_confidence:\n                # Get confidence scores\n                if tracks_arr.shape[-1] == 3:\n                    scores = track_data[:, 2].copy()\n                else:\n                    scores = np.ones(n_nodes)\n\n                # Fix NaN scores\n                scores = np.where(np.isnan(scores), 1.0, scores)\n\n                # Create instance with confidence scores\n                new_instance = PredictedInstance.from_numpy(\n                    points_data=points,\n                    skeleton=skeleton,\n                    point_scores=scores,\n                    score=1.0,\n                    track=track,\n                )\n            else:\n                # Create instance with default scores\n                new_instance = PredictedInstance.from_numpy(\n                    points_data=points,\n                    skeleton=skeleton,\n                    point_scores=np.ones(n_nodes),\n                    score=1.0,\n                    track=track,\n                )\n\n            # Add to frame\n            labeled_frame.instances.append(new_instance)\n            frame_has_valid_instances = True\n\n        # Only add frames that have instances\n        if frame_has_valid_instances:\n            labels.append(labeled_frame, update=False)\n\n    # Update internal references\n    labels.update()\n\n    return labels\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Labels.make_training_splits","title":"<code>make_training_splits(n_train, n_val=None, n_test=None, save_dir=None, seed=None, embed=True)</code>","text":"<p>Make splits for training with embedded images.</p> <p>Parameters:</p> Name Type Description Default <code>n_train</code> <code>int | float</code> <p>Size of the training split as integer or fraction.</p> required <code>n_val</code> <code>int | float | None</code> <p>Size of the validation split as integer or fraction. If <code>None</code>, this will be inferred based on the values of <code>n_train</code> and <code>n_test</code>. If <code>n_test</code> is <code>None</code>, this will be the remainder of the data after the training split.</p> <code>None</code> <code>n_test</code> <code>int | float | None</code> <p>Size of the testing split as integer or fraction. If <code>None</code>, the test split will not be saved.</p> <code>None</code> <code>save_dir</code> <code>str | Path | None</code> <p>If specified, save splits to SLP files with embedded images.</p> <code>None</code> <code>seed</code> <code>int | None</code> <p>Optional integer seed to use for reproducibility.</p> <code>None</code> <code>embed</code> <code>bool</code> <p>If <code>True</code> (the default), embed user labeled frame images in the saved files, which is useful for portability but can be slow for large projects. If <code>False</code>, labels are saved with references to the source videos files.</p> <code>True</code> <p>Returns:</p> Type Description <code>LabelsSet</code> <p>A <code>LabelsSet</code> containing \"train\", \"val\", and optionally \"test\" keys. The <code>LabelsSet</code> can be unpacked for backward compatibility: <code>train, val = labels.make_training_splits(0.8)</code> <code>train, val, test = labels.make_training_splits(0.8, n_test=0.1)</code></p> Notes <p>Predictions and suggestions will be removed before saving, leaving only frames with user labeled data (the source labels are not affected).</p> <p>Frames with user labeled data will be embedded in the resulting files.</p> <p>If <code>save_dir</code> is specified, this will save the randomly sampled splits to:</p> <ul> <li><code>{save_dir}/train.pkg.slp</code></li> <li><code>{save_dir}/val.pkg.slp</code></li> <li><code>{save_dir}/test.pkg.slp</code> (if <code>n_test</code> is specified)</li> </ul> <p>If <code>embed</code> is <code>False</code>, the files will be saved without embedded images to:</p> <ul> <li><code>{save_dir}/train.slp</code></li> <li><code>{save_dir}/val.slp</code></li> <li><code>{save_dir}/test.slp</code> (if <code>n_test</code> is specified)</li> </ul> <p>See also: <code>Labels.split</code></p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def make_training_splits(\n    self,\n    n_train: int | float,\n    n_val: int | float | None = None,\n    n_test: int | float | None = None,\n    save_dir: str | Path | None = None,\n    seed: int | None = None,\n    embed: bool = True,\n) -&gt; LabelsSet:\n    \"\"\"Make splits for training with embedded images.\n\n    Args:\n        n_train: Size of the training split as integer or fraction.\n        n_val: Size of the validation split as integer or fraction. If `None`,\n            this will be inferred based on the values of `n_train` and `n_test`. If\n            `n_test` is `None`, this will be the remainder of the data after the\n            training split.\n        n_test: Size of the testing split as integer or fraction. If `None`, the\n            test split will not be saved.\n        save_dir: If specified, save splits to SLP files with embedded images.\n        seed: Optional integer seed to use for reproducibility.\n        embed: If `True` (the default), embed user labeled frame images in the saved\n            files, which is useful for portability but can be slow for large\n            projects. If `False`, labels are saved with references to the source\n            videos files.\n\n    Returns:\n        A `LabelsSet` containing \"train\", \"val\", and optionally \"test\" keys.\n        The `LabelsSet` can be unpacked for backward compatibility:\n        `train, val = labels.make_training_splits(0.8)`\n        `train, val, test = labels.make_training_splits(0.8, n_test=0.1)`\n\n    Notes:\n        Predictions and suggestions will be removed before saving, leaving only\n        frames with user labeled data (the source labels are not affected).\n\n        Frames with user labeled data will be embedded in the resulting files.\n\n        If `save_dir` is specified, this will save the randomly sampled splits to:\n\n        - `{save_dir}/train.pkg.slp`\n        - `{save_dir}/val.pkg.slp`\n        - `{save_dir}/test.pkg.slp` (if `n_test` is specified)\n\n        If `embed` is `False`, the files will be saved without embedded images to:\n\n        - `{save_dir}/train.slp`\n        - `{save_dir}/val.slp`\n        - `{save_dir}/test.slp` (if `n_test` is specified)\n\n    See also: `Labels.split`\n    \"\"\"\n    # Import here to avoid circular imports\n    from sleap_io.model.labels_set import LabelsSet\n\n    # Clean up labels.\n    labels = deepcopy(self)\n    labels.remove_predictions()\n    labels.suggestions = []\n    labels.clean()\n\n    # Make train split.\n    labels_train, labels_rest = labels.split(n_train, seed=seed)\n\n    # Make test split.\n    if n_test is not None:\n        if n_test &lt; 1:\n            n_test = (n_test * len(labels)) / len(labels_rest)\n        labels_test, labels_rest = labels_rest.split(n=n_test, seed=seed)\n\n    # Make val split.\n    if n_val is not None:\n        if n_val &lt; 1:\n            n_val = (n_val * len(labels)) / len(labels_rest)\n        if isinstance(n_val, float) and n_val == 1.0:\n            labels_val = labels_rest\n        else:\n            labels_val, _ = labels_rest.split(n=n_val, seed=seed)\n    else:\n        labels_val = labels_rest\n\n    # Update provenance.\n    source_labels = self.provenance.get(\"filename\", None)\n    labels_train.provenance[\"source_labels\"] = source_labels\n    if n_val is not None:\n        labels_val.provenance[\"source_labels\"] = source_labels\n    if n_test is not None:\n        labels_test.provenance[\"source_labels\"] = source_labels\n\n    # Create LabelsSet\n    if n_test is None:\n        labels_set = LabelsSet({\"train\": labels_train, \"val\": labels_val})\n    else:\n        labels_set = LabelsSet(\n            {\"train\": labels_train, \"val\": labels_val, \"test\": labels_test}\n        )\n\n    # Save.\n    if save_dir is not None:\n        labels_set.save(save_dir, embed=embed)\n\n    return labels_set\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Labels.merge","title":"<code>merge(other, instance_matcher=None, skeleton_matcher=None, video_matcher=None, track_matcher=None, frame_strategy='smart', validate=True, progress_callback=None, error_mode='continue')</code>","text":"<p>Merge another Labels object into this one.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>'Labels'</code> <p>Another Labels object to merge into this one.</p> required <code>instance_matcher</code> <code>Optional['InstanceMatcher']</code> <p>Matcher for comparing instances. If None, uses default spatial matching with 5px tolerance.</p> <code>None</code> <code>skeleton_matcher</code> <code>Optional['SkeletonMatcher']</code> <p>Matcher for comparing skeletons. If None, uses structure matching.</p> <code>None</code> <code>video_matcher</code> <code>Optional['VideoMatcher']</code> <p>Matcher for comparing videos. If None, uses auto matching.</p> <code>None</code> <code>track_matcher</code> <code>Optional['TrackMatcher']</code> <p>Matcher for comparing tracks. If None, uses name matching.</p> <code>None</code> <code>frame_strategy</code> <code>str</code> <p>Strategy for merging frames: - \"smart\": Keep user labels, update predictions - \"keep_original\": Keep original frames - \"keep_new\": Replace with new frames - \"keep_both\": Keep all frames</p> <code>'smart'</code> <code>validate</code> <code>bool</code> <p>If True, validate for conflicts before merging.</p> <code>True</code> <code>progress_callback</code> <code>Optional[Callable]</code> <p>Optional callback for progress updates. Should accept (current, total, message) arguments.</p> <code>None</code> <code>error_mode</code> <code>str</code> <p>How to handle errors: - \"continue\": Log errors but continue - \"strict\": Raise exception on first error - \"warn\": Print warnings but continue</p> <code>'continue'</code> <p>Returns:</p> Type Description <code>'MergeResult'</code> <p>MergeResult object with statistics and any errors/conflicts.</p> Notes <p>This method modifies the Labels object in place. The merge is designed to handle common workflows like merging predictions back into a project.</p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def merge(\n    self,\n    other: \"Labels\",\n    instance_matcher: Optional[\"InstanceMatcher\"] = None,\n    skeleton_matcher: Optional[\"SkeletonMatcher\"] = None,\n    video_matcher: Optional[\"VideoMatcher\"] = None,\n    track_matcher: Optional[\"TrackMatcher\"] = None,\n    frame_strategy: str = \"smart\",\n    validate: bool = True,\n    progress_callback: Optional[Callable] = None,\n    error_mode: str = \"continue\",\n) -&gt; \"MergeResult\":\n    \"\"\"Merge another Labels object into this one.\n\n    Args:\n        other: Another Labels object to merge into this one.\n        instance_matcher: Matcher for comparing instances. If None, uses default\n            spatial matching with 5px tolerance.\n        skeleton_matcher: Matcher for comparing skeletons. If None, uses structure\n            matching.\n        video_matcher: Matcher for comparing videos. If None, uses auto matching.\n        track_matcher: Matcher for comparing tracks. If None, uses name matching.\n        frame_strategy: Strategy for merging frames:\n            - \"smart\": Keep user labels, update predictions\n            - \"keep_original\": Keep original frames\n            - \"keep_new\": Replace with new frames\n            - \"keep_both\": Keep all frames\n        validate: If True, validate for conflicts before merging.\n        progress_callback: Optional callback for progress updates.\n            Should accept (current, total, message) arguments.\n        error_mode: How to handle errors:\n            - \"continue\": Log errors but continue\n            - \"strict\": Raise exception on first error\n            - \"warn\": Print warnings but continue\n\n    Returns:\n        MergeResult object with statistics and any errors/conflicts.\n\n    Notes:\n        This method modifies the Labels object in place. The merge is designed to\n        handle common workflows like merging predictions back into a project.\n    \"\"\"\n    from datetime import datetime\n    from pathlib import Path\n\n    from sleap_io.model.matching import (\n        ConflictResolution,\n        ErrorMode,\n        InstanceMatcher,\n        MergeError,\n        MergeResult,\n        SkeletonMatcher,\n        SkeletonMatchMethod,\n        SkeletonMismatchError,\n        TrackMatcher,\n        VideoMatcher,\n        VideoMatchMethod,\n    )\n\n    # Initialize matchers with defaults if not provided\n    if instance_matcher is None:\n        instance_matcher = InstanceMatcher()\n    if skeleton_matcher is None:\n        skeleton_matcher = SkeletonMatcher(method=SkeletonMatchMethod.STRUCTURE)\n    if video_matcher is None:\n        video_matcher = VideoMatcher()\n    if track_matcher is None:\n        track_matcher = TrackMatcher()\n\n    # Parse error mode\n    error_mode_enum = ErrorMode(error_mode)\n\n    # Initialize result\n    result = MergeResult(successful=True)\n\n    # Track merge history in provenance\n    if \"merge_history\" not in self.provenance:\n        self.provenance[\"merge_history\"] = []\n\n    merge_record = {\n        \"timestamp\": datetime.now().isoformat(),\n        \"source_labels\": {\n            \"n_frames\": len(other.labeled_frames),\n            \"n_videos\": len(other.videos),\n            \"n_skeletons\": len(other.skeletons),\n            \"n_tracks\": len(other.tracks),\n        },\n        \"strategy\": frame_strategy,\n    }\n\n    try:\n        # Step 1: Match and merge skeletons\n        skeleton_map = {}\n        for other_skel in other.skeletons:\n            matched = False\n            for self_skel in self.skeletons:\n                if skeleton_matcher.match(self_skel, other_skel):\n                    skeleton_map[other_skel] = self_skel\n                    matched = True\n                    break\n\n            if not matched:\n                if validate and error_mode_enum == ErrorMode.STRICT:\n                    raise SkeletonMismatchError(\n                        message=f\"No matching skeleton found for {other_skel.name}\",\n                        details={\"skeleton\": other_skel},\n                    )\n                elif error_mode_enum == ErrorMode.WARN:\n                    print(f\"Warning: No matching skeleton for {other_skel.name}\")\n\n                # Add new skeleton if no match\n                self.skeletons.append(other_skel)\n                skeleton_map[other_skel] = other_skel\n\n        # Step 2: Match and merge videos\n        video_map = {}\n        frame_idx_map = {}  # Maps (old_video, old_idx) -&gt; (new_video, new_idx)\n\n        for other_video in other.videos:\n            matched = False\n            for self_video in self.videos:\n                if video_matcher.match(self_video, other_video):\n                    # Special handling for different match methods\n                    if video_matcher.method == VideoMatchMethod.IMAGE_DEDUP:\n                        # Deduplicate images from other_video\n                        deduped_video = other_video.deduplicate_with(self_video)\n                        if deduped_video is None:\n                            # All images were duplicates, map to existing video\n                            video_map[other_video] = self_video\n                            # Build frame index mapping for deduplicated frames\n                            if isinstance(\n                                other_video.filename, list\n                            ) and isinstance(self_video.filename, list):\n                                other_basenames = [\n                                    Path(f).name for f in other_video.filename\n                                ]\n                                self_basenames = [\n                                    Path(f).name for f in self_video.filename\n                                ]\n                                for old_idx, basename in enumerate(other_basenames):\n                                    if basename in self_basenames:\n                                        new_idx = self_basenames.index(basename)\n                                        frame_idx_map[(other_video, old_idx)] = (\n                                            self_video,\n                                            new_idx,\n                                        )\n                        else:\n                            # Add deduplicated video as new\n                            self.videos.append(deduped_video)\n                            video_map[other_video] = deduped_video\n                            # Build frame index mapping for remaining frames\n                            if isinstance(\n                                other_video.filename, list\n                            ) and isinstance(deduped_video.filename, list):\n                                other_basenames = [\n                                    Path(f).name for f in other_video.filename\n                                ]\n                                deduped_basenames = [\n                                    Path(f).name for f in deduped_video.filename\n                                ]\n                                for old_idx, basename in enumerate(other_basenames):\n                                    if basename in deduped_basenames:\n                                        new_idx = deduped_basenames.index(basename)\n                                        frame_idx_map[(other_video, old_idx)] = (\n                                            deduped_video,\n                                            new_idx,\n                                        )\n                    elif video_matcher.method == VideoMatchMethod.SHAPE:\n                        # Merge videos with same shape\n                        merged_video = self_video.merge_with(other_video)\n                        # Replace self_video with merged version\n                        self_video_idx = self.videos.index(self_video)\n                        self.videos[self_video_idx] = merged_video\n                        video_map[other_video] = merged_video\n                        video_map[self_video] = (\n                            merged_video  # Update mapping for self too\n                        )\n                        # Build frame index mapping\n                        if isinstance(other_video.filename, list) and isinstance(\n                            merged_video.filename, list\n                        ):\n                            other_basenames = [\n                                Path(f).name for f in other_video.filename\n                            ]\n                            merged_basenames = [\n                                Path(f).name for f in merged_video.filename\n                            ]\n                            for old_idx, basename in enumerate(other_basenames):\n                                if basename in merged_basenames:\n                                    new_idx = merged_basenames.index(basename)\n                                    frame_idx_map[(other_video, old_idx)] = (\n                                        merged_video,\n                                        new_idx,\n                                    )\n                    else:\n                        # Regular matching, no special handling\n                        video_map[other_video] = self_video\n                    matched = True\n                    break\n\n            if not matched:\n                # Add new video if no match\n                self.videos.append(other_video)\n                video_map[other_video] = other_video\n\n        # Step 3: Match and merge tracks\n        track_map = {}\n        for other_track in other.tracks:\n            matched = False\n            for self_track in self.tracks:\n                if track_matcher.match(self_track, other_track):\n                    track_map[other_track] = self_track\n                    matched = True\n                    break\n\n            if not matched:\n                # Add new track if no match\n                self.tracks.append(other_track)\n                track_map[other_track] = other_track\n\n        # Step 4: Merge frames\n        total_frames = len(other.labeled_frames)\n\n        for frame_idx, other_frame in enumerate(other.labeled_frames):\n            if progress_callback:\n                progress_callback(\n                    frame_idx,\n                    total_frames,\n                    f\"Merging frame {frame_idx + 1}/{total_frames}\",\n                )\n\n            # Check if frame index needs remapping (for deduplicated/merged videos)\n            if (other_frame.video, other_frame.frame_idx) in frame_idx_map:\n                mapped_video, mapped_frame_idx = frame_idx_map[\n                    (other_frame.video, other_frame.frame_idx)\n                ]\n            else:\n                # Map video to self\n                mapped_video = video_map.get(other_frame.video, other_frame.video)\n                mapped_frame_idx = other_frame.frame_idx\n\n            # Find matching frame in self\n            matching_frames = self.find(mapped_video, mapped_frame_idx)\n\n            if len(matching_frames) == 0:\n                # No matching frame, create new one\n                new_frame = LabeledFrame(\n                    video=mapped_video,\n                    frame_idx=mapped_frame_idx,\n                    instances=[],\n                )\n\n                # Map instances to new skeleton/track\n                for inst in other_frame.instances:\n                    new_inst = self._map_instance(inst, skeleton_map, track_map)\n                    new_frame.instances.append(new_inst)\n                    result.instances_added += 1\n\n                self.append(new_frame)\n                result.frames_merged += 1\n\n            else:\n                # Merge into existing frame\n                self_frame = matching_frames[0]\n\n                # Merge instances using frame-level merge\n                merged_instances, conflicts = self_frame.merge(\n                    other_frame,\n                    instance_matcher=instance_matcher,\n                    strategy=frame_strategy,\n                )\n\n                # Remap skeleton and track references for instances from other frame\n                remapped_instances = []\n                for inst in merged_instances:\n                    # Check if instance needs remapping (from other_frame)\n                    if inst.skeleton in skeleton_map:\n                        # Instance needs remapping\n                        remapped_inst = self._map_instance(\n                            inst, skeleton_map, track_map\n                        )\n                        remapped_instances.append(remapped_inst)\n                    else:\n                        # Instance already has correct skeleton (from self_frame)\n                        remapped_instances.append(inst)\n                merged_instances = remapped_instances\n\n                # Count changes\n                n_before = len(self_frame.instances)\n                n_after = len(merged_instances)\n                result.instances_added += max(0, n_after - n_before)\n\n                # Record conflicts\n                for orig, new, resolution in conflicts:\n                    result.conflicts.append(\n                        ConflictResolution(\n                            frame=self_frame,\n                            conflict_type=\"instance_conflict\",\n                            original_data=orig,\n                            new_data=new,\n                            resolution=resolution,\n                        )\n                    )\n\n                # Update frame instances\n                self_frame.instances = merged_instances\n                result.frames_merged += 1\n\n        # Step 5: Merge suggestions\n        for other_suggestion in other.suggestions:\n            mapped_video = video_map.get(\n                other_suggestion.video, other_suggestion.video\n            )\n            # Check if suggestion already exists\n            exists = False\n            for self_suggestion in self.suggestions:\n                if (\n                    self_suggestion.video == mapped_video\n                    and self_suggestion.frame_idx == other_suggestion.frame_idx\n                ):\n                    exists = True\n                    break\n            if not exists:\n                # Create new suggestion with mapped video\n                new_suggestion = SuggestionFrame(\n                    video=mapped_video, frame_idx=other_suggestion.frame_idx\n                )\n                self.suggestions.append(new_suggestion)\n\n        # Update merge record\n        merge_record[\"result\"] = {\n            \"frames_merged\": result.frames_merged,\n            \"instances_added\": result.instances_added,\n            \"conflicts\": len(result.conflicts),\n        }\n        self.provenance[\"merge_history\"].append(merge_record)\n\n    except MergeError as e:\n        result.successful = False\n        result.errors.append(e)\n        if error_mode_enum == ErrorMode.STRICT:\n            raise\n    except Exception as e:\n        result.successful = False\n        result.errors.append(\n            MergeError(message=str(e), details={\"exception\": type(e).__name__})\n        )\n        if error_mode_enum == ErrorMode.STRICT:\n            raise\n\n    if progress_callback:\n        progress_callback(total_frames, total_frames, \"Merge complete\")\n\n    return result\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Labels.numpy","title":"<code>numpy(video=None, untracked=False, return_confidence=False, user_instances=True)</code>","text":"<p>Construct a numpy array from instance points.</p> <p>Parameters:</p> Name Type Description Default <code>video</code> <code>Optional[Union[Video, int]]</code> <p>Video or video index to convert to numpy arrays. If <code>None</code> (the default), uses the first video.</p> <code>None</code> <code>untracked</code> <code>bool</code> <p>If <code>False</code> (the default), include only instances that have a track assignment. If <code>True</code>, includes all instances in each frame in arbitrary order.</p> <code>False</code> <code>return_confidence</code> <code>bool</code> <p>If <code>False</code> (the default), only return points of nodes. If <code>True</code>, return the points and scores of nodes.</p> <code>False</code> <code>user_instances</code> <code>bool</code> <p>If <code>True</code> (the default), include user instances when available, preferring them over predicted instances with the same track. If <code>False</code>, only include predicted instances.</p> <code>True</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>An array of tracks of shape <code>(n_frames, n_tracks, n_nodes, 2)</code> if <code>return_confidence</code> is <code>False</code>. Otherwise returned shape is <code>(n_frames, n_tracks, n_nodes, 3)</code> if <code>return_confidence</code> is <code>True</code>.</p> <p>Missing data will be replaced with <code>np.nan</code>.</p> <p>If this is a single instance project, a track does not need to be assigned.</p> <p>When <code>user_instances=False</code>, only predicted instances will be returned. When <code>user_instances=True</code>, user instances will be preferred over predicted instances with the same track or if linked via <code>from_predicted</code>.</p> Notes <p>This method assumes that instances have tracks assigned and is intended to function primarily for single-video prediction results.</p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def numpy(\n    self,\n    video: Optional[Union[Video, int]] = None,\n    untracked: bool = False,\n    return_confidence: bool = False,\n    user_instances: bool = True,\n) -&gt; np.ndarray:\n    \"\"\"Construct a numpy array from instance points.\n\n    Args:\n        video: Video or video index to convert to numpy arrays. If `None` (the\n            default), uses the first video.\n        untracked: If `False` (the default), include only instances that have a\n            track assignment. If `True`, includes all instances in each frame in\n            arbitrary order.\n        return_confidence: If `False` (the default), only return points of nodes. If\n            `True`, return the points and scores of nodes.\n        user_instances: If `True` (the default), include user instances when\n            available, preferring them over predicted instances with the same track.\n            If `False`,\n            only include predicted instances.\n\n    Returns:\n        An array of tracks of shape `(n_frames, n_tracks, n_nodes, 2)` if\n        `return_confidence` is `False`. Otherwise returned shape is\n        `(n_frames, n_tracks, n_nodes, 3)` if `return_confidence` is `True`.\n\n        Missing data will be replaced with `np.nan`.\n\n        If this is a single instance project, a track does not need to be assigned.\n\n        When `user_instances=False`, only predicted instances will be returned.\n        When `user_instances=True`, user instances will be preferred over predicted\n        instances with the same track or if linked via `from_predicted`.\n\n    Notes:\n        This method assumes that instances have tracks assigned and is intended to\n        function primarily for single-video prediction results.\n    \"\"\"\n    # Get labeled frames for specified video.\n    if video is None:\n        video = 0\n    if type(video) is int:\n        video = self.videos[video]\n    lfs = [lf for lf in self.labeled_frames if lf.video == video]\n\n    # Figure out frame index range.\n    first_frame, last_frame = 0, 0\n    for lf in lfs:\n        first_frame = min(first_frame, lf.frame_idx)\n        last_frame = max(last_frame, lf.frame_idx)\n\n    # Figure out the number of tracks based on number of instances in each frame.\n    # Check the max number of instances (predicted or user, depending on settings)\n    n_instances = 0\n    for lf in lfs:\n        if user_instances:\n            # Count max of either user or predicted instances per frame (not sum)\n            n_frame_instances = max(\n                len(lf.user_instances), len(lf.predicted_instances)\n            )\n        else:\n            n_frame_instances = len(lf.predicted_instances)\n        n_instances = max(n_instances, n_frame_instances)\n\n    # Case 1: We don't care about order because there's only 1 instance per frame,\n    # or we're considering untracked instances.\n    is_single_instance = n_instances == 1\n    untracked = untracked or is_single_instance\n    if untracked:\n        n_tracks = n_instances\n    else:\n        # Case 2: We're considering only tracked instances.\n        n_tracks = len(self.tracks)\n\n    n_frames = int(last_frame - first_frame + 1)\n    skeleton = self.skeletons[-1]  # Assume project only uses last skeleton\n    n_nodes = len(skeleton.nodes)\n\n    if return_confidence:\n        tracks = np.full((n_frames, n_tracks, n_nodes, 3), np.nan, dtype=\"float32\")\n    else:\n        tracks = np.full((n_frames, n_tracks, n_nodes, 2), np.nan, dtype=\"float32\")\n\n    for lf in lfs:\n        i = int(lf.frame_idx - first_frame)\n\n        if untracked:\n            # For untracked instances, fill them in arbitrary order\n            j = 0\n            instances_to_include = []\n\n            # If user instances are preferred, add them first\n            if user_instances and lf.has_user_instances:\n                # First collect all user instances\n                for inst in lf.user_instances:\n                    instances_to_include.append(inst)\n\n                # For the trivial case (single instance per frame), if we found\n                # user instances, we shouldn't include any predicted instances\n                if is_single_instance and len(instances_to_include) &gt; 0:\n                    pass  # Skip adding predicted instances\n                else:\n                    # Add predicted instances that don't have a corresponding\n                    # user instance\n                    for inst in lf.predicted_instances:\n                        skip = False\n                        for user_inst in lf.user_instances:\n                            # Skip if this predicted instance is linked to a user\n                            # instance via from_predicted\n                            if (\n                                hasattr(user_inst, \"from_predicted\")\n                                and user_inst.from_predicted == inst\n                            ):\n                                skip = True\n                                break\n                            # Skip if user and predicted instances share same track\n                            if (\n                                user_inst.track is not None\n                                and inst.track is not None\n                                and user_inst.track == inst.track\n                            ):\n                                skip = True\n                                break\n                        if not skip:\n                            instances_to_include.append(inst)\n            else:\n                # If user_instances=False, only include predicted instances\n                instances_to_include = lf.predicted_instances\n\n            # Now process all the instances we want to include\n            for inst in instances_to_include:\n                if j &lt; n_tracks:\n                    if return_confidence:\n                        if isinstance(inst, PredictedInstance):\n                            tracks[i, j] = inst.numpy(scores=True)\n                        else:\n                            # For user instances, set confidence to 1.0\n                            points_data = inst.numpy()\n                            confidence = np.ones(\n                                (points_data.shape[0], 1), dtype=\"float32\"\n                            )\n                            tracks[i, j] = np.hstack((points_data, confidence))\n                    else:\n                        tracks[i, j] = inst.numpy()\n                    j += 1\n        else:  # untracked is False\n            # For tracked instances, organize by track ID\n\n            # Create mapping from track to best instance for this frame\n            track_to_instance = {}\n\n            # First, add predicted instances to the mapping\n            for inst in lf.predicted_instances:\n                if inst.track is not None:\n                    track_to_instance[inst.track] = inst\n\n            # Then, add user instances to the mapping (if user_instances=True)\n            if user_instances:\n                for inst in lf.user_instances:\n                    if inst.track is not None:\n                        track_to_instance[inst.track] = inst\n\n            # Process the preferred instances for each track\n            for track in track_to_instance:\n                inst = track_to_instance[track]\n                j = self.tracks.index(track)\n\n                if type(inst) is PredictedInstance:\n                    tracks[i, j] = inst.numpy(scores=return_confidence)\n                elif type(inst) is Instance:\n                    tracks[i, j, :, :2] = inst.numpy()\n\n                    # If return_confidence is True, add dummy confidence scores\n                    if return_confidence:\n                        tracks[i, j, :, 2] = 1.0\n\n    return tracks\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Labels.remove_nodes","title":"<code>remove_nodes(nodes, skeleton=None)</code>","text":"<p>Remove nodes from the skeleton.</p> <p>Parameters:</p> Name Type Description Default <code>nodes</code> <code>list[NodeOrIndex]</code> <p>A list of node names, indices, or <code>Node</code> objects to remove.</p> required <code>skeleton</code> <code>Skeleton | None</code> <p><code>Skeleton</code> to update. If <code>None</code> (the default), assumes there is only one skeleton in the labels and raises <code>ValueError</code> otherwise.</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the nodes are not found in the skeleton, or if there is more than one skeleton in the labels and it is not specified.</p> Notes <p>This method should always be used when removing nodes from the skeleton as it handles updating the lookup caches necessary for indexing nodes by name, and updating instances to reflect the changes made to the skeleton.</p> <p>Any edges and symmetries that are connected to the removed nodes will also be removed.</p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def remove_nodes(self, nodes: list[NodeOrIndex], skeleton: Skeleton | None = None):\n    \"\"\"Remove nodes from the skeleton.\n\n    Args:\n        nodes: A list of node names, indices, or `Node` objects to remove.\n        skeleton: `Skeleton` to update. If `None` (the default), assumes there is\n            only one skeleton in the labels and raises `ValueError` otherwise.\n\n    Raises:\n        ValueError: If the nodes are not found in the skeleton, or if there is more\n            than one skeleton in the labels and it is not specified.\n\n    Notes:\n        This method should always be used when removing nodes from the skeleton as\n        it handles updating the lookup caches necessary for indexing nodes by name,\n        and updating instances to reflect the changes made to the skeleton.\n\n        Any edges and symmetries that are connected to the removed nodes will also\n        be removed.\n    \"\"\"\n    if skeleton is None:\n        if len(self.skeletons) != 1:\n            raise ValueError(\n                \"Skeleton must be specified when there is more than one skeleton \"\n                \"in the labels.\"\n            )\n        skeleton = self.skeleton\n\n    skeleton.remove_nodes(nodes)\n\n    for inst in self.instances:\n        if inst.skeleton == skeleton:\n            inst.update_skeleton()\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Labels.remove_predictions","title":"<code>remove_predictions(clean=True)</code>","text":"<p>Remove all predicted instances from the labels.</p> <p>Parameters:</p> Name Type Description Default <code>clean</code> <code>bool</code> <p>If <code>True</code> (the default), also remove any empty frames and unused tracks and skeletons. It does NOT remove videos that have no labeled frames or instances with no visible points.</p> <code>True</code> <p>See also: <code>Labels.clean</code></p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def remove_predictions(self, clean: bool = True):\n    \"\"\"Remove all predicted instances from the labels.\n\n    Args:\n        clean: If `True` (the default), also remove any empty frames and unused\n            tracks and skeletons. It does NOT remove videos that have no labeled\n            frames or instances with no visible points.\n\n    See also: `Labels.clean`\n    \"\"\"\n    for lf in self.labeled_frames:\n        lf.remove_predictions()\n\n    if clean:\n        self.clean(\n            frames=True,\n            empty_instances=False,\n            skeletons=True,\n            tracks=True,\n            videos=False,\n        )\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Labels.rename_nodes","title":"<code>rename_nodes(name_map, skeleton=None)</code>","text":"<p>Rename nodes in the skeleton.</p> <p>Parameters:</p> Name Type Description Default <code>name_map</code> <code>dict[NodeOrIndex, str] | list[str]</code> <p>A dictionary mapping old node names to new node names. Keys can be specified as <code>Node</code> objects, integer indices, or string names. Values must be specified as string names.</p> <p>If a list of strings is provided of the same length as the current nodes, the nodes will be renamed to the names in the list in order.</p> required <code>skeleton</code> <code>Skeleton | None</code> <p><code>Skeleton</code> to update. If <code>None</code> (the default), assumes there is only one skeleton in the labels and raises <code>ValueError</code> otherwise.</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the new node names exist in the skeleton, if the old node names are not found in the skeleton, or if there is more than one skeleton in the <code>Labels</code> but it is not specified.</p> Notes <p>This method is recommended over <code>Skeleton.rename_nodes</code> as it will update all instances in the labels to reflect the new node names.</p> Example <p>labels = Labels(skeletons=[Skeleton([\"A\", \"B\", \"C\"])]) labels.rename_nodes({\"A\": \"X\", \"B\": \"Y\", \"C\": \"Z\"}) labels.skeleton.node_names [\"X\", \"Y\", \"Z\"] labels.rename_nodes([\"a\", \"b\", \"c\"]) labels.skeleton.node_names [\"a\", \"b\", \"c\"]</p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def rename_nodes(\n    self,\n    name_map: dict[NodeOrIndex, str] | list[str],\n    skeleton: Skeleton | None = None,\n):\n    \"\"\"Rename nodes in the skeleton.\n\n    Args:\n        name_map: A dictionary mapping old node names to new node names. Keys can be\n            specified as `Node` objects, integer indices, or string names. Values\n            must be specified as string names.\n\n            If a list of strings is provided of the same length as the current\n            nodes, the nodes will be renamed to the names in the list in order.\n        skeleton: `Skeleton` to update. If `None` (the default), assumes there is\n            only one skeleton in the labels and raises `ValueError` otherwise.\n\n    Raises:\n        ValueError: If the new node names exist in the skeleton, if the old node\n            names are not found in the skeleton, or if there is more than one\n            skeleton in the `Labels` but it is not specified.\n\n    Notes:\n        This method is recommended over `Skeleton.rename_nodes` as it will update\n        all instances in the labels to reflect the new node names.\n\n    Example:\n        &gt;&gt;&gt; labels = Labels(skeletons=[Skeleton([\"A\", \"B\", \"C\"])])\n        &gt;&gt;&gt; labels.rename_nodes({\"A\": \"X\", \"B\": \"Y\", \"C\": \"Z\"})\n        &gt;&gt;&gt; labels.skeleton.node_names\n        [\"X\", \"Y\", \"Z\"]\n        &gt;&gt;&gt; labels.rename_nodes([\"a\", \"b\", \"c\"])\n        &gt;&gt;&gt; labels.skeleton.node_names\n        [\"a\", \"b\", \"c\"]\n    \"\"\"\n    if skeleton is None:\n        if len(self.skeletons) != 1:\n            raise ValueError(\n                \"Skeleton must be specified when there is more than one skeleton \"\n                \"in the labels.\"\n            )\n        skeleton = self.skeleton\n\n    skeleton.rename_nodes(name_map)\n\n    # Update instances.\n    for inst in self.instances:\n        if inst.skeleton == skeleton:\n            inst.points[\"name\"] = inst.skeleton.node_names\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Labels.reorder_nodes","title":"<code>reorder_nodes(new_order, skeleton=None)</code>","text":"<p>Reorder nodes in the skeleton.</p> <p>Parameters:</p> Name Type Description Default <code>new_order</code> <code>list[NodeOrIndex]</code> <p>A list of node names, indices, or <code>Node</code> objects specifying the new order of the nodes.</p> required <code>skeleton</code> <code>Skeleton | None</code> <p><code>Skeleton</code> to update. If <code>None</code> (the default), assumes there is only one skeleton in the labels and raises <code>ValueError</code> otherwise.</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the new order of nodes is not the same length as the current nodes, or if there is more than one skeleton in the <code>Labels</code> but it is not specified.</p> Notes <p>This method handles updating the lookup caches necessary for indexing nodes by name, as well as updating instances to reflect the changes made to the skeleton.</p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def reorder_nodes(\n    self, new_order: list[NodeOrIndex], skeleton: Skeleton | None = None\n):\n    \"\"\"Reorder nodes in the skeleton.\n\n    Args:\n        new_order: A list of node names, indices, or `Node` objects specifying the\n            new order of the nodes.\n        skeleton: `Skeleton` to update. If `None` (the default), assumes there is\n            only one skeleton in the labels and raises `ValueError` otherwise.\n\n    Raises:\n        ValueError: If the new order of nodes is not the same length as the current\n            nodes, or if there is more than one skeleton in the `Labels` but it is\n            not specified.\n\n    Notes:\n        This method handles updating the lookup caches necessary for indexing nodes\n        by name, as well as updating instances to reflect the changes made to the\n        skeleton.\n    \"\"\"\n    if skeleton is None:\n        if len(self.skeletons) != 1:\n            raise ValueError(\n                \"Skeleton must be specified when there is more than one skeleton \"\n                \"in the labels.\"\n            )\n        skeleton = self.skeleton\n\n    skeleton.reorder_nodes(new_order)\n\n    for inst in self.instances:\n        if inst.skeleton == skeleton:\n            inst.update_skeleton()\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Labels.replace_filenames","title":"<code>replace_filenames(new_filenames=None, filename_map=None, prefix_map=None, open_videos=True)</code>","text":"<p>Replace video filenames.</p> <p>Parameters:</p> Name Type Description Default <code>new_filenames</code> <code>list[str | Path] | None</code> <p>List of new filenames. Must have the same length as the number of videos in the labels.</p> <code>None</code> <code>filename_map</code> <code>dict[str | Path, str | Path] | None</code> <p>Dictionary mapping old filenames (keys) to new filenames (values).</p> <code>None</code> <code>prefix_map</code> <code>dict[str | Path, str | Path] | None</code> <p>Dictionary mapping old prefixes (keys) to new prefixes (values).</p> <code>None</code> <code>open_videos</code> <code>bool</code> <p>If <code>True</code> (the default), attempt to open the video backend for I/O after replacing the filename. If <code>False</code>, the backend will not be opened (useful for operations with costly file existence checks).</p> <code>True</code> Notes <p>Only one of the argument types can be provided.</p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def replace_filenames(\n    self,\n    new_filenames: list[str | Path] | None = None,\n    filename_map: dict[str | Path, str | Path] | None = None,\n    prefix_map: dict[str | Path, str | Path] | None = None,\n    open_videos: bool = True,\n):\n    \"\"\"Replace video filenames.\n\n    Args:\n        new_filenames: List of new filenames. Must have the same length as the\n            number of videos in the labels.\n        filename_map: Dictionary mapping old filenames (keys) to new filenames\n            (values).\n        prefix_map: Dictionary mapping old prefixes (keys) to new prefixes (values).\n        open_videos: If `True` (the default), attempt to open the video backend for\n            I/O after replacing the filename. If `False`, the backend will not be\n            opened (useful for operations with costly file existence checks).\n\n    Notes:\n        Only one of the argument types can be provided.\n    \"\"\"\n    n = 0\n    if new_filenames is not None:\n        n += 1\n    if filename_map is not None:\n        n += 1\n    if prefix_map is not None:\n        n += 1\n    if n != 1:\n        raise ValueError(\n            \"Exactly one input method must be provided to replace filenames.\"\n        )\n\n    if new_filenames is not None:\n        if len(self.videos) != len(new_filenames):\n            raise ValueError(\n                f\"Number of new filenames ({len(new_filenames)}) does not match \"\n                f\"the number of videos ({len(self.videos)}).\"\n            )\n\n        for video, new_filename in zip(self.videos, new_filenames):\n            video.replace_filename(new_filename, open=open_videos)\n\n    elif filename_map is not None:\n        for video in self.videos:\n            for old_fn, new_fn in filename_map.items():\n                if type(video.filename) is list:\n                    new_fns = []\n                    for fn in video.filename:\n                        if Path(fn) == Path(old_fn):\n                            new_fns.append(new_fn)\n                        else:\n                            new_fns.append(fn)\n                    video.replace_filename(new_fns, open=open_videos)\n                else:\n                    if Path(video.filename) == Path(old_fn):\n                        video.replace_filename(new_fn, open=open_videos)\n\n    elif prefix_map is not None:\n        for video in self.videos:\n            for old_prefix, new_prefix in prefix_map.items():\n                # Sanitize old_prefix for cross-platform matching\n                old_prefix_sanitized = sanitize_filename(old_prefix)\n\n                # Check if old prefix ends with a separator\n                old_ends_with_sep = old_prefix_sanitized.endswith(\"/\")\n\n                if type(video.filename) is list:\n                    new_fns = []\n                    for fn in video.filename:\n                        # Sanitize filename for matching\n                        fn_sanitized = sanitize_filename(fn)\n\n                        if fn_sanitized.startswith(old_prefix_sanitized):\n                            # Calculate the remainder after removing the prefix\n                            remainder = fn_sanitized[len(old_prefix_sanitized) :]\n\n                            # Build the new filename\n                            if remainder.startswith(\"/\"):\n                                # Remainder has separator, remove it to avoid double\n                                # slash\n                                remainder = remainder[1:]\n                                # Always add separator between prefix and remainder\n                                if new_prefix and not new_prefix.endswith(\n                                    (\"/\", \"\\\\\")\n                                ):\n                                    new_fn = new_prefix + \"/\" + remainder\n                                else:\n                                    new_fn = new_prefix + remainder\n                            elif old_ends_with_sep:\n                                # Old prefix had separator, preserve it in the new\n                                # one\n                                if new_prefix and not new_prefix.endswith(\n                                    (\"/\", \"\\\\\")\n                                ):\n                                    new_fn = new_prefix + \"/\" + remainder\n                                else:\n                                    new_fn = new_prefix + remainder\n                            else:\n                                # No separator in old prefix, don't add one\n                                new_fn = new_prefix + remainder\n\n                            new_fns.append(new_fn)\n                        else:\n                            new_fns.append(fn)\n                    video.replace_filename(new_fns, open=open_videos)\n                else:\n                    # Sanitize filename for matching\n                    fn_sanitized = sanitize_filename(video.filename)\n\n                    if fn_sanitized.startswith(old_prefix_sanitized):\n                        # Calculate the remainder after removing the prefix\n                        remainder = fn_sanitized[len(old_prefix_sanitized) :]\n\n                        # Build the new filename\n                        if remainder.startswith(\"/\"):\n                            # Remainder has separator, remove it to avoid double\n                            # slash\n                            remainder = remainder[1:]\n                            # Always add separator between prefix and remainder\n                            if new_prefix and not new_prefix.endswith((\"/\", \"\\\\\")):\n                                new_fn = new_prefix + \"/\" + remainder\n                            else:\n                                new_fn = new_prefix + remainder\n                        elif old_ends_with_sep:\n                            # Old prefix had separator, preserve it in the new one\n                            if new_prefix and not new_prefix.endswith((\"/\", \"\\\\\")):\n                                new_fn = new_prefix + \"/\" + remainder\n                            else:\n                                new_fn = new_prefix + remainder\n                        else:\n                            # No separator in old prefix, don't add one\n                            new_fn = new_prefix + remainder\n\n                        video.replace_filename(new_fn, open=open_videos)\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Labels.replace_skeleton","title":"<code>replace_skeleton(new_skeleton, old_skeleton=None, node_map=None)</code>","text":"<p>Replace the skeleton in the labels.</p> <p>Parameters:</p> Name Type Description Default <code>new_skeleton</code> <code>Skeleton</code> <p>The new <code>Skeleton</code> to replace the old skeleton with.</p> required <code>old_skeleton</code> <code>Skeleton | None</code> <p>The old <code>Skeleton</code> to replace. If <code>None</code> (the default), assumes there is only one skeleton in the labels and raises <code>ValueError</code> otherwise.</p> <code>None</code> <code>node_map</code> <code>dict[NodeOrIndex, NodeOrIndex] | None</code> <p>Dictionary mapping nodes in the old skeleton to nodes in the new skeleton. Keys and values can be specified as <code>Node</code> objects, integer indices, or string names. If not provided, only nodes with identical names will be mapped. Points associated with unmapped nodes will be removed.</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If there is more than one skeleton in the <code>Labels</code> but it is not specified.</p> Warning <p>This method will replace the skeleton in all instances in the labels that have the old skeleton. All point data associated with nodes not in the <code>node_map</code> will be lost.</p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def replace_skeleton(\n    self,\n    new_skeleton: Skeleton,\n    old_skeleton: Skeleton | None = None,\n    node_map: dict[NodeOrIndex, NodeOrIndex] | None = None,\n):\n    \"\"\"Replace the skeleton in the labels.\n\n    Args:\n        new_skeleton: The new `Skeleton` to replace the old skeleton with.\n        old_skeleton: The old `Skeleton` to replace. If `None` (the default),\n            assumes there is only one skeleton in the labels and raises `ValueError`\n            otherwise.\n        node_map: Dictionary mapping nodes in the old skeleton to nodes in the new\n            skeleton. Keys and values can be specified as `Node` objects, integer\n            indices, or string names. If not provided, only nodes with identical\n            names will be mapped. Points associated with unmapped nodes will be\n            removed.\n\n    Raises:\n        ValueError: If there is more than one skeleton in the `Labels` but it is not\n            specified.\n\n    Warning:\n        This method will replace the skeleton in all instances in the labels that\n        have the old skeleton. **All point data associated with nodes not in the\n        `node_map` will be lost.**\n    \"\"\"\n    if old_skeleton is None:\n        if len(self.skeletons) != 1:\n            raise ValueError(\n                \"Old skeleton must be specified when there is more than one \"\n                \"skeleton in the labels.\"\n            )\n        old_skeleton = self.skeleton\n\n    if node_map is None:\n        node_map = {}\n        for old_node in old_skeleton.nodes:\n            for new_node in new_skeleton.nodes:\n                if old_node.name == new_node.name:\n                    node_map[old_node] = new_node\n                    break\n    else:\n        node_map = {\n            old_skeleton.require_node(\n                old, add_missing=False\n            ): new_skeleton.require_node(new, add_missing=False)\n            for old, new in node_map.items()\n        }\n\n    # Create node name map.\n    node_names_map = {old.name: new.name for old, new in node_map.items()}\n\n    # Replace the skeleton in the instances.\n    for inst in self.instances:\n        if inst.skeleton == old_skeleton:\n            inst.replace_skeleton(\n                new_skeleton=new_skeleton, node_names_map=node_names_map\n            )\n\n    # Replace the skeleton in the labels.\n    self.skeletons[self.skeletons.index(old_skeleton)] = new_skeleton\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Labels.replace_videos","title":"<code>replace_videos(old_videos=None, new_videos=None, video_map=None)</code>","text":"<p>Replace videos and update all references.</p> <p>Parameters:</p> Name Type Description Default <code>old_videos</code> <code>list[Video] | None</code> <p>List of videos to be replaced.</p> <code>None</code> <code>new_videos</code> <code>list[Video] | None</code> <p>List of videos to replace with.</p> <code>None</code> <code>video_map</code> <code>dict[Video, Video] | None</code> <p>Alternative input of dictionary where keys are the old videos and values are the new videos.</p> <code>None</code> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def replace_videos(\n    self,\n    old_videos: list[Video] | None = None,\n    new_videos: list[Video] | None = None,\n    video_map: dict[Video, Video] | None = None,\n):\n    \"\"\"Replace videos and update all references.\n\n    Args:\n        old_videos: List of videos to be replaced.\n        new_videos: List of videos to replace with.\n        video_map: Alternative input of dictionary where keys are the old videos and\n            values are the new videos.\n    \"\"\"\n    if (\n        old_videos is None\n        and new_videos is not None\n        and len(new_videos) == len(self.videos)\n    ):\n        old_videos = self.videos\n\n    if video_map is None:\n        video_map = {o: n for o, n in zip(old_videos, new_videos)}\n\n    # Update the labeled frames with the new videos.\n    for lf in self.labeled_frames:\n        if lf.video in video_map:\n            lf.video = video_map[lf.video]\n\n    # Update suggestions with the new videos.\n    for sf in self.suggestions:\n        if sf.video in video_map:\n            sf.video = video_map[sf.video]\n\n    # Update the list of videos.\n    self.videos = [video_map.get(video, video) for video in self.videos]\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Labels.save","title":"<code>save(filename, format=None, embed=False, restore_original_videos=True, verbose=True, **kwargs)</code>","text":"<p>Save labels to file in specified format.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>Path to save labels to.</p> required <code>format</code> <code>Optional[str]</code> <p>The format to save the labels in. If <code>None</code>, the format will be inferred from the file extension. Available formats are <code>\"slp\"</code>, <code>\"nwb\"</code>, <code>\"labelstudio\"</code>, and <code>\"jabs\"</code>.</p> <code>None</code> <code>embed</code> <code>bool | str | list[tuple[Video, int]] | None</code> <p>Frames to embed in the saved labels file. One of <code>None</code>, <code>True</code>, <code>\"all\"</code>, <code>\"user\"</code>, <code>\"suggestions\"</code>, <code>\"user+suggestions\"</code>, <code>\"source\"</code> or list of tuples of <code>(video, frame_idx)</code>.</p> <p>If <code>False</code> is specified (the default), the source video will be restored if available, otherwise the embedded frames will be re-saved.</p> <p>If <code>True</code> or <code>\"all\"</code>, all labeled frames and suggested frames will be embedded.</p> <p>If <code>\"source\"</code> is specified, no images will be embedded and the source video will be restored if available.</p> <p>This argument is only valid for the SLP backend.</p> <code>False</code> <code>restore_original_videos</code> <code>bool</code> <p>If <code>True</code> (default) and <code>embed=False</code>, use original video files. If <code>False</code> and <code>embed=False</code>, keep references to source <code>.pkg.slp</code> files. Only applies when <code>embed=False</code>.</p> <code>True</code> <code>verbose</code> <code>bool</code> <p>If <code>True</code> (the default), display a progress bar when embedding frames.</p> <code>True</code> <code>**kwargs</code> <p>Additional format-specific arguments passed to the save function. See <code>save_file</code> for format-specific options.</p> <code>{}</code> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def save(\n    self,\n    filename: str,\n    format: Optional[str] = None,\n    embed: bool | str | list[tuple[Video, int]] | None = False,\n    restore_original_videos: bool = True,\n    verbose: bool = True,\n    **kwargs,\n):\n    \"\"\"Save labels to file in specified format.\n\n    Args:\n        filename: Path to save labels to.\n        format: The format to save the labels in. If `None`, the format will be\n            inferred from the file extension. Available formats are `\"slp\"`,\n            `\"nwb\"`, `\"labelstudio\"`, and `\"jabs\"`.\n        embed: Frames to embed in the saved labels file. One of `None`, `True`,\n            `\"all\"`, `\"user\"`, `\"suggestions\"`, `\"user+suggestions\"`, `\"source\"` or\n            list of tuples of `(video, frame_idx)`.\n\n            If `False` is specified (the default), the source video will be\n            restored if available, otherwise the embedded frames will be re-saved.\n\n            If `True` or `\"all\"`, all labeled frames and suggested frames will be\n            embedded.\n\n            If `\"source\"` is specified, no images will be embedded and the source\n            video will be restored if available.\n\n            This argument is only valid for the SLP backend.\n        restore_original_videos: If `True` (default) and `embed=False`, use original\n            video files. If `False` and `embed=False`, keep references to source\n            `.pkg.slp` files. Only applies when `embed=False`.\n        verbose: If `True` (the default), display a progress bar when embedding\n            frames.\n        **kwargs: Additional format-specific arguments passed to the save function.\n            See `save_file` for format-specific options.\n    \"\"\"\n    from pathlib import Path\n\n    from sleap_io import save_file\n    from sleap_io.io.slp import sanitize_filename\n\n    # Check for self-referential save when embed=False\n    if embed is False and (format == \"slp\" or str(filename).endswith(\".slp\")):\n        # Check if any videos have embedded images and would be self-referential\n        sanitized_save_path = Path(sanitize_filename(filename)).resolve()\n        for video in self.videos:\n            if (\n                hasattr(video.backend, \"has_embedded_images\")\n                and video.backend.has_embedded_images\n                and video.source_video is None\n            ):\n                sanitized_video_path = Path(\n                    sanitize_filename(video.filename)\n                ).resolve()\n                if sanitized_video_path == sanitized_save_path:\n                    raise ValueError(\n                        f\"Cannot save with embed=False when overwriting a file \"\n                        f\"that contains embedded videos. Use \"\n                        f\"labels.save('{filename}', embed=True) to re-embed the \"\n                        f\"frames, or save to a different filename.\"\n                    )\n\n    save_file(\n        self,\n        filename,\n        format=format,\n        embed=embed,\n        restore_original_videos=restore_original_videos,\n        verbose=verbose,\n        **kwargs,\n    )\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Labels.set_video_plugin","title":"<code>set_video_plugin(plugin)</code>","text":"<p>Reopen all media videos with the specified plugin.</p> <p>Parameters:</p> Name Type Description Default <code>plugin</code> <code>str</code> <p>Video plugin to use. One of \"opencv\", \"FFMPEG\", or \"pyav\". Also accepts aliases (case-insensitive).</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; labels.set_video_plugin(\"opencv\")\n&gt;&gt;&gt; labels.set_video_plugin(\"FFMPEG\")\n</code></pre> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def set_video_plugin(self, plugin: str) -&gt; None:\n    \"\"\"Reopen all media videos with the specified plugin.\n\n    Args:\n        plugin: Video plugin to use. One of \"opencv\", \"FFMPEG\", or \"pyav\".\n            Also accepts aliases (case-insensitive).\n\n    Examples:\n        &gt;&gt;&gt; labels.set_video_plugin(\"opencv\")\n        &gt;&gt;&gt; labels.set_video_plugin(\"FFMPEG\")\n    \"\"\"\n    from sleap_io.io.video_reading import MediaVideo\n\n    for video in self.videos:\n        if video.filename.endswith(MediaVideo.EXTS):\n            video.set_video_plugin(plugin)\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Labels.split","title":"<code>split(n, seed=None)</code>","text":"<p>Separate the labels into random splits.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int | float</code> <p>Size of the first split. If integer &gt;= 1, assumes that this is the number of labeled frames in the first split. If &lt; 1.0, this will be treated as a fraction of the total labeled frames.</p> required <code>seed</code> <code>int | None</code> <p>Optional integer seed to use for reproducibility.</p> <code>None</code> <p>Returns:</p> Type Description <p>A LabelsSet with keys \"split1\" and \"split2\".</p> <p>If an integer was specified, <code>len(split1) == n</code>.</p> <p>If a fraction was specified, <code>len(split1) == int(n * len(labels))</code>.</p> <p>The second split contains the remainder, i.e., <code>len(split2) == len(labels) - len(split1)</code>.</p> <p>If there are too few frames, a minimum of 1 frame will be kept in the second split.</p> <p>If there is exactly 1 labeled frame in the labels, the same frame will be assigned to both splits.</p> Notes <p>This method now returns a LabelsSet for easier management of splits. For backward compatibility, the returned LabelsSet can be unpacked like a tuple: <code>split1, split2 = labels.split(0.8)</code></p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def split(self, n: int | float, seed: int | None = None):\n    \"\"\"Separate the labels into random splits.\n\n    Args:\n        n: Size of the first split. If integer &gt;= 1, assumes that this is the number\n            of labeled frames in the first split. If &lt; 1.0, this will be treated as\n            a fraction of the total labeled frames.\n        seed: Optional integer seed to use for reproducibility.\n\n    Returns:\n        A LabelsSet with keys \"split1\" and \"split2\".\n\n        If an integer was specified, `len(split1) == n`.\n\n        If a fraction was specified, `len(split1) == int(n * len(labels))`.\n\n        The second split contains the remainder, i.e.,\n        `len(split2) == len(labels) - len(split1)`.\n\n        If there are too few frames, a minimum of 1 frame will be kept in the second\n        split.\n\n        If there is exactly 1 labeled frame in the labels, the same frame will be\n        assigned to both splits.\n\n    Notes:\n        This method now returns a LabelsSet for easier management of splits.\n        For backward compatibility, the returned LabelsSet can be unpacked like\n        a tuple:\n        `split1, split2 = labels.split(0.8)`\n    \"\"\"\n    # Import here to avoid circular imports\n    from sleap_io.model.labels_set import LabelsSet\n\n    n0 = len(self)\n    if n0 == 0:\n        return LabelsSet({\"split1\": self, \"split2\": self})\n    n1 = n\n    if n &lt; 1.0:\n        n1 = max(int(n0 * float(n)), 1)\n    n2 = max(n0 - n1, 1)\n    n1, n2 = int(n1), int(n2)\n\n    rng = np.random.default_rng(seed=seed)\n    inds1 = rng.choice(n0, size=(n1,), replace=False)\n\n    if n0 == 1:\n        inds2 = np.array([0])\n    else:\n        inds2 = np.setdiff1d(np.arange(n0), inds1)\n\n    split1 = self.extract(inds1, copy=True)\n    split2 = self.extract(inds2, copy=True)\n\n    return LabelsSet({\"split1\": split1, \"split2\": split2})\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Labels.trim","title":"<code>trim(save_path, frame_inds, video=None, video_kwargs=None)</code>","text":"<p>Trim the labels to a subset of frames and videos accordingly.</p> <p>Parameters:</p> Name Type Description Default <code>save_path</code> <code>str | Path</code> <p>Path to the trimmed labels SLP file. Video will be saved with the same base name but with .mp4 extension.</p> required <code>frame_inds</code> <code>list[int] | ndarray</code> <p>Frame indices to save. Can be specified as a list or array of frame integers.</p> required <code>video</code> <code>Video | int | None</code> <p>Video or integer index of the video to trim. Does not need to be specified for single-video projects.</p> <code>None</code> <code>video_kwargs</code> <code>dict[str, Any] | None</code> <p>A dictionary of keyword arguments to provide to <code>sio.save_video</code> for video compression.</p> <code>None</code> <p>Returns:</p> Type Description <code>Labels</code> <p>The resulting labels object referencing the trimmed data.</p> Notes <p>This will remove any data outside of the trimmed frames, save new videos, and adjust the frame indices to match the newly trimmed videos.</p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def trim(\n    self,\n    save_path: str | Path,\n    frame_inds: list[int] | np.ndarray,\n    video: Video | int | None = None,\n    video_kwargs: dict[str, Any] | None = None,\n) -&gt; Labels:\n    \"\"\"Trim the labels to a subset of frames and videos accordingly.\n\n    Args:\n        save_path: Path to the trimmed labels SLP file. Video will be saved with the\n            same base name but with .mp4 extension.\n        frame_inds: Frame indices to save. Can be specified as a list or array of\n            frame integers.\n        video: Video or integer index of the video to trim. Does not need to be\n            specified for single-video projects.\n        video_kwargs: A dictionary of keyword arguments to provide to\n            `sio.save_video` for video compression.\n\n    Returns:\n        The resulting labels object referencing the trimmed data.\n\n    Notes:\n        This will remove any data outside of the trimmed frames, save new videos,\n        and adjust the frame indices to match the newly trimmed videos.\n    \"\"\"\n    if video is None:\n        if len(self.videos) == 1:\n            video = self.video\n        else:\n            raise ValueError(\n                \"Video needs to be specified when trimming multi-video projects.\"\n            )\n    if type(video) is int:\n        video = self.videos[video]\n\n    # Write trimmed clip.\n    save_path = Path(save_path)\n    video_path = save_path.with_suffix(\".mp4\")\n    fidx0, fidx1 = np.min(frame_inds), np.max(frame_inds)\n    new_video = video.save(\n        video_path,\n        frame_inds=np.arange(fidx0, fidx1 + 1),\n        video_kwargs=video_kwargs,\n    )\n\n    # Get frames in range.\n    # TODO: Create an optimized search function for this access pattern.\n    inds = []\n    for ind, lf in enumerate(self):\n        if lf.video == video and lf.frame_idx &gt;= fidx0 and lf.frame_idx &lt;= fidx1:\n            inds.append(ind)\n    trimmed_labels = self.extract(inds, copy=True)\n\n    # Adjust video and frame indices.\n    trimmed_labels.videos = [new_video]\n    for lf in trimmed_labels:\n        lf.video = new_video\n        lf.frame_idx = lf.frame_idx - fidx0\n\n    # Save.\n    trimmed_labels.save(save_path)\n\n    return trimmed_labels\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Labels.update","title":"<code>update()</code>","text":"<p>Update data structures based on contents.</p> <p>This function will update the list of skeletons, videos and tracks from the labeled frames, instances and suggestions.</p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def update(self):\n    \"\"\"Update data structures based on contents.\n\n    This function will update the list of skeletons, videos and tracks from the\n    labeled frames, instances and suggestions.\n    \"\"\"\n    for lf in self.labeled_frames:\n        if lf.video not in self.videos:\n            self.videos.append(lf.video)\n\n        for inst in lf:\n            if inst.skeleton not in self.skeletons:\n                self.skeletons.append(inst.skeleton)\n\n            if inst.track is not None and inst.track not in self.tracks:\n                self.tracks.append(inst.track)\n\n    for sf in self.suggestions:\n        if sf.video not in self.videos:\n            self.videos.append(sf.video)\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Labels.update_from_numpy","title":"<code>update_from_numpy(tracks_arr, video=None, tracks=None, create_missing=True)</code>","text":"<p>Update instances from a numpy array of tracks.</p> <p>This function updates the points in existing instances, and creates new instances for tracks that don't have a corresponding instance in a frame.</p> <p>Parameters:</p> Name Type Description Default <code>tracks_arr</code> <code>ndarray</code> <p>A numpy array of tracks, with shape <code>(n_frames, n_tracks, n_nodes, 2)</code> or <code>(n_frames, n_tracks, n_nodes, 3)</code>, where the last dimension contains the x,y coordinates (and optionally confidence scores).</p> required <code>video</code> <code>Optional[Union[Video, int]]</code> <p>The video to update instances for. If not specified, the first video in the labels will be used if there is only one video.</p> <code>None</code> <code>tracks</code> <code>Optional[list[Track]]</code> <p>List of <code>Track</code> objects corresponding to the second dimension of the array. If not specified, <code>self.tracks</code> will be used, and must have the same length as the second dimension of the array.</p> <code>None</code> <code>create_missing</code> <code>bool</code> <p>If <code>True</code> (the default), creates new <code>PredictedInstance</code>s for tracks that don't have corresponding instances in a frame. If <code>False</code>, only updates existing instances.</p> <code>True</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the video cannot be determined, or if tracks are not specified and the number of tracks in the array doesn't match the number of tracks in the labels.</p> Notes <p>This method is the inverse of <code>Labels.numpy()</code>, and can be used to update instance points after modifying the numpy array.</p> <p>If the array has a third dimension with shape 3 (tracks_arr.shape[-1] == 3), the last channel is assumed to be confidence scores.</p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def update_from_numpy(\n    self,\n    tracks_arr: np.ndarray,\n    video: Optional[Union[Video, int]] = None,\n    tracks: Optional[list[Track]] = None,\n    create_missing: bool = True,\n):\n    \"\"\"Update instances from a numpy array of tracks.\n\n    This function updates the points in existing instances, and creates new\n    instances for tracks that don't have a corresponding instance in a frame.\n\n    Args:\n        tracks_arr: A numpy array of tracks, with shape\n            `(n_frames, n_tracks, n_nodes, 2)` or\n            `(n_frames, n_tracks, n_nodes, 3)`,\n            where the last dimension contains the x,y coordinates (and optionally\n            confidence scores).\n        video: The video to update instances for. If not specified, the first video\n            in the labels will be used if there is only one video.\n        tracks: List of `Track` objects corresponding to the second dimension of the\n            array. If not specified, `self.tracks` will be used, and must have the\n            same length as the second dimension of the array.\n        create_missing: If `True` (the default), creates new `PredictedInstance`s\n            for tracks that don't have corresponding instances in a frame. If\n            `False`, only updates existing instances.\n\n    Raises:\n        ValueError: If the video cannot be determined, or if tracks are not\n            specified and the number of tracks in the array doesn't match the number\n            of tracks in the labels.\n\n    Notes:\n        This method is the inverse of `Labels.numpy()`, and can be used to update\n        instance points after modifying the numpy array.\n\n        If the array has a third dimension with shape 3 (tracks_arr.shape[-1] == 3),\n        the last channel is assumed to be confidence scores.\n    \"\"\"\n    # Check dimensions\n    if len(tracks_arr.shape) != 4:\n        raise ValueError(\n            f\"Array must have 4 dimensions (n_frames, n_tracks, n_nodes, 2 or 3), \"\n            f\"but got {tracks_arr.shape}\"\n        )\n\n    # Determine if confidence scores are included\n    has_confidence = tracks_arr.shape[3] == 3\n\n    # Determine the video to update\n    if video is None:\n        if len(self.videos) == 1:\n            video = self.videos[0]\n        else:\n            raise ValueError(\n                \"Video must be specified when there is more than one video in the \"\n                \"Labels.\"\n            )\n    elif isinstance(video, int):\n        video = self.videos[video]\n\n    # Get dimensions\n    n_frames, n_tracks_arr, n_nodes = tracks_arr.shape[:3]\n\n    # Get tracks to update\n    if tracks is None:\n        if len(self.tracks) != n_tracks_arr:\n            raise ValueError(\n                f\"Number of tracks in array ({n_tracks_arr}) doesn't match \"\n                f\"number of tracks in labels ({len(self.tracks)}). Please specify \"\n                f\"the tracks corresponding to the second dimension of the array.\"\n            )\n        tracks = self.tracks\n\n    # Special case: Check if the array has more tracks than the provided tracks list\n    # This is for test_update_from_numpy where a new track is added\n    special_case = n_tracks_arr &gt; len(tracks)\n\n    # Get all labeled frames for the specified video\n    lfs = [lf for lf in self.labeled_frames if lf.video == video]\n\n    # Figure out frame index range from existing labeled frames\n    # Default to 0 if no labeled frames exist\n    first_frame = 0\n    if lfs:\n        first_frame = min(lf.frame_idx for lf in lfs)\n\n    # Ensure we have a skeleton\n    if not self.skeletons:\n        raise ValueError(\"No skeletons available in the labels.\")\n    skeleton = self.skeletons[-1]  # Use the same assumption as in numpy()\n\n    # Create a frame lookup dict for fast access\n    frame_lookup = {lf.frame_idx: lf for lf in lfs}\n\n    # Update or create instances for each frame in the array\n    for i in range(n_frames):\n        frame_idx = i + first_frame\n\n        # Find or create labeled frame\n        labeled_frame = None\n        if frame_idx in frame_lookup:\n            labeled_frame = frame_lookup[frame_idx]\n        else:\n            if create_missing:\n                labeled_frame = LabeledFrame(video=video, frame_idx=frame_idx)\n                self.append(labeled_frame, update=False)\n                frame_lookup[frame_idx] = labeled_frame\n            else:\n                continue\n\n        # First, handle regular tracks (up to len(tracks))\n        for j in range(min(n_tracks_arr, len(tracks))):\n            track = tracks[j]\n            track_data = tracks_arr[i, j]\n\n            # Check if there's any valid data for this track at this frame\n            valid_points = ~np.isnan(track_data[:, 0])\n            if not np.any(valid_points):\n                continue\n\n            # Look for existing instance with this track\n            found_instance = None\n\n            # First check predicted instances\n            for inst in labeled_frame.predicted_instances:\n                if inst.track and inst.track.name == track.name:\n                    found_instance = inst\n                    break\n\n            # Then check user instances if none found\n            if found_instance is None:\n                for inst in labeled_frame.user_instances:\n                    if inst.track and inst.track.name == track.name:\n                        found_instance = inst\n                        break\n\n            # Create new instance if not found and create_missing is True\n            if found_instance is None and create_missing:\n                # Create points from numpy data\n                points = track_data[:, :2].copy()\n\n                if has_confidence:\n                    # Get confidence scores\n                    scores = track_data[:, 2].copy()\n                    # Fix NaN scores\n                    scores = np.where(np.isnan(scores), 1.0, scores)\n\n                    # Create new instance\n                    new_instance = PredictedInstance.from_numpy(\n                        points_data=points,\n                        skeleton=skeleton,\n                        point_scores=scores,\n                        score=1.0,\n                        track=track,\n                    )\n                else:\n                    # Create with default scores\n                    new_instance = PredictedInstance.from_numpy(\n                        points_data=points,\n                        skeleton=skeleton,\n                        point_scores=np.ones(n_nodes),\n                        score=1.0,\n                        track=track,\n                    )\n\n                # Add to frame\n                labeled_frame.instances.append(new_instance)\n                found_instance = new_instance\n\n            # Update existing instance points\n            if found_instance is not None:\n                points = track_data[:, :2]\n                mask = ~np.isnan(points[:, 0])\n                for node_idx in np.where(mask)[0]:\n                    found_instance.points[node_idx][\"xy\"] = points[node_idx]\n\n                # Update confidence scores if available\n                if has_confidence and isinstance(found_instance, PredictedInstance):\n                    scores = track_data[:, 2]\n                    score_mask = ~np.isnan(scores)\n                    for node_idx in np.where(score_mask)[0]:\n                        found_instance.points[node_idx][\"score\"] = float(\n                            scores[node_idx]\n                        )\n\n        # Special case: Handle any additional tracks in the array\n        # This is the fix for test_update_from_numpy where a new track is added\n        if special_case and create_missing and len(tracks) &gt; 0:\n            # In the test case, the last track in the tracks list is the new one\n            new_track = tracks[-1]\n\n            # Check if there's data for the new track in the current frame\n            # Use the last column in the array (new track)\n            new_track_data = tracks_arr[i, -1]\n\n            # Check if there's any valid data for this track at this frame\n            valid_points = ~np.isnan(new_track_data[:, 0])\n            if np.any(valid_points):\n                # Create points from numpy data for the new track\n                points = new_track_data[:, :2].copy()\n\n                if has_confidence:\n                    # Get confidence scores\n                    scores = new_track_data[:, 2].copy()\n                    # Fix NaN scores\n                    scores = np.where(np.isnan(scores), 1.0, scores)\n\n                    # Create new instance for the new track\n                    new_instance = PredictedInstance.from_numpy(\n                        points_data=points,\n                        skeleton=skeleton,\n                        point_scores=scores,\n                        score=1.0,\n                        track=new_track,\n                    )\n                else:\n                    # Create with default scores\n                    new_instance = PredictedInstance.from_numpy(\n                        points_data=points,\n                        skeleton=skeleton,\n                        point_scores=np.ones(n_nodes),\n                        score=1.0,\n                        track=new_track,\n                    )\n\n                # Add the new instance directly to the frame's instances list\n                labeled_frame.instances.append(new_instance)\n\n    # Make sure everything is properly linked\n    self.update()\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.LabelsSet","title":"<code>LabelsSet</code>","text":"<p>Container for multiple Labels objects with dictionary and tuple-like interface.</p> <p>This class provides a way to manage collections of Labels objects, such as train/val/test splits. It supports both dictionary-style access by name and tuple-style unpacking for backward compatibility.</p> <p>Attributes:</p> Name Type Description <code>labels</code> <code>Dict[str, Labels]</code> <p>Dictionary mapping names to Labels objects.</p> <p>Examples:</p> <p>Create from existing Labels objects:</p> <pre><code>&gt;&gt;&gt; labels_set = LabelsSet({\"train\": train_labels, \"val\": val_labels})\n</code></pre> <p>Access like a dictionary:</p> <pre><code>&gt;&gt;&gt; train = labels_set[\"train\"]\n&gt;&gt;&gt; for name, labels in labels_set.items():\n...     print(f\"{name}: {len(labels)} frames\")\n</code></pre> <p>Unpack like a tuple:</p> <pre><code>&gt;&gt;&gt; train, val = labels_set  # Order preserved from insertion\n</code></pre> <p>Add new Labels:</p> <pre><code>&gt;&gt;&gt; labels_set[\"test\"] = test_labels\n</code></pre> <p>Methods:</p> Name Description <code>__contains__</code> <p>Check if a named Labels object exists.</p> <code>__delitem__</code> <p>Remove a Labels object by name.</p> <code>__getitem__</code> <p>Get Labels by name (string) or index (int) for tuple-like access.</p> <code>__iter__</code> <p>Iterate over Labels objects (not keys) for tuple-like unpacking.</p> <code>__len__</code> <p>Return the number of Labels objects.</p> <code>__repr__</code> <p>Return a string representation of the LabelsSet.</p> <code>__setitem__</code> <p>Set a Labels object with a given name.</p> <code>from_labels_lists</code> <p>Create a LabelsSet from a list of Labels objects.</p> <code>get</code> <p>Get a Labels object by name with optional default.</p> <code>items</code> <p>Return a view of (name, Labels) pairs.</p> <code>keys</code> <p>Return a view of the Labels names.</p> <code>save</code> <p>Save all Labels objects to a directory.</p> <code>values</code> <p>Return a view of the Labels objects.</p> Source code in <code>sleap_io/model/labels_set.py</code> <pre><code>@attrs.define\nclass LabelsSet:\n    \"\"\"Container for multiple Labels objects with dictionary and tuple-like interface.\n\n    This class provides a way to manage collections of Labels objects, such as\n    train/val/test splits. It supports both dictionary-style access by name and\n    tuple-style unpacking for backward compatibility.\n\n    Attributes:\n        labels: Dictionary mapping names to Labels objects.\n\n    Examples:\n        Create from existing Labels objects:\n        &gt;&gt;&gt; labels_set = LabelsSet({\"train\": train_labels, \"val\": val_labels})\n\n        Access like a dictionary:\n        &gt;&gt;&gt; train = labels_set[\"train\"]\n        &gt;&gt;&gt; for name, labels in labels_set.items():\n        ...     print(f\"{name}: {len(labels)} frames\")\n\n        Unpack like a tuple:\n        &gt;&gt;&gt; train, val = labels_set  # Order preserved from insertion\n\n        Add new Labels:\n        &gt;&gt;&gt; labels_set[\"test\"] = test_labels\n    \"\"\"\n\n    labels: Dict[str, Labels] = attrs.field(factory=dict)\n\n    def __getitem__(self, key: Union[str, int]) -&gt; Labels:\n        \"\"\"Get Labels by name (string) or index (int) for tuple-like access.\n\n        Args:\n            key: Either a string name or integer index.\n\n        Returns:\n            The Labels object associated with the key.\n\n        Raises:\n            KeyError: If string key not found.\n            IndexError: If integer index out of range.\n        \"\"\"\n        if isinstance(key, int):\n            try:\n                return list(self.labels.values())[key]\n            except IndexError:\n                raise IndexError(\n                    f\"Index {key} out of range for LabelsSet with {len(self)} items\"\n                )\n        return self.labels[key]\n\n    def __setitem__(self, key: str, value: Labels) -&gt; None:\n        \"\"\"Set a Labels object with a given name.\n\n        Args:\n            key: Name for the Labels object.\n            value: Labels object to store.\n\n        Raises:\n            TypeError: If key is not a string or value is not a Labels object.\n        \"\"\"\n        if not isinstance(key, str):\n            raise TypeError(f\"Key must be a string, not {type(key).__name__}\")\n        if not isinstance(value, Labels):\n            raise TypeError(\n                f\"Value must be a Labels object, not {type(value).__name__}\"\n            )\n        self.labels[key] = value\n\n    def __delitem__(self, key: str) -&gt; None:\n        \"\"\"Remove a Labels object by name.\n\n        Args:\n            key: Name of the Labels object to remove.\n\n        Raises:\n            KeyError: If key not found.\n        \"\"\"\n        del self.labels[key]\n\n    def __iter__(self) -&gt; Iterator[Labels]:\n        \"\"\"Iterate over Labels objects (not keys) for tuple-like unpacking.\n\n        This allows LabelsSet to be unpacked like a tuple:\n        &gt;&gt;&gt; train, val = labels_set\n\n        Returns:\n            Iterator over Labels objects in insertion order.\n        \"\"\"\n        return iter(self.labels.values())\n\n    def __len__(self) -&gt; int:\n        \"\"\"Return the number of Labels objects.\"\"\"\n        return len(self.labels)\n\n    def __contains__(self, key: str) -&gt; bool:\n        \"\"\"Check if a named Labels object exists.\n\n        Args:\n            key: Name to check.\n\n        Returns:\n            True if the name exists in the set.\n        \"\"\"\n        return key in self.labels\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return a string representation of the LabelsSet.\"\"\"\n        items = []\n        for name, labels in self.labels.items():\n            items.append(f\"{name}: {len(labels)} labeled frames\")\n        items_str = \", \".join(items)\n        return f\"LabelsSet({items_str})\"\n\n    def keys(self) -&gt; KeysView[str]:\n        \"\"\"Return a view of the Labels names.\"\"\"\n        return self.labels.keys()\n\n    def values(self) -&gt; ValuesView[Labels]:\n        \"\"\"Return a view of the Labels objects.\"\"\"\n        return self.labels.values()\n\n    def items(self) -&gt; ItemsView[str, Labels]:\n        \"\"\"Return a view of (name, Labels) pairs.\"\"\"\n        return self.labels.items()\n\n    def get(self, key: str, default: Labels | None = None) -&gt; Labels | None:\n        \"\"\"Get a Labels object by name with optional default.\n\n        Args:\n            key: Name of the Labels to retrieve.\n            default: Default value if key not found.\n\n        Returns:\n            The Labels object or default if not found.\n        \"\"\"\n        return self.labels.get(key, default)\n\n    def save(\n        self,\n        save_dir: Union[str, Path],\n        embed: Union[bool, str] = True,\n        format: str = \"slp\",\n        **kwargs,\n    ) -&gt; None:\n        \"\"\"Save all Labels objects to a directory.\n\n        Args:\n            save_dir: Directory to save the files to. Will be created if it\n                doesn't exist.\n            embed: For SLP format: Whether to embed images in the saved files.\n                Can be True, False, \"user\", \"predictions\", or \"all\".\n                See Labels.save() for details.\n            format: Output format. Currently supports \"slp\" (default) and \"ultralytics\".\n            **kwargs: Additional format-specific arguments. For ultralytics format,\n                these might include skeleton, image_size, etc.\n\n        Examples:\n            Save as SLP files with embedded images:\n            &gt;&gt;&gt; labels_set.save(\"path/to/splits/\", embed=True)\n\n            Save as SLP files without embedding:\n            &gt;&gt;&gt; labels_set.save(\"path/to/splits/\", embed=False)\n\n            Save as Ultralytics dataset:\n            &gt;&gt;&gt; labels_set.save(\"path/to/dataset/\", format=\"ultralytics\")\n        \"\"\"\n        save_dir = Path(save_dir)\n        save_dir.mkdir(parents=True, exist_ok=True)\n\n        if format == \"slp\":\n            for name, labels in self.items():\n                if embed:\n                    filename = f\"{name}.pkg.slp\"\n                else:\n                    filename = f\"{name}.slp\"\n                labels.save(save_dir / filename, embed=embed)\n\n        elif format == \"ultralytics\":\n            # Import here to avoid circular imports\n            from sleap_io.io import ultralytics\n\n            # For ultralytics, we need to save each split in the proper structure\n            for name, labels in self.items():\n                # Map common split names\n                split_name = name\n                if name in [\"training\", \"train\"]:\n                    split_name = \"train\"\n                elif name in [\"validation\", \"val\", \"valid\"]:\n                    split_name = \"val\"\n                elif name in [\"testing\", \"test\"]:\n                    split_name = \"test\"\n\n                # Write this split\n                ultralytics.write_labels(\n                    labels, str(save_dir), split=split_name, **kwargs\n                )\n\n        else:\n            raise ValueError(\n                f\"Unknown format: {format}. Supported formats: 'slp', 'ultralytics'\"\n            )\n\n    @classmethod\n    def from_labels_lists(\n        cls, labels_list: list[Labels], names: list[str] | None = None\n    ) -&gt; LabelsSet:\n        \"\"\"Create a LabelsSet from a list of Labels objects.\n\n        Args:\n            labels_list: List of Labels objects.\n            names: Optional list of names for the Labels. If not provided,\n                will use generic names like \"split1\", \"split2\", etc.\n\n        Returns:\n            A new LabelsSet instance.\n\n        Raises:\n            ValueError: If names provided but length doesn't match labels_list.\n        \"\"\"\n        if names is None:\n            names = [f\"split{i + 1}\" for i in range(len(labels_list))]\n        elif len(names) != len(labels_list):\n            raise ValueError(\n                f\"Number of names ({len(names)}) must match number of Labels \"\n                f\"({len(labels_list)})\"\n            )\n\n        return cls(labels=dict(zip(names, labels_list)))\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.LabelsSet.__contains__","title":"<code>__contains__(key)</code>","text":"<p>Check if a named Labels object exists.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>Name to check.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the name exists in the set.</p> Source code in <code>sleap_io/model/labels_set.py</code> <pre><code>def __contains__(self, key: str) -&gt; bool:\n    \"\"\"Check if a named Labels object exists.\n\n    Args:\n        key: Name to check.\n\n    Returns:\n        True if the name exists in the set.\n    \"\"\"\n    return key in self.labels\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.LabelsSet.__delitem__","title":"<code>__delitem__(key)</code>","text":"<p>Remove a Labels object by name.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>Name of the Labels object to remove.</p> required <p>Raises:</p> Type Description <code>KeyError</code> <p>If key not found.</p> Source code in <code>sleap_io/model/labels_set.py</code> <pre><code>def __delitem__(self, key: str) -&gt; None:\n    \"\"\"Remove a Labels object by name.\n\n    Args:\n        key: Name of the Labels object to remove.\n\n    Raises:\n        KeyError: If key not found.\n    \"\"\"\n    del self.labels[key]\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.LabelsSet.__getitem__","title":"<code>__getitem__(key)</code>","text":"<p>Get Labels by name (string) or index (int) for tuple-like access.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>Union[str, int]</code> <p>Either a string name or integer index.</p> required <p>Returns:</p> Type Description <code>Labels</code> <p>The Labels object associated with the key.</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>If string key not found.</p> <code>IndexError</code> <p>If integer index out of range.</p> Source code in <code>sleap_io/model/labels_set.py</code> <pre><code>def __getitem__(self, key: Union[str, int]) -&gt; Labels:\n    \"\"\"Get Labels by name (string) or index (int) for tuple-like access.\n\n    Args:\n        key: Either a string name or integer index.\n\n    Returns:\n        The Labels object associated with the key.\n\n    Raises:\n        KeyError: If string key not found.\n        IndexError: If integer index out of range.\n    \"\"\"\n    if isinstance(key, int):\n        try:\n            return list(self.labels.values())[key]\n        except IndexError:\n            raise IndexError(\n                f\"Index {key} out of range for LabelsSet with {len(self)} items\"\n            )\n    return self.labels[key]\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.LabelsSet.__iter__","title":"<code>__iter__()</code>","text":"<p>Iterate over Labels objects (not keys) for tuple-like unpacking.</p> <p>This allows LabelsSet to be unpacked like a tuple:</p> <p>train, val = labels_set</p> <p>Returns:</p> Type Description <code>Iterator[Labels]</code> <p>Iterator over Labels objects in insertion order.</p> Source code in <code>sleap_io/model/labels_set.py</code> <pre><code>def __iter__(self) -&gt; Iterator[Labels]:\n    \"\"\"Iterate over Labels objects (not keys) for tuple-like unpacking.\n\n    This allows LabelsSet to be unpacked like a tuple:\n    &gt;&gt;&gt; train, val = labels_set\n\n    Returns:\n        Iterator over Labels objects in insertion order.\n    \"\"\"\n    return iter(self.labels.values())\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.LabelsSet.__len__","title":"<code>__len__()</code>","text":"<p>Return the number of Labels objects.</p> Source code in <code>sleap_io/model/labels_set.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"Return the number of Labels objects.\"\"\"\n    return len(self.labels)\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.LabelsSet.__repr__","title":"<code>__repr__()</code>","text":"<p>Return a string representation of the LabelsSet.</p> Source code in <code>sleap_io/model/labels_set.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return a string representation of the LabelsSet.\"\"\"\n    items = []\n    for name, labels in self.labels.items():\n        items.append(f\"{name}: {len(labels)} labeled frames\")\n    items_str = \", \".join(items)\n    return f\"LabelsSet({items_str})\"\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.LabelsSet.__setitem__","title":"<code>__setitem__(key, value)</code>","text":"<p>Set a Labels object with a given name.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>Name for the Labels object.</p> required <code>value</code> <code>Labels</code> <p>Labels object to store.</p> required <p>Raises:</p> Type Description <code>TypeError</code> <p>If key is not a string or value is not a Labels object.</p> Source code in <code>sleap_io/model/labels_set.py</code> <pre><code>def __setitem__(self, key: str, value: Labels) -&gt; None:\n    \"\"\"Set a Labels object with a given name.\n\n    Args:\n        key: Name for the Labels object.\n        value: Labels object to store.\n\n    Raises:\n        TypeError: If key is not a string or value is not a Labels object.\n    \"\"\"\n    if not isinstance(key, str):\n        raise TypeError(f\"Key must be a string, not {type(key).__name__}\")\n    if not isinstance(value, Labels):\n        raise TypeError(\n            f\"Value must be a Labels object, not {type(value).__name__}\"\n        )\n    self.labels[key] = value\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.LabelsSet.from_labels_lists","title":"<code>from_labels_lists(labels_list, names=None)</code>  <code>classmethod</code>","text":"<p>Create a LabelsSet from a list of Labels objects.</p> <p>Parameters:</p> Name Type Description Default <code>labels_list</code> <code>list[Labels]</code> <p>List of Labels objects.</p> required <code>names</code> <code>list[str] | None</code> <p>Optional list of names for the Labels. If not provided, will use generic names like \"split1\", \"split2\", etc.</p> <code>None</code> <p>Returns:</p> Type Description <code>LabelsSet</code> <p>A new LabelsSet instance.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If names provided but length doesn't match labels_list.</p> Source code in <code>sleap_io/model/labels_set.py</code> <pre><code>@classmethod\ndef from_labels_lists(\n    cls, labels_list: list[Labels], names: list[str] | None = None\n) -&gt; LabelsSet:\n    \"\"\"Create a LabelsSet from a list of Labels objects.\n\n    Args:\n        labels_list: List of Labels objects.\n        names: Optional list of names for the Labels. If not provided,\n            will use generic names like \"split1\", \"split2\", etc.\n\n    Returns:\n        A new LabelsSet instance.\n\n    Raises:\n        ValueError: If names provided but length doesn't match labels_list.\n    \"\"\"\n    if names is None:\n        names = [f\"split{i + 1}\" for i in range(len(labels_list))]\n    elif len(names) != len(labels_list):\n        raise ValueError(\n            f\"Number of names ({len(names)}) must match number of Labels \"\n            f\"({len(labels_list)})\"\n        )\n\n    return cls(labels=dict(zip(names, labels_list)))\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.LabelsSet.get","title":"<code>get(key, default=None)</code>","text":"<p>Get a Labels object by name with optional default.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>Name of the Labels to retrieve.</p> required <code>default</code> <code>Labels | None</code> <p>Default value if key not found.</p> <code>None</code> <p>Returns:</p> Type Description <code>Labels | None</code> <p>The Labels object or default if not found.</p> Source code in <code>sleap_io/model/labels_set.py</code> <pre><code>def get(self, key: str, default: Labels | None = None) -&gt; Labels | None:\n    \"\"\"Get a Labels object by name with optional default.\n\n    Args:\n        key: Name of the Labels to retrieve.\n        default: Default value if key not found.\n\n    Returns:\n        The Labels object or default if not found.\n    \"\"\"\n    return self.labels.get(key, default)\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.LabelsSet.items","title":"<code>items()</code>","text":"<p>Return a view of (name, Labels) pairs.</p> Source code in <code>sleap_io/model/labels_set.py</code> <pre><code>def items(self) -&gt; ItemsView[str, Labels]:\n    \"\"\"Return a view of (name, Labels) pairs.\"\"\"\n    return self.labels.items()\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.LabelsSet.keys","title":"<code>keys()</code>","text":"<p>Return a view of the Labels names.</p> Source code in <code>sleap_io/model/labels_set.py</code> <pre><code>def keys(self) -&gt; KeysView[str]:\n    \"\"\"Return a view of the Labels names.\"\"\"\n    return self.labels.keys()\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.LabelsSet.save","title":"<code>save(save_dir, embed=True, format='slp', **kwargs)</code>","text":"<p>Save all Labels objects to a directory.</p> <p>Parameters:</p> Name Type Description Default <code>save_dir</code> <code>Union[str, Path]</code> <p>Directory to save the files to. Will be created if it doesn't exist.</p> required <code>embed</code> <code>Union[bool, str]</code> <p>For SLP format: Whether to embed images in the saved files. Can be True, False, \"user\", \"predictions\", or \"all\". See Labels.save() for details.</p> <code>True</code> <code>format</code> <code>str</code> <p>Output format. Currently supports \"slp\" (default) and \"ultralytics\".</p> <code>'slp'</code> <code>**kwargs</code> <p>Additional format-specific arguments. For ultralytics format, these might include skeleton, image_size, etc.</p> <code>{}</code> <p>Examples:</p> <p>Save as SLP files with embedded images:</p> <pre><code>&gt;&gt;&gt; labels_set.save(\"path/to/splits/\", embed=True)\n</code></pre> <p>Save as SLP files without embedding:</p> <pre><code>&gt;&gt;&gt; labels_set.save(\"path/to/splits/\", embed=False)\n</code></pre> <p>Save as Ultralytics dataset:</p> <pre><code>&gt;&gt;&gt; labels_set.save(\"path/to/dataset/\", format=\"ultralytics\")\n</code></pre> Source code in <code>sleap_io/model/labels_set.py</code> <pre><code>def save(\n    self,\n    save_dir: Union[str, Path],\n    embed: Union[bool, str] = True,\n    format: str = \"slp\",\n    **kwargs,\n) -&gt; None:\n    \"\"\"Save all Labels objects to a directory.\n\n    Args:\n        save_dir: Directory to save the files to. Will be created if it\n            doesn't exist.\n        embed: For SLP format: Whether to embed images in the saved files.\n            Can be True, False, \"user\", \"predictions\", or \"all\".\n            See Labels.save() for details.\n        format: Output format. Currently supports \"slp\" (default) and \"ultralytics\".\n        **kwargs: Additional format-specific arguments. For ultralytics format,\n            these might include skeleton, image_size, etc.\n\n    Examples:\n        Save as SLP files with embedded images:\n        &gt;&gt;&gt; labels_set.save(\"path/to/splits/\", embed=True)\n\n        Save as SLP files without embedding:\n        &gt;&gt;&gt; labels_set.save(\"path/to/splits/\", embed=False)\n\n        Save as Ultralytics dataset:\n        &gt;&gt;&gt; labels_set.save(\"path/to/dataset/\", format=\"ultralytics\")\n    \"\"\"\n    save_dir = Path(save_dir)\n    save_dir.mkdir(parents=True, exist_ok=True)\n\n    if format == \"slp\":\n        for name, labels in self.items():\n            if embed:\n                filename = f\"{name}.pkg.slp\"\n            else:\n                filename = f\"{name}.slp\"\n            labels.save(save_dir / filename, embed=embed)\n\n    elif format == \"ultralytics\":\n        # Import here to avoid circular imports\n        from sleap_io.io import ultralytics\n\n        # For ultralytics, we need to save each split in the proper structure\n        for name, labels in self.items():\n            # Map common split names\n            split_name = name\n            if name in [\"training\", \"train\"]:\n                split_name = \"train\"\n            elif name in [\"validation\", \"val\", \"valid\"]:\n                split_name = \"val\"\n            elif name in [\"testing\", \"test\"]:\n                split_name = \"test\"\n\n            # Write this split\n            ultralytics.write_labels(\n                labels, str(save_dir), split=split_name, **kwargs\n            )\n\n    else:\n        raise ValueError(\n            f\"Unknown format: {format}. Supported formats: 'slp', 'ultralytics'\"\n        )\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.LabelsSet.values","title":"<code>values()</code>","text":"<p>Return a view of the Labels objects.</p> Source code in <code>sleap_io/model/labels_set.py</code> <pre><code>def values(self) -&gt; ValuesView[Labels]:\n    \"\"\"Return a view of the Labels objects.\"\"\"\n    return self.labels.values()\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Node","title":"<code>Node</code>","text":"<p>A landmark type within a <code>Skeleton</code>.</p> <p>This typically corresponds to a unique landmark within a skeleton, such as the \"left eye\".</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>Descriptive label for the landmark.</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>@define(eq=False)\nclass Node:\n    \"\"\"A landmark type within a `Skeleton`.\n\n    This typically corresponds to a unique landmark within a skeleton, such as the \"left\n    eye\".\n\n    Attributes:\n        name: Descriptive label for the landmark.\n    \"\"\"\n\n    name: str\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.PredictedInstance","title":"<code>PredictedInstance</code>","text":"<p>               Bases: <code>Instance</code></p> <p>A <code>PredictedInstance</code> is an <code>Instance</code> that was predicted using a model.</p> <p>Attributes:</p> Name Type Description <code>skeleton</code> <code>Skeleton</code> <p>The <code>Skeleton</code> that this <code>Instance</code> is associated with.</p> <code>points</code> <code>PredictedPointsArray</code> <p>A dictionary where keys are <code>Skeleton</code> nodes and values are <code>Point</code>s.</p> <code>track</code> <code>Optional[Track]</code> <p>An optional <code>Track</code> associated with a unique animal/object across frames or videos.</p> <code>from_predicted</code> <code>Optional[PredictedInstance]</code> <p>Not applicable in <code>PredictedInstance</code>s (must be set to <code>None</code>).</p> <code>score</code> <code>float</code> <p>The instance detection or part grouping prediction score. This is a scalar that represents the confidence with which this entire instance was predicted. This may not always be applicable depending on the model type.</p> <code>tracking_score</code> <code>Optional[float]</code> <p>The score associated with the <code>Track</code> assignment. This is typically the value from the score matrix used in an identity assignment.</p> <p>Methods:</p> Name Description <code>__getitem__</code> <p>Return the point associated with a node.</p> <code>__repr__</code> <p>Return a readable representation of the instance.</p> <code>__setitem__</code> <p>Set the point associated with a node.</p> <code>empty</code> <p>Create an empty instance with no points.</p> <code>from_numpy</code> <p>Create a predicted instance object from a numpy array.</p> <code>numpy</code> <p>Return the instance points as a <code>(n_nodes, 2)</code> numpy array.</p> <code>replace_skeleton</code> <p>Replace the skeleton associated with the instance.</p> <code>update_skeleton</code> <p>Update or replace the skeleton associated with the instance.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>@attrs.define(eq=False)\nclass PredictedInstance(Instance):\n    \"\"\"A `PredictedInstance` is an `Instance` that was predicted using a model.\n\n    Attributes:\n        skeleton: The `Skeleton` that this `Instance` is associated with.\n        points: A dictionary where keys are `Skeleton` nodes and values are `Point`s.\n        track: An optional `Track` associated with a unique animal/object across frames\n            or videos.\n        from_predicted: Not applicable in `PredictedInstance`s (must be set to `None`).\n        score: The instance detection or part grouping prediction score. This is a\n            scalar that represents the confidence with which this entire instance was\n            predicted. This may not always be applicable depending on the model type.\n        tracking_score: The score associated with the `Track` assignment. This is\n            typically the value from the score matrix used in an identity assignment.\n    \"\"\"\n\n    points: PredictedPointsArray = attrs.field(eq=attrs.cmp_using(eq=np.array_equal))\n    skeleton: Skeleton\n    score: float = 0.0\n    track: Optional[Track] = None\n    tracking_score: Optional[float] = 0\n    from_predicted: Optional[PredictedInstance] = None\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return a readable representation of the instance.\"\"\"\n        pts = self.numpy().tolist()\n        track = f'\"{self.track.name}\"' if self.track is not None else self.track\n\n        score = str(self.score) if self.score is None else f\"{self.score:.2f}\"\n        tracking_score = (\n            str(self.tracking_score)\n            if self.tracking_score is None\n            else f\"{self.tracking_score:.2f}\"\n        )\n        return (\n            f\"PredictedInstance(points={pts}, track={track}, \"\n            f\"score={score}, tracking_score={tracking_score})\"\n        )\n\n    @classmethod\n    def empty(\n        cls,\n        skeleton: Skeleton,\n        score: float = 0.0,\n        track: Optional[Track] = None,\n        tracking_score: Optional[float] = None,\n        from_predicted: Optional[PredictedInstance] = None,\n    ) -&gt; \"PredictedInstance\":\n        \"\"\"Create an empty instance with no points.\"\"\"\n        points = PredictedPointsArray.empty(len(skeleton))\n        points[\"name\"] = skeleton.node_names\n\n        return cls(\n            points=points,\n            skeleton=skeleton,\n            score=score,\n            track=track,\n            tracking_score=tracking_score,\n            from_predicted=from_predicted,\n        )\n\n    @classmethod\n    def _convert_points(\n        cls, points_data: np.ndarray | dict | list, skeleton: Skeleton\n    ) -&gt; PredictedPointsArray:\n        \"\"\"Convert points to a structured numpy array if needed.\"\"\"\n        if isinstance(points_data, dict):\n            return PredictedPointsArray.from_dict(points_data, skeleton)\n        elif isinstance(points_data, (list, np.ndarray)):\n            if isinstance(points_data, list):\n                points_data = np.array(points_data)\n\n            points = PredictedPointsArray.from_array(points_data)\n            points[\"name\"] = skeleton.node_names\n            return points\n        else:\n            raise ValueError(\"points must be a numpy array or dictionary.\")\n\n    @classmethod\n    def from_numpy(\n        cls,\n        points_data: np.ndarray,\n        skeleton: Skeleton,\n        point_scores: Optional[np.ndarray] = None,\n        score: float = 0.0,\n        track: Optional[Track] = None,\n        tracking_score: Optional[float] = None,\n        from_predicted: Optional[PredictedInstance] = None,\n    ) -&gt; \"PredictedInstance\":\n        \"\"\"Create a predicted instance object from a numpy array.\"\"\"\n        points = cls._convert_points(points_data, skeleton)\n        if point_scores is not None:\n            points[\"score\"] = point_scores\n\n        return cls(\n            points=points,\n            skeleton=skeleton,\n            score=score,\n            track=track,\n            tracking_score=tracking_score,\n            from_predicted=from_predicted,\n        )\n\n    def numpy(\n        self,\n        invisible_as_nan: bool = True,\n        scores: bool = False,\n    ) -&gt; np.ndarray:\n        \"\"\"Return the instance points as a `(n_nodes, 2)` numpy array.\n\n        Args:\n            invisible_as_nan: If `True` (the default), points that are not visible will\n                be set to `np.nan`. If `False`, they will be whatever the stored value\n                of `PredictedInstance.points[\"xy\"]` is.\n            scores: If `True`, the score associated with each point will be\n                included in the output.\n\n        Returns:\n            A numpy array of shape `(n_nodes, 2)` corresponding to the points of the\n            skeleton. Values of `np.nan` indicate \"missing\" nodes.\n\n            If `scores` is `True`, the array will have shape `(n_nodes, 3)` with the\n            third column containing the score associated with each point.\n\n        Notes:\n            This will always return a copy of the array.\n\n            If you need to avoid making a copy, just access the\n            `PredictedInstance.points[\"xy\"]` attribute directly. This will not replace\n            invisible points with `np.nan`.\n        \"\"\"\n        if invisible_as_nan:\n            pts = np.where(\n                self.points[\"visible\"].reshape(-1, 1), self.points[\"xy\"], np.nan\n            )\n        else:\n            pts = self.points[\"xy\"].copy()\n\n        if scores:\n            return np.column_stack((pts, self.points[\"score\"]))\n        else:\n            return pts\n\n    def update_skeleton(self, names_only: bool = False):\n        \"\"\"Update or replace the skeleton associated with the instance.\n\n        Args:\n            names_only: If `True`, only update the node names in the points array. If\n                `False`, the points array will be updated to match the new skeleton.\n        \"\"\"\n        if names_only:\n            # Update the node names.\n            self.points[\"name\"] = self.skeleton.node_names\n            return\n\n        # Find correspondences.\n        new_node_inds, old_node_inds = self.skeleton.match_nodes(self.points[\"name\"])\n\n        # Update the points.\n        new_points = PredictedPointsArray.empty(len(self.skeleton))\n        new_points[new_node_inds] = self.points[old_node_inds]\n        new_points[\"name\"] = self.skeleton.node_names\n        self.points = new_points\n\n    def replace_skeleton(\n        self,\n        new_skeleton: Skeleton,\n        node_names_map: dict[str, str] | None = None,\n    ):\n        \"\"\"Replace the skeleton associated with the instance.\n\n        Args:\n            new_skeleton: The new `Skeleton` to associate with the instance.\n            node_names_map: Dictionary mapping nodes in the old skeleton to nodes in the\n                new skeleton. Keys and values should be specified as lists of strings.\n                If not provided, only nodes with identical names will be mapped. Points\n                associated with unmapped nodes will be removed.\n\n        Notes:\n            This method will update the `PredictedInstance.skeleton` attribute and the\n            `PredictedInstance.points` attribute in place (a copy is made of the points\n            array).\n\n            It is recommended to use `Labels.replace_skeleton` instead of this method if\n            more flexible node mapping is required.\n        \"\"\"\n        # Update skeleton object.\n        self.skeleton = new_skeleton\n\n        # Get node names with replacements from node map if possible.\n        old_node_names = self.points[\"name\"].tolist()\n        if node_names_map is not None:\n            old_node_names = [node_names_map.get(node, node) for node in old_node_names]\n\n        # Find correspondences.\n        new_node_inds, old_node_inds = self.skeleton.match_nodes(old_node_names)\n\n        # Update the points.\n        new_points = PredictedPointsArray.empty(len(self.skeleton))\n        new_points[new_node_inds] = self.points[old_node_inds]\n        self.points = new_points\n        self.points[\"name\"] = self.skeleton.node_names\n\n    def __getitem__(self, node: Union[int, str, Node]) -&gt; np.ndarray:\n        \"\"\"Return the point associated with a node.\"\"\"\n        # Inherit from Instance.__getitem__\n        return super().__getitem__(node)\n\n    def __setitem__(self, node: Union[int, str, Node], value):\n        \"\"\"Set the point associated with a node.\n\n        Args:\n            node: The node to set the point for. Can be an integer index, string name,\n                or Node object.\n            value: A tuple or array-like of length 2 or 3 containing (x, y) coordinates\n                and optionally a confidence score. If the score is not provided, it\n                defaults to 1.0.\n\n        Notes:\n            This sets the point coordinates, score, and marks the point as visible.\n        \"\"\"\n        if type(node) is not int:\n            node = self.skeleton.index(node)\n\n        if len(value) &lt; 2:\n            raise ValueError(\"Value must have at least 2 elements (x, y)\")\n\n        self.points[node][\"xy\"] = value[:2]\n\n        # Set score if provided, otherwise default to 1.0\n        if len(value) &gt;= 3:\n            self.points[node][\"score\"] = value[2]\n        else:\n            self.points[node][\"score\"] = 1.0\n\n        self.points[node][\"visible\"] = True\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.PredictedInstance.__getitem__","title":"<code>__getitem__(node)</code>","text":"<p>Return the point associated with a node.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>def __getitem__(self, node: Union[int, str, Node]) -&gt; np.ndarray:\n    \"\"\"Return the point associated with a node.\"\"\"\n    # Inherit from Instance.__getitem__\n    return super().__getitem__(node)\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.PredictedInstance.__repr__","title":"<code>__repr__()</code>","text":"<p>Return a readable representation of the instance.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return a readable representation of the instance.\"\"\"\n    pts = self.numpy().tolist()\n    track = f'\"{self.track.name}\"' if self.track is not None else self.track\n\n    score = str(self.score) if self.score is None else f\"{self.score:.2f}\"\n    tracking_score = (\n        str(self.tracking_score)\n        if self.tracking_score is None\n        else f\"{self.tracking_score:.2f}\"\n    )\n    return (\n        f\"PredictedInstance(points={pts}, track={track}, \"\n        f\"score={score}, tracking_score={tracking_score})\"\n    )\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.PredictedInstance.__setitem__","title":"<code>__setitem__(node, value)</code>","text":"<p>Set the point associated with a node.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>Union[int, str, Node]</code> <p>The node to set the point for. Can be an integer index, string name, or Node object.</p> required <code>value</code> <p>A tuple or array-like of length 2 or 3 containing (x, y) coordinates and optionally a confidence score. If the score is not provided, it defaults to 1.0.</p> required Notes <p>This sets the point coordinates, score, and marks the point as visible.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>def __setitem__(self, node: Union[int, str, Node], value):\n    \"\"\"Set the point associated with a node.\n\n    Args:\n        node: The node to set the point for. Can be an integer index, string name,\n            or Node object.\n        value: A tuple or array-like of length 2 or 3 containing (x, y) coordinates\n            and optionally a confidence score. If the score is not provided, it\n            defaults to 1.0.\n\n    Notes:\n        This sets the point coordinates, score, and marks the point as visible.\n    \"\"\"\n    if type(node) is not int:\n        node = self.skeleton.index(node)\n\n    if len(value) &lt; 2:\n        raise ValueError(\"Value must have at least 2 elements (x, y)\")\n\n    self.points[node][\"xy\"] = value[:2]\n\n    # Set score if provided, otherwise default to 1.0\n    if len(value) &gt;= 3:\n        self.points[node][\"score\"] = value[2]\n    else:\n        self.points[node][\"score\"] = 1.0\n\n    self.points[node][\"visible\"] = True\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.PredictedInstance.empty","title":"<code>empty(skeleton, score=0.0, track=None, tracking_score=None, from_predicted=None)</code>  <code>classmethod</code>","text":"<p>Create an empty instance with no points.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>@classmethod\ndef empty(\n    cls,\n    skeleton: Skeleton,\n    score: float = 0.0,\n    track: Optional[Track] = None,\n    tracking_score: Optional[float] = None,\n    from_predicted: Optional[PredictedInstance] = None,\n) -&gt; \"PredictedInstance\":\n    \"\"\"Create an empty instance with no points.\"\"\"\n    points = PredictedPointsArray.empty(len(skeleton))\n    points[\"name\"] = skeleton.node_names\n\n    return cls(\n        points=points,\n        skeleton=skeleton,\n        score=score,\n        track=track,\n        tracking_score=tracking_score,\n        from_predicted=from_predicted,\n    )\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.PredictedInstance.from_numpy","title":"<code>from_numpy(points_data, skeleton, point_scores=None, score=0.0, track=None, tracking_score=None, from_predicted=None)</code>  <code>classmethod</code>","text":"<p>Create a predicted instance object from a numpy array.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>@classmethod\ndef from_numpy(\n    cls,\n    points_data: np.ndarray,\n    skeleton: Skeleton,\n    point_scores: Optional[np.ndarray] = None,\n    score: float = 0.0,\n    track: Optional[Track] = None,\n    tracking_score: Optional[float] = None,\n    from_predicted: Optional[PredictedInstance] = None,\n) -&gt; \"PredictedInstance\":\n    \"\"\"Create a predicted instance object from a numpy array.\"\"\"\n    points = cls._convert_points(points_data, skeleton)\n    if point_scores is not None:\n        points[\"score\"] = point_scores\n\n    return cls(\n        points=points,\n        skeleton=skeleton,\n        score=score,\n        track=track,\n        tracking_score=tracking_score,\n        from_predicted=from_predicted,\n    )\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.PredictedInstance.numpy","title":"<code>numpy(invisible_as_nan=True, scores=False)</code>","text":"<p>Return the instance points as a <code>(n_nodes, 2)</code> numpy array.</p> <p>Parameters:</p> Name Type Description Default <code>invisible_as_nan</code> <code>bool</code> <p>If <code>True</code> (the default), points that are not visible will be set to <code>np.nan</code>. If <code>False</code>, they will be whatever the stored value of <code>PredictedInstance.points[\"xy\"]</code> is.</p> <code>True</code> <code>scores</code> <code>bool</code> <p>If <code>True</code>, the score associated with each point will be included in the output.</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>A numpy array of shape <code>(n_nodes, 2)</code> corresponding to the points of the skeleton. Values of <code>np.nan</code> indicate \"missing\" nodes.</p> <p>If <code>scores</code> is <code>True</code>, the array will have shape <code>(n_nodes, 3)</code> with the third column containing the score associated with each point.</p> Notes <p>This will always return a copy of the array.</p> <p>If you need to avoid making a copy, just access the <code>PredictedInstance.points[\"xy\"]</code> attribute directly. This will not replace invisible points with <code>np.nan</code>.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>def numpy(\n    self,\n    invisible_as_nan: bool = True,\n    scores: bool = False,\n) -&gt; np.ndarray:\n    \"\"\"Return the instance points as a `(n_nodes, 2)` numpy array.\n\n    Args:\n        invisible_as_nan: If `True` (the default), points that are not visible will\n            be set to `np.nan`. If `False`, they will be whatever the stored value\n            of `PredictedInstance.points[\"xy\"]` is.\n        scores: If `True`, the score associated with each point will be\n            included in the output.\n\n    Returns:\n        A numpy array of shape `(n_nodes, 2)` corresponding to the points of the\n        skeleton. Values of `np.nan` indicate \"missing\" nodes.\n\n        If `scores` is `True`, the array will have shape `(n_nodes, 3)` with the\n        third column containing the score associated with each point.\n\n    Notes:\n        This will always return a copy of the array.\n\n        If you need to avoid making a copy, just access the\n        `PredictedInstance.points[\"xy\"]` attribute directly. This will not replace\n        invisible points with `np.nan`.\n    \"\"\"\n    if invisible_as_nan:\n        pts = np.where(\n            self.points[\"visible\"].reshape(-1, 1), self.points[\"xy\"], np.nan\n        )\n    else:\n        pts = self.points[\"xy\"].copy()\n\n    if scores:\n        return np.column_stack((pts, self.points[\"score\"]))\n    else:\n        return pts\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.PredictedInstance.replace_skeleton","title":"<code>replace_skeleton(new_skeleton, node_names_map=None)</code>","text":"<p>Replace the skeleton associated with the instance.</p> <p>Parameters:</p> Name Type Description Default <code>new_skeleton</code> <code>Skeleton</code> <p>The new <code>Skeleton</code> to associate with the instance.</p> required <code>node_names_map</code> <code>dict[str, str] | None</code> <p>Dictionary mapping nodes in the old skeleton to nodes in the new skeleton. Keys and values should be specified as lists of strings. If not provided, only nodes with identical names will be mapped. Points associated with unmapped nodes will be removed.</p> <code>None</code> Notes <p>This method will update the <code>PredictedInstance.skeleton</code> attribute and the <code>PredictedInstance.points</code> attribute in place (a copy is made of the points array).</p> <p>It is recommended to use <code>Labels.replace_skeleton</code> instead of this method if more flexible node mapping is required.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>def replace_skeleton(\n    self,\n    new_skeleton: Skeleton,\n    node_names_map: dict[str, str] | None = None,\n):\n    \"\"\"Replace the skeleton associated with the instance.\n\n    Args:\n        new_skeleton: The new `Skeleton` to associate with the instance.\n        node_names_map: Dictionary mapping nodes in the old skeleton to nodes in the\n            new skeleton. Keys and values should be specified as lists of strings.\n            If not provided, only nodes with identical names will be mapped. Points\n            associated with unmapped nodes will be removed.\n\n    Notes:\n        This method will update the `PredictedInstance.skeleton` attribute and the\n        `PredictedInstance.points` attribute in place (a copy is made of the points\n        array).\n\n        It is recommended to use `Labels.replace_skeleton` instead of this method if\n        more flexible node mapping is required.\n    \"\"\"\n    # Update skeleton object.\n    self.skeleton = new_skeleton\n\n    # Get node names with replacements from node map if possible.\n    old_node_names = self.points[\"name\"].tolist()\n    if node_names_map is not None:\n        old_node_names = [node_names_map.get(node, node) for node in old_node_names]\n\n    # Find correspondences.\n    new_node_inds, old_node_inds = self.skeleton.match_nodes(old_node_names)\n\n    # Update the points.\n    new_points = PredictedPointsArray.empty(len(self.skeleton))\n    new_points[new_node_inds] = self.points[old_node_inds]\n    self.points = new_points\n    self.points[\"name\"] = self.skeleton.node_names\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.PredictedInstance.update_skeleton","title":"<code>update_skeleton(names_only=False)</code>","text":"<p>Update or replace the skeleton associated with the instance.</p> <p>Parameters:</p> Name Type Description Default <code>names_only</code> <code>bool</code> <p>If <code>True</code>, only update the node names in the points array. If <code>False</code>, the points array will be updated to match the new skeleton.</p> <code>False</code> Source code in <code>sleap_io/model/instance.py</code> <pre><code>def update_skeleton(self, names_only: bool = False):\n    \"\"\"Update or replace the skeleton associated with the instance.\n\n    Args:\n        names_only: If `True`, only update the node names in the points array. If\n            `False`, the points array will be updated to match the new skeleton.\n    \"\"\"\n    if names_only:\n        # Update the node names.\n        self.points[\"name\"] = self.skeleton.node_names\n        return\n\n    # Find correspondences.\n    new_node_inds, old_node_inds = self.skeleton.match_nodes(self.points[\"name\"])\n\n    # Update the points.\n    new_points = PredictedPointsArray.empty(len(self.skeleton))\n    new_points[new_node_inds] = self.points[old_node_inds]\n    new_points[\"name\"] = self.skeleton.node_names\n    self.points = new_points\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.RecordingSession","title":"<code>RecordingSession</code>","text":"<p>A recording session with multiple cameras.</p> <p>Attributes:</p> Name Type Description <code>camera_group</code> <code>CameraGroup</code> <p><code>CameraGroup</code> object containing cameras in the session.</p> <code>frame_groups</code> <code>dict[int, FrameGroup]</code> <p>Dictionary mapping frame index to <code>FrameGroup</code>.</p> <code>videos</code> <code>list[Video]</code> <p>List of <code>Video</code> objects linked to <code>Camera</code>s in the session.</p> <code>cameras</code> <code>list[Camera]</code> <p>List of <code>Camera</code> objects linked to <code>Video</code>s in the session.</p> <code>metadata</code> <code>dict</code> <p>Dictionary of metadata.</p> <p>Methods:</p> Name Description <code>__repr__</code> <p>Return a readable representation of the session.</p> <code>add_video</code> <p>Add <code>video</code> to <code>RecordingSession</code> and mapping to <code>camera</code>.</p> <code>get_camera</code> <p>Get <code>Camera</code> associated with <code>video</code>.</p> <code>get_video</code> <p>Get <code>Video</code> associated with <code>camera</code>.</p> <code>remove_video</code> <p>Remove <code>video</code> from <code>RecordingSession</code> and mapping to <code>Camera</code>.</p> Source code in <code>sleap_io/model/camera.py</code> <pre><code>@define(eq=False)  # Set eq to false to make class hashable\nclass RecordingSession:\n    \"\"\"A recording session with multiple cameras.\n\n    Attributes:\n        camera_group: `CameraGroup` object containing cameras in the session.\n        frame_groups: Dictionary mapping frame index to `FrameGroup`.\n        videos: List of `Video` objects linked to `Camera`s in the session.\n        cameras: List of `Camera` objects linked to `Video`s in the session.\n        metadata: Dictionary of metadata.\n    \"\"\"\n\n    camera_group: CameraGroup = field(\n        factory=CameraGroup, validator=instance_of(CameraGroup)\n    )\n    _video_by_camera: dict[Camera, Video] = field(\n        factory=dict, validator=instance_of(dict)\n    )\n    _camera_by_video: dict[Video, Camera] = field(\n        factory=dict, validator=instance_of(dict)\n    )\n    _frame_group_by_frame_idx: dict[int, FrameGroup] = field(\n        factory=dict, validator=instance_of(dict)\n    )\n    metadata: dict = field(factory=dict, validator=instance_of(dict))\n\n    @property\n    def frame_groups(self) -&gt; dict[int, FrameGroup]:\n        \"\"\"Get dictionary of `FrameGroup` objects by frame index.\n\n        Returns:\n            Dictionary of `FrameGroup` objects by frame index.\n        \"\"\"\n        return self._frame_group_by_frame_idx\n\n    @property\n    def videos(self) -&gt; list[Video]:\n        \"\"\"Get list of `Video` objects in the `RecordingSession`.\n\n        Returns:\n            List of `Video` objects in `RecordingSession`.\n        \"\"\"\n        return list(self._video_by_camera.values())\n\n    @property\n    def cameras(self) -&gt; list[Camera]:\n        \"\"\"Get list of `Camera` objects linked to `Video`s in the `RecordingSession`.\n\n        Returns:\n            List of `Camera` objects in `RecordingSession`.\n        \"\"\"\n        return list(self._video_by_camera.keys())\n\n    def get_camera(self, video: Video) -&gt; Camera | None:\n        \"\"\"Get `Camera` associated with `video`.\n\n        Args:\n            video: `Video` to get `Camera`\n\n        Returns:\n            `Camera` associated with `video` or None if not found\n        \"\"\"\n        return self._camera_by_video.get(video, None)\n\n    def get_video(self, camera: Camera) -&gt; Video | None:\n        \"\"\"Get `Video` associated with `camera`.\n\n        Args:\n            camera: `Camera` to get `Video`\n\n        Returns:\n            `Video` associated with `camera` or None if not found\n        \"\"\"\n        return self._video_by_camera.get(camera, None)\n\n    def add_video(self, video: Video, camera: Camera):\n        \"\"\"Add `video` to `RecordingSession` and mapping to `camera`.\n\n        Args:\n            video: `Video` object to add to `RecordingSession`.\n            camera: `Camera` object to associate with `video`.\n\n        Raises:\n            ValueError: If `camera` is not in associated `CameraGroup`.\n            ValueError: If `video` is not a `Video` object.\n        \"\"\"\n        # Raise ValueError if camera is not in associated camera group\n        self.camera_group.cameras.index(camera)\n\n        # Raise ValueError if `Video` is not a `Video` object\n        if not isinstance(video, Video):\n            raise ValueError(\n                f\"Expected `Video` object, but received {type(video)} object.\"\n            )\n\n        # Add camera to video mapping\n        self._video_by_camera[camera] = video\n\n        # Add video to camera mapping\n        self._camera_by_video[video] = camera\n\n    def remove_video(self, video: Video):\n        \"\"\"Remove `video` from `RecordingSession` and mapping to `Camera`.\n\n        Args:\n            video: `Video` object to remove from `RecordingSession`.\n\n        Raises:\n            ValueError: If `video` is not in associated `RecordingSession`.\n        \"\"\"\n        # Remove video from camera mapping\n        camera = self._camera_by_video.pop(video)\n\n        # Remove camera from video mapping\n        self._video_by_camera.pop(camera)\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return a readable representation of the session.\"\"\"\n        return (\n            \"RecordingSession(\"\n            f\"camera_group={len(self.camera_group.cameras)}cameras, \"\n            f\"videos={len(self.videos)}, \"\n            f\"frame_groups={len(self.frame_groups)}\"\n            \")\"\n        )\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.RecordingSession.cameras","title":"<code>cameras</code>  <code>property</code>","text":"<p>Get list of <code>Camera</code> objects linked to <code>Video</code>s in the <code>RecordingSession</code>.</p> <p>Returns:</p> Type Description <code>list[Camera]</code> <p>List of <code>Camera</code> objects in <code>RecordingSession</code>.</p>"},{"location":"reference/sleap_io/#sleap_io.RecordingSession.frame_groups","title":"<code>frame_groups</code>  <code>property</code>","text":"<p>Get dictionary of <code>FrameGroup</code> objects by frame index.</p> <p>Returns:</p> Type Description <code>dict[int, FrameGroup]</code> <p>Dictionary of <code>FrameGroup</code> objects by frame index.</p>"},{"location":"reference/sleap_io/#sleap_io.RecordingSession.videos","title":"<code>videos</code>  <code>property</code>","text":"<p>Get list of <code>Video</code> objects in the <code>RecordingSession</code>.</p> <p>Returns:</p> Type Description <code>list[Video]</code> <p>List of <code>Video</code> objects in <code>RecordingSession</code>.</p>"},{"location":"reference/sleap_io/#sleap_io.RecordingSession.__repr__","title":"<code>__repr__()</code>","text":"<p>Return a readable representation of the session.</p> Source code in <code>sleap_io/model/camera.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return a readable representation of the session.\"\"\"\n    return (\n        \"RecordingSession(\"\n        f\"camera_group={len(self.camera_group.cameras)}cameras, \"\n        f\"videos={len(self.videos)}, \"\n        f\"frame_groups={len(self.frame_groups)}\"\n        \")\"\n    )\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.RecordingSession.add_video","title":"<code>add_video(video, camera)</code>","text":"<p>Add <code>video</code> to <code>RecordingSession</code> and mapping to <code>camera</code>.</p> <p>Parameters:</p> Name Type Description Default <code>video</code> <code>Video</code> <p><code>Video</code> object to add to <code>RecordingSession</code>.</p> required <code>camera</code> <code>Camera</code> <p><code>Camera</code> object to associate with <code>video</code>.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If <code>camera</code> is not in associated <code>CameraGroup</code>.</p> <code>ValueError</code> <p>If <code>video</code> is not a <code>Video</code> object.</p> Source code in <code>sleap_io/model/camera.py</code> <pre><code>def add_video(self, video: Video, camera: Camera):\n    \"\"\"Add `video` to `RecordingSession` and mapping to `camera`.\n\n    Args:\n        video: `Video` object to add to `RecordingSession`.\n        camera: `Camera` object to associate with `video`.\n\n    Raises:\n        ValueError: If `camera` is not in associated `CameraGroup`.\n        ValueError: If `video` is not a `Video` object.\n    \"\"\"\n    # Raise ValueError if camera is not in associated camera group\n    self.camera_group.cameras.index(camera)\n\n    # Raise ValueError if `Video` is not a `Video` object\n    if not isinstance(video, Video):\n        raise ValueError(\n            f\"Expected `Video` object, but received {type(video)} object.\"\n        )\n\n    # Add camera to video mapping\n    self._video_by_camera[camera] = video\n\n    # Add video to camera mapping\n    self._camera_by_video[video] = camera\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.RecordingSession.get_camera","title":"<code>get_camera(video)</code>","text":"<p>Get <code>Camera</code> associated with <code>video</code>.</p> <p>Parameters:</p> Name Type Description Default <code>video</code> <code>Video</code> <p><code>Video</code> to get <code>Camera</code></p> required <p>Returns:</p> Type Description <code>Camera | None</code> <p><code>Camera</code> associated with <code>video</code> or None if not found</p> Source code in <code>sleap_io/model/camera.py</code> <pre><code>def get_camera(self, video: Video) -&gt; Camera | None:\n    \"\"\"Get `Camera` associated with `video`.\n\n    Args:\n        video: `Video` to get `Camera`\n\n    Returns:\n        `Camera` associated with `video` or None if not found\n    \"\"\"\n    return self._camera_by_video.get(video, None)\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.RecordingSession.get_video","title":"<code>get_video(camera)</code>","text":"<p>Get <code>Video</code> associated with <code>camera</code>.</p> <p>Parameters:</p> Name Type Description Default <code>camera</code> <code>Camera</code> <p><code>Camera</code> to get <code>Video</code></p> required <p>Returns:</p> Type Description <code>Video | None</code> <p><code>Video</code> associated with <code>camera</code> or None if not found</p> Source code in <code>sleap_io/model/camera.py</code> <pre><code>def get_video(self, camera: Camera) -&gt; Video | None:\n    \"\"\"Get `Video` associated with `camera`.\n\n    Args:\n        camera: `Camera` to get `Video`\n\n    Returns:\n        `Video` associated with `camera` or None if not found\n    \"\"\"\n    return self._video_by_camera.get(camera, None)\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.RecordingSession.remove_video","title":"<code>remove_video(video)</code>","text":"<p>Remove <code>video</code> from <code>RecordingSession</code> and mapping to <code>Camera</code>.</p> <p>Parameters:</p> Name Type Description Default <code>video</code> <code>Video</code> <p><code>Video</code> object to remove from <code>RecordingSession</code>.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If <code>video</code> is not in associated <code>RecordingSession</code>.</p> Source code in <code>sleap_io/model/camera.py</code> <pre><code>def remove_video(self, video: Video):\n    \"\"\"Remove `video` from `RecordingSession` and mapping to `Camera`.\n\n    Args:\n        video: `Video` object to remove from `RecordingSession`.\n\n    Raises:\n        ValueError: If `video` is not in associated `RecordingSession`.\n    \"\"\"\n    # Remove video from camera mapping\n    camera = self._camera_by_video.pop(video)\n\n    # Remove camera from video mapping\n    self._video_by_camera.pop(camera)\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Skeleton","title":"<code>Skeleton</code>","text":"<p>A description of a set of landmark types and connections between them.</p> <p>Skeletons are represented by a directed graph composed of a set of <code>Node</code>s (landmark types such as body parts) and <code>Edge</code>s (connections between parts).</p> <p>Attributes:</p> Name Type Description <code>nodes</code> <code>list[Node]</code> <p>A list of <code>Node</code>s. May be specified as a list of strings to create new nodes from their names.</p> <code>edges</code> <code>list[Edge]</code> <p>A list of <code>Edge</code>s. May be specified as a list of 2-tuples of string names or integer indices of <code>nodes</code>. Each edge corresponds to a pair of source and destination nodes forming a directed edge.</p> <code>symmetries</code> <code>list[Symmetry]</code> <p>A list of <code>Symmetry</code>s. Each symmetry corresponds to symmetric body parts, such as <code>\"left eye\", \"right eye\"</code>. This is used when applying flip (reflection) augmentation to images in order to appropriately swap the indices of symmetric landmarks.</p> <code>name</code> <code>str | None</code> <p>A descriptive name for the <code>Skeleton</code>.</p> <p>Methods:</p> Name Description <code>__attrs_post_init__</code> <p>Ensure nodes are <code>Node</code>s, edges are <code>Edge</code>s, and <code>Node</code> map is updated.</p> <code>__contains__</code> <p>Check if a node is in the skeleton.</p> <code>__getitem__</code> <p>Return a <code>Node</code> when indexing by name or integer.</p> <code>__len__</code> <p>Return the number of nodes in the skeleton.</p> <code>__repr__</code> <p>Return a readable representation of the skeleton.</p> <code>add_edge</code> <p>Add an <code>Edge</code> to the skeleton.</p> <code>add_edges</code> <p>Add multiple <code>Edge</code>s to the skeleton.</p> <code>add_node</code> <p>Add a <code>Node</code> to the skeleton.</p> <code>add_nodes</code> <p>Add multiple <code>Node</code>s to the skeleton.</p> <code>add_symmetries</code> <p>Add multiple <code>Symmetry</code> relationships to the skeleton.</p> <code>add_symmetry</code> <p>Add a symmetry relationship to the skeleton.</p> <code>get_flipped_node_inds</code> <p>Returns node indices that should be switched when horizontally flipping.</p> <code>index</code> <p>Return the index of a node specified as a <code>Node</code> or string name.</p> <code>match_nodes</code> <p>Return the order of nodes in the skeleton.</p> <code>matches</code> <p>Check if this skeleton matches another skeleton's structure.</p> <code>node_similarities</code> <p>Calculate node overlap metrics with another skeleton.</p> <code>rebuild_cache</code> <p>Rebuild the node name/index to <code>Node</code> map caches.</p> <code>remove_node</code> <p>Remove a single node from the skeleton.</p> <code>remove_nodes</code> <p>Remove nodes from the skeleton.</p> <code>rename_node</code> <p>Rename a single node in the skeleton.</p> <code>rename_nodes</code> <p>Rename nodes in the skeleton.</p> <code>reorder_nodes</code> <p>Reorder nodes in the skeleton.</p> <code>require_node</code> <p>Return a <code>Node</code> object, handling indexing and adding missing nodes.</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>@define(eq=False)\nclass Skeleton:\n    \"\"\"A description of a set of landmark types and connections between them.\n\n    Skeletons are represented by a directed graph composed of a set of `Node`s (landmark\n    types such as body parts) and `Edge`s (connections between parts).\n\n    Attributes:\n        nodes: A list of `Node`s. May be specified as a list of strings to create new\n            nodes from their names.\n        edges: A list of `Edge`s. May be specified as a list of 2-tuples of string names\n            or integer indices of `nodes`. Each edge corresponds to a pair of source and\n            destination nodes forming a directed edge.\n        symmetries: A list of `Symmetry`s. Each symmetry corresponds to symmetric body\n            parts, such as `\"left eye\", \"right eye\"`. This is used when applying flip\n            (reflection) augmentation to images in order to appropriately swap the\n            indices of symmetric landmarks.\n        name: A descriptive name for the `Skeleton`.\n    \"\"\"\n\n    def _nodes_on_setattr(self, attr, new_nodes):\n        \"\"\"Callback to update caches when nodes are set.\"\"\"\n        self.rebuild_cache(nodes=new_nodes)\n        return new_nodes\n\n    nodes: list[Node] = field(\n        factory=list,\n        on_setattr=_nodes_on_setattr,\n    )\n    edges: list[Edge] = field(factory=list)\n    symmetries: list[Symmetry] = field(factory=list)\n    name: str | None = None\n    _name_to_node_cache: dict[str, Node] = field(init=False, repr=False, eq=False)\n    _node_to_ind_cache: dict[Node, int] = field(init=False, repr=False, eq=False)\n\n    def __attrs_post_init__(self):\n        \"\"\"Ensure nodes are `Node`s, edges are `Edge`s, and `Node` map is updated.\"\"\"\n        self._convert_nodes()\n        self._convert_edges()\n        self._convert_symmetries()\n        self.rebuild_cache()\n\n    def _convert_nodes(self):\n        \"\"\"Convert nodes to `Node` objects if needed.\"\"\"\n        if isinstance(self.nodes, np.ndarray):\n            object.__setattr__(self, \"nodes\", self.nodes.tolist())\n        for i, node in enumerate(self.nodes):\n            if type(node) is str:\n                self.nodes[i] = Node(node)\n\n    def _convert_edges(self):\n        \"\"\"Convert list of edge names or integers to `Edge` objects if needed.\"\"\"\n        if isinstance(self.edges, np.ndarray):\n            self.edges = self.edges.tolist()\n        node_names = self.node_names\n        for i, edge in enumerate(self.edges):\n            if type(edge) is Edge:\n                continue\n            src, dst = edge\n            if type(src) is str:\n                try:\n                    src = node_names.index(src)\n                except ValueError:\n                    raise ValueError(\n                        f\"Node '{src}' specified in the edge list is not in the nodes.\"\n                    )\n            if type(src) is int or (\n                np.isscalar(src) and np.issubdtype(src.dtype, np.integer)\n            ):\n                src = self.nodes[src]\n\n            if type(dst) is str:\n                try:\n                    dst = node_names.index(dst)\n                except ValueError:\n                    raise ValueError(\n                        f\"Node '{dst}' specified in the edge list is not in the nodes.\"\n                    )\n            if type(dst) is int or (\n                np.isscalar(dst) and np.issubdtype(dst.dtype, np.integer)\n            ):\n                dst = self.nodes[dst]\n\n            self.edges[i] = Edge(src, dst)\n\n    def _convert_symmetries(self):\n        \"\"\"Convert list of symmetric node names or integers to `Symmetry` objects.\"\"\"\n        if isinstance(self.symmetries, np.ndarray):\n            self.symmetries = self.symmetries.tolist()\n\n        node_names = self.node_names\n        for i, symmetry in enumerate(self.symmetries):\n            if type(symmetry) is Symmetry:\n                continue\n            node1, node2 = symmetry\n            if type(node1) is str:\n                try:\n                    node1 = node_names.index(node1)\n                except ValueError:\n                    raise ValueError(\n                        f\"Node '{node1}' specified in the symmetry list is not in the \"\n                        \"nodes.\"\n                    )\n            if type(node1) is int or (\n                np.isscalar(node1) and np.issubdtype(node1.dtype, np.integer)\n            ):\n                node1 = self.nodes[node1]\n\n            if type(node2) is str:\n                try:\n                    node2 = node_names.index(node2)\n                except ValueError:\n                    raise ValueError(\n                        f\"Node '{node2}' specified in the symmetry list is not in the \"\n                        \"nodes.\"\n                    )\n            if type(node2) is int or (\n                np.isscalar(node2) and np.issubdtype(node2.dtype, np.integer)\n            ):\n                node2 = self.nodes[node2]\n\n            self.symmetries[i] = Symmetry({node1, node2})\n\n    def rebuild_cache(self, nodes: list[Node] | None = None):\n        \"\"\"Rebuild the node name/index to `Node` map caches.\n\n        Args:\n            nodes: A list of `Node` objects to update the cache with. If not provided,\n                the cache will be updated with the current nodes in the skeleton. If\n                nodes are provided, the cache will be updated with the provided nodes,\n                but the current nodes in the skeleton will not be updated. Default is\n                `None`.\n\n        Notes:\n            This function should be called when nodes or node list is mutated to update\n            the lookup caches for indexing nodes by name or `Node` object.\n\n            This is done automatically when nodes are added or removed from the skeleton\n            using the convenience methods in this class.\n\n            This method only needs to be used when manually mutating nodes or the node\n            list directly.\n        \"\"\"\n        if nodes is None:\n            nodes = self.nodes\n        self._name_to_node_cache = {node.name: node for node in nodes}\n        self._node_to_ind_cache = {node: i for i, node in enumerate(nodes)}\n\n    @property\n    def node_names(self) -&gt; list[str]:\n        \"\"\"Names of the nodes associated with this skeleton as a list of strings.\"\"\"\n        return [node.name for node in self.nodes]\n\n    @property\n    def edge_inds(self) -&gt; list[tuple[int, int]]:\n        \"\"\"Edges indices as a list of 2-tuples.\"\"\"\n        return [\n            (self.nodes.index(edge.source), self.nodes.index(edge.destination))\n            for edge in self.edges\n        ]\n\n    @property\n    def edge_names(self) -&gt; list[str, str]:\n        \"\"\"Edge names as a list of 2-tuples with string node names.\"\"\"\n        return [(edge.source.name, edge.destination.name) for edge in self.edges]\n\n    @property\n    def symmetry_inds(self) -&gt; list[tuple[int, int]]:\n        \"\"\"Symmetry indices as a list of 2-tuples.\"\"\"\n        return [\n            tuple(sorted((self.index(symmetry[0]), self.index(symmetry[1]))))\n            for symmetry in self.symmetries\n        ]\n\n    @property\n    def symmetry_names(self) -&gt; list[str, str]:\n        \"\"\"Symmetry names as a list of 2-tuples with string node names.\"\"\"\n        return [\n            (self.nodes[i].name, self.nodes[j].name) for (i, j) in self.symmetry_inds\n        ]\n\n    def get_flipped_node_inds(self) -&gt; list[int]:\n        \"\"\"Returns node indices that should be switched when horizontally flipping.\n\n        This is useful as a lookup table for flipping the landmark coordinates when\n        doing data augmentation.\n\n        Example:\n            &gt;&gt;&gt; skel = Skeleton([\"A\", \"B_left\", \"B_right\", \"C\", \"D_left\", \"D_right\"])\n            &gt;&gt;&gt; skel.add_symmetry(\"B_left\", \"B_right\")\n            &gt;&gt;&gt; skel.add_symmetry(\"D_left\", \"D_right\")\n            &gt;&gt;&gt; skel.flipped_node_inds\n            [0, 2, 1, 3, 5, 4]\n            &gt;&gt;&gt; pose = np.array([[0, 0], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5]])\n            &gt;&gt;&gt; pose[skel.flipped_node_inds]\n            array([[0, 0],\n                   [2, 2],\n                   [1, 1],\n                   [3, 3],\n                   [5, 5],\n                   [4, 4]])\n        \"\"\"\n        flip_idx = np.arange(len(self.nodes))\n        if len(self.symmetries) &gt; 0:\n            symmetry_inds = np.array(\n                [(self.index(a), self.index(b)) for a, b in self.symmetries]\n            )\n            flip_idx[symmetry_inds[:, 0]] = symmetry_inds[:, 1]\n            flip_idx[symmetry_inds[:, 1]] = symmetry_inds[:, 0]\n\n        flip_idx = flip_idx.tolist()\n        return flip_idx\n\n    def __len__(self) -&gt; int:\n        \"\"\"Return the number of nodes in the skeleton.\"\"\"\n        return len(self.nodes)\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return a readable representation of the skeleton.\"\"\"\n        nodes = \", \".join([f'\"{node}\"' for node in self.node_names])\n        return f\"Skeleton(nodes=[{nodes}], edges={self.edge_inds})\"\n\n    def index(self, node: Node | str) -&gt; int:\n        \"\"\"Return the index of a node specified as a `Node` or string name.\"\"\"\n        if type(node) is str:\n            return self.index(self._name_to_node_cache[node])\n        elif type(node) is Node:\n            return self._node_to_ind_cache[node]\n        else:\n            raise IndexError(f\"Invalid indexing argument for skeleton: {node}\")\n\n    def __getitem__(self, idx: NodeOrIndex) -&gt; Node:\n        \"\"\"Return a `Node` when indexing by name or integer.\"\"\"\n        if type(idx) is int:\n            return self.nodes[idx]\n        elif type(idx) is str:\n            return self._name_to_node_cache[idx]\n        else:\n            raise IndexError(f\"Invalid indexing argument for skeleton: {idx}\")\n\n    def __contains__(self, node: NodeOrIndex) -&gt; bool:\n        \"\"\"Check if a node is in the skeleton.\"\"\"\n        if type(node) is str:\n            return node in self._name_to_node_cache\n        elif type(node) is Node:\n            return node in self.nodes\n        elif type(node) is int:\n            return 0 &lt;= node &lt; len(self.nodes)\n        else:\n            raise ValueError(f\"Invalid node type for skeleton: {node}\")\n\n    def add_node(self, node: Node | str):\n        \"\"\"Add a `Node` to the skeleton.\n\n        Args:\n            node: A `Node` object or a string name to create a new node.\n\n        Raises:\n            ValueError: If the node already exists in the skeleton or if the node is\n                not specified as a `Node` or string.\n        \"\"\"\n        if node in self:\n            raise ValueError(f\"Node '{node}' already exists in the skeleton.\")\n\n        if type(node) is str:\n            node = Node(node)\n\n        if type(node) is not Node:\n            raise ValueError(f\"Invalid node type: {node} ({type(node)})\")\n\n        self.nodes.append(node)\n\n        # Atomic update of the cache.\n        self._name_to_node_cache[node.name] = node\n        self._node_to_ind_cache[node] = len(self.nodes) - 1\n\n    def add_nodes(self, nodes: list[Node | str]):\n        \"\"\"Add multiple `Node`s to the skeleton.\n\n        Args:\n            nodes: A list of `Node` objects or string names to create new nodes.\n        \"\"\"\n        for node in nodes:\n            self.add_node(node)\n\n    def require_node(self, node: NodeOrIndex, add_missing: bool = True) -&gt; Node:\n        \"\"\"Return a `Node` object, handling indexing and adding missing nodes.\n\n        Args:\n            node: A `Node` object, name or index.\n            add_missing: If `True`, missing nodes will be added to the skeleton. If\n                `False`, an error will be raised if the node is not found. Default is\n                `True`.\n\n        Returns:\n            The `Node` object.\n\n        Raises:\n            IndexError: If the node is not found in the skeleton and `add_missing` is\n                `False`.\n        \"\"\"\n        if node not in self:\n            if add_missing:\n                self.add_node(node)\n            else:\n                raise IndexError(f\"Node '{node}' not found in the skeleton.\")\n\n        if type(node) is Node:\n            return node\n\n        return self[node]\n\n    def add_edge(\n        self,\n        src: NodeOrIndex | Edge | tuple[NodeOrIndex, NodeOrIndex],\n        dst: NodeOrIndex | None = None,\n    ):\n        \"\"\"Add an `Edge` to the skeleton.\n\n        Args:\n            src: The source node specified as a `Node`, name or index.\n            dst: The destination node specified as a `Node`, name or index.\n        \"\"\"\n        edge = None\n        if type(src) is tuple:\n            src, dst = src\n\n        if is_node_or_index(src):\n            if not is_node_or_index(dst):\n                raise ValueError(\"Destination node must be specified.\")\n\n            src = self.require_node(src)\n            dst = self.require_node(dst)\n            edge = Edge(src, dst)\n\n        if type(src) is Edge:\n            edge = src\n\n        if edge not in self.edges:\n            self.edges.append(edge)\n\n    def add_edges(self, edges: list[Edge | tuple[NodeOrIndex, NodeOrIndex]]):\n        \"\"\"Add multiple `Edge`s to the skeleton.\n\n        Args:\n            edges: A list of `Edge` objects or 2-tuples of source and destination nodes.\n        \"\"\"\n        for edge in edges:\n            self.add_edge(edge)\n\n    def add_symmetry(\n        self, node1: Symmetry | NodeOrIndex = None, node2: NodeOrIndex | None = None\n    ):\n        \"\"\"Add a symmetry relationship to the skeleton.\n\n        Args:\n            node1: The first node specified as a `Node`, name or index. If a `Symmetry`\n                object is provided, it will be added directly to the skeleton.\n            node2: The second node specified as a `Node`, name or index.\n        \"\"\"\n        symmetry = None\n        if type(node1) is Symmetry:\n            symmetry = node1\n            node1, node2 = symmetry\n\n        node1 = self.require_node(node1)\n        node2 = self.require_node(node2)\n\n        if symmetry is None:\n            symmetry = Symmetry({node1, node2})\n\n        if symmetry not in self.symmetries:\n            self.symmetries.append(symmetry)\n\n    def add_symmetries(\n        self, symmetries: list[Symmetry | tuple[NodeOrIndex, NodeOrIndex]]\n    ):\n        \"\"\"Add multiple `Symmetry` relationships to the skeleton.\n\n        Args:\n            symmetries: A list of `Symmetry` objects or 2-tuples of symmetric nodes.\n        \"\"\"\n        for symmetry in symmetries:\n            self.add_symmetry(*symmetry)\n\n    def rename_nodes(self, name_map: dict[NodeOrIndex, str] | list[str]):\n        \"\"\"Rename nodes in the skeleton.\n\n        Args:\n            name_map: A dictionary mapping old node names to new node names. Keys can be\n                specified as `Node` objects, integer indices, or string names. Values\n                must be specified as string names.\n\n                If a list of strings is provided of the same length as the current\n                nodes, the nodes will be renamed to the names in the list in order.\n\n        Raises:\n            ValueError: If the new node names exist in the skeleton or if the old node\n                names are not found in the skeleton.\n\n        Notes:\n            This method should always be used when renaming nodes in the skeleton as it\n            handles updating the lookup caches necessary for indexing nodes by name.\n\n            After renaming, instances using this skeleton **do NOT need to be updated**\n            as the nodes are stored by reference in the skeleton, so changes are\n            reflected automatically.\n\n        Example:\n            &gt;&gt;&gt; skel = Skeleton([\"A\", \"B\", \"C\"], edges=[(\"A\", \"B\"), (\"B\", \"C\")])\n            &gt;&gt;&gt; skel.rename_nodes({\"A\": \"X\", \"B\": \"Y\", \"C\": \"Z\"})\n            &gt;&gt;&gt; skel.node_names\n            [\"X\", \"Y\", \"Z\"]\n            &gt;&gt;&gt; skel.rename_nodes([\"a\", \"b\", \"c\"])\n            &gt;&gt;&gt; skel.node_names\n            [\"a\", \"b\", \"c\"]\n        \"\"\"\n        if type(name_map) is list:\n            if len(name_map) != len(self.nodes):\n                raise ValueError(\n                    \"List of new node names must be the same length as the current \"\n                    \"nodes.\"\n                )\n            name_map = {node: name for node, name in zip(self.nodes, name_map)}\n\n        for old_name, new_name in name_map.items():\n            if type(old_name) is Node:\n                old_name = old_name.name\n            if type(old_name) is int:\n                old_name = self.nodes[old_name].name\n\n            if old_name not in self._name_to_node_cache:\n                raise ValueError(f\"Node '{old_name}' not found in the skeleton.\")\n            if new_name in self._name_to_node_cache:\n                raise ValueError(f\"Node '{new_name}' already exists in the skeleton.\")\n\n            node = self._name_to_node_cache[old_name]\n            node.name = new_name\n            self._name_to_node_cache[new_name] = node\n            del self._name_to_node_cache[old_name]\n\n    def rename_node(self, old_name: NodeOrIndex, new_name: str):\n        \"\"\"Rename a single node in the skeleton.\n\n        Args:\n            old_name: The name of the node to rename. Can also be specified as an\n                integer index or `Node` object.\n            new_name: The new name for the node.\n        \"\"\"\n        self.rename_nodes({old_name: new_name})\n\n    def remove_nodes(self, nodes: list[NodeOrIndex]):\n        \"\"\"Remove nodes from the skeleton.\n\n        Args:\n            nodes: A list of node names, indices, or `Node` objects to remove.\n\n        Notes:\n            This method handles updating the lookup caches necessary for indexing nodes\n            by name.\n\n            Any edges and symmetries that are connected to the removed nodes will also\n            be removed.\n\n        Warning:\n            **This method does NOT update instances** that use this skeleton to reflect\n            changes.\n\n            It is recommended to use the `Labels.remove_nodes()` method which will\n            update all contained to reflect the changes made to the skeleton.\n\n            To manually update instances after this method is called, call\n            `instance.update_nodes()` on each instance that uses this skeleton.\n        \"\"\"\n        # Standardize input and make a pre-mutation copy before keys are changed.\n        rm_node_objs = [self.require_node(node, add_missing=False) for node in nodes]\n\n        # Remove nodes from the skeleton.\n        for node in rm_node_objs:\n            self.nodes.remove(node)\n            del self._name_to_node_cache[node.name]\n\n        # Remove edges connected to the removed nodes.\n        self.edges = [\n            edge\n            for edge in self.edges\n            if edge.source not in rm_node_objs and edge.destination not in rm_node_objs\n        ]\n\n        # Remove symmetries connected to the removed nodes.\n        self.symmetries = [\n            symmetry\n            for symmetry in self.symmetries\n            if symmetry.nodes.isdisjoint(rm_node_objs)\n        ]\n\n        # Update node index map.\n        self.rebuild_cache()\n\n    def remove_node(self, node: NodeOrIndex):\n        \"\"\"Remove a single node from the skeleton.\n\n        Args:\n            node: The node to remove. Can be specified as a string name, integer index,\n                or `Node` object.\n\n        Notes:\n            This method handles updating the lookup caches necessary for indexing nodes\n            by name.\n\n            Any edges and symmetries that are connected to the removed node will also be\n            removed.\n\n        Warning:\n            **This method does NOT update instances** that use this skeleton to reflect\n            changes.\n\n            It is recommended to use the `Labels.remove_nodes()` method which will\n            update all contained instances to reflect the changes made to the skeleton.\n\n            To manually update instances after this method is called, call\n            `Instance.update_skeleton()` on each instance that uses this skeleton.\n        \"\"\"\n        self.remove_nodes([node])\n\n    def reorder_nodes(self, new_order: list[NodeOrIndex]):\n        \"\"\"Reorder nodes in the skeleton.\n\n        Args:\n            new_order: A list of node names, indices, or `Node` objects specifying the\n                new order of the nodes.\n\n        Raises:\n            ValueError: If the new order of nodes is not the same length as the current\n                nodes.\n\n        Notes:\n            This method handles updating the lookup caches necessary for indexing nodes\n            by name.\n\n        Warning:\n            After reordering, instances using this skeleton do not need to be updated as\n            the nodes are stored by reference in the skeleton.\n\n            However, the order that points are stored in the instances will not be\n            updated to match the new order of the nodes in the skeleton. This should not\n            matter unless the ordering of the keys in the `Instance.points` dictionary\n            is used instead of relying on the skeleton node order.\n\n            To make sure these are aligned, it is recommended to use the\n            `Labels.reorder_nodes()` method which will update all contained instances to\n            reflect the changes made to the skeleton.\n\n            To manually update instances after this method is called, call\n            `Instance.update_skeleton()` on each instance that uses this skeleton.\n        \"\"\"\n        if len(new_order) != len(self.nodes):\n            raise ValueError(\n                \"New order of nodes must be the same length as the current nodes.\"\n            )\n\n        new_nodes = [self.require_node(node, add_missing=False) for node in new_order]\n        self.nodes = new_nodes\n\n    def match_nodes(self, other_nodes: list[str, Node]) -&gt; tuple[list[int], list[int]]:\n        \"\"\"Return the order of nodes in the skeleton.\n\n        Args:\n            other_nodes: A list of node names or `Node` objects.\n\n        Returns:\n            A tuple of `skeleton_inds, `other_inds`.\n\n            `skeleton_inds` contains the indices of the nodes in the skeleton that match\n            the input nodes.\n\n            `other_inds` contains the indices of the input nodes that match the nodes in\n            the skeleton.\n\n            These can be used to reorder point data to match the order of nodes in the\n            skeleton.\n\n        See also: match_nodes_cached\n        \"\"\"\n        if isinstance(other_nodes, np.ndarray):\n            other_nodes = other_nodes.tolist()\n        if type(other_nodes) is not tuple:\n            other_nodes = [x.name if type(x) is Node else x for x in other_nodes]\n\n        skeleton_inds, other_inds = match_nodes_cached(\n            tuple(self.node_names), tuple(other_nodes)\n        )\n\n        return list(skeleton_inds), list(other_inds)\n\n    def matches(self, other: \"Skeleton\", require_same_order: bool = False) -&gt; bool:\n        \"\"\"Check if this skeleton matches another skeleton's structure.\n\n        Args:\n            other: Another skeleton to compare with.\n            require_same_order: If True, nodes must be in the same order.\n                If False, only the node names and edges need to match.\n\n        Returns:\n            True if the skeletons match, False otherwise.\n\n        Notes:\n            Two skeletons match if they have the same nodes (by name) and edges.\n            If require_same_order is True, the nodes must also be in the same order.\n        \"\"\"\n        # Check if we have the same number of nodes\n        if len(self.nodes) != len(other.nodes):\n            return False\n\n        # Check node names\n        if require_same_order:\n            if self.node_names != other.node_names:\n                return False\n        else:\n            if set(self.node_names) != set(other.node_names):\n                return False\n\n        # Check edges (considering node name mapping if order differs)\n        if len(self.edges) != len(other.edges):\n            return False\n\n        # Create edge sets for comparison\n        self_edge_set = {\n            (edge.source.name, edge.destination.name) for edge in self.edges\n        }\n        other_edge_set = {\n            (edge.source.name, edge.destination.name) for edge in other.edges\n        }\n\n        if self_edge_set != other_edge_set:\n            return False\n\n        # Check symmetries\n        if len(self.symmetries) != len(other.symmetries):\n            return False\n\n        self_sym_set = {\n            frozenset(node.name for node in sym.nodes) for sym in self.symmetries\n        }\n        other_sym_set = {\n            frozenset(node.name for node in sym.nodes) for sym in other.symmetries\n        }\n\n        return self_sym_set == other_sym_set\n\n    def node_similarities(self, other: \"Skeleton\") -&gt; dict[str, float]:\n        \"\"\"Calculate node overlap metrics with another skeleton.\n\n        Args:\n            other: Another skeleton to compare with.\n\n        Returns:\n            A dictionary with similarity metrics:\n            - 'n_common': Number of nodes in common\n            - 'n_self_only': Number of nodes only in this skeleton\n            - 'n_other_only': Number of nodes only in the other skeleton\n            - 'jaccard': Jaccard similarity (intersection/union)\n            - 'dice': Dice coefficient (2*intersection/(n_self + n_other))\n        \"\"\"\n        self_nodes = set(self.node_names)\n        other_nodes = set(other.node_names)\n\n        n_common = len(self_nodes &amp; other_nodes)\n        n_self_only = len(self_nodes - other_nodes)\n        n_other_only = len(other_nodes - self_nodes)\n        n_union = len(self_nodes | other_nodes)\n\n        jaccard = n_common / n_union if n_union &gt; 0 else 0\n        dice = (\n            2 * n_common / (len(self_nodes) + len(other_nodes))\n            if (len(self_nodes) + len(other_nodes)) &gt; 0\n            else 0\n        )\n\n        return {\n            \"n_common\": n_common,\n            \"n_self_only\": n_self_only,\n            \"n_other_only\": n_other_only,\n            \"jaccard\": jaccard,\n            \"dice\": dice,\n        }\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Skeleton.edge_inds","title":"<code>edge_inds</code>  <code>property</code>","text":"<p>Edges indices as a list of 2-tuples.</p>"},{"location":"reference/sleap_io/#sleap_io.Skeleton.edge_names","title":"<code>edge_names</code>  <code>property</code>","text":"<p>Edge names as a list of 2-tuples with string node names.</p>"},{"location":"reference/sleap_io/#sleap_io.Skeleton.node_names","title":"<code>node_names</code>  <code>property</code>","text":"<p>Names of the nodes associated with this skeleton as a list of strings.</p>"},{"location":"reference/sleap_io/#sleap_io.Skeleton.symmetry_inds","title":"<code>symmetry_inds</code>  <code>property</code>","text":"<p>Symmetry indices as a list of 2-tuples.</p>"},{"location":"reference/sleap_io/#sleap_io.Skeleton.symmetry_names","title":"<code>symmetry_names</code>  <code>property</code>","text":"<p>Symmetry names as a list of 2-tuples with string node names.</p>"},{"location":"reference/sleap_io/#sleap_io.Skeleton.__attrs_post_init__","title":"<code>__attrs_post_init__()</code>","text":"<p>Ensure nodes are <code>Node</code>s, edges are <code>Edge</code>s, and <code>Node</code> map is updated.</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def __attrs_post_init__(self):\n    \"\"\"Ensure nodes are `Node`s, edges are `Edge`s, and `Node` map is updated.\"\"\"\n    self._convert_nodes()\n    self._convert_edges()\n    self._convert_symmetries()\n    self.rebuild_cache()\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Skeleton.__contains__","title":"<code>__contains__(node)</code>","text":"<p>Check if a node is in the skeleton.</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def __contains__(self, node: NodeOrIndex) -&gt; bool:\n    \"\"\"Check if a node is in the skeleton.\"\"\"\n    if type(node) is str:\n        return node in self._name_to_node_cache\n    elif type(node) is Node:\n        return node in self.nodes\n    elif type(node) is int:\n        return 0 &lt;= node &lt; len(self.nodes)\n    else:\n        raise ValueError(f\"Invalid node type for skeleton: {node}\")\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Skeleton.__getitem__","title":"<code>__getitem__(idx)</code>","text":"<p>Return a <code>Node</code> when indexing by name or integer.</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def __getitem__(self, idx: NodeOrIndex) -&gt; Node:\n    \"\"\"Return a `Node` when indexing by name or integer.\"\"\"\n    if type(idx) is int:\n        return self.nodes[idx]\n    elif type(idx) is str:\n        return self._name_to_node_cache[idx]\n    else:\n        raise IndexError(f\"Invalid indexing argument for skeleton: {idx}\")\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Skeleton.__len__","title":"<code>__len__()</code>","text":"<p>Return the number of nodes in the skeleton.</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"Return the number of nodes in the skeleton.\"\"\"\n    return len(self.nodes)\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Skeleton.__repr__","title":"<code>__repr__()</code>","text":"<p>Return a readable representation of the skeleton.</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return a readable representation of the skeleton.\"\"\"\n    nodes = \", \".join([f'\"{node}\"' for node in self.node_names])\n    return f\"Skeleton(nodes=[{nodes}], edges={self.edge_inds})\"\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Skeleton.add_edge","title":"<code>add_edge(src, dst=None)</code>","text":"<p>Add an <code>Edge</code> to the skeleton.</p> <p>Parameters:</p> Name Type Description Default <code>src</code> <code>NodeOrIndex | Edge | tuple[NodeOrIndex, NodeOrIndex]</code> <p>The source node specified as a <code>Node</code>, name or index.</p> required <code>dst</code> <code>NodeOrIndex | None</code> <p>The destination node specified as a <code>Node</code>, name or index.</p> <code>None</code> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def add_edge(\n    self,\n    src: NodeOrIndex | Edge | tuple[NodeOrIndex, NodeOrIndex],\n    dst: NodeOrIndex | None = None,\n):\n    \"\"\"Add an `Edge` to the skeleton.\n\n    Args:\n        src: The source node specified as a `Node`, name or index.\n        dst: The destination node specified as a `Node`, name or index.\n    \"\"\"\n    edge = None\n    if type(src) is tuple:\n        src, dst = src\n\n    if is_node_or_index(src):\n        if not is_node_or_index(dst):\n            raise ValueError(\"Destination node must be specified.\")\n\n        src = self.require_node(src)\n        dst = self.require_node(dst)\n        edge = Edge(src, dst)\n\n    if type(src) is Edge:\n        edge = src\n\n    if edge not in self.edges:\n        self.edges.append(edge)\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Skeleton.add_edges","title":"<code>add_edges(edges)</code>","text":"<p>Add multiple <code>Edge</code>s to the skeleton.</p> <p>Parameters:</p> Name Type Description Default <code>edges</code> <code>list[Edge | tuple[NodeOrIndex, NodeOrIndex]]</code> <p>A list of <code>Edge</code> objects or 2-tuples of source and destination nodes.</p> required Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def add_edges(self, edges: list[Edge | tuple[NodeOrIndex, NodeOrIndex]]):\n    \"\"\"Add multiple `Edge`s to the skeleton.\n\n    Args:\n        edges: A list of `Edge` objects or 2-tuples of source and destination nodes.\n    \"\"\"\n    for edge in edges:\n        self.add_edge(edge)\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Skeleton.add_node","title":"<code>add_node(node)</code>","text":"<p>Add a <code>Node</code> to the skeleton.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>Node | str</code> <p>A <code>Node</code> object or a string name to create a new node.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If the node already exists in the skeleton or if the node is not specified as a <code>Node</code> or string.</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def add_node(self, node: Node | str):\n    \"\"\"Add a `Node` to the skeleton.\n\n    Args:\n        node: A `Node` object or a string name to create a new node.\n\n    Raises:\n        ValueError: If the node already exists in the skeleton or if the node is\n            not specified as a `Node` or string.\n    \"\"\"\n    if node in self:\n        raise ValueError(f\"Node '{node}' already exists in the skeleton.\")\n\n    if type(node) is str:\n        node = Node(node)\n\n    if type(node) is not Node:\n        raise ValueError(f\"Invalid node type: {node} ({type(node)})\")\n\n    self.nodes.append(node)\n\n    # Atomic update of the cache.\n    self._name_to_node_cache[node.name] = node\n    self._node_to_ind_cache[node] = len(self.nodes) - 1\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Skeleton.add_nodes","title":"<code>add_nodes(nodes)</code>","text":"<p>Add multiple <code>Node</code>s to the skeleton.</p> <p>Parameters:</p> Name Type Description Default <code>nodes</code> <code>list[Node | str]</code> <p>A list of <code>Node</code> objects or string names to create new nodes.</p> required Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def add_nodes(self, nodes: list[Node | str]):\n    \"\"\"Add multiple `Node`s to the skeleton.\n\n    Args:\n        nodes: A list of `Node` objects or string names to create new nodes.\n    \"\"\"\n    for node in nodes:\n        self.add_node(node)\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Skeleton.add_symmetries","title":"<code>add_symmetries(symmetries)</code>","text":"<p>Add multiple <code>Symmetry</code> relationships to the skeleton.</p> <p>Parameters:</p> Name Type Description Default <code>symmetries</code> <code>list[Symmetry | tuple[NodeOrIndex, NodeOrIndex]]</code> <p>A list of <code>Symmetry</code> objects or 2-tuples of symmetric nodes.</p> required Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def add_symmetries(\n    self, symmetries: list[Symmetry | tuple[NodeOrIndex, NodeOrIndex]]\n):\n    \"\"\"Add multiple `Symmetry` relationships to the skeleton.\n\n    Args:\n        symmetries: A list of `Symmetry` objects or 2-tuples of symmetric nodes.\n    \"\"\"\n    for symmetry in symmetries:\n        self.add_symmetry(*symmetry)\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Skeleton.add_symmetry","title":"<code>add_symmetry(node1=None, node2=None)</code>","text":"<p>Add a symmetry relationship to the skeleton.</p> <p>Parameters:</p> Name Type Description Default <code>node1</code> <code>Symmetry | NodeOrIndex</code> <p>The first node specified as a <code>Node</code>, name or index. If a <code>Symmetry</code> object is provided, it will be added directly to the skeleton.</p> <code>None</code> <code>node2</code> <code>NodeOrIndex | None</code> <p>The second node specified as a <code>Node</code>, name or index.</p> <code>None</code> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def add_symmetry(\n    self, node1: Symmetry | NodeOrIndex = None, node2: NodeOrIndex | None = None\n):\n    \"\"\"Add a symmetry relationship to the skeleton.\n\n    Args:\n        node1: The first node specified as a `Node`, name or index. If a `Symmetry`\n            object is provided, it will be added directly to the skeleton.\n        node2: The second node specified as a `Node`, name or index.\n    \"\"\"\n    symmetry = None\n    if type(node1) is Symmetry:\n        symmetry = node1\n        node1, node2 = symmetry\n\n    node1 = self.require_node(node1)\n    node2 = self.require_node(node2)\n\n    if symmetry is None:\n        symmetry = Symmetry({node1, node2})\n\n    if symmetry not in self.symmetries:\n        self.symmetries.append(symmetry)\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Skeleton.get_flipped_node_inds","title":"<code>get_flipped_node_inds()</code>","text":"<p>Returns node indices that should be switched when horizontally flipping.</p> <p>This is useful as a lookup table for flipping the landmark coordinates when doing data augmentation.</p> Example <p>skel = Skeleton([\"A\", \"B_left\", \"B_right\", \"C\", \"D_left\", \"D_right\"]) skel.add_symmetry(\"B_left\", \"B_right\") skel.add_symmetry(\"D_left\", \"D_right\") skel.flipped_node_inds [0, 2, 1, 3, 5, 4] pose = np.array([[0, 0], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5]]) pose[skel.flipped_node_inds] array([[0, 0],        [2, 2],        [1, 1],        [3, 3],        [5, 5],        [4, 4]])</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def get_flipped_node_inds(self) -&gt; list[int]:\n    \"\"\"Returns node indices that should be switched when horizontally flipping.\n\n    This is useful as a lookup table for flipping the landmark coordinates when\n    doing data augmentation.\n\n    Example:\n        &gt;&gt;&gt; skel = Skeleton([\"A\", \"B_left\", \"B_right\", \"C\", \"D_left\", \"D_right\"])\n        &gt;&gt;&gt; skel.add_symmetry(\"B_left\", \"B_right\")\n        &gt;&gt;&gt; skel.add_symmetry(\"D_left\", \"D_right\")\n        &gt;&gt;&gt; skel.flipped_node_inds\n        [0, 2, 1, 3, 5, 4]\n        &gt;&gt;&gt; pose = np.array([[0, 0], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5]])\n        &gt;&gt;&gt; pose[skel.flipped_node_inds]\n        array([[0, 0],\n               [2, 2],\n               [1, 1],\n               [3, 3],\n               [5, 5],\n               [4, 4]])\n    \"\"\"\n    flip_idx = np.arange(len(self.nodes))\n    if len(self.symmetries) &gt; 0:\n        symmetry_inds = np.array(\n            [(self.index(a), self.index(b)) for a, b in self.symmetries]\n        )\n        flip_idx[symmetry_inds[:, 0]] = symmetry_inds[:, 1]\n        flip_idx[symmetry_inds[:, 1]] = symmetry_inds[:, 0]\n\n    flip_idx = flip_idx.tolist()\n    return flip_idx\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Skeleton.index","title":"<code>index(node)</code>","text":"<p>Return the index of a node specified as a <code>Node</code> or string name.</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def index(self, node: Node | str) -&gt; int:\n    \"\"\"Return the index of a node specified as a `Node` or string name.\"\"\"\n    if type(node) is str:\n        return self.index(self._name_to_node_cache[node])\n    elif type(node) is Node:\n        return self._node_to_ind_cache[node]\n    else:\n        raise IndexError(f\"Invalid indexing argument for skeleton: {node}\")\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Skeleton.match_nodes","title":"<code>match_nodes(other_nodes)</code>","text":"<p>Return the order of nodes in the skeleton.</p> <p>Parameters:</p> Name Type Description Default <code>other_nodes</code> <code>list[str, Node]</code> <p>A list of node names or <code>Node</code> objects.</p> required <p>Returns:</p> Type Description <code>tuple[list[int], list[int]]</code> <p>A tuple of <code>skeleton_inds,</code>other_inds`.</p> <p><code>skeleton_inds</code> contains the indices of the nodes in the skeleton that match the input nodes.</p> <p><code>other_inds</code> contains the indices of the input nodes that match the nodes in the skeleton.</p> <p>These can be used to reorder point data to match the order of nodes in the skeleton.</p> <p>See also: match_nodes_cached</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def match_nodes(self, other_nodes: list[str, Node]) -&gt; tuple[list[int], list[int]]:\n    \"\"\"Return the order of nodes in the skeleton.\n\n    Args:\n        other_nodes: A list of node names or `Node` objects.\n\n    Returns:\n        A tuple of `skeleton_inds, `other_inds`.\n\n        `skeleton_inds` contains the indices of the nodes in the skeleton that match\n        the input nodes.\n\n        `other_inds` contains the indices of the input nodes that match the nodes in\n        the skeleton.\n\n        These can be used to reorder point data to match the order of nodes in the\n        skeleton.\n\n    See also: match_nodes_cached\n    \"\"\"\n    if isinstance(other_nodes, np.ndarray):\n        other_nodes = other_nodes.tolist()\n    if type(other_nodes) is not tuple:\n        other_nodes = [x.name if type(x) is Node else x for x in other_nodes]\n\n    skeleton_inds, other_inds = match_nodes_cached(\n        tuple(self.node_names), tuple(other_nodes)\n    )\n\n    return list(skeleton_inds), list(other_inds)\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Skeleton.matches","title":"<code>matches(other, require_same_order=False)</code>","text":"<p>Check if this skeleton matches another skeleton's structure.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>'Skeleton'</code> <p>Another skeleton to compare with.</p> required <code>require_same_order</code> <code>bool</code> <p>If True, nodes must be in the same order. If False, only the node names and edges need to match.</p> <code>False</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if the skeletons match, False otherwise.</p> Notes <p>Two skeletons match if they have the same nodes (by name) and edges. If require_same_order is True, the nodes must also be in the same order.</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def matches(self, other: \"Skeleton\", require_same_order: bool = False) -&gt; bool:\n    \"\"\"Check if this skeleton matches another skeleton's structure.\n\n    Args:\n        other: Another skeleton to compare with.\n        require_same_order: If True, nodes must be in the same order.\n            If False, only the node names and edges need to match.\n\n    Returns:\n        True if the skeletons match, False otherwise.\n\n    Notes:\n        Two skeletons match if they have the same nodes (by name) and edges.\n        If require_same_order is True, the nodes must also be in the same order.\n    \"\"\"\n    # Check if we have the same number of nodes\n    if len(self.nodes) != len(other.nodes):\n        return False\n\n    # Check node names\n    if require_same_order:\n        if self.node_names != other.node_names:\n            return False\n    else:\n        if set(self.node_names) != set(other.node_names):\n            return False\n\n    # Check edges (considering node name mapping if order differs)\n    if len(self.edges) != len(other.edges):\n        return False\n\n    # Create edge sets for comparison\n    self_edge_set = {\n        (edge.source.name, edge.destination.name) for edge in self.edges\n    }\n    other_edge_set = {\n        (edge.source.name, edge.destination.name) for edge in other.edges\n    }\n\n    if self_edge_set != other_edge_set:\n        return False\n\n    # Check symmetries\n    if len(self.symmetries) != len(other.symmetries):\n        return False\n\n    self_sym_set = {\n        frozenset(node.name for node in sym.nodes) for sym in self.symmetries\n    }\n    other_sym_set = {\n        frozenset(node.name for node in sym.nodes) for sym in other.symmetries\n    }\n\n    return self_sym_set == other_sym_set\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Skeleton.node_similarities","title":"<code>node_similarities(other)</code>","text":"<p>Calculate node overlap metrics with another skeleton.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>'Skeleton'</code> <p>Another skeleton to compare with.</p> required <p>Returns:</p> Type Description <code>dict[str, float]</code> <p>A dictionary with similarity metrics: - 'n_common': Number of nodes in common - 'n_self_only': Number of nodes only in this skeleton - 'n_other_only': Number of nodes only in the other skeleton - 'jaccard': Jaccard similarity (intersection/union) - 'dice': Dice coefficient (2*intersection/(n_self + n_other))</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def node_similarities(self, other: \"Skeleton\") -&gt; dict[str, float]:\n    \"\"\"Calculate node overlap metrics with another skeleton.\n\n    Args:\n        other: Another skeleton to compare with.\n\n    Returns:\n        A dictionary with similarity metrics:\n        - 'n_common': Number of nodes in common\n        - 'n_self_only': Number of nodes only in this skeleton\n        - 'n_other_only': Number of nodes only in the other skeleton\n        - 'jaccard': Jaccard similarity (intersection/union)\n        - 'dice': Dice coefficient (2*intersection/(n_self + n_other))\n    \"\"\"\n    self_nodes = set(self.node_names)\n    other_nodes = set(other.node_names)\n\n    n_common = len(self_nodes &amp; other_nodes)\n    n_self_only = len(self_nodes - other_nodes)\n    n_other_only = len(other_nodes - self_nodes)\n    n_union = len(self_nodes | other_nodes)\n\n    jaccard = n_common / n_union if n_union &gt; 0 else 0\n    dice = (\n        2 * n_common / (len(self_nodes) + len(other_nodes))\n        if (len(self_nodes) + len(other_nodes)) &gt; 0\n        else 0\n    )\n\n    return {\n        \"n_common\": n_common,\n        \"n_self_only\": n_self_only,\n        \"n_other_only\": n_other_only,\n        \"jaccard\": jaccard,\n        \"dice\": dice,\n    }\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Skeleton.rebuild_cache","title":"<code>rebuild_cache(nodes=None)</code>","text":"<p>Rebuild the node name/index to <code>Node</code> map caches.</p> <p>Parameters:</p> Name Type Description Default <code>nodes</code> <code>list[Node] | None</code> <p>A list of <code>Node</code> objects to update the cache with. If not provided, the cache will be updated with the current nodes in the skeleton. If nodes are provided, the cache will be updated with the provided nodes, but the current nodes in the skeleton will not be updated. Default is <code>None</code>.</p> <code>None</code> Notes <p>This function should be called when nodes or node list is mutated to update the lookup caches for indexing nodes by name or <code>Node</code> object.</p> <p>This is done automatically when nodes are added or removed from the skeleton using the convenience methods in this class.</p> <p>This method only needs to be used when manually mutating nodes or the node list directly.</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def rebuild_cache(self, nodes: list[Node] | None = None):\n    \"\"\"Rebuild the node name/index to `Node` map caches.\n\n    Args:\n        nodes: A list of `Node` objects to update the cache with. If not provided,\n            the cache will be updated with the current nodes in the skeleton. If\n            nodes are provided, the cache will be updated with the provided nodes,\n            but the current nodes in the skeleton will not be updated. Default is\n            `None`.\n\n    Notes:\n        This function should be called when nodes or node list is mutated to update\n        the lookup caches for indexing nodes by name or `Node` object.\n\n        This is done automatically when nodes are added or removed from the skeleton\n        using the convenience methods in this class.\n\n        This method only needs to be used when manually mutating nodes or the node\n        list directly.\n    \"\"\"\n    if nodes is None:\n        nodes = self.nodes\n    self._name_to_node_cache = {node.name: node for node in nodes}\n    self._node_to_ind_cache = {node: i for i, node in enumerate(nodes)}\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Skeleton.remove_node","title":"<code>remove_node(node)</code>","text":"<p>Remove a single node from the skeleton.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>NodeOrIndex</code> <p>The node to remove. Can be specified as a string name, integer index, or <code>Node</code> object.</p> required Notes <p>This method handles updating the lookup caches necessary for indexing nodes by name.</p> <p>Any edges and symmetries that are connected to the removed node will also be removed.</p> Warning <p>This method does NOT update instances that use this skeleton to reflect changes.</p> <p>It is recommended to use the <code>Labels.remove_nodes()</code> method which will update all contained instances to reflect the changes made to the skeleton.</p> <p>To manually update instances after this method is called, call <code>Instance.update_skeleton()</code> on each instance that uses this skeleton.</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def remove_node(self, node: NodeOrIndex):\n    \"\"\"Remove a single node from the skeleton.\n\n    Args:\n        node: The node to remove. Can be specified as a string name, integer index,\n            or `Node` object.\n\n    Notes:\n        This method handles updating the lookup caches necessary for indexing nodes\n        by name.\n\n        Any edges and symmetries that are connected to the removed node will also be\n        removed.\n\n    Warning:\n        **This method does NOT update instances** that use this skeleton to reflect\n        changes.\n\n        It is recommended to use the `Labels.remove_nodes()` method which will\n        update all contained instances to reflect the changes made to the skeleton.\n\n        To manually update instances after this method is called, call\n        `Instance.update_skeleton()` on each instance that uses this skeleton.\n    \"\"\"\n    self.remove_nodes([node])\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Skeleton.remove_nodes","title":"<code>remove_nodes(nodes)</code>","text":"<p>Remove nodes from the skeleton.</p> <p>Parameters:</p> Name Type Description Default <code>nodes</code> <code>list[NodeOrIndex]</code> <p>A list of node names, indices, or <code>Node</code> objects to remove.</p> required Notes <p>This method handles updating the lookup caches necessary for indexing nodes by name.</p> <p>Any edges and symmetries that are connected to the removed nodes will also be removed.</p> Warning <p>This method does NOT update instances that use this skeleton to reflect changes.</p> <p>It is recommended to use the <code>Labels.remove_nodes()</code> method which will update all contained to reflect the changes made to the skeleton.</p> <p>To manually update instances after this method is called, call <code>instance.update_nodes()</code> on each instance that uses this skeleton.</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def remove_nodes(self, nodes: list[NodeOrIndex]):\n    \"\"\"Remove nodes from the skeleton.\n\n    Args:\n        nodes: A list of node names, indices, or `Node` objects to remove.\n\n    Notes:\n        This method handles updating the lookup caches necessary for indexing nodes\n        by name.\n\n        Any edges and symmetries that are connected to the removed nodes will also\n        be removed.\n\n    Warning:\n        **This method does NOT update instances** that use this skeleton to reflect\n        changes.\n\n        It is recommended to use the `Labels.remove_nodes()` method which will\n        update all contained to reflect the changes made to the skeleton.\n\n        To manually update instances after this method is called, call\n        `instance.update_nodes()` on each instance that uses this skeleton.\n    \"\"\"\n    # Standardize input and make a pre-mutation copy before keys are changed.\n    rm_node_objs = [self.require_node(node, add_missing=False) for node in nodes]\n\n    # Remove nodes from the skeleton.\n    for node in rm_node_objs:\n        self.nodes.remove(node)\n        del self._name_to_node_cache[node.name]\n\n    # Remove edges connected to the removed nodes.\n    self.edges = [\n        edge\n        for edge in self.edges\n        if edge.source not in rm_node_objs and edge.destination not in rm_node_objs\n    ]\n\n    # Remove symmetries connected to the removed nodes.\n    self.symmetries = [\n        symmetry\n        for symmetry in self.symmetries\n        if symmetry.nodes.isdisjoint(rm_node_objs)\n    ]\n\n    # Update node index map.\n    self.rebuild_cache()\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Skeleton.rename_node","title":"<code>rename_node(old_name, new_name)</code>","text":"<p>Rename a single node in the skeleton.</p> <p>Parameters:</p> Name Type Description Default <code>old_name</code> <code>NodeOrIndex</code> <p>The name of the node to rename. Can also be specified as an integer index or <code>Node</code> object.</p> required <code>new_name</code> <code>str</code> <p>The new name for the node.</p> required Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def rename_node(self, old_name: NodeOrIndex, new_name: str):\n    \"\"\"Rename a single node in the skeleton.\n\n    Args:\n        old_name: The name of the node to rename. Can also be specified as an\n            integer index or `Node` object.\n        new_name: The new name for the node.\n    \"\"\"\n    self.rename_nodes({old_name: new_name})\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Skeleton.rename_nodes","title":"<code>rename_nodes(name_map)</code>","text":"<p>Rename nodes in the skeleton.</p> <p>Parameters:</p> Name Type Description Default <code>name_map</code> <code>dict[NodeOrIndex, str] | list[str]</code> <p>A dictionary mapping old node names to new node names. Keys can be specified as <code>Node</code> objects, integer indices, or string names. Values must be specified as string names.</p> <p>If a list of strings is provided of the same length as the current nodes, the nodes will be renamed to the names in the list in order.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If the new node names exist in the skeleton or if the old node names are not found in the skeleton.</p> Notes <p>This method should always be used when renaming nodes in the skeleton as it handles updating the lookup caches necessary for indexing nodes by name.</p> <p>After renaming, instances using this skeleton do NOT need to be updated as the nodes are stored by reference in the skeleton, so changes are reflected automatically.</p> Example <p>skel = Skeleton([\"A\", \"B\", \"C\"], edges=[(\"A\", \"B\"), (\"B\", \"C\")]) skel.rename_nodes({\"A\": \"X\", \"B\": \"Y\", \"C\": \"Z\"}) skel.node_names [\"X\", \"Y\", \"Z\"] skel.rename_nodes([\"a\", \"b\", \"c\"]) skel.node_names [\"a\", \"b\", \"c\"]</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def rename_nodes(self, name_map: dict[NodeOrIndex, str] | list[str]):\n    \"\"\"Rename nodes in the skeleton.\n\n    Args:\n        name_map: A dictionary mapping old node names to new node names. Keys can be\n            specified as `Node` objects, integer indices, or string names. Values\n            must be specified as string names.\n\n            If a list of strings is provided of the same length as the current\n            nodes, the nodes will be renamed to the names in the list in order.\n\n    Raises:\n        ValueError: If the new node names exist in the skeleton or if the old node\n            names are not found in the skeleton.\n\n    Notes:\n        This method should always be used when renaming nodes in the skeleton as it\n        handles updating the lookup caches necessary for indexing nodes by name.\n\n        After renaming, instances using this skeleton **do NOT need to be updated**\n        as the nodes are stored by reference in the skeleton, so changes are\n        reflected automatically.\n\n    Example:\n        &gt;&gt;&gt; skel = Skeleton([\"A\", \"B\", \"C\"], edges=[(\"A\", \"B\"), (\"B\", \"C\")])\n        &gt;&gt;&gt; skel.rename_nodes({\"A\": \"X\", \"B\": \"Y\", \"C\": \"Z\"})\n        &gt;&gt;&gt; skel.node_names\n        [\"X\", \"Y\", \"Z\"]\n        &gt;&gt;&gt; skel.rename_nodes([\"a\", \"b\", \"c\"])\n        &gt;&gt;&gt; skel.node_names\n        [\"a\", \"b\", \"c\"]\n    \"\"\"\n    if type(name_map) is list:\n        if len(name_map) != len(self.nodes):\n            raise ValueError(\n                \"List of new node names must be the same length as the current \"\n                \"nodes.\"\n            )\n        name_map = {node: name for node, name in zip(self.nodes, name_map)}\n\n    for old_name, new_name in name_map.items():\n        if type(old_name) is Node:\n            old_name = old_name.name\n        if type(old_name) is int:\n            old_name = self.nodes[old_name].name\n\n        if old_name not in self._name_to_node_cache:\n            raise ValueError(f\"Node '{old_name}' not found in the skeleton.\")\n        if new_name in self._name_to_node_cache:\n            raise ValueError(f\"Node '{new_name}' already exists in the skeleton.\")\n\n        node = self._name_to_node_cache[old_name]\n        node.name = new_name\n        self._name_to_node_cache[new_name] = node\n        del self._name_to_node_cache[old_name]\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Skeleton.reorder_nodes","title":"<code>reorder_nodes(new_order)</code>","text":"<p>Reorder nodes in the skeleton.</p> <p>Parameters:</p> Name Type Description Default <code>new_order</code> <code>list[NodeOrIndex]</code> <p>A list of node names, indices, or <code>Node</code> objects specifying the new order of the nodes.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If the new order of nodes is not the same length as the current nodes.</p> Notes <p>This method handles updating the lookup caches necessary for indexing nodes by name.</p> Warning <p>After reordering, instances using this skeleton do not need to be updated as the nodes are stored by reference in the skeleton.</p> <p>However, the order that points are stored in the instances will not be updated to match the new order of the nodes in the skeleton. This should not matter unless the ordering of the keys in the <code>Instance.points</code> dictionary is used instead of relying on the skeleton node order.</p> <p>To make sure these are aligned, it is recommended to use the <code>Labels.reorder_nodes()</code> method which will update all contained instances to reflect the changes made to the skeleton.</p> <p>To manually update instances after this method is called, call <code>Instance.update_skeleton()</code> on each instance that uses this skeleton.</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def reorder_nodes(self, new_order: list[NodeOrIndex]):\n    \"\"\"Reorder nodes in the skeleton.\n\n    Args:\n        new_order: A list of node names, indices, or `Node` objects specifying the\n            new order of the nodes.\n\n    Raises:\n        ValueError: If the new order of nodes is not the same length as the current\n            nodes.\n\n    Notes:\n        This method handles updating the lookup caches necessary for indexing nodes\n        by name.\n\n    Warning:\n        After reordering, instances using this skeleton do not need to be updated as\n        the nodes are stored by reference in the skeleton.\n\n        However, the order that points are stored in the instances will not be\n        updated to match the new order of the nodes in the skeleton. This should not\n        matter unless the ordering of the keys in the `Instance.points` dictionary\n        is used instead of relying on the skeleton node order.\n\n        To make sure these are aligned, it is recommended to use the\n        `Labels.reorder_nodes()` method which will update all contained instances to\n        reflect the changes made to the skeleton.\n\n        To manually update instances after this method is called, call\n        `Instance.update_skeleton()` on each instance that uses this skeleton.\n    \"\"\"\n    if len(new_order) != len(self.nodes):\n        raise ValueError(\n            \"New order of nodes must be the same length as the current nodes.\"\n        )\n\n    new_nodes = [self.require_node(node, add_missing=False) for node in new_order]\n    self.nodes = new_nodes\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Skeleton.require_node","title":"<code>require_node(node, add_missing=True)</code>","text":"<p>Return a <code>Node</code> object, handling indexing and adding missing nodes.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>NodeOrIndex</code> <p>A <code>Node</code> object, name or index.</p> required <code>add_missing</code> <code>bool</code> <p>If <code>True</code>, missing nodes will be added to the skeleton. If <code>False</code>, an error will be raised if the node is not found. Default is <code>True</code>.</p> <code>True</code> <p>Returns:</p> Type Description <code>Node</code> <p>The <code>Node</code> object.</p> <p>Raises:</p> Type Description <code>IndexError</code> <p>If the node is not found in the skeleton and <code>add_missing</code> is <code>False</code>.</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def require_node(self, node: NodeOrIndex, add_missing: bool = True) -&gt; Node:\n    \"\"\"Return a `Node` object, handling indexing and adding missing nodes.\n\n    Args:\n        node: A `Node` object, name or index.\n        add_missing: If `True`, missing nodes will be added to the skeleton. If\n            `False`, an error will be raised if the node is not found. Default is\n            `True`.\n\n    Returns:\n        The `Node` object.\n\n    Raises:\n        IndexError: If the node is not found in the skeleton and `add_missing` is\n            `False`.\n    \"\"\"\n    if node not in self:\n        if add_missing:\n            self.add_node(node)\n        else:\n            raise IndexError(f\"Node '{node}' not found in the skeleton.\")\n\n    if type(node) is Node:\n        return node\n\n    return self[node]\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.SuggestionFrame","title":"<code>SuggestionFrame</code>","text":"<p>Data structure for a single frame of suggestions.</p> <p>Attributes:</p> Name Type Description <code>video</code> <code>Video</code> <p>The video associated with the frame.</p> <code>frame_idx</code> <code>int</code> <p>The index of the frame in the video.</p> Source code in <code>sleap_io/model/suggestions.py</code> <pre><code>@attrs.define(auto_attribs=True)\nclass SuggestionFrame:\n    \"\"\"Data structure for a single frame of suggestions.\n\n    Attributes:\n        video: The video associated with the frame.\n        frame_idx: The index of the frame in the video.\n    \"\"\"\n\n    video: Video\n    frame_idx: int\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Symmetry","title":"<code>Symmetry</code>","text":"<p>A relationship between a pair of nodes denoting their left/right pairing.</p> <p>Attributes:</p> Name Type Description <code>nodes</code> <code>set[Node]</code> <p>A set of two <code>Node</code>s.</p> <p>Methods:</p> Name Description <code>__getitem__</code> <p>Return the first node.</p> <code>__iter__</code> <p>Iterate over the symmetric nodes.</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>@define\nclass Symmetry:\n    \"\"\"A relationship between a pair of nodes denoting their left/right pairing.\n\n    Attributes:\n        nodes: A set of two `Node`s.\n    \"\"\"\n\n    nodes: set[Node] = field(converter=set, validator=lambda _, __, val: len(val) == 2)\n\n    def __iter__(self):\n        \"\"\"Iterate over the symmetric nodes.\"\"\"\n        return iter(self.nodes)\n\n    def __getitem__(self, idx) -&gt; Node:\n        \"\"\"Return the first node.\"\"\"\n        for i, node in enumerate(self.nodes):\n            if i == idx:\n                return node\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Symmetry.__getitem__","title":"<code>__getitem__(idx)</code>","text":"<p>Return the first node.</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def __getitem__(self, idx) -&gt; Node:\n    \"\"\"Return the first node.\"\"\"\n    for i, node in enumerate(self.nodes):\n        if i == idx:\n            return node\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Symmetry.__iter__","title":"<code>__iter__()</code>","text":"<p>Iterate over the symmetric nodes.</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def __iter__(self):\n    \"\"\"Iterate over the symmetric nodes.\"\"\"\n    return iter(self.nodes)\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Track","title":"<code>Track</code>","text":"<p>An object that represents the same animal/object across multiple detections.</p> <p>This allows tracking of unique entities in the video over time and space.</p> <p>A <code>Track</code> may also be used to refer to unique identity classes that span multiple videos, such as <code>\"female mouse\"</code>.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>A name given to this track for identification purposes.</p> Notes <p><code>Track</code>s are compared by identity. This means that unique track objects with the same name are considered to be different.</p> <p>Methods:</p> Name Description <code>matches</code> <p>Check if this track matches another track.</p> <code>similarity_to</code> <p>Calculate similarity metrics with another track.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>@attrs.define(eq=False)\nclass Track:\n    \"\"\"An object that represents the same animal/object across multiple detections.\n\n    This allows tracking of unique entities in the video over time and space.\n\n    A `Track` may also be used to refer to unique identity classes that span multiple\n    videos, such as `\"female mouse\"`.\n\n    Attributes:\n        name: A name given to this track for identification purposes.\n\n    Notes:\n        `Track`s are compared by identity. This means that unique track objects with the\n        same name are considered to be different.\n    \"\"\"\n\n    name: str = \"\"\n\n    def matches(self, other: \"Track\", method: str = \"name\") -&gt; bool:\n        \"\"\"Check if this track matches another track.\n\n        Args:\n            other: Another track to compare with.\n            method: Matching method - \"name\" (match by name) or \"identity\"\n                (match by object identity).\n\n        Returns:\n            True if the tracks match according to the specified method.\n        \"\"\"\n        if method == \"name\":\n            return self.name == other.name\n        elif method == \"identity\":\n            return self is other\n        else:\n            raise ValueError(f\"Unknown matching method: {method}\")\n\n    def similarity_to(self, other: \"Track\") -&gt; dict[str, any]:\n        \"\"\"Calculate similarity metrics with another track.\n\n        Args:\n            other: Another track to compare with.\n\n        Returns:\n            A dictionary with similarity metrics:\n            - 'same_name': Whether the tracks have the same name\n            - 'same_identity': Whether the tracks are the same object\n            - 'name_similarity': Simple string similarity score (0-1)\n        \"\"\"\n        # Calculate simple string similarity\n        if self.name and other.name:\n            # Simple character overlap similarity\n            common_chars = set(self.name.lower()) &amp; set(other.name.lower())\n            all_chars = set(self.name.lower()) | set(other.name.lower())\n            name_similarity = len(common_chars) / len(all_chars) if all_chars else 0\n        else:\n            name_similarity = 1.0 if self.name == other.name else 0.0\n\n        return {\n            \"same_name\": self.name == other.name,\n            \"same_identity\": self is other,\n            \"name_similarity\": name_similarity,\n        }\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Track.matches","title":"<code>matches(other, method='name')</code>","text":"<p>Check if this track matches another track.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>'Track'</code> <p>Another track to compare with.</p> required <code>method</code> <code>str</code> <p>Matching method - \"name\" (match by name) or \"identity\" (match by object identity).</p> <code>'name'</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if the tracks match according to the specified method.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>def matches(self, other: \"Track\", method: str = \"name\") -&gt; bool:\n    \"\"\"Check if this track matches another track.\n\n    Args:\n        other: Another track to compare with.\n        method: Matching method - \"name\" (match by name) or \"identity\"\n            (match by object identity).\n\n    Returns:\n        True if the tracks match according to the specified method.\n    \"\"\"\n    if method == \"name\":\n        return self.name == other.name\n    elif method == \"identity\":\n        return self is other\n    else:\n        raise ValueError(f\"Unknown matching method: {method}\")\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Track.similarity_to","title":"<code>similarity_to(other)</code>","text":"<p>Calculate similarity metrics with another track.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>'Track'</code> <p>Another track to compare with.</p> required <p>Returns:</p> Type Description <code>dict[str, any]</code> <p>A dictionary with similarity metrics: - 'same_name': Whether the tracks have the same name - 'same_identity': Whether the tracks are the same object - 'name_similarity': Simple string similarity score (0-1)</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>def similarity_to(self, other: \"Track\") -&gt; dict[str, any]:\n    \"\"\"Calculate similarity metrics with another track.\n\n    Args:\n        other: Another track to compare with.\n\n    Returns:\n        A dictionary with similarity metrics:\n        - 'same_name': Whether the tracks have the same name\n        - 'same_identity': Whether the tracks are the same object\n        - 'name_similarity': Simple string similarity score (0-1)\n    \"\"\"\n    # Calculate simple string similarity\n    if self.name and other.name:\n        # Simple character overlap similarity\n        common_chars = set(self.name.lower()) &amp; set(other.name.lower())\n        all_chars = set(self.name.lower()) | set(other.name.lower())\n        name_similarity = len(common_chars) / len(all_chars) if all_chars else 0\n    else:\n        name_similarity = 1.0 if self.name == other.name else 0.0\n\n    return {\n        \"same_name\": self.name == other.name,\n        \"same_identity\": self is other,\n        \"name_similarity\": name_similarity,\n    }\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Video","title":"<code>Video</code>","text":"<p><code>Video</code> class used by sleap to represent videos and data associated with them.</p> <p>This class is used to store information regarding a video and its components. It is used to store the video's <code>filename</code>, <code>shape</code>, and the video's <code>backend</code>.</p> <p>To create a <code>Video</code> object, use the <code>from_filename</code> method which will select the backend appropriately.</p> <p>Attributes:</p> Name Type Description <code>filename</code> <code>str | list[str]</code> <p>The filename(s) of the video. Supported extensions: \"mp4\", \"avi\", \"mov\", \"mj2\", \"mkv\", \"h5\", \"hdf5\", \"slp\", \"png\", \"jpg\", \"jpeg\", \"tif\", \"tiff\", \"bmp\". If the filename is a list, a list of image filenames are expected. If filename is a folder, it will be searched for images.</p> <code>backend</code> <code>Optional[VideoBackend]</code> <p>An object that implements the basic methods for reading and manipulating frames of a specific video type.</p> <code>backend_metadata</code> <code>dict[str, any]</code> <p>A dictionary of metadata specific to the backend. This is useful for storing metadata that requires an open backend (e.g., shape information) without having access to the video file itself.</p> <code>source_video</code> <code>Optional[Video]</code> <p>The source video object if this is a proxy video. This is present when the video contains an embedded subset of frames from another video.</p> <code>open_backend</code> <code>bool</code> <p>Whether to open the backend when the video is available. If <code>True</code> (the default), the backend will be automatically opened if the video exists. Set this to <code>False</code> when you want to manually open the backend, or when the you know the video file does not exist and you want to avoid trying to open the file.</p> Notes <p>Instances of this class are hashed by identity, not by value. This means that two <code>Video</code> instances with the same attributes will NOT be considered equal in a set or dict.</p> Media Video Plugin Support <p>For media files (mp4, avi, etc.), the following plugins are supported: - \"opencv\": Uses OpenCV (cv2) for video reading - \"FFMPEG\": Uses imageio-ffmpeg for video reading - \"pyav\": Uses PyAV for video reading</p> <p>Plugin aliases (case-insensitive): - opencv: \"opencv\", \"cv\", \"cv2\", \"ocv\" - FFMPEG: \"FFMPEG\", \"ffmpeg\", \"imageio-ffmpeg\", \"imageio_ffmpeg\" - pyav: \"pyav\", \"av\"</p> <p>Plugin selection priority: 1. Explicitly specified plugin parameter 2. Backend metadata plugin value 3. Global default (set via sio.set_default_video_plugin) 4. Auto-detection based on available packages</p> See Also <p>VideoBackend: The backend interface for reading video data. sleap_io.set_default_video_plugin: Set global default plugin. sleap_io.get_default_video_plugin: Get current default plugin.</p> <p>Methods:</p> Name Description <code>__attrs_post_init__</code> <p>Post init syntactic sugar.</p> <code>__deepcopy__</code> <p>Deep copy the video object.</p> <code>__getitem__</code> <p>Return the frames of the video at the given indices.</p> <code>__len__</code> <p>Return the length of the video as the number of frames.</p> <code>__repr__</code> <p>Informal string representation (for print or format).</p> <code>__str__</code> <p>Informal string representation (for print or format).</p> <code>close</code> <p>Close the video backend.</p> <code>deduplicate_with</code> <p>Create a new video with duplicate images removed.</p> <code>exists</code> <p>Check if the video file exists and is accessible.</p> <code>from_filename</code> <p>Create a Video from a filename.</p> <code>has_overlapping_images</code> <p>Check if this video has overlapping images with another video.</p> <code>matches_content</code> <p>Check if this video has the same content as another video.</p> <code>matches_path</code> <p>Check if this video has the same path as another video.</p> <code>matches_shape</code> <p>Check if this video has the same shape as another video.</p> <code>merge_with</code> <p>Merge another video's images into this one.</p> <code>open</code> <p>Open the video backend for reading.</p> <code>replace_filename</code> <p>Update the filename of the video, optionally opening the backend.</p> <code>save</code> <p>Save video frames to a new video file.</p> <code>set_video_plugin</code> <p>Set the video plugin and reopen the video.</p> Source code in <code>sleap_io/model/video.py</code> <pre><code>@attrs.define(eq=False)\nclass Video:\n    \"\"\"`Video` class used by sleap to represent videos and data associated with them.\n\n    This class is used to store information regarding a video and its components.\n    It is used to store the video's `filename`, `shape`, and the video's `backend`.\n\n    To create a `Video` object, use the `from_filename` method which will select the\n    backend appropriately.\n\n    Attributes:\n        filename: The filename(s) of the video. Supported extensions: \"mp4\", \"avi\",\n            \"mov\", \"mj2\", \"mkv\", \"h5\", \"hdf5\", \"slp\", \"png\", \"jpg\", \"jpeg\", \"tif\",\n            \"tiff\", \"bmp\". If the filename is a list, a list of image filenames are\n            expected. If filename is a folder, it will be searched for images.\n        backend: An object that implements the basic methods for reading and\n            manipulating frames of a specific video type.\n        backend_metadata: A dictionary of metadata specific to the backend. This is\n            useful for storing metadata that requires an open backend (e.g., shape\n            information) without having access to the video file itself.\n        source_video: The source video object if this is a proxy video. This is present\n            when the video contains an embedded subset of frames from another video.\n        open_backend: Whether to open the backend when the video is available. If `True`\n            (the default), the backend will be automatically opened if the video exists.\n            Set this to `False` when you want to manually open the backend, or when the\n            you know the video file does not exist and you want to avoid trying to open\n            the file.\n\n    Notes:\n        Instances of this class are hashed by identity, not by value. This means that\n        two `Video` instances with the same attributes will NOT be considered equal in a\n        set or dict.\n\n    Media Video Plugin Support:\n        For media files (mp4, avi, etc.), the following plugins are supported:\n        - \"opencv\": Uses OpenCV (cv2) for video reading\n        - \"FFMPEG\": Uses imageio-ffmpeg for video reading\n        - \"pyav\": Uses PyAV for video reading\n\n        Plugin aliases (case-insensitive):\n        - opencv: \"opencv\", \"cv\", \"cv2\", \"ocv\"\n        - FFMPEG: \"FFMPEG\", \"ffmpeg\", \"imageio-ffmpeg\", \"imageio_ffmpeg\"\n        - pyav: \"pyav\", \"av\"\n\n        Plugin selection priority:\n        1. Explicitly specified plugin parameter\n        2. Backend metadata plugin value\n        3. Global default (set via sio.set_default_video_plugin)\n        4. Auto-detection based on available packages\n\n    See Also:\n        VideoBackend: The backend interface for reading video data.\n        sleap_io.set_default_video_plugin: Set global default plugin.\n        sleap_io.get_default_video_plugin: Get current default plugin.\n    \"\"\"\n\n    filename: str | list[str]\n    backend: Optional[VideoBackend] = None\n    backend_metadata: dict[str, any] = attrs.field(factory=dict)\n    source_video: Optional[Video] = None\n    original_video: Optional[Video] = None\n    open_backend: bool = True\n\n    EXTS = MediaVideo.EXTS + HDF5Video.EXTS + ImageVideo.EXTS\n\n    def __attrs_post_init__(self):\n        \"\"\"Post init syntactic sugar.\"\"\"\n        if self.open_backend and self.backend is None and self.exists():\n            try:\n                self.open()\n            except Exception:\n                # If we can't open the backend, just ignore it for now so we don't\n                # prevent the user from building the Video object entirely.\n                pass\n\n    def __deepcopy__(self, memo):\n        \"\"\"Deep copy the video object.\"\"\"\n        if id(self) in memo:\n            return memo[id(self)]\n\n        reopen = False\n        if self.is_open:\n            reopen = True\n            self.close()\n\n        new_video = Video(\n            filename=self.filename,\n            backend=None,\n            backend_metadata=self.backend_metadata,\n            source_video=self.source_video,\n            open_backend=self.open_backend,\n        )\n\n        memo[id(self)] = new_video\n\n        if reopen:\n            self.open()\n\n        return new_video\n\n    @classmethod\n    def from_filename(\n        cls,\n        filename: str | list[str],\n        dataset: Optional[str] = None,\n        grayscale: Optional[bool] = None,\n        keep_open: bool = True,\n        source_video: Optional[Video] = None,\n        **kwargs,\n    ) -&gt; VideoBackend:\n        \"\"\"Create a Video from a filename.\n\n        Args:\n            filename: The filename(s) of the video. Supported extensions: \"mp4\", \"avi\",\n                \"mov\", \"mj2\", \"mkv\", \"h5\", \"hdf5\", \"slp\", \"png\", \"jpg\", \"jpeg\", \"tif\",\n                \"tiff\", \"bmp\". If the filename is a list, a list of image filenames are\n                expected. If filename is a folder, it will be searched for images.\n            dataset: Name of dataset in HDF5 file.\n            grayscale: Whether to force grayscale. If None, autodetect on first frame\n                load.\n            keep_open: Whether to keep the video reader open between calls to read\n                frames. If False, will close the reader after each call. If True (the\n                default), it will keep the reader open and cache it for subsequent calls\n                which may enhance the performance of reading multiple frames.\n            source_video: The source video object if this is a proxy video. This is\n                present when the video contains an embedded subset of frames from\n                another video.\n            **kwargs: Additional backend-specific arguments passed to\n                VideoBackend.from_filename. See VideoBackend.from_filename for supported\n                arguments.\n\n        Returns:\n            Video instance with the appropriate backend instantiated.\n        \"\"\"\n        return cls(\n            filename=filename,\n            backend=VideoBackend.from_filename(\n                filename,\n                dataset=dataset,\n                grayscale=grayscale,\n                keep_open=keep_open,\n                **kwargs,\n            ),\n            source_video=source_video,\n        )\n\n    @property\n    def shape(self) -&gt; Tuple[int, int, int, int] | None:\n        \"\"\"Return the shape of the video as (num_frames, height, width, channels).\n\n        If the video backend is not set or it cannot determine the shape of the video,\n        this will return None.\n        \"\"\"\n        return self._get_shape()\n\n    def _get_shape(self) -&gt; Tuple[int, int, int, int] | None:\n        \"\"\"Return the shape of the video as (num_frames, height, width, channels).\n\n        This suppresses errors related to querying the backend for the video shape, such\n        as when it has not been set or when the video file is not found.\n        \"\"\"\n        try:\n            return self.backend.shape\n        except Exception:\n            if \"shape\" in self.backend_metadata:\n                return self.backend_metadata[\"shape\"]\n            return None\n\n    @property\n    def grayscale(self) -&gt; bool | None:\n        \"\"\"Return whether the video is grayscale.\n\n        If the video backend is not set or it cannot determine whether the video is\n        grayscale, this will return None.\n        \"\"\"\n        shape = self.shape\n        if shape is not None:\n            return shape[-1] == 1\n        else:\n            grayscale = None\n            if \"grayscale\" in self.backend_metadata:\n                grayscale = self.backend_metadata[\"grayscale\"]\n            return grayscale\n\n    @grayscale.setter\n    def grayscale(self, value: bool):\n        \"\"\"Set the grayscale value and adjust the backend.\"\"\"\n        if self.backend is not None:\n            self.backend.grayscale = value\n            self.backend._cached_shape = None\n\n        self.backend_metadata[\"grayscale\"] = value\n\n    def __len__(self) -&gt; int:\n        \"\"\"Return the length of the video as the number of frames.\"\"\"\n        shape = self.shape\n        return 0 if shape is None else shape[0]\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Informal string representation (for print or format).\"\"\"\n        dataset = (\n            f\"dataset={self.backend.dataset}, \"\n            if getattr(self.backend, \"dataset\", \"\")\n            else \"\"\n        )\n        return (\n            \"Video(\"\n            f'filename=\"{self.filename}\", '\n            f\"shape={self.shape}, \"\n            f\"{dataset}\"\n            f\"backend={type(self.backend).__name__}\"\n            \")\"\n        )\n\n    def __str__(self) -&gt; str:\n        \"\"\"Informal string representation (for print or format).\"\"\"\n        return self.__repr__()\n\n    def __getitem__(self, inds: int | list[int] | slice) -&gt; np.ndarray:\n        \"\"\"Return the frames of the video at the given indices.\n\n        Args:\n            inds: Index or list of indices of frames to read.\n\n        Returns:\n            Frame or frames as a numpy array of shape `(height, width, channels)` if a\n            scalar index is provided, or `(frames, height, width, channels)` if a list\n            of indices is provided.\n\n        See also: VideoBackend.get_frame, VideoBackend.get_frames\n        \"\"\"\n        if not self.is_open:\n            if self.open_backend:\n                self.open()\n            else:\n                raise ValueError(\n                    \"Video backend is not open. Call video.open() or set \"\n                    \"video.open_backend to True to do automatically on frame read.\"\n                )\n        return self.backend[inds]\n\n    def exists(self, check_all: bool = False, dataset: str | None = None) -&gt; bool:\n        \"\"\"Check if the video file exists and is accessible.\n\n        Args:\n            check_all: If `True`, check that all filenames in a list exist. If `False`\n                (the default), check that the first filename exists.\n            dataset: Name of dataset in HDF5 file. If specified, this will function will\n                return `False` if the dataset does not exist.\n\n        Returns:\n            `True` if the file exists and is accessible, `False` otherwise.\n        \"\"\"\n        if isinstance(self.filename, list):\n            if check_all:\n                for f in self.filename:\n                    if not is_file_accessible(f):\n                        return False\n                return True\n            else:\n                return is_file_accessible(self.filename[0])\n\n        file_is_accessible = is_file_accessible(self.filename)\n        if not file_is_accessible:\n            return False\n\n        if dataset is None or dataset == \"\":\n            dataset = self.backend_metadata.get(\"dataset\", None)\n\n        if dataset is not None and dataset != \"\":\n            has_dataset = False\n            if (\n                self.backend is not None\n                and type(self.backend) is HDF5Video\n                and self.backend._open_reader is not None\n            ):\n                has_dataset = dataset in self.backend._open_reader\n            else:\n                with h5py.File(self.filename, \"r\") as f:\n                    has_dataset = dataset in f\n            return has_dataset\n\n        return True\n\n    @property\n    def is_open(self) -&gt; bool:\n        \"\"\"Check if the video backend is open.\"\"\"\n        return self.exists() and self.backend is not None\n\n    def open(\n        self,\n        filename: Optional[str] = None,\n        dataset: Optional[str] = None,\n        grayscale: Optional[str] = None,\n        keep_open: bool = True,\n        plugin: Optional[str] = None,\n    ):\n        \"\"\"Open the video backend for reading.\n\n        Args:\n            filename: Filename to open. If not specified, will use the filename set on\n                the video object.\n            dataset: Name of dataset in HDF5 file.\n            grayscale: Whether to force grayscale. If None, autodetect on first frame\n                load.\n            keep_open: Whether to keep the video reader open between calls to read\n                frames. If False, will close the reader after each call. If True (the\n                default), it will keep the reader open and cache it for subsequent calls\n                which may enhance the performance of reading multiple frames.\n            plugin: Video plugin to use for MediaVideo files. One of \"opencv\",\n                \"FFMPEG\", or \"pyav\". Also accepts aliases (case-insensitive).\n                If not specified, uses the backend metadata, global default,\n                or auto-detection in that order.\n\n        Notes:\n            This is useful for opening the video backend to read frames and then closing\n            it after reading all the necessary frames.\n\n            If the backend was already open, it will be closed before opening a new one.\n            Values for the HDF5 dataset and grayscale will be remembered if not\n            specified.\n        \"\"\"\n        if filename is not None:\n            self.replace_filename(filename, open=False)\n\n        # Try to remember values from previous backend if available and not specified.\n        if self.backend is not None:\n            if dataset is None:\n                dataset = getattr(self.backend, \"dataset\", None)\n            if grayscale is None:\n                grayscale = getattr(self.backend, \"grayscale\", None)\n\n        else:\n            if dataset is None and \"dataset\" in self.backend_metadata:\n                dataset = self.backend_metadata[\"dataset\"]\n            if grayscale is None:\n                if \"grayscale\" in self.backend_metadata:\n                    grayscale = self.backend_metadata[\"grayscale\"]\n                elif \"shape\" in self.backend_metadata:\n                    grayscale = self.backend_metadata[\"shape\"][-1] == 1\n\n        if not self.exists(dataset=dataset):\n            msg = (\n                f\"Video does not exist or cannot be opened for reading: {self.filename}\"\n            )\n            if dataset is not None:\n                msg += f\" (dataset: {dataset})\"\n            raise FileNotFoundError(msg)\n\n        # Close previous backend if open.\n        self.close()\n\n        # Handle plugin parameter\n        backend_kwargs = {}\n        if plugin is not None:\n            from sleap_io.io.video_reading import normalize_plugin_name\n\n            plugin = normalize_plugin_name(plugin)\n            self.backend_metadata[\"plugin\"] = plugin\n\n        if \"plugin\" in self.backend_metadata:\n            backend_kwargs[\"plugin\"] = self.backend_metadata[\"plugin\"]\n\n        # Create new backend.\n        self.backend = VideoBackend.from_filename(\n            self.filename,\n            dataset=dataset,\n            grayscale=grayscale,\n            keep_open=keep_open,\n            **backend_kwargs,\n        )\n\n    def close(self):\n        \"\"\"Close the video backend.\"\"\"\n        if self.backend is not None:\n            # Try to remember values from previous backend if available and not\n            # specified.\n            try:\n                self.backend_metadata[\"dataset\"] = getattr(\n                    self.backend, \"dataset\", None\n                )\n                self.backend_metadata[\"grayscale\"] = getattr(\n                    self.backend, \"grayscale\", None\n                )\n                self.backend_metadata[\"shape\"] = getattr(self.backend, \"shape\", None)\n            except Exception:\n                pass\n\n            del self.backend\n            self.backend = None\n\n    def replace_filename(\n        self, new_filename: str | Path | list[str] | list[Path], open: bool = True\n    ):\n        \"\"\"Update the filename of the video, optionally opening the backend.\n\n        Args:\n            new_filename: New filename to set for the video.\n            open: If `True` (the default), open the backend with the new filename. If\n                the new filename does not exist, no error is raised.\n        \"\"\"\n        if isinstance(new_filename, Path):\n            new_filename = new_filename.as_posix()\n\n        if isinstance(new_filename, list):\n            new_filename = [\n                p.as_posix() if isinstance(p, Path) else p for p in new_filename\n            ]\n\n        self.filename = new_filename\n        self.backend_metadata[\"filename\"] = new_filename\n\n        if open:\n            if self.exists():\n                self.open()\n            else:\n                self.close()\n\n    def matches_path(self, other: \"Video\", strict: bool = False) -&gt; bool:\n        \"\"\"Check if this video has the same path as another video.\n\n        Args:\n            other: Another video to compare with.\n            strict: If True, require exact path match. If False, consider videos\n                with the same filename (basename) as matching.\n\n        Returns:\n            True if the videos have matching paths, False otherwise.\n        \"\"\"\n        if isinstance(self.filename, list) and isinstance(other.filename, list):\n            # Both are image sequences\n            if strict:\n                return self.filename == other.filename\n            else:\n                # Compare basenames\n                self_basenames = [Path(f).name for f in self.filename]\n                other_basenames = [Path(f).name for f in other.filename]\n                return self_basenames == other_basenames\n        elif isinstance(self.filename, list) or isinstance(other.filename, list):\n            # One is image sequence, other is single file\n            return False\n        else:\n            # Both are single files\n            if strict:\n                return Path(self.filename).resolve() == Path(other.filename).resolve()\n            else:\n                return Path(self.filename).name == Path(other.filename).name\n\n    def matches_content(self, other: \"Video\") -&gt; bool:\n        \"\"\"Check if this video has the same content as another video.\n\n        Args:\n            other: Another video to compare with.\n\n        Returns:\n            True if the videos have the same shape and backend type.\n\n        Notes:\n            This compares metadata like shape and backend type, not actual frame data.\n        \"\"\"\n        # Compare shapes\n        self_shape = self.shape\n        other_shape = other.shape\n\n        if self_shape != other_shape:\n            return False\n\n        # Compare backend types\n        if self.backend is None and other.backend is None:\n            return True\n        elif self.backend is None or other.backend is None:\n            return False\n\n        return type(self.backend).__name__ == type(other.backend).__name__\n\n    def matches_shape(self, other: \"Video\") -&gt; bool:\n        \"\"\"Check if this video has the same shape as another video.\n\n        Args:\n            other: Another video to compare with.\n\n        Returns:\n            True if the videos have the same height, width, and channels.\n\n        Notes:\n            This only compares spatial dimensions, not the number of frames.\n        \"\"\"\n        # Try to get shape from backend metadata first if shape is not available\n        if self.backend is None and \"shape\" in self.backend_metadata:\n            self_shape = self.backend_metadata[\"shape\"]\n        else:\n            self_shape = self.shape\n\n        if other.backend is None and \"shape\" in other.backend_metadata:\n            other_shape = other.backend_metadata[\"shape\"]\n        else:\n            other_shape = other.shape\n\n        # Handle None shapes\n        if self_shape is None or other_shape is None:\n            return False\n\n        # Compare only height, width, channels (not frames)\n        return self_shape[1:] == other_shape[1:]\n\n    def has_overlapping_images(self, other: \"Video\") -&gt; bool:\n        \"\"\"Check if this video has overlapping images with another video.\n\n        This method is specifically for ImageVideo backends (image sequences).\n\n        Args:\n            other: Another video to compare with.\n\n        Returns:\n            True if both are ImageVideo instances with overlapping image files.\n            False if either video is not an ImageVideo or no overlap exists.\n\n        Notes:\n            Only works with ImageVideo backends where filename is a list.\n            Compares individual image filenames (basenames only).\n        \"\"\"\n        # Both must be image sequences\n        if not (isinstance(self.filename, list) and isinstance(other.filename, list)):\n            return False\n\n        # Get basenames for comparison\n        self_basenames = set(Path(f).name for f in self.filename)\n        other_basenames = set(Path(f).name for f in other.filename)\n\n        # Check if there's any overlap\n        return len(self_basenames &amp; other_basenames) &gt; 0\n\n    def deduplicate_with(self, other: \"Video\") -&gt; \"Video\":\n        \"\"\"Create a new video with duplicate images removed.\n\n        This method is specifically for ImageVideo backends (image sequences).\n\n        Args:\n            other: Another video to deduplicate against. Must also be ImageVideo.\n\n        Returns:\n            A new Video object with duplicate images removed from this video,\n            or None if all images were duplicates.\n\n        Raises:\n            ValueError: If either video is not an ImageVideo backend.\n\n        Notes:\n            Only works with ImageVideo backends where filename is a list.\n            Images are considered duplicates if they have the same basename.\n            The returned video contains only images from this video that are\n            not present in the other video.\n        \"\"\"\n        if not isinstance(self.filename, list):\n            raise ValueError(\"deduplicate_with only works with ImageVideo backends\")\n        if not isinstance(other.filename, list):\n            raise ValueError(\"Other video must also be ImageVideo backend\")\n\n        # Get basenames from other video\n        other_basenames = set(Path(f).name for f in other.filename)\n\n        # Keep only non-duplicate images\n        deduplicated_paths = [\n            f for f in self.filename if Path(f).name not in other_basenames\n        ]\n\n        if not deduplicated_paths:\n            # All images were duplicates\n            return None\n\n        # Create new video with deduplicated images\n        return Video.from_filename(deduplicated_paths, grayscale=self.grayscale)\n\n    def merge_with(self, other: \"Video\") -&gt; \"Video\":\n        \"\"\"Merge another video's images into this one.\n\n        This method is specifically for ImageVideo backends (image sequences).\n\n        Args:\n            other: Another video to merge with. Must also be ImageVideo.\n\n        Returns:\n            A new Video object with unique images from both videos.\n\n        Raises:\n            ValueError: If either video is not an ImageVideo backend.\n\n        Notes:\n            Only works with ImageVideo backends where filename is a list.\n            The merged video contains all unique images from both videos,\n            with automatic deduplication based on image basename.\n        \"\"\"\n        if not isinstance(self.filename, list):\n            raise ValueError(\"merge_with only works with ImageVideo backends\")\n        if not isinstance(other.filename, list):\n            raise ValueError(\"Other video must also be ImageVideo backend\")\n\n        # Get all unique images (by basename) preserving order\n        seen_basenames = set()\n        merged_paths = []\n\n        for path in self.filename:\n            basename = Path(path).name\n            if basename not in seen_basenames:\n                merged_paths.append(path)\n                seen_basenames.add(basename)\n\n        for path in other.filename:\n            basename = Path(path).name\n            if basename not in seen_basenames:\n                merged_paths.append(path)\n                seen_basenames.add(basename)\n\n        # Create new video with merged images\n        return Video.from_filename(merged_paths, grayscale=self.grayscale)\n\n    def save(\n        self,\n        save_path: str | Path,\n        frame_inds: list[int] | np.ndarray | None = None,\n        video_kwargs: dict[str, Any] | None = None,\n    ) -&gt; Video:\n        \"\"\"Save video frames to a new video file.\n\n        Args:\n            save_path: Path to the new video file. Should end in MP4.\n            frame_inds: Frame indices to save. Can be specified as a list or array of\n                frame integers. If not specified, saves all video frames.\n            video_kwargs: A dictionary of keyword arguments to provide to\n                `sio.save_video` for video compression.\n\n        Returns:\n            A new `Video` object pointing to the new video file.\n        \"\"\"\n        video_kwargs = {} if video_kwargs is None else video_kwargs\n        frame_inds = np.arange(len(self)) if frame_inds is None else frame_inds\n\n        with VideoWriter(save_path, **video_kwargs) as vw:\n            for frame_ind in frame_inds:\n                vw(self[frame_ind])\n\n        new_video = Video.from_filename(save_path, grayscale=self.grayscale)\n        return new_video\n\n    def set_video_plugin(self, plugin: str) -&gt; None:\n        \"\"\"Set the video plugin and reopen the video.\n\n        Args:\n            plugin: Video plugin to use. One of \"opencv\", \"FFMPEG\", or \"pyav\".\n                Also accepts aliases (case-insensitive).\n\n        Raises:\n            ValueError: If the video is not a MediaVideo type.\n\n        Examples:\n            &gt;&gt;&gt; video.set_video_plugin(\"opencv\")\n            &gt;&gt;&gt; video.set_video_plugin(\"CV2\")  # Same as \"opencv\"\n        \"\"\"\n        from sleap_io.io.video_reading import MediaVideo, normalize_plugin_name\n\n        if not self.filename.endswith(MediaVideo.EXTS):\n            raise ValueError(f\"Cannot set plugin for non-media video: {self.filename}\")\n\n        plugin = normalize_plugin_name(plugin)\n\n        # Close current backend if open\n        was_open = self.is_open\n        if was_open:\n            self.close()\n\n        # Update backend metadata\n        self.backend_metadata[\"plugin\"] = plugin\n\n        # Reopen with new plugin if it was open\n        if was_open:\n            self.open()\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Video.grayscale","title":"<code>grayscale</code>  <code>property</code> <code>writable</code>","text":"<p>Return whether the video is grayscale.</p> <p>If the video backend is not set or it cannot determine whether the video is grayscale, this will return None.</p>"},{"location":"reference/sleap_io/#sleap_io.Video.is_open","title":"<code>is_open</code>  <code>property</code>","text":"<p>Check if the video backend is open.</p>"},{"location":"reference/sleap_io/#sleap_io.Video.shape","title":"<code>shape</code>  <code>property</code>","text":"<p>Return the shape of the video as (num_frames, height, width, channels).</p> <p>If the video backend is not set or it cannot determine the shape of the video, this will return None.</p>"},{"location":"reference/sleap_io/#sleap_io.Video.__attrs_post_init__","title":"<code>__attrs_post_init__()</code>","text":"<p>Post init syntactic sugar.</p> Source code in <code>sleap_io/model/video.py</code> <pre><code>def __attrs_post_init__(self):\n    \"\"\"Post init syntactic sugar.\"\"\"\n    if self.open_backend and self.backend is None and self.exists():\n        try:\n            self.open()\n        except Exception:\n            # If we can't open the backend, just ignore it for now so we don't\n            # prevent the user from building the Video object entirely.\n            pass\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Video.__deepcopy__","title":"<code>__deepcopy__(memo)</code>","text":"<p>Deep copy the video object.</p> Source code in <code>sleap_io/model/video.py</code> <pre><code>def __deepcopy__(self, memo):\n    \"\"\"Deep copy the video object.\"\"\"\n    if id(self) in memo:\n        return memo[id(self)]\n\n    reopen = False\n    if self.is_open:\n        reopen = True\n        self.close()\n\n    new_video = Video(\n        filename=self.filename,\n        backend=None,\n        backend_metadata=self.backend_metadata,\n        source_video=self.source_video,\n        open_backend=self.open_backend,\n    )\n\n    memo[id(self)] = new_video\n\n    if reopen:\n        self.open()\n\n    return new_video\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Video.__getitem__","title":"<code>__getitem__(inds)</code>","text":"<p>Return the frames of the video at the given indices.</p> <p>Parameters:</p> Name Type Description Default <code>inds</code> <code>int | list[int] | slice</code> <p>Index or list of indices of frames to read.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Frame or frames as a numpy array of shape <code>(height, width, channels)</code> if a scalar index is provided, or <code>(frames, height, width, channels)</code> if a list of indices is provided.</p> <p>See also: VideoBackend.get_frame, VideoBackend.get_frames</p> Source code in <code>sleap_io/model/video.py</code> <pre><code>def __getitem__(self, inds: int | list[int] | slice) -&gt; np.ndarray:\n    \"\"\"Return the frames of the video at the given indices.\n\n    Args:\n        inds: Index or list of indices of frames to read.\n\n    Returns:\n        Frame or frames as a numpy array of shape `(height, width, channels)` if a\n        scalar index is provided, or `(frames, height, width, channels)` if a list\n        of indices is provided.\n\n    See also: VideoBackend.get_frame, VideoBackend.get_frames\n    \"\"\"\n    if not self.is_open:\n        if self.open_backend:\n            self.open()\n        else:\n            raise ValueError(\n                \"Video backend is not open. Call video.open() or set \"\n                \"video.open_backend to True to do automatically on frame read.\"\n            )\n    return self.backend[inds]\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Video.__len__","title":"<code>__len__()</code>","text":"<p>Return the length of the video as the number of frames.</p> Source code in <code>sleap_io/model/video.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"Return the length of the video as the number of frames.\"\"\"\n    shape = self.shape\n    return 0 if shape is None else shape[0]\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Video.__repr__","title":"<code>__repr__()</code>","text":"<p>Informal string representation (for print or format).</p> Source code in <code>sleap_io/model/video.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Informal string representation (for print or format).\"\"\"\n    dataset = (\n        f\"dataset={self.backend.dataset}, \"\n        if getattr(self.backend, \"dataset\", \"\")\n        else \"\"\n    )\n    return (\n        \"Video(\"\n        f'filename=\"{self.filename}\", '\n        f\"shape={self.shape}, \"\n        f\"{dataset}\"\n        f\"backend={type(self.backend).__name__}\"\n        \")\"\n    )\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Video.__str__","title":"<code>__str__()</code>","text":"<p>Informal string representation (for print or format).</p> Source code in <code>sleap_io/model/video.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Informal string representation (for print or format).\"\"\"\n    return self.__repr__()\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Video.close","title":"<code>close()</code>","text":"<p>Close the video backend.</p> Source code in <code>sleap_io/model/video.py</code> <pre><code>def close(self):\n    \"\"\"Close the video backend.\"\"\"\n    if self.backend is not None:\n        # Try to remember values from previous backend if available and not\n        # specified.\n        try:\n            self.backend_metadata[\"dataset\"] = getattr(\n                self.backend, \"dataset\", None\n            )\n            self.backend_metadata[\"grayscale\"] = getattr(\n                self.backend, \"grayscale\", None\n            )\n            self.backend_metadata[\"shape\"] = getattr(self.backend, \"shape\", None)\n        except Exception:\n            pass\n\n        del self.backend\n        self.backend = None\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Video.deduplicate_with","title":"<code>deduplicate_with(other)</code>","text":"<p>Create a new video with duplicate images removed.</p> <p>This method is specifically for ImageVideo backends (image sequences).</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>'Video'</code> <p>Another video to deduplicate against. Must also be ImageVideo.</p> required <p>Returns:</p> Type Description <code>'Video'</code> <p>A new Video object with duplicate images removed from this video, or None if all images were duplicates.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If either video is not an ImageVideo backend.</p> Notes <p>Only works with ImageVideo backends where filename is a list. Images are considered duplicates if they have the same basename. The returned video contains only images from this video that are not present in the other video.</p> Source code in <code>sleap_io/model/video.py</code> <pre><code>def deduplicate_with(self, other: \"Video\") -&gt; \"Video\":\n    \"\"\"Create a new video with duplicate images removed.\n\n    This method is specifically for ImageVideo backends (image sequences).\n\n    Args:\n        other: Another video to deduplicate against. Must also be ImageVideo.\n\n    Returns:\n        A new Video object with duplicate images removed from this video,\n        or None if all images were duplicates.\n\n    Raises:\n        ValueError: If either video is not an ImageVideo backend.\n\n    Notes:\n        Only works with ImageVideo backends where filename is a list.\n        Images are considered duplicates if they have the same basename.\n        The returned video contains only images from this video that are\n        not present in the other video.\n    \"\"\"\n    if not isinstance(self.filename, list):\n        raise ValueError(\"deduplicate_with only works with ImageVideo backends\")\n    if not isinstance(other.filename, list):\n        raise ValueError(\"Other video must also be ImageVideo backend\")\n\n    # Get basenames from other video\n    other_basenames = set(Path(f).name for f in other.filename)\n\n    # Keep only non-duplicate images\n    deduplicated_paths = [\n        f for f in self.filename if Path(f).name not in other_basenames\n    ]\n\n    if not deduplicated_paths:\n        # All images were duplicates\n        return None\n\n    # Create new video with deduplicated images\n    return Video.from_filename(deduplicated_paths, grayscale=self.grayscale)\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Video.exists","title":"<code>exists(check_all=False, dataset=None)</code>","text":"<p>Check if the video file exists and is accessible.</p> <p>Parameters:</p> Name Type Description Default <code>check_all</code> <code>bool</code> <p>If <code>True</code>, check that all filenames in a list exist. If <code>False</code> (the default), check that the first filename exists.</p> <code>False</code> <code>dataset</code> <code>str | None</code> <p>Name of dataset in HDF5 file. If specified, this will function will return <code>False</code> if the dataset does not exist.</p> <code>None</code> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if the file exists and is accessible, <code>False</code> otherwise.</p> Source code in <code>sleap_io/model/video.py</code> <pre><code>def exists(self, check_all: bool = False, dataset: str | None = None) -&gt; bool:\n    \"\"\"Check if the video file exists and is accessible.\n\n    Args:\n        check_all: If `True`, check that all filenames in a list exist. If `False`\n            (the default), check that the first filename exists.\n        dataset: Name of dataset in HDF5 file. If specified, this will function will\n            return `False` if the dataset does not exist.\n\n    Returns:\n        `True` if the file exists and is accessible, `False` otherwise.\n    \"\"\"\n    if isinstance(self.filename, list):\n        if check_all:\n            for f in self.filename:\n                if not is_file_accessible(f):\n                    return False\n            return True\n        else:\n            return is_file_accessible(self.filename[0])\n\n    file_is_accessible = is_file_accessible(self.filename)\n    if not file_is_accessible:\n        return False\n\n    if dataset is None or dataset == \"\":\n        dataset = self.backend_metadata.get(\"dataset\", None)\n\n    if dataset is not None and dataset != \"\":\n        has_dataset = False\n        if (\n            self.backend is not None\n            and type(self.backend) is HDF5Video\n            and self.backend._open_reader is not None\n        ):\n            has_dataset = dataset in self.backend._open_reader\n        else:\n            with h5py.File(self.filename, \"r\") as f:\n                has_dataset = dataset in f\n        return has_dataset\n\n    return True\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Video.from_filename","title":"<code>from_filename(filename, dataset=None, grayscale=None, keep_open=True, source_video=None, **kwargs)</code>  <code>classmethod</code>","text":"<p>Create a Video from a filename.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str | list[str]</code> <p>The filename(s) of the video. Supported extensions: \"mp4\", \"avi\", \"mov\", \"mj2\", \"mkv\", \"h5\", \"hdf5\", \"slp\", \"png\", \"jpg\", \"jpeg\", \"tif\", \"tiff\", \"bmp\". If the filename is a list, a list of image filenames are expected. If filename is a folder, it will be searched for images.</p> required <code>dataset</code> <code>Optional[str]</code> <p>Name of dataset in HDF5 file.</p> <code>None</code> <code>grayscale</code> <code>Optional[bool]</code> <p>Whether to force grayscale. If None, autodetect on first frame load.</p> <code>None</code> <code>keep_open</code> <code>bool</code> <p>Whether to keep the video reader open between calls to read frames. If False, will close the reader after each call. If True (the default), it will keep the reader open and cache it for subsequent calls which may enhance the performance of reading multiple frames.</p> <code>True</code> <code>source_video</code> <code>Optional[Video]</code> <p>The source video object if this is a proxy video. This is present when the video contains an embedded subset of frames from another video.</p> <code>None</code> <code>**kwargs</code> <p>Additional backend-specific arguments passed to VideoBackend.from_filename. See VideoBackend.from_filename for supported arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>VideoBackend</code> <p>Video instance with the appropriate backend instantiated.</p> Source code in <code>sleap_io/model/video.py</code> <pre><code>@classmethod\ndef from_filename(\n    cls,\n    filename: str | list[str],\n    dataset: Optional[str] = None,\n    grayscale: Optional[bool] = None,\n    keep_open: bool = True,\n    source_video: Optional[Video] = None,\n    **kwargs,\n) -&gt; VideoBackend:\n    \"\"\"Create a Video from a filename.\n\n    Args:\n        filename: The filename(s) of the video. Supported extensions: \"mp4\", \"avi\",\n            \"mov\", \"mj2\", \"mkv\", \"h5\", \"hdf5\", \"slp\", \"png\", \"jpg\", \"jpeg\", \"tif\",\n            \"tiff\", \"bmp\". If the filename is a list, a list of image filenames are\n            expected. If filename is a folder, it will be searched for images.\n        dataset: Name of dataset in HDF5 file.\n        grayscale: Whether to force grayscale. If None, autodetect on first frame\n            load.\n        keep_open: Whether to keep the video reader open between calls to read\n            frames. If False, will close the reader after each call. If True (the\n            default), it will keep the reader open and cache it for subsequent calls\n            which may enhance the performance of reading multiple frames.\n        source_video: The source video object if this is a proxy video. This is\n            present when the video contains an embedded subset of frames from\n            another video.\n        **kwargs: Additional backend-specific arguments passed to\n            VideoBackend.from_filename. See VideoBackend.from_filename for supported\n            arguments.\n\n    Returns:\n        Video instance with the appropriate backend instantiated.\n    \"\"\"\n    return cls(\n        filename=filename,\n        backend=VideoBackend.from_filename(\n            filename,\n            dataset=dataset,\n            grayscale=grayscale,\n            keep_open=keep_open,\n            **kwargs,\n        ),\n        source_video=source_video,\n    )\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Video.has_overlapping_images","title":"<code>has_overlapping_images(other)</code>","text":"<p>Check if this video has overlapping images with another video.</p> <p>This method is specifically for ImageVideo backends (image sequences).</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>'Video'</code> <p>Another video to compare with.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if both are ImageVideo instances with overlapping image files. False if either video is not an ImageVideo or no overlap exists.</p> Notes <p>Only works with ImageVideo backends where filename is a list. Compares individual image filenames (basenames only).</p> Source code in <code>sleap_io/model/video.py</code> <pre><code>def has_overlapping_images(self, other: \"Video\") -&gt; bool:\n    \"\"\"Check if this video has overlapping images with another video.\n\n    This method is specifically for ImageVideo backends (image sequences).\n\n    Args:\n        other: Another video to compare with.\n\n    Returns:\n        True if both are ImageVideo instances with overlapping image files.\n        False if either video is not an ImageVideo or no overlap exists.\n\n    Notes:\n        Only works with ImageVideo backends where filename is a list.\n        Compares individual image filenames (basenames only).\n    \"\"\"\n    # Both must be image sequences\n    if not (isinstance(self.filename, list) and isinstance(other.filename, list)):\n        return False\n\n    # Get basenames for comparison\n    self_basenames = set(Path(f).name for f in self.filename)\n    other_basenames = set(Path(f).name for f in other.filename)\n\n    # Check if there's any overlap\n    return len(self_basenames &amp; other_basenames) &gt; 0\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Video.matches_content","title":"<code>matches_content(other)</code>","text":"<p>Check if this video has the same content as another video.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>'Video'</code> <p>Another video to compare with.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the videos have the same shape and backend type.</p> Notes <p>This compares metadata like shape and backend type, not actual frame data.</p> Source code in <code>sleap_io/model/video.py</code> <pre><code>def matches_content(self, other: \"Video\") -&gt; bool:\n    \"\"\"Check if this video has the same content as another video.\n\n    Args:\n        other: Another video to compare with.\n\n    Returns:\n        True if the videos have the same shape and backend type.\n\n    Notes:\n        This compares metadata like shape and backend type, not actual frame data.\n    \"\"\"\n    # Compare shapes\n    self_shape = self.shape\n    other_shape = other.shape\n\n    if self_shape != other_shape:\n        return False\n\n    # Compare backend types\n    if self.backend is None and other.backend is None:\n        return True\n    elif self.backend is None or other.backend is None:\n        return False\n\n    return type(self.backend).__name__ == type(other.backend).__name__\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Video.matches_path","title":"<code>matches_path(other, strict=False)</code>","text":"<p>Check if this video has the same path as another video.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>'Video'</code> <p>Another video to compare with.</p> required <code>strict</code> <code>bool</code> <p>If True, require exact path match. If False, consider videos with the same filename (basename) as matching.</p> <code>False</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if the videos have matching paths, False otherwise.</p> Source code in <code>sleap_io/model/video.py</code> <pre><code>def matches_path(self, other: \"Video\", strict: bool = False) -&gt; bool:\n    \"\"\"Check if this video has the same path as another video.\n\n    Args:\n        other: Another video to compare with.\n        strict: If True, require exact path match. If False, consider videos\n            with the same filename (basename) as matching.\n\n    Returns:\n        True if the videos have matching paths, False otherwise.\n    \"\"\"\n    if isinstance(self.filename, list) and isinstance(other.filename, list):\n        # Both are image sequences\n        if strict:\n            return self.filename == other.filename\n        else:\n            # Compare basenames\n            self_basenames = [Path(f).name for f in self.filename]\n            other_basenames = [Path(f).name for f in other.filename]\n            return self_basenames == other_basenames\n    elif isinstance(self.filename, list) or isinstance(other.filename, list):\n        # One is image sequence, other is single file\n        return False\n    else:\n        # Both are single files\n        if strict:\n            return Path(self.filename).resolve() == Path(other.filename).resolve()\n        else:\n            return Path(self.filename).name == Path(other.filename).name\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Video.matches_shape","title":"<code>matches_shape(other)</code>","text":"<p>Check if this video has the same shape as another video.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>'Video'</code> <p>Another video to compare with.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the videos have the same height, width, and channels.</p> Notes <p>This only compares spatial dimensions, not the number of frames.</p> Source code in <code>sleap_io/model/video.py</code> <pre><code>def matches_shape(self, other: \"Video\") -&gt; bool:\n    \"\"\"Check if this video has the same shape as another video.\n\n    Args:\n        other: Another video to compare with.\n\n    Returns:\n        True if the videos have the same height, width, and channels.\n\n    Notes:\n        This only compares spatial dimensions, not the number of frames.\n    \"\"\"\n    # Try to get shape from backend metadata first if shape is not available\n    if self.backend is None and \"shape\" in self.backend_metadata:\n        self_shape = self.backend_metadata[\"shape\"]\n    else:\n        self_shape = self.shape\n\n    if other.backend is None and \"shape\" in other.backend_metadata:\n        other_shape = other.backend_metadata[\"shape\"]\n    else:\n        other_shape = other.shape\n\n    # Handle None shapes\n    if self_shape is None or other_shape is None:\n        return False\n\n    # Compare only height, width, channels (not frames)\n    return self_shape[1:] == other_shape[1:]\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Video.merge_with","title":"<code>merge_with(other)</code>","text":"<p>Merge another video's images into this one.</p> <p>This method is specifically for ImageVideo backends (image sequences).</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>'Video'</code> <p>Another video to merge with. Must also be ImageVideo.</p> required <p>Returns:</p> Type Description <code>'Video'</code> <p>A new Video object with unique images from both videos.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If either video is not an ImageVideo backend.</p> Notes <p>Only works with ImageVideo backends where filename is a list. The merged video contains all unique images from both videos, with automatic deduplication based on image basename.</p> Source code in <code>sleap_io/model/video.py</code> <pre><code>def merge_with(self, other: \"Video\") -&gt; \"Video\":\n    \"\"\"Merge another video's images into this one.\n\n    This method is specifically for ImageVideo backends (image sequences).\n\n    Args:\n        other: Another video to merge with. Must also be ImageVideo.\n\n    Returns:\n        A new Video object with unique images from both videos.\n\n    Raises:\n        ValueError: If either video is not an ImageVideo backend.\n\n    Notes:\n        Only works with ImageVideo backends where filename is a list.\n        The merged video contains all unique images from both videos,\n        with automatic deduplication based on image basename.\n    \"\"\"\n    if not isinstance(self.filename, list):\n        raise ValueError(\"merge_with only works with ImageVideo backends\")\n    if not isinstance(other.filename, list):\n        raise ValueError(\"Other video must also be ImageVideo backend\")\n\n    # Get all unique images (by basename) preserving order\n    seen_basenames = set()\n    merged_paths = []\n\n    for path in self.filename:\n        basename = Path(path).name\n        if basename not in seen_basenames:\n            merged_paths.append(path)\n            seen_basenames.add(basename)\n\n    for path in other.filename:\n        basename = Path(path).name\n        if basename not in seen_basenames:\n            merged_paths.append(path)\n            seen_basenames.add(basename)\n\n    # Create new video with merged images\n    return Video.from_filename(merged_paths, grayscale=self.grayscale)\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Video.open","title":"<code>open(filename=None, dataset=None, grayscale=None, keep_open=True, plugin=None)</code>","text":"<p>Open the video backend for reading.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>Optional[str]</code> <p>Filename to open. If not specified, will use the filename set on the video object.</p> <code>None</code> <code>dataset</code> <code>Optional[str]</code> <p>Name of dataset in HDF5 file.</p> <code>None</code> <code>grayscale</code> <code>Optional[str]</code> <p>Whether to force grayscale. If None, autodetect on first frame load.</p> <code>None</code> <code>keep_open</code> <code>bool</code> <p>Whether to keep the video reader open between calls to read frames. If False, will close the reader after each call. If True (the default), it will keep the reader open and cache it for subsequent calls which may enhance the performance of reading multiple frames.</p> <code>True</code> <code>plugin</code> <code>Optional[str]</code> <p>Video plugin to use for MediaVideo files. One of \"opencv\", \"FFMPEG\", or \"pyav\". Also accepts aliases (case-insensitive). If not specified, uses the backend metadata, global default, or auto-detection in that order.</p> <code>None</code> Notes <p>This is useful for opening the video backend to read frames and then closing it after reading all the necessary frames.</p> <p>If the backend was already open, it will be closed before opening a new one. Values for the HDF5 dataset and grayscale will be remembered if not specified.</p> Source code in <code>sleap_io/model/video.py</code> <pre><code>def open(\n    self,\n    filename: Optional[str] = None,\n    dataset: Optional[str] = None,\n    grayscale: Optional[str] = None,\n    keep_open: bool = True,\n    plugin: Optional[str] = None,\n):\n    \"\"\"Open the video backend for reading.\n\n    Args:\n        filename: Filename to open. If not specified, will use the filename set on\n            the video object.\n        dataset: Name of dataset in HDF5 file.\n        grayscale: Whether to force grayscale. If None, autodetect on first frame\n            load.\n        keep_open: Whether to keep the video reader open between calls to read\n            frames. If False, will close the reader after each call. If True (the\n            default), it will keep the reader open and cache it for subsequent calls\n            which may enhance the performance of reading multiple frames.\n        plugin: Video plugin to use for MediaVideo files. One of \"opencv\",\n            \"FFMPEG\", or \"pyav\". Also accepts aliases (case-insensitive).\n            If not specified, uses the backend metadata, global default,\n            or auto-detection in that order.\n\n    Notes:\n        This is useful for opening the video backend to read frames and then closing\n        it after reading all the necessary frames.\n\n        If the backend was already open, it will be closed before opening a new one.\n        Values for the HDF5 dataset and grayscale will be remembered if not\n        specified.\n    \"\"\"\n    if filename is not None:\n        self.replace_filename(filename, open=False)\n\n    # Try to remember values from previous backend if available and not specified.\n    if self.backend is not None:\n        if dataset is None:\n            dataset = getattr(self.backend, \"dataset\", None)\n        if grayscale is None:\n            grayscale = getattr(self.backend, \"grayscale\", None)\n\n    else:\n        if dataset is None and \"dataset\" in self.backend_metadata:\n            dataset = self.backend_metadata[\"dataset\"]\n        if grayscale is None:\n            if \"grayscale\" in self.backend_metadata:\n                grayscale = self.backend_metadata[\"grayscale\"]\n            elif \"shape\" in self.backend_metadata:\n                grayscale = self.backend_metadata[\"shape\"][-1] == 1\n\n    if not self.exists(dataset=dataset):\n        msg = (\n            f\"Video does not exist or cannot be opened for reading: {self.filename}\"\n        )\n        if dataset is not None:\n            msg += f\" (dataset: {dataset})\"\n        raise FileNotFoundError(msg)\n\n    # Close previous backend if open.\n    self.close()\n\n    # Handle plugin parameter\n    backend_kwargs = {}\n    if plugin is not None:\n        from sleap_io.io.video_reading import normalize_plugin_name\n\n        plugin = normalize_plugin_name(plugin)\n        self.backend_metadata[\"plugin\"] = plugin\n\n    if \"plugin\" in self.backend_metadata:\n        backend_kwargs[\"plugin\"] = self.backend_metadata[\"plugin\"]\n\n    # Create new backend.\n    self.backend = VideoBackend.from_filename(\n        self.filename,\n        dataset=dataset,\n        grayscale=grayscale,\n        keep_open=keep_open,\n        **backend_kwargs,\n    )\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Video.replace_filename","title":"<code>replace_filename(new_filename, open=True)</code>","text":"<p>Update the filename of the video, optionally opening the backend.</p> <p>Parameters:</p> Name Type Description Default <code>new_filename</code> <code>str | Path | list[str] | list[Path]</code> <p>New filename to set for the video.</p> required <code>open</code> <code>bool</code> <p>If <code>True</code> (the default), open the backend with the new filename. If the new filename does not exist, no error is raised.</p> <code>True</code> Source code in <code>sleap_io/model/video.py</code> <pre><code>def replace_filename(\n    self, new_filename: str | Path | list[str] | list[Path], open: bool = True\n):\n    \"\"\"Update the filename of the video, optionally opening the backend.\n\n    Args:\n        new_filename: New filename to set for the video.\n        open: If `True` (the default), open the backend with the new filename. If\n            the new filename does not exist, no error is raised.\n    \"\"\"\n    if isinstance(new_filename, Path):\n        new_filename = new_filename.as_posix()\n\n    if isinstance(new_filename, list):\n        new_filename = [\n            p.as_posix() if isinstance(p, Path) else p for p in new_filename\n        ]\n\n    self.filename = new_filename\n    self.backend_metadata[\"filename\"] = new_filename\n\n    if open:\n        if self.exists():\n            self.open()\n        else:\n            self.close()\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Video.save","title":"<code>save(save_path, frame_inds=None, video_kwargs=None)</code>","text":"<p>Save video frames to a new video file.</p> <p>Parameters:</p> Name Type Description Default <code>save_path</code> <code>str | Path</code> <p>Path to the new video file. Should end in MP4.</p> required <code>frame_inds</code> <code>list[int] | ndarray | None</code> <p>Frame indices to save. Can be specified as a list or array of frame integers. If not specified, saves all video frames.</p> <code>None</code> <code>video_kwargs</code> <code>dict[str, Any] | None</code> <p>A dictionary of keyword arguments to provide to <code>sio.save_video</code> for video compression.</p> <code>None</code> <p>Returns:</p> Type Description <code>Video</code> <p>A new <code>Video</code> object pointing to the new video file.</p> Source code in <code>sleap_io/model/video.py</code> <pre><code>def save(\n    self,\n    save_path: str | Path,\n    frame_inds: list[int] | np.ndarray | None = None,\n    video_kwargs: dict[str, Any] | None = None,\n) -&gt; Video:\n    \"\"\"Save video frames to a new video file.\n\n    Args:\n        save_path: Path to the new video file. Should end in MP4.\n        frame_inds: Frame indices to save. Can be specified as a list or array of\n            frame integers. If not specified, saves all video frames.\n        video_kwargs: A dictionary of keyword arguments to provide to\n            `sio.save_video` for video compression.\n\n    Returns:\n        A new `Video` object pointing to the new video file.\n    \"\"\"\n    video_kwargs = {} if video_kwargs is None else video_kwargs\n    frame_inds = np.arange(len(self)) if frame_inds is None else frame_inds\n\n    with VideoWriter(save_path, **video_kwargs) as vw:\n        for frame_ind in frame_inds:\n            vw(self[frame_ind])\n\n    new_video = Video.from_filename(save_path, grayscale=self.grayscale)\n    return new_video\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.Video.set_video_plugin","title":"<code>set_video_plugin(plugin)</code>","text":"<p>Set the video plugin and reopen the video.</p> <p>Parameters:</p> Name Type Description Default <code>plugin</code> <code>str</code> <p>Video plugin to use. One of \"opencv\", \"FFMPEG\", or \"pyav\". Also accepts aliases (case-insensitive).</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If the video is not a MediaVideo type.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; video.set_video_plugin(\"opencv\")\n&gt;&gt;&gt; video.set_video_plugin(\"CV2\")  # Same as \"opencv\"\n</code></pre> Source code in <code>sleap_io/model/video.py</code> <pre><code>def set_video_plugin(self, plugin: str) -&gt; None:\n    \"\"\"Set the video plugin and reopen the video.\n\n    Args:\n        plugin: Video plugin to use. One of \"opencv\", \"FFMPEG\", or \"pyav\".\n            Also accepts aliases (case-insensitive).\n\n    Raises:\n        ValueError: If the video is not a MediaVideo type.\n\n    Examples:\n        &gt;&gt;&gt; video.set_video_plugin(\"opencv\")\n        &gt;&gt;&gt; video.set_video_plugin(\"CV2\")  # Same as \"opencv\"\n    \"\"\"\n    from sleap_io.io.video_reading import MediaVideo, normalize_plugin_name\n\n    if not self.filename.endswith(MediaVideo.EXTS):\n        raise ValueError(f\"Cannot set plugin for non-media video: {self.filename}\")\n\n    plugin = normalize_plugin_name(plugin)\n\n    # Close current backend if open\n    was_open = self.is_open\n    if was_open:\n        self.close()\n\n    # Update backend metadata\n    self.backend_metadata[\"plugin\"] = plugin\n\n    # Reopen with new plugin if it was open\n    if was_open:\n        self.open()\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.VideoBackend","title":"<code>VideoBackend</code>","text":"<p>Base class for video backends.</p> <p>This class is not meant to be used directly. Instead, use the <code>from_filename</code> constructor to create a backend instance.</p> <p>Attributes:</p> Name Type Description <code>filename</code> <code>str | Path | list[str] | list[Path]</code> <p>Path to video file(s).</p> <code>grayscale</code> <code>Optional[bool]</code> <p>Whether to force grayscale. If None, autodetect on first frame load.</p> <code>keep_open</code> <code>bool</code> <p>Whether to keep the video reader open between calls to read frames. If False, will close the reader after each call. If True (the default), it will keep the reader open and cache it for subsequent calls which may enhance the performance of reading multiple frames.</p> <p>Methods:</p> Name Description <code>__getitem__</code> <p>Return a single frame or a list of frames from the video.</p> <code>__len__</code> <p>Return number of frames in the video.</p> <code>detect_grayscale</code> <p>Detect whether the video is grayscale.</p> <code>from_filename</code> <p>Create a VideoBackend from a filename.</p> <code>get_frame</code> <p>Read a single frame from the video.</p> <code>get_frames</code> <p>Read a list of frames from the video.</p> <code>has_frame</code> <p>Check if a frame index is contained in the video.</p> <code>read_test_frame</code> <p>Read a single frame from the video to test for grayscale.</p> Source code in <code>sleap_io/io/video_reading.py</code> <pre><code>@attrs.define\nclass VideoBackend:\n    \"\"\"Base class for video backends.\n\n    This class is not meant to be used directly. Instead, use the `from_filename`\n    constructor to create a backend instance.\n\n    Attributes:\n        filename: Path to video file(s).\n        grayscale: Whether to force grayscale. If None, autodetect on first frame load.\n        keep_open: Whether to keep the video reader open between calls to read frames.\n            If False, will close the reader after each call. If True (the default), it\n            will keep the reader open and cache it for subsequent calls which may\n            enhance the performance of reading multiple frames.\n    \"\"\"\n\n    filename: str | Path | list[str] | list[Path]\n    grayscale: Optional[bool] = None\n    keep_open: bool = True\n    _cached_shape: Optional[Tuple[int, int, int, int]] = None\n    _open_reader: Optional[object] = None\n\n    @classmethod\n    def from_filename(\n        cls,\n        filename: str | list[str],\n        dataset: Optional[str] = None,\n        grayscale: Optional[bool] = None,\n        keep_open: bool = True,\n        **kwargs,\n    ) -&gt; VideoBackend:\n        \"\"\"Create a VideoBackend from a filename.\n\n        Args:\n            filename: Path to video file(s).\n            dataset: Name of dataset in HDF5 file.\n            grayscale: Whether to force grayscale. If None, autodetect on first frame\n                load.\n            keep_open: Whether to keep the video reader open between calls to read\n                frames. If False, will close the reader after each call. If True (the\n                default), it will keep the reader open and cache it for subsequent calls\n                which may enhance the performance of reading multiple frames.\n            **kwargs: Additional backend-specific arguments. These are filtered to only\n                include parameters that are valid for the specific backend being\n                created:\n                - For ImageVideo: No additional arguments.\n                - For MediaVideo: plugin (str): Video plugin to use. One of \"opencv\",\n                  \"FFMPEG\", or \"pyav\". Also accepts aliases (case-insensitive).\n                  If None, uses global default if set, otherwise auto-detects.\n                - For HDF5Video: input_format (str), frame_map (dict),\n                  source_filename (str),\n                  source_inds (np.ndarray), image_format (str). See HDF5Video for\n                  details.\n\n        Returns:\n            VideoBackend subclass instance.\n        \"\"\"\n        if isinstance(filename, Path):\n            filename = filename.as_posix()\n\n        if type(filename) is str and Path(filename).is_dir():\n            filename = ImageVideo.find_images(filename)\n\n        if type(filename) is list:\n            filename = [Path(f).as_posix() for f in filename]\n            return ImageVideo(\n                filename, grayscale=grayscale, **_get_valid_kwargs(ImageVideo, kwargs)\n            )\n        elif filename.endswith((\"tif\", \"tiff\")):\n            # Detect TIFF format\n            format_type, metadata = TiffVideo.detect_format(filename)\n\n            if format_type in (\"multi_page\", \"rank3_video\", \"rank4_video\"):\n                # Use TiffVideo for multi-page or multi-dimensional TIFFs\n                tiff_kwargs = _get_valid_kwargs(TiffVideo, kwargs)\n                # Add format if detected\n                if format_type in (\"rank3_video\", \"rank4_video\"):\n                    tiff_kwargs[\"format\"] = metadata.get(\"format\")\n                return TiffVideo(\n                    filename,\n                    grayscale=grayscale,\n                    keep_open=keep_open,\n                    **tiff_kwargs,\n                )\n            else:\n                # Single-page TIFF, treat as regular image\n                return ImageVideo(\n                    [filename],\n                    grayscale=grayscale,\n                    **_get_valid_kwargs(ImageVideo, kwargs),\n                )\n        elif filename.endswith(ImageVideo.EXTS):\n            return ImageVideo(\n                [filename], grayscale=grayscale, **_get_valid_kwargs(ImageVideo, kwargs)\n            )\n        elif filename.endswith(MediaVideo.EXTS):\n            return MediaVideo(\n                filename,\n                grayscale=grayscale,\n                keep_open=keep_open,\n                **_get_valid_kwargs(MediaVideo, kwargs),\n            )\n        elif filename.endswith(HDF5Video.EXTS):\n            return HDF5Video(\n                filename,\n                dataset=dataset,\n                grayscale=grayscale,\n                keep_open=keep_open,\n                **_get_valid_kwargs(HDF5Video, kwargs),\n            )\n        else:\n            raise ValueError(f\"Unknown video file type: {filename}\")\n\n    def _read_frame(self, frame_idx: int) -&gt; np.ndarray:\n        \"\"\"Read a single frame from the video. Must be implemented in subclasses.\"\"\"\n        raise NotImplementedError\n\n    def _read_frames(self, frame_inds: list) -&gt; np.ndarray:\n        \"\"\"Read a list of frames from the video.\"\"\"\n        return np.stack([self.get_frame(i) for i in frame_inds], axis=0)\n\n    def read_test_frame(self) -&gt; np.ndarray:\n        \"\"\"Read a single frame from the video to test for grayscale.\n\n        Note:\n            This reads the frame at index 0. This may not be appropriate if the first\n            frame is not available in a given backend.\n        \"\"\"\n        return self._read_frame(0)\n\n    def detect_grayscale(self, test_img: np.ndarray | None = None) -&gt; bool:\n        \"\"\"Detect whether the video is grayscale.\n\n        This works by reading in a test frame and comparing the first and last channel\n        for equality. It may fail in cases where, due to compression, the first and\n        last channels are not exactly the same.\n\n        Args:\n            test_img: Optional test image to use. If not provided, a test image will be\n                loaded via the `read_test_frame` method.\n\n        Returns:\n            Whether the video is grayscale. This value is also cached in the `grayscale`\n            attribute of the class.\n        \"\"\"\n        if test_img is None:\n            test_img = self.read_test_frame()\n        is_grayscale = np.array_equal(test_img[..., 0], test_img[..., -1])\n        self.grayscale = is_grayscale\n        return is_grayscale\n\n    @property\n    def num_frames(self) -&gt; int:\n        \"\"\"Number of frames in the video. Must be implemented in subclasses.\"\"\"\n        raise NotImplementedError\n\n    @property\n    def img_shape(self) -&gt; Tuple[int, int, int]:\n        \"\"\"Shape of a single frame in the video.\"\"\"\n        height, width, channels = self.read_test_frame().shape\n        if self.grayscale is None:\n            self.detect_grayscale()\n        if self.grayscale is False:\n            channels = 3\n        elif self.grayscale is True:\n            channels = 1\n        return int(height), int(width), int(channels)\n\n    @property\n    def shape(self) -&gt; Tuple[int, int, int, int]:\n        \"\"\"Shape of the video as a tuple of `(frames, height, width, channels)`.\n\n        On first call, this will defer to `num_frames` and `img_shape` to determine the\n        full shape. This call may be expensive for some subclasses, so the result is\n        cached and returned on subsequent calls.\n        \"\"\"\n        if self._cached_shape is not None:\n            return self._cached_shape\n        else:\n            shape = (self.num_frames,) + self.img_shape\n            self._cached_shape = shape\n            return shape\n\n    @property\n    def frames(self) -&gt; int:\n        \"\"\"Number of frames in the video.\"\"\"\n        return self.shape[0]\n\n    def __len__(self) -&gt; int:\n        \"\"\"Return number of frames in the video.\"\"\"\n        return self.shape[0]\n\n    def has_frame(self, frame_idx: int) -&gt; bool:\n        \"\"\"Check if a frame index is contained in the video.\n\n        Args:\n            frame_idx: Index of frame to check.\n\n        Returns:\n            `True` if the index is contained in the video, otherwise `False`.\n        \"\"\"\n        return frame_idx &lt; len(self)\n\n    def get_frame(self, frame_idx: int) -&gt; np.ndarray:\n        \"\"\"Read a single frame from the video.\n\n        Args:\n            frame_idx: Index of frame to read.\n\n        Returns:\n            Frame as a numpy array of shape `(height, width, channels)` where the\n            `channels` dimension is 1 for grayscale videos and 3 for color videos.\n\n        Notes:\n            If the `grayscale` attribute is set to `True`, the `channels` dimension will\n            be reduced to 1 if an RGB frame is loaded from the backend.\n\n            If the `grayscale` attribute is set to `None`, the `grayscale` attribute\n            will be automatically set based on the first frame read.\n\n        See also: `get_frames`\n        \"\"\"\n        if not self.has_frame(frame_idx):\n            raise IndexError(f\"Frame index {frame_idx} out of range.\")\n\n        img = self._read_frame(frame_idx)\n\n        if self.grayscale is None:\n            self.detect_grayscale(img)\n\n        if self.grayscale:\n            img = img[..., [0]]\n\n        return img\n\n    def get_frames(self, frame_inds: list[int]) -&gt; np.ndarray:\n        \"\"\"Read a list of frames from the video.\n\n        Depending on the backend implementation, this may be faster than reading frames\n        individually using `get_frame`.\n\n        Args:\n            frame_inds: List of frame indices to read.\n\n        Returns:\n            Frames as a numpy array of shape `(frames, height, width, channels)` where\n            `channels` dimension is 1 for grayscale videos and 3 for color videos.\n\n        Notes:\n            If the `grayscale` attribute is set to `True`, the `channels` dimension will\n            be reduced to 1 if an RGB frame is loaded from the backend.\n\n            If the `grayscale` attribute is set to `None`, the `grayscale` attribute\n            will be automatically set based on the first frame read.\n\n        See also: `get_frame`\n        \"\"\"\n        imgs = self._read_frames(frame_inds)\n\n        if self.grayscale is None:\n            self.detect_grayscale(imgs[0])\n\n        if self.grayscale:\n            imgs = imgs[..., [0]]\n\n        return imgs\n\n    def __getitem__(self, ind: int | list[int] | slice) -&gt; np.ndarray:\n        \"\"\"Return a single frame or a list of frames from the video.\n\n        Args:\n            ind: Index or list of indices of frames to read.\n\n        Returns:\n            Frame or frames as a numpy array of shape `(height, width, channels)` if a\n            scalar index is provided, or `(frames, height, width, channels)` if a list\n            of indices is provided.\n\n        See also: get_frame, get_frames\n        \"\"\"\n        if np.isscalar(ind):\n            return self.get_frame(ind)\n        else:\n            if type(ind) is slice:\n                start = (ind.start or 0) % len(self)\n                stop = ind.stop or len(self)\n                if stop &lt; 0:\n                    stop = len(self) + stop\n                step = ind.step or 1\n                ind = range(start, stop, step)\n            return self.get_frames(ind)\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.VideoBackend.frames","title":"<code>frames</code>  <code>property</code>","text":"<p>Number of frames in the video.</p>"},{"location":"reference/sleap_io/#sleap_io.VideoBackend.img_shape","title":"<code>img_shape</code>  <code>property</code>","text":"<p>Shape of a single frame in the video.</p>"},{"location":"reference/sleap_io/#sleap_io.VideoBackend.num_frames","title":"<code>num_frames</code>  <code>property</code>","text":"<p>Number of frames in the video. Must be implemented in subclasses.</p>"},{"location":"reference/sleap_io/#sleap_io.VideoBackend.shape","title":"<code>shape</code>  <code>property</code>","text":"<p>Shape of the video as a tuple of <code>(frames, height, width, channels)</code>.</p> <p>On first call, this will defer to <code>num_frames</code> and <code>img_shape</code> to determine the full shape. This call may be expensive for some subclasses, so the result is cached and returned on subsequent calls.</p>"},{"location":"reference/sleap_io/#sleap_io.VideoBackend.__getitem__","title":"<code>__getitem__(ind)</code>","text":"<p>Return a single frame or a list of frames from the video.</p> <p>Parameters:</p> Name Type Description Default <code>ind</code> <code>int | list[int] | slice</code> <p>Index or list of indices of frames to read.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Frame or frames as a numpy array of shape <code>(height, width, channels)</code> if a scalar index is provided, or <code>(frames, height, width, channels)</code> if a list of indices is provided.</p> <p>See also: get_frame, get_frames</p> Source code in <code>sleap_io/io/video_reading.py</code> <pre><code>def __getitem__(self, ind: int | list[int] | slice) -&gt; np.ndarray:\n    \"\"\"Return a single frame or a list of frames from the video.\n\n    Args:\n        ind: Index or list of indices of frames to read.\n\n    Returns:\n        Frame or frames as a numpy array of shape `(height, width, channels)` if a\n        scalar index is provided, or `(frames, height, width, channels)` if a list\n        of indices is provided.\n\n    See also: get_frame, get_frames\n    \"\"\"\n    if np.isscalar(ind):\n        return self.get_frame(ind)\n    else:\n        if type(ind) is slice:\n            start = (ind.start or 0) % len(self)\n            stop = ind.stop or len(self)\n            if stop &lt; 0:\n                stop = len(self) + stop\n            step = ind.step or 1\n            ind = range(start, stop, step)\n        return self.get_frames(ind)\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.VideoBackend.__len__","title":"<code>__len__()</code>","text":"<p>Return number of frames in the video.</p> Source code in <code>sleap_io/io/video_reading.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"Return number of frames in the video.\"\"\"\n    return self.shape[0]\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.VideoBackend.detect_grayscale","title":"<code>detect_grayscale(test_img=None)</code>","text":"<p>Detect whether the video is grayscale.</p> <p>This works by reading in a test frame and comparing the first and last channel for equality. It may fail in cases where, due to compression, the first and last channels are not exactly the same.</p> <p>Parameters:</p> Name Type Description Default <code>test_img</code> <code>ndarray | None</code> <p>Optional test image to use. If not provided, a test image will be loaded via the <code>read_test_frame</code> method.</p> <code>None</code> <p>Returns:</p> Type Description <code>bool</code> <p>Whether the video is grayscale. This value is also cached in the <code>grayscale</code> attribute of the class.</p> Source code in <code>sleap_io/io/video_reading.py</code> <pre><code>def detect_grayscale(self, test_img: np.ndarray | None = None) -&gt; bool:\n    \"\"\"Detect whether the video is grayscale.\n\n    This works by reading in a test frame and comparing the first and last channel\n    for equality. It may fail in cases where, due to compression, the first and\n    last channels are not exactly the same.\n\n    Args:\n        test_img: Optional test image to use. If not provided, a test image will be\n            loaded via the `read_test_frame` method.\n\n    Returns:\n        Whether the video is grayscale. This value is also cached in the `grayscale`\n        attribute of the class.\n    \"\"\"\n    if test_img is None:\n        test_img = self.read_test_frame()\n    is_grayscale = np.array_equal(test_img[..., 0], test_img[..., -1])\n    self.grayscale = is_grayscale\n    return is_grayscale\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.VideoBackend.from_filename","title":"<code>from_filename(filename, dataset=None, grayscale=None, keep_open=True, **kwargs)</code>  <code>classmethod</code>","text":"<p>Create a VideoBackend from a filename.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str | list[str]</code> <p>Path to video file(s).</p> required <code>dataset</code> <code>Optional[str]</code> <p>Name of dataset in HDF5 file.</p> <code>None</code> <code>grayscale</code> <code>Optional[bool]</code> <p>Whether to force grayscale. If None, autodetect on first frame load.</p> <code>None</code> <code>keep_open</code> <code>bool</code> <p>Whether to keep the video reader open between calls to read frames. If False, will close the reader after each call. If True (the default), it will keep the reader open and cache it for subsequent calls which may enhance the performance of reading multiple frames.</p> <code>True</code> <code>**kwargs</code> <p>Additional backend-specific arguments. These are filtered to only include parameters that are valid for the specific backend being created: - For ImageVideo: No additional arguments. - For MediaVideo: plugin (str): Video plugin to use. One of \"opencv\",   \"FFMPEG\", or \"pyav\". Also accepts aliases (case-insensitive).   If None, uses global default if set, otherwise auto-detects. - For HDF5Video: input_format (str), frame_map (dict),   source_filename (str),   source_inds (np.ndarray), image_format (str). See HDF5Video for   details.</p> <code>{}</code> <p>Returns:</p> Type Description <code>VideoBackend</code> <p>VideoBackend subclass instance.</p> Source code in <code>sleap_io/io/video_reading.py</code> <pre><code>@classmethod\ndef from_filename(\n    cls,\n    filename: str | list[str],\n    dataset: Optional[str] = None,\n    grayscale: Optional[bool] = None,\n    keep_open: bool = True,\n    **kwargs,\n) -&gt; VideoBackend:\n    \"\"\"Create a VideoBackend from a filename.\n\n    Args:\n        filename: Path to video file(s).\n        dataset: Name of dataset in HDF5 file.\n        grayscale: Whether to force grayscale. If None, autodetect on first frame\n            load.\n        keep_open: Whether to keep the video reader open between calls to read\n            frames. If False, will close the reader after each call. If True (the\n            default), it will keep the reader open and cache it for subsequent calls\n            which may enhance the performance of reading multiple frames.\n        **kwargs: Additional backend-specific arguments. These are filtered to only\n            include parameters that are valid for the specific backend being\n            created:\n            - For ImageVideo: No additional arguments.\n            - For MediaVideo: plugin (str): Video plugin to use. One of \"opencv\",\n              \"FFMPEG\", or \"pyav\". Also accepts aliases (case-insensitive).\n              If None, uses global default if set, otherwise auto-detects.\n            - For HDF5Video: input_format (str), frame_map (dict),\n              source_filename (str),\n              source_inds (np.ndarray), image_format (str). See HDF5Video for\n              details.\n\n    Returns:\n        VideoBackend subclass instance.\n    \"\"\"\n    if isinstance(filename, Path):\n        filename = filename.as_posix()\n\n    if type(filename) is str and Path(filename).is_dir():\n        filename = ImageVideo.find_images(filename)\n\n    if type(filename) is list:\n        filename = [Path(f).as_posix() for f in filename]\n        return ImageVideo(\n            filename, grayscale=grayscale, **_get_valid_kwargs(ImageVideo, kwargs)\n        )\n    elif filename.endswith((\"tif\", \"tiff\")):\n        # Detect TIFF format\n        format_type, metadata = TiffVideo.detect_format(filename)\n\n        if format_type in (\"multi_page\", \"rank3_video\", \"rank4_video\"):\n            # Use TiffVideo for multi-page or multi-dimensional TIFFs\n            tiff_kwargs = _get_valid_kwargs(TiffVideo, kwargs)\n            # Add format if detected\n            if format_type in (\"rank3_video\", \"rank4_video\"):\n                tiff_kwargs[\"format\"] = metadata.get(\"format\")\n            return TiffVideo(\n                filename,\n                grayscale=grayscale,\n                keep_open=keep_open,\n                **tiff_kwargs,\n            )\n        else:\n            # Single-page TIFF, treat as regular image\n            return ImageVideo(\n                [filename],\n                grayscale=grayscale,\n                **_get_valid_kwargs(ImageVideo, kwargs),\n            )\n    elif filename.endswith(ImageVideo.EXTS):\n        return ImageVideo(\n            [filename], grayscale=grayscale, **_get_valid_kwargs(ImageVideo, kwargs)\n        )\n    elif filename.endswith(MediaVideo.EXTS):\n        return MediaVideo(\n            filename,\n            grayscale=grayscale,\n            keep_open=keep_open,\n            **_get_valid_kwargs(MediaVideo, kwargs),\n        )\n    elif filename.endswith(HDF5Video.EXTS):\n        return HDF5Video(\n            filename,\n            dataset=dataset,\n            grayscale=grayscale,\n            keep_open=keep_open,\n            **_get_valid_kwargs(HDF5Video, kwargs),\n        )\n    else:\n        raise ValueError(f\"Unknown video file type: {filename}\")\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.VideoBackend.get_frame","title":"<code>get_frame(frame_idx)</code>","text":"<p>Read a single frame from the video.</p> <p>Parameters:</p> Name Type Description Default <code>frame_idx</code> <code>int</code> <p>Index of frame to read.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Frame as a numpy array of shape <code>(height, width, channels)</code> where the <code>channels</code> dimension is 1 for grayscale videos and 3 for color videos.</p> Notes <p>If the <code>grayscale</code> attribute is set to <code>True</code>, the <code>channels</code> dimension will be reduced to 1 if an RGB frame is loaded from the backend.</p> <p>If the <code>grayscale</code> attribute is set to <code>None</code>, the <code>grayscale</code> attribute will be automatically set based on the first frame read.</p> <p>See also: <code>get_frames</code></p> Source code in <code>sleap_io/io/video_reading.py</code> <pre><code>def get_frame(self, frame_idx: int) -&gt; np.ndarray:\n    \"\"\"Read a single frame from the video.\n\n    Args:\n        frame_idx: Index of frame to read.\n\n    Returns:\n        Frame as a numpy array of shape `(height, width, channels)` where the\n        `channels` dimension is 1 for grayscale videos and 3 for color videos.\n\n    Notes:\n        If the `grayscale` attribute is set to `True`, the `channels` dimension will\n        be reduced to 1 if an RGB frame is loaded from the backend.\n\n        If the `grayscale` attribute is set to `None`, the `grayscale` attribute\n        will be automatically set based on the first frame read.\n\n    See also: `get_frames`\n    \"\"\"\n    if not self.has_frame(frame_idx):\n        raise IndexError(f\"Frame index {frame_idx} out of range.\")\n\n    img = self._read_frame(frame_idx)\n\n    if self.grayscale is None:\n        self.detect_grayscale(img)\n\n    if self.grayscale:\n        img = img[..., [0]]\n\n    return img\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.VideoBackend.get_frames","title":"<code>get_frames(frame_inds)</code>","text":"<p>Read a list of frames from the video.</p> <p>Depending on the backend implementation, this may be faster than reading frames individually using <code>get_frame</code>.</p> <p>Parameters:</p> Name Type Description Default <code>frame_inds</code> <code>list[int]</code> <p>List of frame indices to read.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Frames as a numpy array of shape <code>(frames, height, width, channels)</code> where <code>channels</code> dimension is 1 for grayscale videos and 3 for color videos.</p> Notes <p>If the <code>grayscale</code> attribute is set to <code>True</code>, the <code>channels</code> dimension will be reduced to 1 if an RGB frame is loaded from the backend.</p> <p>If the <code>grayscale</code> attribute is set to <code>None</code>, the <code>grayscale</code> attribute will be automatically set based on the first frame read.</p> <p>See also: <code>get_frame</code></p> Source code in <code>sleap_io/io/video_reading.py</code> <pre><code>def get_frames(self, frame_inds: list[int]) -&gt; np.ndarray:\n    \"\"\"Read a list of frames from the video.\n\n    Depending on the backend implementation, this may be faster than reading frames\n    individually using `get_frame`.\n\n    Args:\n        frame_inds: List of frame indices to read.\n\n    Returns:\n        Frames as a numpy array of shape `(frames, height, width, channels)` where\n        `channels` dimension is 1 for grayscale videos and 3 for color videos.\n\n    Notes:\n        If the `grayscale` attribute is set to `True`, the `channels` dimension will\n        be reduced to 1 if an RGB frame is loaded from the backend.\n\n        If the `grayscale` attribute is set to `None`, the `grayscale` attribute\n        will be automatically set based on the first frame read.\n\n    See also: `get_frame`\n    \"\"\"\n    imgs = self._read_frames(frame_inds)\n\n    if self.grayscale is None:\n        self.detect_grayscale(imgs[0])\n\n    if self.grayscale:\n        imgs = imgs[..., [0]]\n\n    return imgs\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.VideoBackend.has_frame","title":"<code>has_frame(frame_idx)</code>","text":"<p>Check if a frame index is contained in the video.</p> <p>Parameters:</p> Name Type Description Default <code>frame_idx</code> <code>int</code> <p>Index of frame to check.</p> required <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if the index is contained in the video, otherwise <code>False</code>.</p> Source code in <code>sleap_io/io/video_reading.py</code> <pre><code>def has_frame(self, frame_idx: int) -&gt; bool:\n    \"\"\"Check if a frame index is contained in the video.\n\n    Args:\n        frame_idx: Index of frame to check.\n\n    Returns:\n        `True` if the index is contained in the video, otherwise `False`.\n    \"\"\"\n    return frame_idx &lt; len(self)\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.VideoBackend.read_test_frame","title":"<code>read_test_frame()</code>","text":"<p>Read a single frame from the video to test for grayscale.</p> Note <p>This reads the frame at index 0. This may not be appropriate if the first frame is not available in a given backend.</p> Source code in <code>sleap_io/io/video_reading.py</code> <pre><code>def read_test_frame(self) -&gt; np.ndarray:\n    \"\"\"Read a single frame from the video to test for grayscale.\n\n    Note:\n        This reads the frame at index 0. This may not be appropriate if the first\n        frame is not available in a given backend.\n    \"\"\"\n    return self._read_frame(0)\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.VideoWriter","title":"<code>VideoWriter</code>","text":"<p>Simple video writer using imageio and FFMPEG.</p> <p>Attributes:</p> Name Type Description <code>filename</code> <code>Path</code> <p>Path to output video file.</p> <code>fps</code> <code>float</code> <p>Frames per second. Defaults to 30.</p> <code>pixelformat</code> <code>str</code> <p>Pixel format for video. Defaults to \"yuv420p\".</p> <code>codec</code> <code>str</code> <p>Codec to use for encoding. Defaults to \"libx264\".</p> <code>crf</code> <code>int</code> <p>Constant rate factor to control lossiness of video. Values go from 2 to 32, with numbers in the 18 to 30 range being most common. Lower values mean less compressed/higher quality. Defaults to 25. No effect if codec is not \"libx264\".</p> <code>preset</code> <code>str</code> <p>H264 encoding preset. Defaults to \"superfast\". No effect if codec is not \"libx264\".</p> <code>output_params</code> <code>list[str]</code> <p>Additional output parameters for FFMPEG. This should be a list of strings corresponding to command line arguments for FFMPEG and libx264. Use <code>ffmpeg -h encoder=libx264</code> to see all options for libx264 output_params.</p> Notes <p>This class can be used as a context manager to ensure the video is properly closed after writing. For example:</p> <pre><code>with VideoWriter(\"output.mp4\") as writer:\n    for frame in frames:\n        writer(frame)\n</code></pre> <p>Methods:</p> Name Description <code>__call__</code> <p>Write a frame to the video.</p> <code>__enter__</code> <p>Context manager entry.</p> <code>__exit__</code> <p>Context manager exit.</p> <code>build_output_params</code> <p>Build the output parameters for FFMPEG.</p> <code>close</code> <p>Close the video writer.</p> <code>open</code> <p>Open the video writer.</p> <code>write_frame</code> <p>Write a frame to the video.</p> Source code in <code>sleap_io/io/video_writing.py</code> <pre><code>@attrs.define\nclass VideoWriter:\n    \"\"\"Simple video writer using imageio and FFMPEG.\n\n    Attributes:\n        filename: Path to output video file.\n        fps: Frames per second. Defaults to 30.\n        pixelformat: Pixel format for video. Defaults to \"yuv420p\".\n        codec: Codec to use for encoding. Defaults to \"libx264\".\n        crf: Constant rate factor to control lossiness of video. Values go from 2 to 32,\n            with numbers in the 18 to 30 range being most common. Lower values mean less\n            compressed/higher quality. Defaults to 25. No effect if codec is not\n            \"libx264\".\n        preset: H264 encoding preset. Defaults to \"superfast\". No effect if codec is not\n            \"libx264\".\n        output_params: Additional output parameters for FFMPEG. This should be a list of\n            strings corresponding to command line arguments for FFMPEG and libx264. Use\n            `ffmpeg -h encoder=libx264` to see all options for libx264 output_params.\n\n    Notes:\n        This class can be used as a context manager to ensure the video is properly\n        closed after writing. For example:\n\n        ```python\n        with VideoWriter(\"output.mp4\") as writer:\n            for frame in frames:\n                writer(frame)\n        ```\n    \"\"\"\n\n    filename: Path = attrs.field(converter=Path)\n    fps: float = 30\n    pixelformat: str = \"yuv420p\"\n    codec: str = \"libx264\"\n    crf: int = 25\n    preset: str = \"superfast\"\n    output_params: list[str] = attrs.field(factory=list)\n    _writer: \"imageio.plugins.ffmpeg.FfmpegFormat.Writer\" | None = None\n\n    def build_output_params(self) -&gt; list[str]:\n        \"\"\"Build the output parameters for FFMPEG.\"\"\"\n        output_params = []\n        if self.codec == \"libx264\":\n            output_params.extend(\n                [\n                    \"-crf\",\n                    str(self.crf),\n                    \"-preset\",\n                    self.preset,\n                ]\n            )\n        return output_params + self.output_params\n\n    def open(self):\n        \"\"\"Open the video writer.\"\"\"\n        self.close()\n\n        self.filename.parent.mkdir(parents=True, exist_ok=True)\n        self._writer = iio_v2.get_writer(\n            self.filename.as_posix(),\n            format=\"FFMPEG\",\n            fps=self.fps,\n            codec=self.codec,\n            pixelformat=self.pixelformat,\n            output_params=self.build_output_params(),\n        )\n\n    def close(self):\n        \"\"\"Close the video writer.\"\"\"\n        if self._writer is not None:\n            self._writer.close()\n            self._writer = None\n\n    def write_frame(self, frame: np.ndarray):\n        \"\"\"Write a frame to the video.\n\n        Args:\n            frame: Frame to write to video. Should be a 2D or 3D numpy array with\n                dimensions (height, width) or (height, width, channels).\n        \"\"\"\n        if self._writer is None:\n            self.open()\n\n        self._writer.append_data(frame)\n\n    def __enter__(self):\n        \"\"\"Context manager entry.\"\"\"\n        return self\n\n    def __exit__(\n        self,\n        exc_type: Optional[Type[BaseException]],\n        exc_value: Optional[BaseException],\n        traceback: Optional[TracebackType],\n    ) -&gt; Optional[bool]:\n        \"\"\"Context manager exit.\"\"\"\n        self.close()\n        return False\n\n    def __call__(self, frame: np.ndarray):\n        \"\"\"Write a frame to the video.\n\n        Args:\n            frame: Frame to write to video. Should be a 2D or 3D numpy array with\n                dimensions (height, width) or (height, width, channels).\n        \"\"\"\n        self.write_frame(frame)\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.VideoWriter.__call__","title":"<code>__call__(frame)</code>","text":"<p>Write a frame to the video.</p> <p>Parameters:</p> Name Type Description Default <code>frame</code> <code>ndarray</code> <p>Frame to write to video. Should be a 2D or 3D numpy array with dimensions (height, width) or (height, width, channels).</p> required Source code in <code>sleap_io/io/video_writing.py</code> <pre><code>def __call__(self, frame: np.ndarray):\n    \"\"\"Write a frame to the video.\n\n    Args:\n        frame: Frame to write to video. Should be a 2D or 3D numpy array with\n            dimensions (height, width) or (height, width, channels).\n    \"\"\"\n    self.write_frame(frame)\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.VideoWriter.__enter__","title":"<code>__enter__()</code>","text":"<p>Context manager entry.</p> Source code in <code>sleap_io/io/video_writing.py</code> <pre><code>def __enter__(self):\n    \"\"\"Context manager entry.\"\"\"\n    return self\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.VideoWriter.__exit__","title":"<code>__exit__(exc_type, exc_value, traceback)</code>","text":"<p>Context manager exit.</p> Source code in <code>sleap_io/io/video_writing.py</code> <pre><code>def __exit__(\n    self,\n    exc_type: Optional[Type[BaseException]],\n    exc_value: Optional[BaseException],\n    traceback: Optional[TracebackType],\n) -&gt; Optional[bool]:\n    \"\"\"Context manager exit.\"\"\"\n    self.close()\n    return False\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.VideoWriter.build_output_params","title":"<code>build_output_params()</code>","text":"<p>Build the output parameters for FFMPEG.</p> Source code in <code>sleap_io/io/video_writing.py</code> <pre><code>def build_output_params(self) -&gt; list[str]:\n    \"\"\"Build the output parameters for FFMPEG.\"\"\"\n    output_params = []\n    if self.codec == \"libx264\":\n        output_params.extend(\n            [\n                \"-crf\",\n                str(self.crf),\n                \"-preset\",\n                self.preset,\n            ]\n        )\n    return output_params + self.output_params\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.VideoWriter.close","title":"<code>close()</code>","text":"<p>Close the video writer.</p> Source code in <code>sleap_io/io/video_writing.py</code> <pre><code>def close(self):\n    \"\"\"Close the video writer.\"\"\"\n    if self._writer is not None:\n        self._writer.close()\n        self._writer = None\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.VideoWriter.open","title":"<code>open()</code>","text":"<p>Open the video writer.</p> Source code in <code>sleap_io/io/video_writing.py</code> <pre><code>def open(self):\n    \"\"\"Open the video writer.\"\"\"\n    self.close()\n\n    self.filename.parent.mkdir(parents=True, exist_ok=True)\n    self._writer = iio_v2.get_writer(\n        self.filename.as_posix(),\n        format=\"FFMPEG\",\n        fps=self.fps,\n        codec=self.codec,\n        pixelformat=self.pixelformat,\n        output_params=self.build_output_params(),\n    )\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.VideoWriter.write_frame","title":"<code>write_frame(frame)</code>","text":"<p>Write a frame to the video.</p> <p>Parameters:</p> Name Type Description Default <code>frame</code> <code>ndarray</code> <p>Frame to write to video. Should be a 2D or 3D numpy array with dimensions (height, width) or (height, width, channels).</p> required Source code in <code>sleap_io/io/video_writing.py</code> <pre><code>def write_frame(self, frame: np.ndarray):\n    \"\"\"Write a frame to the video.\n\n    Args:\n        frame: Frame to write to video. Should be a 2D or 3D numpy array with\n            dimensions (height, width) or (height, width, channels).\n    \"\"\"\n    if self._writer is None:\n        self.open()\n\n    self._writer.append_data(frame)\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.get_default_video_plugin","title":"<code>get_default_video_plugin()</code>","text":"<p>Get the current default video plugin.</p> <p>Returns:</p> Type Description <code>Optional[str]</code> <p>The current default video plugin name, or None if not set.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import sleap_io as sio\n&gt;&gt;&gt; sio.get_default_video_plugin()\nNone\n&gt;&gt;&gt; sio.set_default_video_plugin(\"opencv\")\n&gt;&gt;&gt; sio.get_default_video_plugin()\n'opencv'\n</code></pre> Source code in <code>sleap_io/io/video_reading.py</code> <pre><code>def get_default_video_plugin() -&gt; Optional[str]:\n    \"\"\"Get the current default video plugin.\n\n    Returns:\n        The current default video plugin name, or None if not set.\n\n    Examples:\n        &gt;&gt;&gt; import sleap_io as sio\n        &gt;&gt;&gt; sio.get_default_video_plugin()\n        None\n        &gt;&gt;&gt; sio.set_default_video_plugin(\"opencv\")\n        &gt;&gt;&gt; sio.get_default_video_plugin()\n        'opencv'\n    \"\"\"\n    return _default_video_plugin\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.load_alphatracker","title":"<code>load_alphatracker(filename)</code>","text":"<p>Read AlphaTracker annotations from a file and return a <code>Labels</code> object.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>Path to the AlphaTracker annotation file in JSON format.</p> required <p>Returns:</p> Type Description <code>Labels</code> <p>Parsed labels as a <code>Labels</code> instance.</p> Source code in <code>sleap_io/io/main.py</code> <pre><code>def load_alphatracker(filename: str) -&gt; Labels:\n    \"\"\"Read AlphaTracker annotations from a file and return a `Labels` object.\n\n    Args:\n        filename: Path to the AlphaTracker annotation file in JSON format.\n\n    Returns:\n        Parsed labels as a `Labels` instance.\n    \"\"\"\n    return alphatracker.read_labels(filename)\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.load_coco","title":"<code>load_coco(json_path, dataset_root=None, grayscale=False, **kwargs)</code>","text":"<p>Load a COCO-style pose dataset and return a Labels object.</p> <p>Parameters:</p> Name Type Description Default <code>json_path</code> <code>str</code> <p>Path to the COCO annotation JSON file.</p> required <code>dataset_root</code> <code>Optional[str]</code> <p>Root directory of the dataset. If None, uses parent directory          of json_path.</p> <code>None</code> <code>grayscale</code> <code>bool</code> <p>If True, load images as grayscale (1 channel). If False, load as        RGB (3 channels). Default is False.</p> <code>False</code> <code>**kwargs</code> <p>Additional arguments (currently unused).</p> <code>{}</code> <p>Returns:</p> Type Description <code>Labels</code> <p>The dataset as a <code>Labels</code> object.</p> Source code in <code>sleap_io/io/main.py</code> <pre><code>def load_coco(\n    json_path: str,\n    dataset_root: Optional[str] = None,\n    grayscale: bool = False,\n    **kwargs,\n) -&gt; Labels:\n    \"\"\"Load a COCO-style pose dataset and return a Labels object.\n\n    Args:\n        json_path: Path to the COCO annotation JSON file.\n        dataset_root: Root directory of the dataset. If None, uses parent directory\n                     of json_path.\n        grayscale: If True, load images as grayscale (1 channel). If False, load as\n                   RGB (3 channels). Default is False.\n        **kwargs: Additional arguments (currently unused).\n\n    Returns:\n        The dataset as a `Labels` object.\n    \"\"\"\n    return coco.read_labels(json_path, dataset_root=dataset_root, grayscale=grayscale)\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.load_dlc","title":"<code>load_dlc(filename, video_search_paths=None, **kwargs)</code>","text":"<p>Read DeepLabCut annotations from a CSV file and return a <code>Labels</code> object.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>Path to DLC CSV file with annotations.</p> required <code>video_search_paths</code> <code>Optional[List[Union[str, Path]]]</code> <p>Optional list of paths to search for video files.</p> <code>None</code> <code>**kwargs</code> <p>Additional arguments passed to DLC loader.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Labels</code> <p>Parsed labels as a <code>Labels</code> instance.</p> Source code in <code>sleap_io/io/main.py</code> <pre><code>def load_dlc(\n    filename: str, video_search_paths: Optional[List[Union[str, Path]]] = None, **kwargs\n) -&gt; Labels:\n    \"\"\"Read DeepLabCut annotations from a CSV file and return a `Labels` object.\n\n    Args:\n        filename: Path to DLC CSV file with annotations.\n        video_search_paths: Optional list of paths to search for video files.\n        **kwargs: Additional arguments passed to DLC loader.\n\n    Returns:\n        Parsed labels as a `Labels` instance.\n    \"\"\"\n    return dlc.load_dlc(filename, video_search_paths=video_search_paths, **kwargs)\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.load_file","title":"<code>load_file(filename, format=None, **kwargs)</code>","text":"<p>Load a file and return the appropriate object.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str | Path</code> <p>Path to a file.</p> required <code>format</code> <code>Optional[str]</code> <p>Optional format to load as. If not provided, will be inferred from the file extension. Available formats are: \"slp\", \"nwb\", \"alphatracker\", \"labelstudio\", \"coco\", \"jabs\", \"dlc\", \"ultralytics\", \"leap\", and \"video\".</p> <code>None</code> <code>**kwargs</code> <p>Additional arguments passed to the format-specific loading function: - For \"slp\" format: No additional arguments. - For \"nwb\" format: No additional arguments. - For \"alphatracker\" format: No additional arguments. - For \"leap\" format: skeleton (Optional[Skeleton]): Skeleton to use if not   defined in the file. - For \"labelstudio\" format: skeleton (Optional[Skeleton]): Skeleton to   use for   the labels. - For \"coco\" format: dataset_root (Optional[str]): Root directory of the   dataset. grayscale (bool): If True, load images as grayscale (1 channel).   If False, load as RGB (3 channels). Default is False. - For \"jabs\" format: skeleton (Optional[Skeleton]): Skeleton to use for   the labels. - For \"dlc\" format: video_search_paths (Optional[List[str]]): Paths to   search for video files. - For \"ultralytics\" format: See <code>load_ultralytics</code> for supported arguments. - For \"video\" format: See <code>load_video</code> for supported arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Union[Labels, Video]</code> <p>A <code>Labels</code> or <code>Video</code> object.</p> Source code in <code>sleap_io/io/main.py</code> <pre><code>def load_file(\n    filename: str | Path, format: Optional[str] = None, **kwargs\n) -&gt; Union[Labels, Video]:\n    \"\"\"Load a file and return the appropriate object.\n\n    Args:\n        filename: Path to a file.\n        format: Optional format to load as. If not provided, will be inferred from the\n            file extension. Available formats are: \"slp\", \"nwb\", \"alphatracker\",\n            \"labelstudio\", \"coco\", \"jabs\", \"dlc\", \"ultralytics\", \"leap\", and \"video\".\n        **kwargs: Additional arguments passed to the format-specific loading function:\n            - For \"slp\" format: No additional arguments.\n            - For \"nwb\" format: No additional arguments.\n            - For \"alphatracker\" format: No additional arguments.\n            - For \"leap\" format: skeleton (Optional[Skeleton]): Skeleton to use if not\n              defined in the file.\n            - For \"labelstudio\" format: skeleton (Optional[Skeleton]): Skeleton to\n              use for\n              the labels.\n            - For \"coco\" format: dataset_root (Optional[str]): Root directory of the\n              dataset. grayscale (bool): If True, load images as grayscale (1 channel).\n              If False, load as RGB (3 channels). Default is False.\n            - For \"jabs\" format: skeleton (Optional[Skeleton]): Skeleton to use for\n              the labels.\n            - For \"dlc\" format: video_search_paths (Optional[List[str]]): Paths to\n              search for video files.\n            - For \"ultralytics\" format: See `load_ultralytics` for supported arguments.\n            - For \"video\" format: See `load_video` for supported arguments.\n\n    Returns:\n        A `Labels` or `Video` object.\n    \"\"\"\n    if isinstance(filename, Path):\n        filename = filename.as_posix()\n\n    if format is None:\n        if filename.endswith(\".slp\"):\n            format = \"slp\"\n        elif filename.endswith(\".nwb\"):\n            format = \"nwb\"\n        elif filename.endswith(\".mat\"):\n            format = \"leap\"\n        elif filename.endswith(\".json\"):\n            # Detect JSON format: AlphaTracker, COCO, or Label Studio\n            if _detect_alphatracker_format(filename):\n                format = \"alphatracker\"\n            elif _detect_coco_format(filename):\n                format = \"coco\"\n            else:\n                format = \"json\"\n        elif filename.endswith(\".h5\"):\n            format = \"jabs\"\n        elif filename.endswith(\"data.yaml\") or (\n            Path(filename).is_dir() and (Path(filename) / \"data.yaml\").exists()\n        ):\n            format = \"ultralytics\"\n        elif filename.endswith(\".csv\") and dlc.is_dlc_file(filename):\n            format = \"dlc\"\n        else:\n            for vid_ext in Video.EXTS:\n                if filename.endswith(vid_ext):\n                    format = \"video\"\n                    break\n        if format is None:\n            raise ValueError(f\"Could not infer format from filename: '{filename}'.\")\n\n    if filename.endswith(\".slp\"):\n        return load_slp(filename, **kwargs)\n    elif filename.endswith(\".nwb\"):\n        return load_nwb(filename, **kwargs)\n    elif filename.endswith(\".mat\"):\n        return load_leap(filename, **kwargs)\n    elif filename.endswith(\".json\"):\n        if format == \"alphatracker\":\n            return load_alphatracker(filename, **kwargs)\n        elif format == \"coco\":\n            return load_coco(filename, **kwargs)\n        else:\n            return load_labelstudio(filename, **kwargs)\n    elif filename.endswith(\".h5\"):\n        return load_jabs(filename, **kwargs)\n    elif format == \"dlc\":\n        return load_dlc(filename, **kwargs)\n    elif format == \"ultralytics\":\n        return load_ultralytics(filename, **kwargs)\n    elif format == \"video\":\n        return load_video(filename, **kwargs)\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.load_jabs","title":"<code>load_jabs(filename, skeleton=None)</code>","text":"<p>Read JABS-style predictions from a file and return a <code>Labels</code> object.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>Path to the jabs h5 pose file.</p> required <code>skeleton</code> <code>Optional[Skeleton]</code> <p>An optional <code>Skeleton</code> object.</p> <code>None</code> <p>Returns:</p> Type Description <code>Labels</code> <p>Parsed labels as a <code>Labels</code> instance.</p> Source code in <code>sleap_io/io/main.py</code> <pre><code>def load_jabs(filename: str, skeleton: Optional[Skeleton] = None) -&gt; Labels:\n    \"\"\"Read JABS-style predictions from a file and return a `Labels` object.\n\n    Args:\n        filename: Path to the jabs h5 pose file.\n        skeleton: An optional `Skeleton` object.\n\n    Returns:\n        Parsed labels as a `Labels` instance.\n    \"\"\"\n    return jabs.read_labels(filename, skeleton=skeleton)\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.load_labels_set","title":"<code>load_labels_set(path, format=None, open_videos=True, **kwargs)</code>","text":"<p>Load a LabelsSet from multiple files.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Union[str, Path, list[Union[str, Path]], dict[str, Union[str, Path]]]</code> <p>Can be one of: - A directory path containing label files - A list of file paths - A dictionary mapping names to file paths</p> required <code>format</code> <code>Optional[str]</code> <p>Optional format specification. If None, will try to infer from path. Supported formats: \"slp\", \"ultralytics\"</p> <code>None</code> <code>open_videos</code> <code>bool</code> <p>If <code>True</code> (the default), attempt to open video backends.</p> <code>True</code> <code>**kwargs</code> <p>Additional format-specific arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>LabelsSet</code> <p>A LabelsSet containing the loaded Labels objects.</p> <p>Examples:</p> <p>Load from SLP directory:</p> <pre><code>&gt;&gt;&gt; labels_set = load_labels_set(\"path/to/splits/\")\n</code></pre> <p>Load from list of SLP files:</p> <pre><code>&gt;&gt;&gt; labels_set = load_labels_set([\"train.slp\", \"val.slp\"])\n</code></pre> <p>Load from Ultralytics dataset:</p> <pre><code>&gt;&gt;&gt; labels_set = load_labels_set(\"path/to/yolo_dataset/\", format=\"ultralytics\")\n</code></pre> Source code in <code>sleap_io/io/main.py</code> <pre><code>def load_labels_set(\n    path: Union[str, Path, list[Union[str, Path]], dict[str, Union[str, Path]]],\n    format: Optional[str] = None,\n    open_videos: bool = True,\n    **kwargs,\n) -&gt; LabelsSet:\n    \"\"\"Load a LabelsSet from multiple files.\n\n    Args:\n        path: Can be one of:\n            - A directory path containing label files\n            - A list of file paths\n            - A dictionary mapping names to file paths\n        format: Optional format specification. If None, will try to infer from path.\n            Supported formats: \"slp\", \"ultralytics\"\n        open_videos: If `True` (the default), attempt to open video backends.\n        **kwargs: Additional format-specific arguments.\n\n    Returns:\n        A LabelsSet containing the loaded Labels objects.\n\n    Examples:\n        Load from SLP directory:\n        &gt;&gt;&gt; labels_set = load_labels_set(\"path/to/splits/\")\n\n        Load from list of SLP files:\n        &gt;&gt;&gt; labels_set = load_labels_set([\"train.slp\", \"val.slp\"])\n\n        Load from Ultralytics dataset:\n        &gt;&gt;&gt; labels_set = load_labels_set(\"path/to/yolo_dataset/\", format=\"ultralytics\")\n    \"\"\"\n    # Try to infer format if not specified\n    if format is None:\n        if isinstance(path, (str, Path)):\n            path_obj = Path(path)\n            if path_obj.is_dir():\n                # Check for ultralytics structure\n                if (path_obj / \"data.yaml\").exists() or any(\n                    (path_obj / split).exists() for split in [\"train\", \"val\", \"test\"]\n                ):\n                    format = \"ultralytics\"\n                else:\n                    # Default to SLP for directories\n                    format = \"slp\"\n            else:\n                # Single file path - check extension\n                if path_obj.suffix == \".slp\":\n                    format = \"slp\"\n        elif isinstance(path, list) and len(path) &gt; 0:\n            # Check first file in list\n            first_path = Path(path[0])\n            if first_path.suffix == \".slp\":\n                format = \"slp\"\n        elif isinstance(path, dict):\n            # Dictionary input defaults to SLP\n            format = \"slp\"\n\n    if format == \"slp\":\n        return slp.read_labels_set(path, open_videos=open_videos)\n    elif format == \"ultralytics\":\n        # Extract ultralytics-specific kwargs\n        splits = kwargs.pop(\"splits\", None)\n        skeleton = kwargs.pop(\"skeleton\", None)\n        image_size = kwargs.pop(\"image_size\", (480, 640))\n        # Remove verbose from kwargs if present (for backward compatibility)\n        kwargs.pop(\"verbose\", None)\n\n        if not isinstance(path, (str, Path)):\n            raise ValueError(\n                \"Ultralytics format requires a directory path, \"\n                f\"got {type(path).__name__}\"\n            )\n\n        return ultralytics.read_labels_set(\n            str(path),\n            splits=splits,\n            skeleton=skeleton,\n            image_size=image_size,\n        )\n    else:\n        raise ValueError(\n            f\"Unknown format: {format}. Supported formats: 'slp', 'ultralytics'\"\n        )\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.load_labelstudio","title":"<code>load_labelstudio(filename, skeleton=None)</code>","text":"<p>Read Label Studio-style annotations from a file and return a <code>Labels</code> object.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>Path to the label-studio annotation file in JSON format.</p> required <code>skeleton</code> <code>Optional[Union[Skeleton, list[str]]]</code> <p>An optional <code>Skeleton</code> object or list of node names. If not provided (the default), skeleton will be inferred from the data. It may be useful to provide this so the keypoint label types can be filtered to just the ones in the skeleton.</p> <code>None</code> <p>Returns:</p> Type Description <code>Labels</code> <p>Parsed labels as a <code>Labels</code> instance.</p> Source code in <code>sleap_io/io/main.py</code> <pre><code>def load_labelstudio(\n    filename: str, skeleton: Optional[Union[Skeleton, list[str]]] = None\n) -&gt; Labels:\n    \"\"\"Read Label Studio-style annotations from a file and return a `Labels` object.\n\n    Args:\n        filename: Path to the label-studio annotation file in JSON format.\n        skeleton: An optional `Skeleton` object or list of node names. If not provided\n            (the default), skeleton will be inferred from the data. It may be useful to\n            provide this so the keypoint label types can be filtered to just the ones in\n            the skeleton.\n\n    Returns:\n        Parsed labels as a `Labels` instance.\n    \"\"\"\n    return labelstudio.read_labels(filename, skeleton=skeleton)\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.load_leap","title":"<code>load_leap(filename, skeleton=None, **kwargs)</code>","text":"<p>Load a LEAP dataset from a .mat file.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>Path to a LEAP .mat file.</p> required <code>skeleton</code> <code>Optional[Skeleton]</code> <p>An optional <code>Skeleton</code> object. If not provided, will be constructed from the data in the file.</p> <code>None</code> <code>**kwargs</code> <p>Additional arguments (currently unused).</p> <code>{}</code> <p>Returns:</p> Type Description <code>Labels</code> <p>The dataset as a <code>Labels</code> object.</p> Source code in <code>sleap_io/io/main.py</code> <pre><code>def load_leap(\n    filename: str,\n    skeleton: Optional[Skeleton] = None,\n    **kwargs,\n) -&gt; Labels:\n    \"\"\"Load a LEAP dataset from a .mat file.\n\n    Args:\n        filename: Path to a LEAP .mat file.\n        skeleton: An optional `Skeleton` object. If not provided, will be constructed\n            from the data in the file.\n        **kwargs: Additional arguments (currently unused).\n\n    Returns:\n        The dataset as a `Labels` object.\n    \"\"\"\n    return leap.read_labels(filename, skeleton=skeleton)\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.load_nwb","title":"<code>load_nwb(filename)</code>","text":"<p>Load an NWB dataset as a SLEAP <code>Labels</code> object.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>Path to a NWB file (<code>.nwb</code>).</p> required <p>Returns:</p> Type Description <code>Labels</code> <p>The dataset as a <code>Labels</code> object.</p> Source code in <code>sleap_io/io/main.py</code> <pre><code>def load_nwb(filename: str) -&gt; Labels:\n    \"\"\"Load an NWB dataset as a SLEAP `Labels` object.\n\n    Args:\n        filename: Path to a NWB file (`.nwb`).\n\n    Returns:\n        The dataset as a `Labels` object.\n    \"\"\"\n    return nwb.load_nwb(filename)\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.load_skeleton","title":"<code>load_skeleton(filename)</code>","text":"<p>Load skeleton(s) from a JSON, YAML, or SLP file.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str | Path</code> <p>Path to a skeleton file. Supported formats: - JSON: Standalone skeleton or training config with embedded skeletons - YAML: Simplified skeleton format - SLP: SLEAP project file</p> required <p>Returns:</p> Type Description <code>Union[Skeleton, List[Skeleton]]</code> <p>A single <code>Skeleton</code> or list of <code>Skeleton</code> objects.</p> Notes <p>This function loads skeletons from various file types: - JSON files: Can be standalone skeleton files (jsonpickle format) or training   config files with embedded skeletons - YAML files: Use a simplified human-readable format - SLP files: Extracts skeletons from SLEAP project files The format is detected based on the file extension and content.</p> Source code in <code>sleap_io/io/main.py</code> <pre><code>def load_skeleton(filename: str | Path) -&gt; Union[Skeleton, List[Skeleton]]:\n    \"\"\"Load skeleton(s) from a JSON, YAML, or SLP file.\n\n    Args:\n        filename: Path to a skeleton file. Supported formats:\n            - JSON: Standalone skeleton or training config with embedded skeletons\n            - YAML: Simplified skeleton format\n            - SLP: SLEAP project file\n\n    Returns:\n        A single `Skeleton` or list of `Skeleton` objects.\n\n    Notes:\n        This function loads skeletons from various file types:\n        - JSON files: Can be standalone skeleton files (jsonpickle format) or training\n          config files with embedded skeletons\n        - YAML files: Use a simplified human-readable format\n        - SLP files: Extracts skeletons from SLEAP project files\n        The format is detected based on the file extension and content.\n    \"\"\"\n    if isinstance(filename, Path):\n        filename = str(filename)\n\n    # Detect format based on extension\n    if filename.lower().endswith(\".slp\"):\n        # SLP format - extract skeletons from SLEAP file\n        from sleap_io.io.slp import read_skeletons\n\n        return read_skeletons(filename)\n    elif filename.lower().endswith((\".yaml\", \".yml\")):\n        # YAML format\n        with open(filename, \"r\") as f:\n            yaml_data = f.read()\n        return decode_yaml_skeleton(yaml_data)\n    else:\n        # JSON format (default) - could be standalone or training config\n        with open(filename, \"r\") as f:\n            json_data = f.read()\n        return load_skeleton_from_json(json_data)\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.load_slp","title":"<code>load_slp(filename, open_videos=True)</code>","text":"<p>Load a SLEAP dataset.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>Path to a SLEAP labels file (<code>.slp</code>).</p> required <code>open_videos</code> <code>bool</code> <p>If <code>True</code> (the default), attempt to open the video backend for I/O. If <code>False</code>, the backend will not be opened (useful for reading metadata when the video files are not available).</p> <code>True</code> <p>Returns:</p> Type Description <code>Labels</code> <p>The dataset as a <code>Labels</code> object.</p> Source code in <code>sleap_io/io/main.py</code> <pre><code>def load_slp(filename: str, open_videos: bool = True) -&gt; Labels:\n    \"\"\"Load a SLEAP dataset.\n\n    Args:\n        filename: Path to a SLEAP labels file (`.slp`).\n        open_videos: If `True` (the default), attempt to open the video backend for\n            I/O. If `False`, the backend will not be opened (useful for reading metadata\n            when the video files are not available).\n\n    Returns:\n        The dataset as a `Labels` object.\n    \"\"\"\n    return slp.read_labels(filename, open_videos=open_videos)\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.load_ultralytics","title":"<code>load_ultralytics(dataset_path, split='train', skeleton=None, **kwargs)</code>","text":"<p>Load an Ultralytics YOLO pose dataset as a SLEAP <code>Labels</code> object.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_path</code> <code>str</code> <p>Path to the Ultralytics dataset root directory containing data.yaml.</p> required <code>split</code> <code>str</code> <p>Dataset split to read ('train', 'val', or 'test'). Defaults to 'train'.</p> <code>'train'</code> <code>skeleton</code> <code>Optional[Skeleton]</code> <p>Optional skeleton to use. If not provided, will be inferred from data.yaml.</p> <code>None</code> <code>**kwargs</code> <p>Additional arguments passed to <code>ultralytics.read_labels</code>. Currently supports: - image_size: Tuple of (height, width) for coordinate denormalization.   Defaults to   (480, 640). Will attempt to infer from actual images if available.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Labels</code> <p>The dataset as a <code>Labels</code> object.</p> Source code in <code>sleap_io/io/main.py</code> <pre><code>def load_ultralytics(\n    dataset_path: str,\n    split: str = \"train\",\n    skeleton: Optional[Skeleton] = None,\n    **kwargs,\n) -&gt; Labels:\n    \"\"\"Load an Ultralytics YOLO pose dataset as a SLEAP `Labels` object.\n\n    Args:\n        dataset_path: Path to the Ultralytics dataset root directory containing\n            data.yaml.\n        split: Dataset split to read ('train', 'val', or 'test'). Defaults to 'train'.\n        skeleton: Optional skeleton to use. If not provided, will be inferred from\n            data.yaml.\n        **kwargs: Additional arguments passed to `ultralytics.read_labels`.\n            Currently supports:\n            - image_size: Tuple of (height, width) for coordinate denormalization.\n              Defaults to\n              (480, 640). Will attempt to infer from actual images if available.\n\n    Returns:\n        The dataset as a `Labels` object.\n    \"\"\"\n    return ultralytics.read_labels(\n        dataset_path, split=split, skeleton=skeleton, **kwargs\n    )\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.load_video","title":"<code>load_video(filename, **kwargs)</code>","text":"<p>Load a video file.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>The filename(s) of the video. Supported extensions: \"mp4\", \"avi\", \"mov\", \"mj2\", \"mkv\", \"h5\", \"hdf5\", \"slp\", \"png\", \"jpg\", \"jpeg\", \"tif\", \"tiff\", \"bmp\". If the filename is a list, a list of image filenames are expected. If filename is a folder, it will be searched for images.</p> required <code>**kwargs</code> <p>Additional arguments passed to <code>Video.from_filename</code>. Currently supports: - dataset: Name of dataset in HDF5 file. - grayscale: Whether to force grayscale. If None, autodetect on first   frame load. - keep_open: Whether to keep the video reader open between calls to read   frames.   If False, will close the reader after each call. If True (the   default), it will   keep the reader open and cache it for subsequent calls which may   enhance the   performance of reading multiple frames. - source_video: Source video object if this is a proxy video. This is   metadata   and does not affect reading. - backend_metadata: Metadata to store on the video backend. This is   useful for   storing metadata that requires an open backend (e.g., shape   information) without   having to open the backend. - plugin: Video plugin to use for MediaVideo backend. One of \"opencv\",   \"FFMPEG\",   or \"pyav\". Also accepts aliases (case-insensitive):   * opencv: \"opencv\", \"cv\", \"cv2\", \"ocv\"   * FFMPEG: \"FFMPEG\", \"ffmpeg\", \"imageio-ffmpeg\", \"imageio_ffmpeg\"   * pyav: \"pyav\", \"av\"</p> <p>If not specified, uses the following priority:   1. Global default set via <code>sio.set_default_video_plugin()</code>   2. Auto-detection based on available packages</p> <p>To set a global default:</p> <p>import sleap_io as sio sio.set_default_video_plugin(\"opencv\") video = sio.load_video(\"video.mp4\")  # Uses opencv - input_format: Format of the data in HDF5 datasets. One of   \"channels_last\" (the   default) in (frames, height, width, channels) order or \"channels_first\" in   (frames, channels, width, height) order. - frame_map: Mapping from frame indices to indices in the HDF5 dataset.   This is   used to translate between frame indices of images within their source   video   and indices of images in the dataset. - source_filename: Path to the source video file for HDF5 embedded videos. - source_inds: Indices of frames in the source video file for HDF5   embedded videos. - image_format: Format of images in HDF5 embedded dataset.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Video</code> <p>A <code>Video</code> object.</p> See Also <p>set_default_video_plugin: Set the default video plugin globally. get_default_video_plugin: Get the current default video plugin.</p> Source code in <code>sleap_io/io/main.py</code> <pre><code>def load_video(filename: str, **kwargs) -&gt; Video:\n    \"\"\"Load a video file.\n\n    Args:\n        filename: The filename(s) of the video. Supported extensions: \"mp4\", \"avi\",\n            \"mov\", \"mj2\", \"mkv\", \"h5\", \"hdf5\", \"slp\", \"png\", \"jpg\", \"jpeg\", \"tif\",\n            \"tiff\", \"bmp\". If the filename is a list, a list of image filenames are\n            expected. If filename is a folder, it will be searched for images.\n        **kwargs: Additional arguments passed to `Video.from_filename`.\n            Currently supports:\n            - dataset: Name of dataset in HDF5 file.\n            - grayscale: Whether to force grayscale. If None, autodetect on first\n              frame load.\n            - keep_open: Whether to keep the video reader open between calls to read\n              frames.\n              If False, will close the reader after each call. If True (the\n              default), it will\n              keep the reader open and cache it for subsequent calls which may\n              enhance the\n              performance of reading multiple frames.\n            - source_video: Source video object if this is a proxy video. This is\n              metadata\n              and does not affect reading.\n            - backend_metadata: Metadata to store on the video backend. This is\n              useful for\n              storing metadata that requires an open backend (e.g., shape\n              information) without\n              having to open the backend.\n            - plugin: Video plugin to use for MediaVideo backend. One of \"opencv\",\n              \"FFMPEG\",\n              or \"pyav\". Also accepts aliases (case-insensitive):\n              * opencv: \"opencv\", \"cv\", \"cv2\", \"ocv\"\n              * FFMPEG: \"FFMPEG\", \"ffmpeg\", \"imageio-ffmpeg\", \"imageio_ffmpeg\"\n              * pyav: \"pyav\", \"av\"\n\n              If not specified, uses the following priority:\n              1. Global default set via `sio.set_default_video_plugin()`\n              2. Auto-detection based on available packages\n\n              To set a global default:\n              &gt;&gt;&gt; import sleap_io as sio\n              &gt;&gt;&gt; sio.set_default_video_plugin(\"opencv\")\n              &gt;&gt;&gt; video = sio.load_video(\"video.mp4\")  # Uses opencv\n            - input_format: Format of the data in HDF5 datasets. One of\n              \"channels_last\" (the\n              default) in (frames, height, width, channels) order or \"channels_first\" in\n              (frames, channels, width, height) order.\n            - frame_map: Mapping from frame indices to indices in the HDF5 dataset.\n              This is\n              used to translate between frame indices of images within their source\n              video\n              and indices of images in the dataset.\n            - source_filename: Path to the source video file for HDF5 embedded videos.\n            - source_inds: Indices of frames in the source video file for HDF5\n              embedded videos.\n            - image_format: Format of images in HDF5 embedded dataset.\n\n    Returns:\n        A `Video` object.\n\n    See Also:\n        set_default_video_plugin: Set the default video plugin globally.\n        get_default_video_plugin: Get the current default video plugin.\n    \"\"\"\n    return Video.from_filename(filename, **kwargs)\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.save_file","title":"<code>save_file(labels, filename, format=None, verbose=True, **kwargs)</code>","text":"<p>Save a file based on the extension.</p> <p>Parameters:</p> Name Type Description Default <code>labels</code> <code>Labels</code> <p>A SLEAP <code>Labels</code> object (see <code>load_slp</code>).</p> required <code>filename</code> <code>str | Path</code> <p>Path to save labels to.</p> required <code>format</code> <code>Optional[str]</code> <p>Optional format to save as. If not provided, will be inferred from the file extension. Available formats are: \"slp\", \"nwb\", \"labelstudio\", \"jabs\", and \"ultralytics\".</p> <code>None</code> <code>verbose</code> <code>bool</code> <p>If <code>True</code> (the default), display a progress bar when embedding frames (only applies to the SLP format).</p> <code>True</code> <code>**kwargs</code> <p>Additional arguments passed to the format-specific saving function: - For \"slp\" format: embed (bool | str | list[tuple[Video, int]] |   None): Frames   to embed in the saved labels file. One of None, True, \"all\", \"user\",   \"suggestions\", \"user+suggestions\", \"source\" or list of tuples of   (video, frame_idx). If False (the default), no frames are embedded. - For \"nwb\" format: pose_estimation_metadata (dict): Metadata to store   in the   NWB file. append (bool): If True, append to existing NWB file. - For \"labelstudio\" format: No additional arguments. - For \"jabs\" format: pose_version (int): JABS pose format version (1-6).   root_folder (Optional[str]): Root folder for JABS project structure. - For \"ultralytics\" format: See <code>save_ultralytics</code> for supported arguments.</p> <code>{}</code> Source code in <code>sleap_io/io/main.py</code> <pre><code>def save_file(\n    labels: Labels,\n    filename: str | Path,\n    format: Optional[str] = None,\n    verbose: bool = True,\n    **kwargs,\n):\n    \"\"\"Save a file based on the extension.\n\n    Args:\n        labels: A SLEAP `Labels` object (see `load_slp`).\n        filename: Path to save labels to.\n        format: Optional format to save as. If not provided, will be inferred from the\n            file extension. Available formats are: \"slp\", \"nwb\", \"labelstudio\", \"jabs\",\n            and \"ultralytics\".\n        verbose: If `True` (the default), display a progress bar when embedding frames\n            (only applies to the SLP format).\n        **kwargs: Additional arguments passed to the format-specific saving function:\n            - For \"slp\" format: embed (bool | str | list[tuple[Video, int]] |\n              None): Frames\n              to embed in the saved labels file. One of None, True, \"all\", \"user\",\n              \"suggestions\", \"user+suggestions\", \"source\" or list of tuples of\n              (video, frame_idx). If False (the default), no frames are embedded.\n            - For \"nwb\" format: pose_estimation_metadata (dict): Metadata to store\n              in the\n              NWB file. append (bool): If True, append to existing NWB file.\n            - For \"labelstudio\" format: No additional arguments.\n            - For \"jabs\" format: pose_version (int): JABS pose format version (1-6).\n              root_folder (Optional[str]): Root folder for JABS project structure.\n            - For \"ultralytics\" format: See `save_ultralytics` for supported arguments.\n    \"\"\"\n    if isinstance(filename, Path):\n        filename = str(filename)\n\n    if format is None:\n        if filename.endswith(\".slp\"):\n            format = \"slp\"\n        elif filename.endswith(\".nwb\"):\n            format = \"nwb\"\n        elif filename.endswith(\".json\"):\n            format = \"labelstudio\"\n        elif \"pose_version\" in kwargs:\n            format = \"jabs\"\n        elif \"split_ratios\" in kwargs or Path(filename).is_dir():\n            format = \"ultralytics\"\n\n    if format == \"slp\":\n        save_slp(labels, filename, verbose=verbose, **kwargs)\n    elif format == \"nwb\":\n        save_nwb(labels, filename, **kwargs)\n    elif format == \"labelstudio\":\n        save_labelstudio(labels, filename, **kwargs)\n    elif format == \"jabs\":\n        pose_version = kwargs.pop(\"pose_version\", 5)\n        root_folder = kwargs.pop(\"root_folder\", filename)\n        save_jabs(labels, pose_version=pose_version, root_folder=root_folder)\n    elif format == \"ultralytics\":\n        save_ultralytics(labels, filename, **kwargs)\n    else:\n        raise ValueError(f\"Unknown format '{format}' for filename: '{filename}'.\")\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.save_jabs","title":"<code>save_jabs(labels, pose_version, root_folder=None)</code>","text":"<p>Save a SLEAP dataset to JABS pose file format.</p> <p>Parameters:</p> Name Type Description Default <code>labels</code> <code>Labels</code> <p>SLEAP <code>Labels</code> object.</p> required <code>pose_version</code> <code>int</code> <p>The JABS pose version to write data out.</p> required <code>root_folder</code> <code>Optional[str]</code> <p>Optional root folder where the files should be saved.</p> <code>None</code> Note <p>Filenames for JABS poses are based on video filenames.</p> Source code in <code>sleap_io/io/main.py</code> <pre><code>def save_jabs(labels: Labels, pose_version: int, root_folder: Optional[str] = None):\n    \"\"\"Save a SLEAP dataset to JABS pose file format.\n\n    Args:\n        labels: SLEAP `Labels` object.\n        pose_version: The JABS pose version to write data out.\n        root_folder: Optional root folder where the files should be saved.\n\n    Note:\n        Filenames for JABS poses are based on video filenames.\n    \"\"\"\n    jabs.write_labels(labels, pose_version, root_folder)\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.save_labelstudio","title":"<code>save_labelstudio(labels, filename)</code>","text":"<p>Save a SLEAP dataset to Label Studio format.</p> <p>Parameters:</p> Name Type Description Default <code>labels</code> <code>Labels</code> <p>A SLEAP <code>Labels</code> object (see <code>load_slp</code>).</p> required <code>filename</code> <code>str</code> <p>Path to save labels to ending with <code>.json</code>.</p> required Source code in <code>sleap_io/io/main.py</code> <pre><code>def save_labelstudio(labels: Labels, filename: str):\n    \"\"\"Save a SLEAP dataset to Label Studio format.\n\n    Args:\n        labels: A SLEAP `Labels` object (see `load_slp`).\n        filename: Path to save labels to ending with `.json`.\n    \"\"\"\n    labelstudio.write_labels(labels, filename)\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.save_nwb","title":"<code>save_nwb(labels, filename, nwb_format=NwbFormat.AUTO, append=False)</code>","text":"<p>Save a SLEAP dataset to NWB format.</p> <p>Parameters:</p> Name Type Description Default <code>labels</code> <code>Labels</code> <p>A SLEAP <code>Labels</code> object (see <code>load_slp</code>).</p> required <code>filename</code> <code>Union[str, Path]</code> <p>Path to NWB file to save to. Must end in <code>.nwb</code>.</p> required <code>nwb_format</code> <code>Union[NwbFormat, str]</code> <p>Format to use for saving. Options are: - \"auto\" (default): Automatically detect based on data - \"annotations\": Save training annotations (PoseTraining) - \"annotations_export\": Export annotations with video frames - \"predictions\": Save predictions (PoseEstimation)</p> <code>AUTO</code> <code>append</code> <code>bool</code> <p>If True, append to existing NWB file. Only supported for predictions format. Defaults to False.</p> <code>False</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If an invalid format is specified.</p> Source code in <code>sleap_io/io/main.py</code> <pre><code>def save_nwb(\n    labels: Labels,\n    filename: Union[str, Path],\n    nwb_format: Union[NwbFormat, str] = NwbFormat.AUTO,\n    append: bool = False,\n) -&gt; None:\n    \"\"\"Save a SLEAP dataset to NWB format.\n\n    Args:\n        labels: A SLEAP `Labels` object (see `load_slp`).\n        filename: Path to NWB file to save to. Must end in `.nwb`.\n        nwb_format: Format to use for saving. Options are:\n            - \"auto\" (default): Automatically detect based on data\n            - \"annotations\": Save training annotations (PoseTraining)\n            - \"annotations_export\": Export annotations with video frames\n            - \"predictions\": Save predictions (PoseEstimation)\n        append: If True, append to existing NWB file. Only supported for\n            predictions format. Defaults to False.\n\n    Raises:\n        ValueError: If an invalid format is specified.\n    \"\"\"\n    nwb.save_nwb(labels, filename, nwb_format, append=append)\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.save_skeleton","title":"<code>save_skeleton(skeleton, filename)</code>","text":"<p>Save skeleton(s) to a JSON or YAML file.</p> <p>Parameters:</p> Name Type Description Default <code>skeleton</code> <code>Union[Skeleton, List[Skeleton]]</code> <p>A single <code>Skeleton</code> or list of <code>Skeleton</code> objects to save.</p> required <code>filename</code> <code>str | Path</code> <p>Path to save the skeleton file.</p> required Notes <p>This function saves skeletons in either JSON or YAML format based on the file extension. JSON files use the jsonpickle format compatible with SLEAP, while YAML files use a simplified human-readable format.</p> Source code in <code>sleap_io/io/main.py</code> <pre><code>def save_skeleton(skeleton: Union[Skeleton, List[Skeleton]], filename: str | Path):\n    \"\"\"Save skeleton(s) to a JSON or YAML file.\n\n    Args:\n        skeleton: A single `Skeleton` or list of `Skeleton` objects to save.\n        filename: Path to save the skeleton file.\n\n    Notes:\n        This function saves skeletons in either JSON or YAML format based on the\n        file extension. JSON files use the jsonpickle format compatible with SLEAP,\n        while YAML files use a simplified human-readable format.\n    \"\"\"\n    if isinstance(filename, Path):\n        filename = str(filename)\n\n    # Detect format based on extension\n    if filename.lower().endswith((\".yaml\", \".yml\")):\n        # YAML format\n        yaml_data = encode_yaml_skeleton(skeleton)\n        with open(filename, \"w\") as f:\n            f.write(yaml_data)\n    else:\n        # JSON format (default)\n        json_data = encode_skeleton(skeleton)\n        with open(filename, \"w\") as f:\n            f.write(json_data)\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.save_slp","title":"<code>save_slp(labels, filename, embed=False, restore_original_videos=True, verbose=True)</code>","text":"<p>Save a SLEAP dataset to a <code>.slp</code> file.</p> <p>Parameters:</p> Name Type Description Default <code>labels</code> <code>Labels</code> <p>A SLEAP <code>Labels</code> object (see <code>load_slp</code>).</p> required <code>filename</code> <code>str</code> <p>Path to save labels to ending with <code>.slp</code>.</p> required <code>embed</code> <code>bool | str | list[tuple[Video, int]] | None</code> <p>Frames to embed in the saved labels file. One of <code>None</code>, <code>True</code>, <code>\"all\"</code>, <code>\"user\"</code>, <code>\"suggestions\"</code>, <code>\"user+suggestions\"</code>, <code>\"source\"</code> or list of tuples of <code>(video, frame_idx)</code>.</p> <p>If <code>False</code> is specified (the default), the source video will be restored if available, otherwise the embedded frames will be re-saved.</p> <p>If <code>True</code> or <code>\"all\"</code>, all labeled frames and suggested frames will be embedded.</p> <p>If <code>\"source\"</code> is specified, no images will be embedded and the source video will be restored if available.</p> <p>This argument is only valid for the SLP backend.</p> <code>False</code> <code>restore_original_videos</code> <code>bool</code> <p>If <code>True</code> (default) and <code>embed=False</code>, use original video files. If <code>False</code> and <code>embed=False</code>, keep references to source <code>.pkg.slp</code> files. Only applies when <code>embed=False</code>.</p> <code>True</code> <code>verbose</code> <code>bool</code> <p>If <code>True</code> (the default), display a progress bar when embedding frames.</p> <code>True</code> Source code in <code>sleap_io/io/main.py</code> <pre><code>def save_slp(\n    labels: Labels,\n    filename: str,\n    embed: bool | str | list[tuple[Video, int]] | None = False,\n    restore_original_videos: bool = True,\n    verbose: bool = True,\n):\n    \"\"\"Save a SLEAP dataset to a `.slp` file.\n\n    Args:\n        labels: A SLEAP `Labels` object (see `load_slp`).\n        filename: Path to save labels to ending with `.slp`.\n        embed: Frames to embed in the saved labels file. One of `None`, `True`,\n            `\"all\"`, `\"user\"`, `\"suggestions\"`, `\"user+suggestions\"`, `\"source\"` or list\n            of tuples of `(video, frame_idx)`.\n\n            If `False` is specified (the default), the source video will be restored\n            if available, otherwise the embedded frames will be re-saved.\n\n            If `True` or `\"all\"`, all labeled frames and suggested frames will be\n            embedded.\n\n            If `\"source\"` is specified, no images will be embedded and the source video\n            will be restored if available.\n\n            This argument is only valid for the SLP backend.\n        restore_original_videos: If `True` (default) and `embed=False`, use original\n            video files. If `False` and `embed=False`, keep references to source\n            `.pkg.slp` files. Only applies when `embed=False`.\n        verbose: If `True` (the default), display a progress bar when embedding frames.\n    \"\"\"\n    return slp.write_labels(\n        filename,\n        labels,\n        embed=embed,\n        restore_original_videos=restore_original_videos,\n        verbose=verbose,\n    )\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.save_ultralytics","title":"<code>save_ultralytics(labels, dataset_path, split_ratios={'train': 0.8, 'val': 0.2}, **kwargs)</code>","text":"<p>Save a SLEAP dataset to Ultralytics YOLO pose format.</p> <p>Parameters:</p> Name Type Description Default <code>labels</code> <code>Labels</code> <p>A SLEAP <code>Labels</code> object.</p> required <code>dataset_path</code> <code>str</code> <p>Path to save the Ultralytics dataset.</p> required <code>split_ratios</code> <code>dict</code> <p>Dictionary mapping split names to ratios (must sum to 1.0).          Defaults to {\"train\": 0.8, \"val\": 0.2}.</p> <code>{'train': 0.8, 'val': 0.2}</code> <code>**kwargs</code> <p>Additional arguments passed to <code>ultralytics.write_labels</code>. Currently supports: - class_id: Class ID to use for all instances (default: 0). - image_format: Image format to use for saving frames. Either \"png\"   (default, lossless) or \"jpg\". - image_quality: Image quality for JPEG format (1-100). For PNG, this is   the compression   level (0-9). If None, uses default quality settings. - verbose: If True (default), show progress bars during export. - use_multiprocessing: If True, use multiprocessing for parallel image   saving. Default is False. - n_workers: Number of worker processes. If None, uses CPU count - 1.   Only used if   use_multiprocessing=True.</p> <code>{}</code> Source code in <code>sleap_io/io/main.py</code> <pre><code>def save_ultralytics(\n    labels: Labels,\n    dataset_path: str,\n    split_ratios: dict = {\"train\": 0.8, \"val\": 0.2},\n    **kwargs,\n):\n    \"\"\"Save a SLEAP dataset to Ultralytics YOLO pose format.\n\n    Args:\n        labels: A SLEAP `Labels` object.\n        dataset_path: Path to save the Ultralytics dataset.\n        split_ratios: Dictionary mapping split names to ratios (must sum to 1.0).\n                     Defaults to {\"train\": 0.8, \"val\": 0.2}.\n        **kwargs: Additional arguments passed to `ultralytics.write_labels`.\n            Currently supports:\n            - class_id: Class ID to use for all instances (default: 0).\n            - image_format: Image format to use for saving frames. Either \"png\"\n              (default, lossless) or \"jpg\".\n            - image_quality: Image quality for JPEG format (1-100). For PNG, this is\n              the compression\n              level (0-9). If None, uses default quality settings.\n            - verbose: If True (default), show progress bars during export.\n            - use_multiprocessing: If True, use multiprocessing for parallel image\n              saving. Default is False.\n            - n_workers: Number of worker processes. If None, uses CPU count - 1.\n              Only used if\n              use_multiprocessing=True.\n    \"\"\"\n    ultralytics.write_labels(labels, dataset_path, split_ratios=split_ratios, **kwargs)\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.save_video","title":"<code>save_video(frames, filename, fps=30, pixelformat='yuv420p', codec='libx264', crf=25, preset='superfast', output_params=None)</code>","text":"<p>Write a list of frames to a video file.</p> <p>Parameters:</p> Name Type Description Default <code>frames</code> <code>ndarray | Video</code> <p>Sequence of frames to write to video. Each frame should be a 2D or 3D numpy array with dimensions (height, width) or (height, width, channels).</p> required <code>filename</code> <code>str | Path</code> <p>Path to output video file.</p> required <code>fps</code> <code>float</code> <p>Frames per second. Defaults to 30.</p> <code>30</code> <code>pixelformat</code> <code>str</code> <p>Pixel format for video. Defaults to \"yuv420p\".</p> <code>'yuv420p'</code> <code>codec</code> <code>str</code> <p>Codec to use for encoding. Defaults to \"libx264\".</p> <code>'libx264'</code> <code>crf</code> <code>int</code> <p>Constant rate factor to control lossiness of video. Values go from 2 to 32, with numbers in the 18 to 30 range being most common. Lower values mean less compressed/higher quality. Defaults to 25. No effect if codec is not \"libx264\".</p> <code>25</code> <code>preset</code> <code>str</code> <p>H264 encoding preset. Defaults to \"superfast\". No effect if codec is not \"libx264\".</p> <code>'superfast'</code> <code>output_params</code> <code>list | None</code> <p>Additional output parameters for FFMPEG. This should be a list of strings corresponding to command line arguments for FFMPEG and libx264. Use <code>ffmpeg -h encoder=libx264</code> to see all options for libx264 output_params.</p> <code>None</code> <p>See also: <code>sio.VideoWriter</code></p> Source code in <code>sleap_io/io/main.py</code> <pre><code>def save_video(\n    frames: np.ndarray | Video,\n    filename: str | Path,\n    fps: float = 30,\n    pixelformat: str = \"yuv420p\",\n    codec: str = \"libx264\",\n    crf: int = 25,\n    preset: str = \"superfast\",\n    output_params: list | None = None,\n):\n    \"\"\"Write a list of frames to a video file.\n\n    Args:\n        frames: Sequence of frames to write to video. Each frame should be a 2D or 3D\n            numpy array with dimensions (height, width) or (height, width, channels).\n        filename: Path to output video file.\n        fps: Frames per second. Defaults to 30.\n        pixelformat: Pixel format for video. Defaults to \"yuv420p\".\n        codec: Codec to use for encoding. Defaults to \"libx264\".\n        crf: Constant rate factor to control lossiness of video. Values go from 2 to 32,\n            with numbers in the 18 to 30 range being most common. Lower values mean less\n            compressed/higher quality. Defaults to 25. No effect if codec is not\n            \"libx264\".\n        preset: H264 encoding preset. Defaults to \"superfast\". No effect if codec is not\n            \"libx264\".\n        output_params: Additional output parameters for FFMPEG. This should be a list of\n            strings corresponding to command line arguments for FFMPEG and libx264. Use\n            `ffmpeg -h encoder=libx264` to see all options for libx264 output_params.\n\n    See also: `sio.VideoWriter`\n    \"\"\"\n    if output_params is None:\n        output_params = []\n\n    with video_writing.VideoWriter(\n        filename,\n        fps=fps,\n        pixelformat=pixelformat,\n        codec=codec,\n        crf=crf,\n        preset=preset,\n        output_params=output_params,\n    ) as writer:\n        for frame in frames:\n            writer(frame)\n</code></pre>"},{"location":"reference/sleap_io/#sleap_io.set_default_video_plugin","title":"<code>set_default_video_plugin(plugin)</code>","text":"<p>Set the default video plugin for all subsequently loaded videos.</p> <p>Parameters:</p> Name Type Description Default <code>plugin</code> <code>Optional[str]</code> <p>Video plugin name. One of \"opencv\", \"FFMPEG\", or \"pyav\". Also accepts aliases: \"cv\", \"cv2\", \"ocv\" for opencv; \"imageio-ffmpeg\", \"imageio_ffmpeg\" for FFMPEG; \"av\" for pyav. Case-insensitive. If None, clears the default preference.</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; import sleap_io as sio\n&gt;&gt;&gt; sio.set_default_video_plugin(\"opencv\")\n&gt;&gt;&gt; sio.set_default_video_plugin(\"cv2\")  # Same as \"opencv\"\n&gt;&gt;&gt; sio.set_default_video_plugin(None)  # Clear preference\n</code></pre> Source code in <code>sleap_io/io/video_reading.py</code> <pre><code>def set_default_video_plugin(plugin: Optional[str]) -&gt; None:\n    \"\"\"Set the default video plugin for all subsequently loaded videos.\n\n    Args:\n        plugin: Video plugin name. One of \"opencv\", \"FFMPEG\", or \"pyav\".\n            Also accepts aliases: \"cv\", \"cv2\", \"ocv\" for opencv;\n            \"imageio-ffmpeg\", \"imageio_ffmpeg\" for FFMPEG; \"av\" for pyav.\n            Case-insensitive. If None, clears the default preference.\n\n    Examples:\n        &gt;&gt;&gt; import sleap_io as sio\n        &gt;&gt;&gt; sio.set_default_video_plugin(\"opencv\")\n        &gt;&gt;&gt; sio.set_default_video_plugin(\"cv2\")  # Same as \"opencv\"\n        &gt;&gt;&gt; sio.set_default_video_plugin(None)  # Clear preference\n    \"\"\"\n    global _default_video_plugin\n    if plugin is not None:\n        plugin = normalize_plugin_name(plugin)\n    _default_video_plugin = plugin\n</code></pre>"},{"location":"reference/sleap_io/version/","title":"version","text":""},{"location":"reference/sleap_io/version/#sleap_io.version","title":"<code>sleap_io.version</code>","text":"<p>This module defines the package version.</p>"},{"location":"reference/sleap_io/io/","title":"io","text":""},{"location":"reference/sleap_io/io/#sleap_io.io","title":"<code>sleap_io.io</code>","text":"<p>This sub-package contains I/O-related modules such as specific format backends.</p> <p>Modules:</p> Name Description <code>alphatracker</code> <p>This module handles direct I/O operations for working with AlphaTracker files.</p> <code>coco</code> <p>Handles direct I/O operations for working with COCO-style pose datasets.</p> <code>dlc</code> <p>This module handles direct I/O operations for working with DeepLabCut (DLC) files.</p> <code>jabs</code> <p>This module handles direct I/O operations for working with JABS files.</p> <code>labelstudio</code> <p>This module handles direct I/O operations for working with Labelstudio files.</p> <code>leap</code> <p>This module handles direct I/O operations for working with LEAP .mat files.</p> <code>main</code> <p>This module contains high-level wrappers for utilizing different I/O backends.</p> <code>nwb</code> <p>Harmonization layer for NWB I/O operations.</p> <code>nwb_annotations</code> <p>NWB formatted annotations.</p> <code>nwb_predictions</code> <p>Functions to write and read from the neurodata without borders (NWB) format.</p> <code>skeleton</code> <p>This module handles I/O operations for standalone skeleton JSON files.</p> <code>slp</code> <p>This module handles direct I/O operations for working with .slp files.</p> <code>ultralytics</code> <p>Handles direct I/O operations for working with Ultralytics YOLO pose format.</p> <code>utils</code> <p>Miscellaneous utilities for working with different I/O formats.</p> <code>video</code> <p>Backends for reading videos.</p> <code>video_reading</code> <p>Backends for reading videos.</p> <code>video_writing</code> <p>Utilities for writing videos.</p>"},{"location":"reference/sleap_io/io/alphatracker/","title":"alphatracker","text":""},{"location":"reference/sleap_io/io/alphatracker/#sleap_io.io.alphatracker","title":"<code>sleap_io.io.alphatracker</code>","text":"<p>This module handles direct I/O operations for working with AlphaTracker files.</p> <p>AlphaTracker is a multi-animal pose tracking system that exports annotations in JSON format. Each JSON file contains an array of frame objects, where each frame includes: - filename: Reference to the image file - class: Always \"image\" for frame objects - annotations: Array containing bounding boxes (class: \"Face\") and keypoints   (class: \"point\")</p> <p>The format groups annotations by animal, with each animal having a Face bounding box followed by its keypoint annotations.</p> <p>Functions:</p> Name Description <code>read_labels</code> <p>Read AlphaTracker style annotations from a file and return a <code>Labels</code> object.</p>"},{"location":"reference/sleap_io/io/alphatracker/#sleap_io.io.alphatracker.read_labels","title":"<code>read_labels(labels_path)</code>","text":"<p>Read AlphaTracker style annotations from a file and return a <code>Labels</code> object.</p> <p>Parameters:</p> Name Type Description Default <code>labels_path</code> <code>str</code> <p>Path to the AlphaTracker annotation file in JSON format.</p> required <p>Returns:</p> Type Description <code>Labels</code> <p>Parsed labels as a <code>Labels</code> instance.</p> Source code in <code>sleap_io/io/alphatracker.py</code> <pre><code>def read_labels(labels_path: str) -&gt; Labels:\n    \"\"\"Read AlphaTracker style annotations from a file and return a `Labels` object.\n\n    Args:\n        labels_path: Path to the AlphaTracker annotation file in JSON format.\n\n    Returns:\n        Parsed labels as a `Labels` instance.\n    \"\"\"\n    labels_path = Path(labels_path)\n\n    # Load the JSON data\n    with open(labels_path, \"r\") as f:\n        data = json.load(f)\n\n    # First pass: determine the number of nodes by scanning all frames\n    max_points = 0\n    for frame_data in data:\n        annotations = frame_data.get(\"annotations\", [])\n\n        # Count points per instance by finding Face followed by points\n        current_points = 0\n        for i, ann in enumerate(annotations):\n            if ann.get(\"class\") == \"Face\":\n                # Count subsequent point annotations\n                current_points = 0\n                for j in range(i + 1, len(annotations)):\n                    if annotations[j].get(\"class\") == \"point\":\n                        current_points += 1\n                    else:\n                        break  # Stop at next Face or other annotation\n                max_points = max(max_points, current_points)\n\n    # Create skeleton with dynamically determined nodes\n    nodes = [Node(str(i + 1)) for i in range(max_points)]\n    skeleton = Skeleton(nodes=nodes)\n\n    # Collect all image filenames to create video\n    image_files = []\n    for frame_data in data:\n        filename = frame_data[\"filename\"]\n        # Build full path to image file (assuming in same directory as JSON)\n        img_path = labels_path.parent / filename\n        image_files.append(str(img_path))\n\n    # Create video from image files\n    video = Video.from_filename(image_files)\n\n    # Parse frames\n    labeled_frames = []\n    for frame_idx, frame_data in enumerate(data):\n        instances = []\n\n        # Get all annotations for this frame\n        annotations = frame_data.get(\"annotations\", [])\n\n        # Group annotations into instances (Face + subsequent points per instance)\n        i = 0\n        while i &lt; len(annotations):\n            if annotations[i].get(\"class\") == \"Face\":\n                # Found a new instance\n                # Collect subsequent point annotations\n                inst_points = []\n                j = i + 1\n                while j &lt; len(annotations) and annotations[j].get(\"class\") == \"point\":\n                    inst_points.append(annotations[j])\n                    j += 1\n\n                # Create points array for this instance\n                points = np.full((len(skeleton.nodes), 2), np.nan)\n                for point_idx, point_data in enumerate(inst_points):\n                    if point_idx &lt; len(skeleton.nodes):\n                        points[point_idx] = [point_data[\"x\"], point_data[\"y\"]]\n\n                # Create instance\n                instance = Instance(points=points, skeleton=skeleton)\n                instances.append(instance)\n\n                # Move to next annotation after the points\n                i = j\n            else:\n                # Skip non-Face annotations that aren't part of an instance\n                i += 1\n\n        # Create labeled frame\n        labeled_frame = LabeledFrame(\n            video=video, frame_idx=frame_idx, instances=instances\n        )\n        labeled_frames.append(labeled_frame)\n\n    # Create and return Labels object\n    labels = Labels(labeled_frames=labeled_frames)\n    labels.provenance[\"filename\"] = str(labels_path)\n\n    return labels\n</code></pre>"},{"location":"reference/sleap_io/io/coco/","title":"coco","text":""},{"location":"reference/sleap_io/io/coco/#sleap_io.io.coco","title":"<code>sleap_io.io.coco</code>","text":"<p>Handles direct I/O operations for working with COCO-style pose datasets.</p> <p>COCO-style pose format specification: - JSON annotation files containing images, annotations, and categories - Image directory structure can vary (flat, categorized, nested, multi-source) - Keypoint annotations with coordinates and visibility flags - Support for multiple animal categories with different skeletons - Visibility encoding: binary (0/1) or ternary (0/\u00bd)</p> <p>Functions:</p> Name Description <code>create_skeleton_from_category</code> <p>Create a Skeleton object from a COCO category definition.</p> <code>decode_keypoints</code> <p>Decode COCO keypoint format to numpy array for Instance creation.</p> <code>parse_coco_json</code> <p>Parse COCO annotation JSON file and validate structure.</p> <code>read_labels</code> <p>Read COCO-style pose dataset and return a Labels object.</p> <code>read_labels_set</code> <p>Read multiple COCO annotation files and return a dictionary of Labels.</p> <code>resolve_image_path</code> <p>Resolve image file path handling various directory structures.</p>"},{"location":"reference/sleap_io/io/coco/#sleap_io.io.coco.create_skeleton_from_category","title":"<code>create_skeleton_from_category(category)</code>","text":"<p>Create a Skeleton object from a COCO category definition.</p> <p>Parameters:</p> Name Type Description Default <code>category</code> <code>Dict</code> <p>COCO category dictionary with keypoints and skeleton.</p> required <p>Returns:</p> Type Description <code>Skeleton</code> <p>Skeleton object corresponding to the category.</p> Source code in <code>sleap_io/io/coco.py</code> <pre><code>def create_skeleton_from_category(category: Dict) -&gt; Skeleton:\n    \"\"\"Create a Skeleton object from a COCO category definition.\n\n    Args:\n        category: COCO category dictionary with keypoints and skeleton.\n\n    Returns:\n        Skeleton object corresponding to the category.\n    \"\"\"\n    if \"keypoints\" not in category:\n        raise ValueError(f\"Category '{category['name']}' has no keypoint definitions\")\n\n    # Create nodes from keypoint names\n    keypoint_names = category[\"keypoints\"]\n    nodes = [Node(name) for name in keypoint_names]\n\n    # Create edges from skeleton connections\n    edges = []\n    if \"skeleton\" in category:\n        for connection in category[\"skeleton\"]:\n            if len(connection) == 2:\n                # COCO skeleton uses 1-based indexing\n                src_idx, dst_idx = connection[0] - 1, connection[1] - 1\n                if 0 &lt;= src_idx &lt; len(nodes) and 0 &lt;= dst_idx &lt; len(nodes):\n                    edges.append(Edge(nodes[src_idx], nodes[dst_idx]))\n\n    skeleton_name = category.get(\"name\", \"unknown\")\n    return Skeleton(nodes, edges, name=skeleton_name)\n</code></pre>"},{"location":"reference/sleap_io/io/coco/#sleap_io.io.coco.decode_keypoints","title":"<code>decode_keypoints(keypoints, num_keypoints, skeleton)</code>","text":"<p>Decode COCO keypoint format to numpy array for Instance creation.</p> <p>Parameters:</p> Name Type Description Default <code>keypoints</code> <code>List[float]</code> <p>Flat list of [x1, y1, v1, x2, y2, v2, ...] values.</p> required <code>num_keypoints</code> <code>int</code> <p>Number of keypoints (for validation).</p> required <code>skeleton</code> <code>Skeleton</code> <p>Skeleton object defining the keypoint structure.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Numpy array of shape (num_keypoints, 3) with [x, y, visibility] values.</p> Source code in <code>sleap_io/io/coco.py</code> <pre><code>def decode_keypoints(\n    keypoints: List[float], num_keypoints: int, skeleton: Skeleton\n) -&gt; np.ndarray:\n    \"\"\"Decode COCO keypoint format to numpy array for Instance creation.\n\n    Args:\n        keypoints: Flat list of [x1, y1, v1, x2, y2, v2, ...] values.\n        num_keypoints: Number of keypoints (for validation).\n        skeleton: Skeleton object defining the keypoint structure.\n\n    Returns:\n        Numpy array of shape (num_keypoints, 3) with [x, y, visibility] values.\n    \"\"\"\n    if len(keypoints) != num_keypoints * 3:\n        raise ValueError(\n            f\"Keypoints length {len(keypoints)} doesn't match expected \"\n            f\"{num_keypoints * 3}\"\n        )\n\n    if len(skeleton.nodes) != num_keypoints:\n        raise ValueError(\n            f\"Skeleton has {len(skeleton.nodes)} nodes but annotation has \"\n            f\"{num_keypoints} keypoints\"\n        )\n\n    points = []\n    for i in range(num_keypoints):\n        x = keypoints[i * 3]\n        y = keypoints[i * 3 + 1]\n        visibility = keypoints[i * 3 + 2]\n\n        # Handle different visibility encodings\n        # 0 = not labeled/not visible, 1 = labeled but not visible,\n        # 2 = labeled and visible\n        # For binary encoding: 0 = not visible, 1 = visible\n        if visibility == 0:\n            # Not labeled or not visible - use NaN coordinates\n            points.append([np.nan, np.nan, False])\n        elif visibility == 1:\n            # Labeled but not visible (occluded) OR visible (in binary encoding)\n            # For now, treat as visible since we can't distinguish binary vs ternary\n            points.append([x, y, True])\n        elif visibility == 2:\n            # Labeled and visible\n            points.append([x, y, True])\n        else:\n            # Unknown visibility value, default to visible\n            points.append([x, y, True])\n\n    return np.array(points, dtype=np.float32)\n</code></pre>"},{"location":"reference/sleap_io/io/coco/#sleap_io.io.coco.parse_coco_json","title":"<code>parse_coco_json(json_path)</code>","text":"<p>Parse COCO annotation JSON file and validate structure.</p> <p>Parameters:</p> Name Type Description Default <code>json_path</code> <code>Union[str, Path]</code> <p>Path to the COCO annotation JSON file.</p> required <p>Returns:</p> Type Description <code>Dict</code> <p>Parsed COCO annotation dictionary.</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If JSON file doesn't exist.</p> <code>ValueError</code> <p>If JSON structure is invalid.</p> Source code in <code>sleap_io/io/coco.py</code> <pre><code>def parse_coco_json(json_path: Union[str, Path]) -&gt; Dict:\n    \"\"\"Parse COCO annotation JSON file and validate structure.\n\n    Args:\n        json_path: Path to the COCO annotation JSON file.\n\n    Returns:\n        Parsed COCO annotation dictionary.\n\n    Raises:\n        FileNotFoundError: If JSON file doesn't exist.\n        ValueError: If JSON structure is invalid.\n    \"\"\"\n    json_path = Path(json_path)\n\n    if not json_path.exists():\n        raise FileNotFoundError(f\"COCO annotation file not found: {json_path}\")\n\n    with open(json_path, \"r\") as f:\n        data = json.load(f)\n\n    # Validate required COCO fields\n    required_fields = [\"images\", \"annotations\", \"categories\"]\n    for field in required_fields:\n        if field not in data:\n            raise ValueError(f\"Missing required COCO field: {field}\")\n\n    # Validate that we have pose data (keypoints in categories)\n    has_keypoints = any(\"keypoints\" in cat for cat in data[\"categories\"])\n    if not has_keypoints:\n        raise ValueError(\n            \"No keypoint definitions found in categories. \"\n            \"This appears to be a detection-only COCO dataset.\"\n        )\n\n    return data\n</code></pre>"},{"location":"reference/sleap_io/io/coco/#sleap_io.io.coco.read_labels","title":"<code>read_labels(json_path, dataset_root=None, grayscale=False)</code>","text":"<p>Read COCO-style pose dataset and return a Labels object.</p> <p>Parameters:</p> Name Type Description Default <code>json_path</code> <code>Union[str, Path]</code> <p>Path to the COCO annotation JSON file.</p> required <code>dataset_root</code> <code>Optional[Union[str, Path]]</code> <p>Root directory of the dataset. If None, uses parent directory          of json_path.</p> <code>None</code> <code>grayscale</code> <code>bool</code> <p>If True, load images as grayscale (1 channel). If False, load as        RGB (3 channels). Default is False.</p> <code>False</code> <p>Returns:</p> Type Description <code>Labels</code> <p>Parsed labels as a Labels instance.</p> Source code in <code>sleap_io/io/coco.py</code> <pre><code>def read_labels(\n    json_path: Union[str, Path],\n    dataset_root: Optional[Union[str, Path]] = None,\n    grayscale: bool = False,\n) -&gt; Labels:\n    \"\"\"Read COCO-style pose dataset and return a Labels object.\n\n    Args:\n        json_path: Path to the COCO annotation JSON file.\n        dataset_root: Root directory of the dataset. If None, uses parent directory\n                     of json_path.\n        grayscale: If True, load images as grayscale (1 channel). If False, load as\n                   RGB (3 channels). Default is False.\n\n    Returns:\n        Parsed labels as a Labels instance.\n    \"\"\"\n    json_path = Path(json_path)\n\n    if dataset_root is None:\n        dataset_root = json_path.parent\n    else:\n        dataset_root = Path(dataset_root)\n\n    # Parse COCO annotation file\n    coco_data = parse_coco_json(json_path)\n\n    # Create skeletons from categories\n    skeletons = {}\n    for category in coco_data[\"categories\"]:\n        if \"keypoints\" in category:\n            skeleton = create_skeleton_from_category(category)\n            skeletons[category[\"id\"]] = skeleton\n\n    # Track management: maps track_id -&gt; Track object\n    track_dict = {}\n\n    # Create image id to annotation mapping\n    image_annotations = {}\n    for annotation in coco_data[\"annotations\"]:\n        image_id = annotation[\"image_id\"]\n        if image_id not in image_annotations:\n            image_annotations[image_id] = []\n        image_annotations[image_id].append(annotation)\n\n    # Group images by shape (height, width) for shared Video objects\n    shape_to_images = {}\n    image_id_to_path = {}\n    image_id_to_shape = {}\n\n    for image_info in coco_data[\"images\"]:\n        image_id = image_info[\"id\"]\n        image_filename = image_info[\"file_name\"]\n        height = image_info.get(\"height\", 0)\n        width = image_info.get(\"width\", 0)\n\n        # Resolve image path\n        try:\n            image_path = resolve_image_path(image_filename, dataset_root)\n            image_id_to_path[image_id] = image_path\n\n            # Group by shape\n            shape_key = (height, width)\n            image_id_to_shape[image_id] = shape_key\n            if shape_key not in shape_to_images:\n                shape_to_images[shape_key] = []\n            shape_to_images[shape_key].append(str(image_path))\n        except FileNotFoundError:\n            # Skip missing images\n            continue\n\n    # Create Video objects for each unique shape\n    shape_to_video = {}\n    for shape_key, image_paths in shape_to_images.items():\n        height, width = shape_key\n        # Create Video from the list of images with this shape\n        video = Video.from_filename(\n            image_paths,\n            grayscale=grayscale,\n        )\n        # Store shape metadata from JSON (useful when images can't be read)\n        channels = 1 if grayscale else 3\n        video.backend_metadata[\"shape\"] = (len(image_paths), height, width, channels)\n        shape_to_video[shape_key] = video\n\n    # Process images and annotations\n    labeled_frames = []\n    image_id_to_frame_idx = {}\n\n    # Build frame index mapping for each image\n    for shape_key, image_paths in shape_to_images.items():\n        for frame_idx, image_path in enumerate(image_paths):\n            # Find the image_id for this path\n            for img_id, path in image_id_to_path.items():\n                if str(path) == image_path:\n                    image_id_to_frame_idx[img_id] = frame_idx\n                    break\n\n    for image_info in coco_data[\"images\"]:\n        image_id = image_info[\"id\"]\n\n        # Skip if image was not found\n        if image_id not in image_id_to_path:\n            continue\n\n        # Get the video and frame index for this image\n        shape_key = image_id_to_shape[image_id]\n        video = shape_to_video[shape_key]\n        frame_idx = image_id_to_frame_idx[image_id]\n\n        # Create instances from annotations\n        instances = []\n        if image_id in image_annotations:\n            for annotation in image_annotations[image_id]:\n                category_id = annotation[\"category_id\"]\n\n                if category_id not in skeletons:\n                    continue  # Skip non-pose annotations\n\n                skeleton = skeletons[category_id]\n\n                # Extract track ID from various possible sources\n                track = None\n                track_id = (\n                    annotation.get(\"attributes\", {}).get(\"object_id\")\n                    or annotation.get(\"track_id\")\n                    or annotation.get(\"instance_id\")\n                )\n\n                if track_id is not None:\n                    # Create or reuse Track object\n                    if track_id not in track_dict:\n                        track_dict[track_id] = Track(name=f\"track_{track_id}\")\n                    track = track_dict[track_id]\n\n                # Decode keypoints\n                keypoints = annotation.get(\"keypoints\", [])\n                # Always use the skeleton length, not num_keypoints which may count\n                # only visible points\n                expected_keypoints = len(skeleton.nodes)\n\n                if keypoints:\n                    points_array = decode_keypoints(\n                        keypoints, expected_keypoints, skeleton\n                    )\n                    instance = Instance.from_numpy(\n                        points_data=points_array, skeleton=skeleton, track=track\n                    )\n                    instances.append(instance)\n\n        # Create labeled frame\n        if (\n            instances or image_id in image_annotations\n        ):  # Include frames even without instances\n            labeled_frame = LabeledFrame(\n                video=video, frame_idx=frame_idx, instances=instances\n            )\n            labeled_frames.append(labeled_frame)\n\n    # Create Labels object (skeletons will be auto-added from instances)\n    return Labels(labeled_frames=labeled_frames)\n</code></pre>"},{"location":"reference/sleap_io/io/coco/#sleap_io.io.coco.read_labels_set","title":"<code>read_labels_set(dataset_path, json_files=None, grayscale=False)</code>","text":"<p>Read multiple COCO annotation files and return a dictionary of Labels.</p> <p>This function is designed to handle datasets with multiple splits (train/val/test) or multiple annotation files.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_path</code> <code>Union[str, Path]</code> <p>Root directory containing COCO annotation files.</p> required <code>json_files</code> <code>Optional[List[str]]</code> <p>List of specific JSON filenames to load. If None, automatically        discovers all .json files in the dataset directory.</p> <code>None</code> <code>grayscale</code> <code>bool</code> <p>If True, load images as grayscale (1 channel). If False, load as        RGB (3 channels). Default is False.</p> <code>False</code> <p>Returns:</p> Type Description <code>Dict[str, Labels]</code> <p>Dictionary mapping split names to Labels objects.</p> Source code in <code>sleap_io/io/coco.py</code> <pre><code>def read_labels_set(\n    dataset_path: Union[str, Path],\n    json_files: Optional[List[str]] = None,\n    grayscale: bool = False,\n) -&gt; Dict[str, Labels]:\n    \"\"\"Read multiple COCO annotation files and return a dictionary of Labels.\n\n    This function is designed to handle datasets with multiple splits (train/val/test)\n    or multiple annotation files.\n\n    Args:\n        dataset_path: Root directory containing COCO annotation files.\n        json_files: List of specific JSON filenames to load. If None, automatically\n                   discovers all .json files in the dataset directory.\n        grayscale: If True, load images as grayscale (1 channel). If False, load as\n                   RGB (3 channels). Default is False.\n\n    Returns:\n        Dictionary mapping split names to Labels objects.\n    \"\"\"\n    dataset_path = Path(dataset_path)\n\n    if json_files is None:\n        # Auto-discover JSON files\n        json_files = [f.name for f in dataset_path.glob(\"*.json\")]\n        if not json_files:\n            raise FileNotFoundError(f\"No JSON annotation files found in {dataset_path}\")\n\n    labels_dict = {}\n\n    for json_file in json_files:\n        json_path = dataset_path / json_file\n\n        # Use filename (without extension) as split name\n        split_name = json_path.stem\n\n        # Load labels for this split\n        labels = read_labels(json_path, dataset_root=dataset_path, grayscale=grayscale)\n        labels_dict[split_name] = labels\n\n    return labels_dict\n</code></pre>"},{"location":"reference/sleap_io/io/coco/#sleap_io.io.coco.resolve_image_path","title":"<code>resolve_image_path(image_filename, dataset_root)</code>","text":"<p>Resolve image file path handling various directory structures.</p> <p>Parameters:</p> Name Type Description Default <code>image_filename</code> <code>str</code> <p>Image filename from COCO annotation.</p> required <code>dataset_root</code> <code>Path</code> <p>Root directory of the dataset.</p> required <p>Returns:</p> Type Description <code>Path</code> <p>Resolved absolute path to the image file.</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If image file cannot be found.</p> Source code in <code>sleap_io/io/coco.py</code> <pre><code>def resolve_image_path(image_filename: str, dataset_root: Path) -&gt; Path:\n    \"\"\"Resolve image file path handling various directory structures.\n\n    Args:\n        image_filename: Image filename from COCO annotation.\n        dataset_root: Root directory of the dataset.\n\n    Returns:\n        Resolved absolute path to the image file.\n\n    Raises:\n        FileNotFoundError: If image file cannot be found.\n    \"\"\"\n    # Try direct path first\n    image_path = dataset_root / image_filename\n    if image_path.exists():\n        return image_path\n\n    # Try common variations\n    common_prefixes = [\"images\", \"imgs\", \"data/images\", \"\"]\n\n    for prefix in common_prefixes:\n        if prefix:\n            test_path = dataset_root / prefix / image_filename\n        else:\n            # Try finding the file anywhere in the dataset\n            test_path = None\n            for found_path in dataset_root.rglob(Path(image_filename).name):\n                if found_path.is_file():\n                    test_path = found_path\n                    break\n\n        if test_path and test_path.exists():\n            return test_path\n\n    raise FileNotFoundError(\n        f\"Image file not found: {image_filename} (searched in {dataset_root})\"\n    )\n</code></pre>"},{"location":"reference/sleap_io/io/dlc/","title":"dlc","text":""},{"location":"reference/sleap_io/io/dlc/#sleap_io.io.dlc","title":"<code>sleap_io.io.dlc</code>","text":"<p>This module handles direct I/O operations for working with DeepLabCut (DLC) files.</p> <p>Functions:</p> Name Description <code>is_dlc_file</code> <p>Check if file is a DLC CSV file.</p> <code>load_dlc</code> <p>Load DeepLabCut annotations from CSV file.</p>"},{"location":"reference/sleap_io/io/dlc/#sleap_io.io.dlc.is_dlc_file","title":"<code>is_dlc_file(filename)</code>","text":"<p>Check if file is a DLC CSV file.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>Union[str, Path]</code> <p>Path to file to check.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if file appears to be a DLC CSV file.</p> Source code in <code>sleap_io/io/dlc.py</code> <pre><code>def is_dlc_file(filename: Union[str, Path]) -&gt; bool:\n    \"\"\"Check if file is a DLC CSV file.\n\n    Args:\n        filename: Path to file to check.\n\n    Returns:\n        True if file appears to be a DLC CSV file.\n    \"\"\"\n    try:\n        # Read first few lines as raw text to check for DLC structure\n        with open(filename, \"r\") as f:\n            lines = [f.readline().strip() for _ in range(4)]\n\n        # Join all lines to search for DLC patterns\n        content = \"\\n\".join(lines).lower()\n\n        # Check for DLC's characteristic patterns\n        has_scorer = \"scorer\" in content\n        has_coords = \"coords\" in content\n        has_xy = \"x\" in content and \"y\" in content\n        has_bodyparts = \"bodyparts\" in content or any(\n            part in content for part in [\"animal\", \"individual\"]\n        )\n\n        return has_scorer and has_coords and has_xy and has_bodyparts\n\n    except Exception:\n        return False\n</code></pre>"},{"location":"reference/sleap_io/io/dlc/#sleap_io.io.dlc.load_dlc","title":"<code>load_dlc(filename, video_search_paths=None, **kwargs)</code>","text":"<p>Load DeepLabCut annotations from CSV file.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>Union[str, Path]</code> <p>Path to DLC CSV file.</p> required <code>video_search_paths</code> <code>Optional[list[Union[str, Path]]]</code> <p>List of paths to search for video files.</p> <code>None</code> <code>**kwargs</code> <p>Additional arguments (unused).</p> <code>{}</code> <p>Returns:</p> Type Description <code>Labels</code> <p>Labels object with loaded data.</p> Source code in <code>sleap_io/io/dlc.py</code> <pre><code>def load_dlc(\n    filename: Union[str, Path],\n    video_search_paths: Optional[list[Union[str, Path]]] = None,\n    **kwargs,\n) -&gt; Labels:\n    \"\"\"Load DeepLabCut annotations from CSV file.\n\n    Args:\n        filename: Path to DLC CSV file.\n        video_search_paths: List of paths to search for video files.\n        **kwargs: Additional arguments (unused).\n\n    Returns:\n        Labels object with loaded data.\n    \"\"\"\n    filename = Path(filename)\n\n    # Try reading first few rows to determine format\n    try:\n        # Try multi-animal format first (header rows 1-3, skipping scorer row)\n        df = pd.read_csv(filename, header=[1, 2, 3], nrows=2)\n        is_multianimal = df.columns[0][0] == \"individuals\"\n    except Exception:\n        # Fall back to single-animal format\n        is_multianimal = False\n\n    # Read full file with appropriate header levels\n    if is_multianimal:\n        # Multi-animal format: skip scorer row, use individuals/bodyparts/coords\n        df = pd.read_csv(filename, header=[1, 2, 3], index_col=0)\n    else:\n        # Single-animal format: use scorer/bodyparts/coords\n        df = pd.read_csv(filename, header=[0, 1, 2], index_col=0)\n\n    # Parse structure based on format\n    if is_multianimal:\n        skeleton, tracks = _parse_multi_animal_structure(df)\n    else:\n        skeleton = _parse_single_animal_structure(df)\n        tracks = []\n\n    # First, group all image paths by their video directory\n    video_image_paths = {}\n    frame_map = {}  # Maps image path to frame index\n\n    for idx in df.index:\n        img_path = str(idx)\n        frame_idx = _extract_frame_index(img_path)\n        frame_map[img_path] = frame_idx\n\n        # Extract video name from path\n        # e.g., \"labeled-data/video/img000.png\" -&gt; \"video\"\n        path_parts = Path(img_path).parts\n        if len(path_parts) &gt;= 2 and path_parts[0] == \"labeled-data\":\n            video_name = path_parts[1]\n        else:\n            video_name = Path(img_path).parent.name or \"default\"\n\n        if video_name not in video_image_paths:\n            video_image_paths[video_name] = []\n        video_image_paths[video_name].append(img_path)\n\n    # Create one Video object per video directory\n    videos = {}\n    for video_name, image_paths in video_image_paths.items():\n        # Sort image paths to ensure consistent ordering\n        sorted_paths = sorted(image_paths, key=lambda p: frame_map[p])\n\n        # Find the actual image files\n        actual_image_files = []\n        for img_path in sorted_paths:\n            # First try the full path from CSV\n            full_path = filename.parent / img_path\n            if full_path.exists():\n                actual_image_files.append(str(full_path))\n            else:\n                # Try just the filename in the same directory as the CSV\n                img_name = Path(img_path).name\n                simple_path = filename.parent / img_name\n                if simple_path.exists():\n                    actual_image_files.append(str(simple_path))\n                else:\n                    # Try going up one directory from CSV location\n                    # (CSV in subdir references parent/subdir/img.png)\n                    parent_path = filename.parent.parent / img_path\n                    if parent_path.exists():\n                        actual_image_files.append(str(parent_path))\n\n        # Only create video if we found actual images\n        if actual_image_files:\n            videos[video_name] = Video.from_filename(actual_image_files)\n\n    # Parse the actual data rows and create labeled frames\n    labeled_frames = []\n    for idx, row in df.iterrows():\n        # Get image path from index\n        img_path = str(idx)\n        frame_idx = _extract_frame_index(img_path)\n\n        # Determine which video this frame belongs to\n        path_parts = Path(img_path).parts\n        if len(path_parts) &gt;= 2 and path_parts[0] == \"labeled-data\":\n            video_name = path_parts[1]\n        else:\n            video_name = Path(img_path).parent.name or \"default\"\n\n        # Skip if we don't have a video for this frame\n        if video_name not in videos:\n            continue\n\n        # Parse instances for this frame\n        if is_multianimal:\n            instances = _parse_multi_animal_row(row, skeleton, tracks)\n        else:\n            instances = _parse_single_animal_row(row, skeleton)\n\n        if instances:\n            # Get the index of this image within its video\n            sorted_video_paths = sorted(\n                video_image_paths[video_name], key=lambda p: frame_map[p]\n            )\n            video_frame_idx = sorted_video_paths.index(img_path)\n            labeled_frames.append(\n                LabeledFrame(\n                    video=videos[video_name],\n                    frame_idx=video_frame_idx,\n                    instances=instances,\n                )\n            )\n\n    unique_videos = list(videos.values())\n\n    return Labels(\n        labeled_frames=labeled_frames,\n        videos=unique_videos,\n        tracks=tracks,\n        skeletons=[skeleton] if skeleton.nodes else [],\n    )\n</code></pre>"},{"location":"reference/sleap_io/io/jabs/","title":"jabs","text":""},{"location":"reference/sleap_io/io/jabs/#sleap_io.io.jabs","title":"<code>sleap_io.io.jabs</code>","text":"<p>This module handles direct I/O operations for working with JABS files.</p> <p>Functions:</p> Name Description <code>convert_labels</code> <p>Convert a <code>Labels</code> object into JABS-formatted annotations.</p> <code>get_max_ids_in_video</code> <p>Determine the maximum number of identities that exist at the same time.</p> <code>make_simple_skeleton</code> <p>Create a <code>Skeleton</code> with a requested number of nodes attached in a line.</p> <code>prediction_to_instance</code> <p>Create an <code>Instance</code> from prediction data.</p> <code>read_labels</code> <p>Read JABS style pose from a file and return a <code>Labels</code> object.</p> <code>tracklets_to_v3</code> <p>Changes identity tracklets to the v3 format specifications.</p> <code>write_jabs_v2</code> <p>Write JABS pose file v2 data to file.</p> <code>write_jabs_v3</code> <p>Write JABS pose file v3 data to file.</p> <code>write_jabs_v4</code> <p>Write JABS pose file v4 data to file.</p> <code>write_jabs_v5</code> <p>Write JABS pose file v5 data to file.</p> <code>write_labels</code> <p>Convert and save a SLEAP <code>Labels</code> object to a JABS pose file.</p>"},{"location":"reference/sleap_io/io/jabs/#sleap_io.io.jabs.convert_labels","title":"<code>convert_labels(all_labels, video)</code>","text":"<p>Convert a <code>Labels</code> object into JABS-formatted annotations.</p> <p>Parameters:</p> Name Type Description Default <code>all_labels</code> <code>Labels</code> <p>SLEAP <code>Labels</code> to be converted to JABS format.</p> required <code>video</code> <code>Video</code> <p>name of video to be converted</p> required <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary of JABS data of the <code>Labels</code> data.</p> Source code in <code>sleap_io/io/jabs.py</code> <pre><code>def convert_labels(all_labels: Labels, video: Video) -&gt; dict:\n    \"\"\"Convert a `Labels` object into JABS-formatted annotations.\n\n    Args:\n        all_labels: SLEAP `Labels` to be converted to JABS format.\n        video: name of video to be converted\n\n    Returns:\n        Dictionary of JABS data of the `Labels` data.\n    \"\"\"\n    labels = all_labels.find(video=video)\n\n    # Determine shape of output\n    # Low estimate of last frame labeled\n    num_frames = max([x.frame_idx for x in labels]) + 1\n    # If there is metadata available for the video, use that\n    if video.shape:\n        num_frames = max(num_frames, video.shape[0])\n    if len(all_labels.skeletons) == 1:\n        skeleton = all_labels.skeleton\n    elif len(all_labels.skeletons) &gt; 1:\n        skeleton = [x for x in all_labels.skeletons if x.name == \"Mouse\"]\n        if len(skeleton) == 0:\n            raise ValueError(\"No mouse skeleton found in labels.\")\n        skeleton = skeleton[0]\n    num_keypoints = len(skeleton.nodes)\n    num_mice = get_max_ids_in_video(labels, key=\"Mouse\")\n    # Note that this 1-indexes identities\n    track_2_idx = {\n        key: val + 1\n        for key, val in zip(all_labels.tracks, range(len(all_labels.tracks)))\n    }\n    last_unassigned_id = num_mice\n\n    keypoint_mat = np.zeros([num_frames, num_mice, num_keypoints, 2], dtype=np.uint16)\n    confidence_mat = np.zeros([num_frames, num_mice, num_keypoints], dtype=np.float32)\n    identity_mat = np.zeros([num_frames, num_mice], dtype=np.uint32)\n    instance_vector = np.zeros([num_frames], dtype=np.uint8)\n    static_objects = {}\n\n    # Populate the matrices with data\n    for label in labels:\n        assigned_instances = 0\n        for instance_idx, instance in enumerate(label.instances):\n            # Static objects just get added to the object dict\n            # This will clobber data if more than one frame is annotated\n            if instance.skeleton.name != \"Mouse\":\n                static_objects[instance.skeleton.name] = instance.numpy()\n                continue\n            pose = instance.numpy()\n            if pose.shape[0] != len(JABS_DEFAULT_KEYPOINTS):\n                warnings.warn(\n                    f\"JABS format only supports 12 keypoints for mice. \"\n                    f\"Skipping storage of instance on frame {label.frame_idx} \"\n                    f\"with {len(instance.points)} keypoints.\"\n                )\n                continue\n            missing_points = np.isnan(pose[:, 0])\n            pose[np.isnan(pose)] = 0\n            # JABS stores y,x for poses\n            pose = np.flip(pose.astype(np.uint16), axis=-1)\n            keypoint_mat[label.frame_idx, instance_idx, :, :] = pose\n            confidence_mat[label.frame_idx, instance_idx, ~missing_points] = 1.0\n            if instance.track:\n                identity_mat[label.frame_idx, instance_idx] = track_2_idx[\n                    instance.track\n                ]\n            else:\n                warnings.warn(\n                    f\"Pose with unassigned track found on {label.video.filename} \"\n                    f\"frame {label.frame_idx} instance {instance_idx}. \"\n                    f\"Assigning ID {last_unassigned_id}.\"\n                )\n                identity_mat[label.frame_idx, instance_idx] = last_unassigned_id\n                last_unassigned_id += 1\n            assigned_instances += 1\n        instance_vector[label.frame_idx] = assigned_instances\n\n    # Return the data as a dict\n    return {\n        \"keypoints\": keypoint_mat.astype(np.uint16),\n        \"confidence\": confidence_mat.astype(np.float32),\n        \"identity\": identity_mat.astype(np.uint32),\n        \"num_identities\": instance_vector.astype(np.uint16),\n        \"static_objects\": static_objects,\n    }\n</code></pre>"},{"location":"reference/sleap_io/io/jabs/#sleap_io.io.jabs.get_max_ids_in_video","title":"<code>get_max_ids_in_video(labels, key='Mouse')</code>","text":"<p>Determine the maximum number of identities that exist at the same time.</p> <p>Parameters:</p> Name Type Description Default <code>labels</code> <code>List[Labels]</code> <p>SLEAP <code>Labels</code> to count</p> required <code>key</code> <code>str</code> <p>Name of the skeleton to select for identities</p> <code>'Mouse'</code> <p>Returns:</p> Type Description <code>int</code> <p>Count of the maximum concurrent identities in a single frame</p> Source code in <code>sleap_io/io/jabs.py</code> <pre><code>def get_max_ids_in_video(labels: List[Labels], key: str = \"Mouse\") -&gt; int:\n    \"\"\"Determine the maximum number of identities that exist at the same time.\n\n    Args:\n        labels: SLEAP `Labels` to count\n        key: Name of the skeleton to select for identities\n\n    Returns:\n        Count of the maximum concurrent identities in a single frame\n    \"\"\"\n    max_labels = 0\n    for label in labels:\n        n_labels = sum([x.skeleton.name == key for x in label.instances])\n        max_labels = max(max_labels, n_labels)\n\n    return max_labels\n</code></pre>"},{"location":"reference/sleap_io/io/jabs/#sleap_io.io.jabs.make_simple_skeleton","title":"<code>make_simple_skeleton(name, num_points)</code>","text":"<p>Create a <code>Skeleton</code> with a requested number of nodes attached in a line.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>name of the skeleton and prefix to nodes</p> required <code>num_points</code> <code>int</code> <p>number of points to use in the skeleton</p> required <p>Returns:</p> Type Description <code>Skeleton</code> <p>Generated <code>Skeleton</code>.</p> Source code in <code>sleap_io/io/jabs.py</code> <pre><code>def make_simple_skeleton(name: str, num_points: int) -&gt; Skeleton:\n    \"\"\"Create a `Skeleton` with a requested number of nodes attached in a line.\n\n    Args:\n        name: name of the skeleton and prefix to nodes\n        num_points: number of points to use in the skeleton\n\n    Returns:\n        Generated `Skeleton`.\n    \"\"\"\n    nodes = [Node(name + \"_kp\" + str(i)) for i in range(num_points)]\n    edges = [Edge(nodes[i], nodes[i + 1]) for i in range(num_points - 1)]\n    return Skeleton(nodes, edges, name=name)\n</code></pre>"},{"location":"reference/sleap_io/io/jabs/#sleap_io.io.jabs.prediction_to_instance","title":"<code>prediction_to_instance(data, confidence, skeleton, track=None)</code>","text":"<p>Create an <code>Instance</code> from prediction data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Union[ndarray[uint16], ndarray[float32]]</code> <p>keypoint locations</p> required <code>confidence</code> <code>ndarray[float32]</code> <p>confidence for keypoints</p> required <code>skeleton</code> <code>Skeleton</code> <p><code>Skeleton</code> to use for <code>Instance</code></p> required <code>track</code> <code>Track</code> <p><code>Track</code> to assign to <code>Instance</code></p> <code>None</code> <p>Returns:</p> Type Description <code>Instance</code> <p>Parsed <code>Instance</code>.</p> Source code in <code>sleap_io/io/jabs.py</code> <pre><code>def prediction_to_instance(\n    data: Union[np.ndarray[np.uint16], np.ndarray[np.float32]],\n    confidence: np.ndarray[np.float32],\n    skeleton: Skeleton,\n    track: Track = None,\n) -&gt; Instance:\n    \"\"\"Create an `Instance` from prediction data.\n\n    Args:\n        data: keypoint locations\n        confidence: confidence for keypoints\n        skeleton: `Skeleton` to use for `Instance`\n        track: `Track` to assign to `Instance`\n\n    Returns:\n        Parsed `Instance`.\n    \"\"\"\n    assert len(skeleton.nodes) == data.shape[0], (\n        f\"Skeleton ({len(skeleton.nodes)}) does not match \"\n        f\"number of keypoints ({data.shape[0]})\"\n    )\n\n    points = {}\n    for i, cur_node in enumerate(skeleton.nodes):\n        # confidence of 0 indicates no keypoint predicted for instance\n        if confidence[i] &gt; 0:\n            points[cur_node] = (\n                data[i, 0],\n                data[i, 1],\n                True,\n            )\n\n    if not points:\n        return None\n    else:\n        return Instance(points, skeleton=skeleton, track=track)\n</code></pre>"},{"location":"reference/sleap_io/io/jabs/#sleap_io.io.jabs.read_labels","title":"<code>read_labels(labels_path, skeleton=JABS_DEFAULT_SKELETON)</code>","text":"<p>Read JABS style pose from a file and return a <code>Labels</code> object.</p> <p>TODO: Attributes are ignored, including px_to_cm field. TODO: Segmentation data ignored in v6, but will read in pose. TODO: Lixit static objects currently stored as n_lixit,2 (eg 1 object).       Should be converted to multiple objects</p> <p>Parameters:</p> Name Type Description Default <code>labels_path</code> <code>str</code> <p>Path to the JABS pose file.</p> required <code>skeleton</code> <code>Optional[Skeleton]</code> <p>An optional <code>Skeleton</code> object. Defaults to JABS pose version 2-6.</p> <code>JABS_DEFAULT_SKELETON</code> <p>Returns:</p> Type Description <code>Labels</code> <p>Parsed labels as a <code>Labels</code> instance.</p> Source code in <code>sleap_io/io/jabs.py</code> <pre><code>def read_labels(\n    labels_path: str, skeleton: Optional[Skeleton] = JABS_DEFAULT_SKELETON\n) -&gt; Labels:\n    \"\"\"Read JABS style pose from a file and return a `Labels` object.\n\n    TODO: Attributes are ignored, including px_to_cm field.\n    TODO: Segmentation data ignored in v6, but will read in pose.\n    TODO: Lixit static objects currently stored as n_lixit,2 (eg 1 object).\n          Should be converted to multiple objects\n\n    Args:\n        labels_path: Path to the JABS pose file.\n        skeleton: An optional `Skeleton` object. Defaults to JABS pose version 2-6.\n\n    Returns:\n        Parsed labels as a `Labels` instance.\n    \"\"\"\n    frames: List[LabeledFrame] = []\n    # Video name is the pose file minus the suffix\n    video_name = re.sub(r\"(_pose_est_v[2-6])?\\.h5\", \".avi\", labels_path)\n    video = Video.from_filename(video_name)\n    if not skeleton:\n        skeleton = JABS_DEFAULT_SKELETON\n    tracks = {}\n\n    if not os.access(labels_path, os.F_OK):\n        raise FileNotFoundError(f\"{labels_path} doesn't exist.\")\n    if not os.access(labels_path, os.R_OK):\n        raise PermissionError(f\"{labels_path} cannot be accessed.\")\n\n    with h5py.File(labels_path, \"r\") as pose_file:\n        num_frames = pose_file[\"poseest/points\"].shape[0]\n        try:\n            pose_version = pose_file[\"poseest\"].attrs[\"version\"][0]\n        except (KeyError, IndexError):\n            pose_version = 2\n            data_shape = pose_file[\"poseest/points\"].shape\n            assert len(data_shape) == 3, (\n                f\"Pose version not present and shape does not match single mouse: \"\n                f\"shape of {data_shape} for {labels_path}\"\n            )\n        if pose_version == 2:\n            tracks[1] = Track(\"1\")\n        # Change field name for newer pose formats\n        if pose_version == 3:\n            id_key = \"instance_track_id\"\n        elif pose_version &gt; 3:\n            id_key = \"instance_embed_id\"\n            max_ids = pose_file[\"poseest/points\"].shape[1]\n\n        for frame_idx in range(num_frames):\n            instances = []\n            pose_data = pose_file[\"poseest/points\"][frame_idx, ...]\n            # JABS stores y,x for poses\n            pose_data = np.flip(pose_data, axis=-1)\n            pose_conf = pose_file[\"poseest/confidence\"][frame_idx, ...]\n            # single animal case\n            if pose_version == 2:\n                new_instance = prediction_to_instance(\n                    pose_data, pose_conf, skeleton, tracks[1]\n                )\n                instances.append(new_instance)\n            # multi-animal case\n            if pose_version &gt; 2:\n                pose_ids = pose_file[\"poseest/\" + id_key][frame_idx, ...]\n                # pose_v3 uses another field to describe the number of valid poses\n                if pose_version == 3:\n                    max_ids = pose_file[\"poseest/instance_count\"][frame_idx]\n                for cur_id in range(max_ids):\n                    # v4+ uses reserved values for invalid/unused poses\n                    # Note: ignores 'poseest/id_mask' to keep predictions that\n                    # were not assigned an id\n                    if pose_version &gt; 3 and pose_ids[cur_id] &lt;= 0:\n                        continue\n                    if pose_ids[cur_id] not in tracks.keys():\n                        tracks[pose_ids[cur_id]] = Track(str(pose_ids[cur_id]))\n                    new_instance = prediction_to_instance(\n                        pose_data[cur_id],\n                        pose_conf[cur_id],\n                        skeleton,\n                        tracks[pose_ids[cur_id]],\n                    )\n                    if new_instance:\n                        instances.append(new_instance)\n            # Static objects\n            if (\n                frame_idx == 0\n                and pose_version &gt;= 5\n                and \"static_objects\" in pose_file.keys()\n            ):\n                present_objects = pose_file[\"static_objects\"].keys()\n                for cur_object in present_objects:\n                    object_keypoints = pose_file[\"static_objects/\" + cur_object][:]\n                    object_skeleton = make_simple_skeleton(\n                        cur_object, object_keypoints.shape[0]\n                    )\n                    new_instance = prediction_to_instance(\n                        object_keypoints,\n                        np.ones(object_keypoints.shape[:-1]),\n                        object_skeleton,\n                    )\n                    if new_instance:\n                        instances.append(new_instance)\n            frame_label = LabeledFrame(video, frame_idx, instances)\n            frames.append(frame_label)\n    labels = Labels(frames)\n    labels.provenance[\"filename\"] = labels_path\n    return labels\n</code></pre>"},{"location":"reference/sleap_io/io/jabs/#sleap_io.io.jabs.tracklets_to_v3","title":"<code>tracklets_to_v3(tracklet_matrix)</code>","text":"<p>Changes identity tracklets to the v3 format specifications.</p> v3 specifications require <p>(a) tracklets are 0-indexed (b) tracklets appear in ascending order \u00a9 tracklets exist for continuous blocks of time</p> <p>Parameters:</p> Name Type Description Default <code>tracklet_matrix</code> <code>ndarray</code> <p>Numpy array of shape (frame, n_animals) that contains identity values. Identities are assumed to be 1-indexed.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>A corrected numpy array of the same shape as input</p> Source code in <code>sleap_io/io/jabs.py</code> <pre><code>def tracklets_to_v3(tracklet_matrix: np.ndarray) -&gt; np.ndarray:\n    \"\"\"Changes identity tracklets to the v3 format specifications.\n\n    v3 specifications require:\n        (a) tracklets are 0-indexed\n        (b) tracklets appear in ascending order\n        (c) tracklets exist for continuous blocks of time\n\n    Args:\n        tracklet_matrix: Numpy array of shape (frame, n_animals) that contains\n            identity values. Identities are assumed to be 1-indexed.\n\n    Returns:\n        A corrected numpy array of the same shape as input\n    \"\"\"\n    assert tracklet_matrix.ndim == 2\n\n    # Fragment the tracklets based on gaps\n    valid_ids = np.unique(tracklet_matrix)\n    valid_ids = valid_ids[valid_ids != 0]\n    track_fragments = {}\n    for cur_id in valid_ids:\n        frame_idx, column_idx = np.where(tracklet_matrix == cur_id)\n        gaps = np.nonzero(np.diff(frame_idx) - 1)[0]\n        for sliced_frame, sliced_column in zip(\n            np.split(frame_idx, gaps + 1), np.split(column_idx, gaps + 1)\n        ):\n            # The keys used here are (first frame, first column) such that\n            # sorting can be used for ascending order\n            track_fragments[sliced_frame[0], sliced_column[0]] = sliced_column\n\n    return_mat = np.zeros_like(tracklet_matrix)\n    for next_id, key in enumerate(sorted(track_fragments.keys())):\n        columns_to_assign = track_fragments[key]\n        return_mat[\n            range(key[0], key[0] + len(columns_to_assign)), columns_to_assign\n        ] = next_id\n\n    return return_mat\n</code></pre>"},{"location":"reference/sleap_io/io/jabs/#sleap_io.io.jabs.write_jabs_v2","title":"<code>write_jabs_v2(data, filename)</code>","text":"<p>Write JABS pose file v2 data to file.</p> <p>Writes single mouse pose data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>dict</code> <p>Dictionary of JABS data generated from convert_labels</p> required <code>filename</code> <code>str</code> <p>Filename to write data to</p> required Source code in <code>sleap_io/io/jabs.py</code> <pre><code>def write_jabs_v2(data: dict, filename: str):\n    \"\"\"Write JABS pose file v2 data to file.\n\n    Writes single mouse pose data.\n\n    Args:\n        data: Dictionary of JABS data generated from convert_labels\n        filename: Filename to write data to\n    \"\"\"\n    # Check that we're trying to write single mouse data\n    assert data[\"keypoints\"].shape[1] == 1\n    out_keypoints = np.squeeze(data[\"keypoints\"], axis=1)\n    out_confidences = np.squeeze(data[\"confidence\"], axis=1)\n\n    with h5py.File(filename, \"w\") as h5:\n        pose_grp = h5.require_group(\"poseest\")\n        pose_grp.attrs.update({\"version\": [2, 0]})\n        pose_grp.require_dataset(\n            \"points\", out_keypoints.shape, out_keypoints.dtype, data=out_keypoints\n        )\n        pose_grp.require_dataset(\n            \"confidence\",\n            out_confidences.shape,\n            out_confidences.dtype,\n            data=out_confidences,\n        )\n</code></pre>"},{"location":"reference/sleap_io/io/jabs/#sleap_io.io.jabs.write_jabs_v3","title":"<code>write_jabs_v3(data, filename)</code>","text":"<p>Write JABS pose file v3 data to file.</p> <p>Writes multi-mouse pose data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>dict</code> <p>Dictionary of JABS data generated from convert_labels</p> required <code>filename</code> <code>str</code> <p>Filename to write data to</p> required Source code in <code>sleap_io/io/jabs.py</code> <pre><code>def write_jabs_v3(data: dict, filename: str):\n    \"\"\"Write JABS pose file v3 data to file.\n\n    Writes multi-mouse pose data.\n\n    Args:\n        data: Dictionary of JABS data generated from convert_labels\n        filename: Filename to write data to\n    \"\"\"\n    v3_tracklets = tracklets_to_v3(data[\"identity\"])\n    with h5py.File(filename, \"w\") as h5:\n        pose_grp = h5.require_group(\"poseest\")\n        pose_grp.attrs.update({\"version\": [3, 0]})\n        # keypoint field\n        pose_grp.require_dataset(\n            \"points\",\n            data[\"keypoints\"].shape,\n            data[\"keypoints\"].dtype,\n            data=data[\"keypoints\"],\n        )\n        # confidence field\n        pose_grp.require_dataset(\n            \"confidence\",\n            data[\"confidence\"].shape,\n            data[\"confidence\"].dtype,\n            data=data[\"confidence\"],\n        )\n        # id field\n        pose_grp.require_dataset(\n            \"instance_track_id\",\n            v3_tracklets.shape,\n            v3_tracklets.dtype,\n            data=v3_tracklets,\n        )\n        # instance count field\n        pose_grp.require_dataset(\n            \"instance_count\",\n            data[\"num_identities\"].shape,\n            data[\"num_identities\"].dtype,\n            data=data[\"num_identities\"],\n        )\n        # extra field where we don't have data, so fill with default data\n        pose_grp.require_dataset(\n            \"instance_embedding\",\n            data[\"confidence\"].shape,\n            data[\"confidence\"].dtype,\n            data=np.zeros_like(data[\"confidence\"]),\n        )\n</code></pre>"},{"location":"reference/sleap_io/io/jabs/#sleap_io.io.jabs.write_jabs_v4","title":"<code>write_jabs_v4(data, filename)</code>","text":"<p>Write JABS pose file v4 data to file.</p> <p>Writes multi-mouse pose and longterm identity object data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>dict</code> <p>Dictionary of JABS data generated from convert_labels</p> required <code>filename</code> <code>str</code> <p>Filename to write data to</p> required Source code in <code>sleap_io/io/jabs.py</code> <pre><code>def write_jabs_v4(data: dict, filename: str):\n    \"\"\"Write JABS pose file v4 data to file.\n\n    Writes multi-mouse pose and longterm identity object data.\n\n    Args:\n        data: Dictionary of JABS data generated from convert_labels\n        filename: Filename to write data to\n    \"\"\"\n    # v4 extends v3\n    write_jabs_v3(data, filename)\n    with h5py.File(filename, \"a\") as h5:\n        pose_grp = h5.require_group(\"poseest\")\n        pose_grp.attrs.update({\"version\": [4, 0]})\n        # new fields on top of v4\n        identity_mask_mat = np.all(data[\"confidence\"] == 0, axis=-1).astype(bool)\n        pose_grp.require_dataset(\n            \"id_mask\",\n            identity_mask_mat.shape,\n            identity_mask_mat.dtype,\n            data=identity_mask_mat,\n        )\n        # No identity embedding data\n        # Note that since the identity information doesn't exist, this will break\n        # any functionality that relies on it\n        default_id_embeds = np.zeros(\n            list(identity_mask_mat.shape) + [0], dtype=np.float32\n        )\n        pose_grp.require_dataset(\n            \"identity_embeds\",\n            default_id_embeds.shape,\n            default_id_embeds.dtype,\n            data=default_id_embeds,\n        )\n        default_id_centers = np.zeros(default_id_embeds.shape[1:], dtype=np.float32)\n        pose_grp.require_dataset(\n            \"instance_id_center\",\n            default_id_centers.shape,\n            default_id_centers.dtype,\n            data=default_id_centers,\n        )\n        # v4 uses an id field that is 1-indexed\n        pose_grp.require_dataset(\n            \"instance_embed_id\",\n            data[\"identity\"].shape,\n            data[\"identity\"].dtype,\n            data=data[\"identity\"],\n        )\n</code></pre>"},{"location":"reference/sleap_io/io/jabs/#sleap_io.io.jabs.write_jabs_v5","title":"<code>write_jabs_v5(data, filename)</code>","text":"<p>Write JABS pose file v5 data to file.</p> <p>Writes multi-mouse pose, longterm identity, and static object data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>dict</code> <p>Dictionary of JABS data generated from convert_labels</p> required <code>filename</code> <code>str</code> <p>Filename to write data to</p> required Source code in <code>sleap_io/io/jabs.py</code> <pre><code>def write_jabs_v5(data: dict, filename: str):\n    \"\"\"Write JABS pose file v5 data to file.\n\n    Writes multi-mouse pose, longterm identity, and static object data.\n\n    Args:\n        data: Dictionary of JABS data generated from convert_labels\n        filename: Filename to write data to\n    \"\"\"\n    # v5 extends v4\n    write_jabs_v4(data, filename)\n    with h5py.File(filename, \"a\") as h5:\n        pose_grp = h5.require_group(\"poseest\")\n        pose_grp.attrs.update({\"version\": [5, 0]})\n        if \"static_objects\" in data.keys():\n            object_grp = h5.require_group(\"static_objects\")\n            for object_key, object_keypoints in data[\"static_objects\"].items():\n                object_grp.require_dataset(\n                    object_key,\n                    object_keypoints.shape,\n                    np.uint16,\n                    data=object_keypoints.astype(np.uint16),\n                )\n</code></pre>"},{"location":"reference/sleap_io/io/jabs/#sleap_io.io.jabs.write_labels","title":"<code>write_labels(labels, pose_version, root_folder)</code>","text":"<p>Convert and save a SLEAP <code>Labels</code> object to a JABS pose file.</p> <p>Only supports pose version 2 (single mouse) and 3-5 (multi mouse).</p> <p>Parameters:</p> Name Type Description Default <code>labels</code> <code>Labels</code> <p>SLEAP <code>Labels</code> to be converted to JABS pose format.</p> required <code>pose_version</code> <code>int</code> <p>JABS pose version to use when writing data.</p> required <code>root_folder</code> <code>str</code> <p>Root folder where the jabs files should be written</p> required Source code in <code>sleap_io/io/jabs.py</code> <pre><code>def write_labels(labels: Labels, pose_version: int, root_folder: str):\n    \"\"\"Convert and save a SLEAP `Labels` object to a JABS pose file.\n\n    Only supports pose version 2 (single mouse) and 3-5 (multi mouse).\n\n    Args:\n        labels: SLEAP `Labels` to be converted to JABS pose format.\n        pose_version: JABS pose version to use when writing data.\n        root_folder: Root folder where the jabs files should be written\n    \"\"\"\n    for video in labels.videos:\n        converted_labels = convert_labels(labels, video)\n        out_filename = (\n            os.path.splitext(video.filename)[0] + f\"_pose_est_v{pose_version}.h5\"\n        )\n        if root_folder:\n            out_filename = os.path.join(root_folder, out_filename)\n        os.makedirs(os.path.dirname(out_filename), exist_ok=True)\n        if os.path.exists(out_filename):\n            warnings.warn(f\"Skipping {out_filename} because it already exists.\")\n            continue\n        if pose_version == 2:\n            write_jabs_v2(converted_labels, out_filename)\n        elif pose_version == 3:\n            write_jabs_v3(converted_labels, out_filename)\n        elif pose_version == 4:\n            write_jabs_v4(converted_labels, out_filename)\n        elif pose_version == 5:\n            write_jabs_v5(converted_labels, out_filename)\n        else:\n            raise NotImplementedError(f\"Pose format {pose_version} not supported.\")\n</code></pre>"},{"location":"reference/sleap_io/io/labelstudio/","title":"labelstudio","text":""},{"location":"reference/sleap_io/io/labelstudio/#sleap_io.io.labelstudio","title":"<code>sleap_io.io.labelstudio</code>","text":"<p>This module handles direct I/O operations for working with Labelstudio files.</p> Some important nomenclature <ul> <li><code>tasks</code>: typically maps to a single frame of data to be annotated, closest   correspondence is to <code>LabeledFrame</code></li> <li><code>annotations</code>: collection of points, polygons, relations, etc. corresponds to   <code>Instance</code>s, but a flattened hierarchy</li> </ul> <p>Functions:</p> Name Description <code>build_relation_map</code> <p>Build a two-way relationship map between annotations.</p> <code>convert_labels</code> <p>Convert a <code>Labels</code> object into Label Studio-formatted annotations.</p> <code>filter_and_index</code> <p>Filter annotations based on the type field and index them by ID.</p> <code>infer_nodes</code> <p>Parse the loaded JSON tasks to create a minimal skeleton.</p> <code>parse_tasks</code> <p>Read Label Studio style annotations from a file and return a <code>Labels</code> object.</p> <code>read_labels</code> <p>Read Label Studio style annotations from a file and return a <code>Labels</code> object.</p> <code>task_to_labeled_frame</code> <p>Parse annotations from an entry.</p> <code>video_from_task</code> <p>Given a Label Studio task, retrieve video information.</p> <code>write_labels</code> <p>Convert and save a SLEAP <code>Labels</code> object to a Label Studio <code>.json</code> file.</p>"},{"location":"reference/sleap_io/io/labelstudio/#sleap_io.io.labelstudio.build_relation_map","title":"<code>build_relation_map(annotations)</code>","text":"<p>Build a two-way relationship map between annotations.</p> <p>Parameters:</p> Name Type Description Default <code>annotations</code> <code>Iterable[dict]</code> <p>annotations, presumably, containing relation types</p> required <p>Returns:</p> Type Description <code>Dict[str, List[str]]</code> <p>A two way map of relations indexed by <code>from_id</code> and <code>to_id</code> fields.</p> Source code in <code>sleap_io/io/labelstudio.py</code> <pre><code>def build_relation_map(annotations: Iterable[dict]) -&gt; Dict[str, List[str]]:\n    \"\"\"Build a two-way relationship map between annotations.\n\n    Args:\n        annotations: annotations, presumably, containing relation types\n\n    Returns:\n        A two way map of relations indexed by `from_id` and `to_id` fields.\n    \"\"\"\n    relations = list(filter(lambda d: d[\"type\"] == \"relation\", annotations))\n    relmap: Dict[str, List[str]] = {}\n    for rel in relations:\n        if rel[\"from_id\"] not in relmap:\n            relmap[rel[\"from_id\"]] = []\n        relmap[rel[\"from_id\"]].append(rel[\"to_id\"])\n\n        if rel[\"to_id\"] not in relmap:\n            relmap[rel[\"to_id\"]] = []\n        relmap[rel[\"to_id\"]].append(rel[\"from_id\"])\n    return relmap\n</code></pre>"},{"location":"reference/sleap_io/io/labelstudio/#sleap_io.io.labelstudio.convert_labels","title":"<code>convert_labels(labels)</code>","text":"<p>Convert a <code>Labels</code> object into Label Studio-formatted annotations.</p> <p>Parameters:</p> Name Type Description Default <code>labels</code> <code>Labels</code> <p>SLEAP <code>Labels</code> to be converted to Label Studio task format.</p> required <p>Returns:</p> Type Description <code>List[dict]</code> <p>Label Studio dictionaries of the <code>Labels</code> data.</p> Source code in <code>sleap_io/io/labelstudio.py</code> <pre><code>def convert_labels(labels: Labels) -&gt; List[dict]:\n    \"\"\"Convert a `Labels` object into Label Studio-formatted annotations.\n\n    Args:\n        labels: SLEAP `Labels` to be converted to Label Studio task format.\n\n    Returns:\n        Label Studio dictionaries of the `Labels` data.\n    \"\"\"\n    out = []\n    for frame in labels.labeled_frames:\n        if frame.video.shape is not None:\n            height = frame.video.shape[1]\n            width = frame.video.shape[2]\n        else:\n            height = 100\n            width = 100\n\n        frame_annots = []\n\n        for instance in frame.instances:\n            inst_id = str(uuid.uuid4())\n            frame_annots.append(\n                {\n                    \"original_width\": width,\n                    \"original_height\": height,\n                    \"image_rotation\": 0,\n                    \"value\": {\n                        \"x\": 0,\n                        \"y\": 0,\n                        \"width\": width,\n                        \"height\": height,\n                        \"rotation\": 0,\n                        \"rectanglelabels\": [\n                            \"instance_class\"\n                        ],  # TODO: need to handle instance classes / identity\n                    },\n                    \"id\": inst_id,\n                    \"from_name\": \"individuals\",\n                    \"to_name\": \"image\",\n                    \"type\": \"rectanglelabels\",\n                }\n            )\n\n            for point in instance.points:\n                point_id = str(uuid.uuid4())\n\n                # add this point\n                frame_annots.append(\n                    {\n                        \"original_width\": width,\n                        \"original_height\": height,\n                        \"image_rotation\": 0,\n                        \"value\": {\n                            \"x\": point[\"xy\"][0] / width * 100,\n                            \"y\": point[\"xy\"][1] / height * 100,\n                            \"keypointlabels\": [point[\"name\"]],\n                        },\n                        \"from_name\": \"keypoint-label\",\n                        \"to_name\": \"image\",\n                        \"type\": \"keypointlabels\",\n                        \"id\": point_id,\n                    }\n                )\n\n                # add relationship of point to individual\n                frame_annots.append(\n                    {\n                        \"from_id\": point_id,\n                        \"to_id\": inst_id,\n                        \"type\": \"relation\",\n                        \"direction\": \"right\",\n                    }\n                )\n\n        out.append(\n            {\n                \"data\": {\n                    # 'image': f\"/data/{up_deets['file']}\"\n                },\n                \"meta\": {\n                    \"video\": {\n                        \"filename\": frame.video.filename,\n                        \"frame_idx\": frame.frame_idx,\n                        \"shape\": frame.video.shape,\n                    }\n                },\n                \"annotations\": [\n                    {\n                        \"result\": frame_annots,\n                        \"was_cancelled\": False,\n                        \"ground_truth\": False,\n                        \"created_at\": datetime.datetime.now(\n                            datetime.timezone.utc\n                        ).strftime(\"%Y-%m-%dT%H:%M:%S.%fZ\"),\n                        \"updated_at\": datetime.datetime.now(\n                            datetime.timezone.utc\n                        ).strftime(\"%Y-%m-%dT%H:%M:%S.%fZ\"),\n                        \"lead_time\": 0,\n                        \"result_count\": 1,\n                        # \"completed_by\": user['id']\n                    }\n                ],\n            }\n        )\n\n    return out\n</code></pre>"},{"location":"reference/sleap_io/io/labelstudio/#sleap_io.io.labelstudio.filter_and_index","title":"<code>filter_and_index(annotations, annot_type)</code>","text":"<p>Filter annotations based on the type field and index them by ID.</p> <p>Parameters:</p> Name Type Description Default <code>annotations</code> <code>Iterable[dict]</code> <p>annotations to filter and index</p> required <code>annot_type</code> <code>str</code> <p>annotation type to filter e.x. 'keypointlabels' or 'rectanglelabels'</p> required <p>Returns:</p> Type Description <code>Dict[str, dict]</code> <p>Dict of ndexed and filtered annotations. Only annotations of type <code>annot_type</code> will survive, and annotations are indexed by ID.</p> Source code in <code>sleap_io/io/labelstudio.py</code> <pre><code>def filter_and_index(annotations: Iterable[dict], annot_type: str) -&gt; Dict[str, dict]:\n    \"\"\"Filter annotations based on the type field and index them by ID.\n\n    Args:\n        annotations: annotations to filter and index\n        annot_type: annotation type to filter e.x. 'keypointlabels' or 'rectanglelabels'\n\n    Returns:\n        Dict of ndexed and filtered annotations. Only annotations of type `annot_type`\n        will survive, and annotations are indexed by ID.\n    \"\"\"\n    filtered = list(filter(lambda d: d[\"type\"] == annot_type, annotations))\n    indexed = {item[\"id\"]: item for item in filtered}\n    return indexed\n</code></pre>"},{"location":"reference/sleap_io/io/labelstudio/#sleap_io.io.labelstudio.infer_nodes","title":"<code>infer_nodes(tasks)</code>","text":"<p>Parse the loaded JSON tasks to create a minimal skeleton.</p> <p>Parameters:</p> Name Type Description Default <code>tasks</code> <code>List[Dict]</code> <p>Collection of tasks loaded from Label Studio JSON.</p> required <p>Returns:</p> Type Description <code>Skeleton</code> <p>The inferred <code>Skeleton</code>.</p> Source code in <code>sleap_io/io/labelstudio.py</code> <pre><code>def infer_nodes(tasks: List[Dict]) -&gt; Skeleton:\n    \"\"\"Parse the loaded JSON tasks to create a minimal skeleton.\n\n    Args:\n        tasks: Collection of tasks loaded from Label Studio JSON.\n\n    Returns:\n        The inferred `Skeleton`.\n    \"\"\"\n    node_names = set()\n    for entry in tasks:\n        if \"annotations\" in entry:\n            key = \"annotations\"\n        elif \"completions\" in entry:\n            key = \"completions\"\n        else:\n            raise ValueError(\"Cannot find annotation data for entry!\")\n\n        for annotation in entry[key]:\n            for datum in annotation[\"result\"]:\n                if datum[\"type\"] == \"keypointlabels\":\n                    for node_name in datum[\"value\"][\"keypointlabels\"]:\n                        node_names.add(node_name)\n\n    skeleton = Skeleton(nodes=list(node_names))\n    return skeleton\n</code></pre>"},{"location":"reference/sleap_io/io/labelstudio/#sleap_io.io.labelstudio.parse_tasks","title":"<code>parse_tasks(tasks, skeleton)</code>","text":"<p>Read Label Studio style annotations from a file and return a <code>Labels</code> object.</p> <p>Parameters:</p> Name Type Description Default <code>tasks</code> <code>List[Dict]</code> <p>Collection of tasks to be converted to <code>Labels</code>.</p> required <code>skeleton</code> <code>Skeleton</code> <p><code>Skeleton</code> with the nodes and edges to be used.</p> required <p>Returns:</p> Type Description <code>Labels</code> <p>Parsed labels as a <code>Labels</code> instance.</p> Source code in <code>sleap_io/io/labelstudio.py</code> <pre><code>def parse_tasks(tasks: List[Dict], skeleton: Skeleton) -&gt; Labels:\n    \"\"\"Read Label Studio style annotations from a file and return a `Labels` object.\n\n    Args:\n        tasks: Collection of tasks to be converted to `Labels`.\n        skeleton: `Skeleton` with the nodes and edges to be used.\n\n    Returns:\n        Parsed labels as a `Labels` instance.\n    \"\"\"\n    frames: List[LabeledFrame] = []\n    for entry in tasks:\n        # depending version, we have seen keys `annotations` and `completions`\n        if \"annotations\" in entry:\n            key = \"annotations\"\n        elif \"completions\" in entry:\n            key = \"completions\"\n        else:\n            raise ValueError(\"Cannot find annotation data for entry!\")\n\n        frames.append(task_to_labeled_frame(entry, skeleton, key=key))\n\n    return Labels(frames)\n</code></pre>"},{"location":"reference/sleap_io/io/labelstudio/#sleap_io.io.labelstudio.read_labels","title":"<code>read_labels(labels_path, skeleton=None)</code>","text":"<p>Read Label Studio style annotations from a file and return a <code>Labels</code> object.</p> <p>Parameters:</p> Name Type Description Default <code>labels_path</code> <code>str</code> <p>Path to the Label Studio annotation file, in json format.</p> required <code>skeleton</code> <code>Optional[Union[Skeleton, List[str]]]</code> <p>An optional <code>Skeleton</code> object or list of node names. If not provided (the default), skeleton will be inferred from the data. It may be useful to provide this so the keypoint label types can be filtered to just the ones in the skeleton.</p> <code>None</code> <p>Returns:</p> Type Description <code>Labels</code> <p>Parsed labels as a <code>Labels</code> instance.</p> Source code in <code>sleap_io/io/labelstudio.py</code> <pre><code>def read_labels(\n    labels_path: str, skeleton: Optional[Union[Skeleton, List[str]]] = None\n) -&gt; Labels:\n    \"\"\"Read Label Studio style annotations from a file and return a `Labels` object.\n\n    Args:\n        labels_path: Path to the Label Studio annotation file, in json format.\n        skeleton: An optional `Skeleton` object or list of node names. If not provided\n            (the default), skeleton will be inferred from the data. It may be useful to\n            provide this so the keypoint label types can be filtered to just the ones in\n            the skeleton.\n\n    Returns:\n        Parsed labels as a `Labels` instance.\n    \"\"\"\n    with open(labels_path, \"r\") as task_file:\n        tasks = json.load(task_file)\n\n    if type(skeleton) is list:\n        skeleton = Skeleton(nodes=skeleton)  # type: ignore[arg-type]\n    elif skeleton is None:\n        skeleton = infer_nodes(tasks)\n    else:\n        assert isinstance(skeleton, Skeleton)\n\n    labels = parse_tasks(tasks, skeleton)\n    labels.provenance[\"filename\"] = labels_path\n    return labels\n</code></pre>"},{"location":"reference/sleap_io/io/labelstudio/#sleap_io.io.labelstudio.task_to_labeled_frame","title":"<code>task_to_labeled_frame(task, skeleton, key='annotations')</code>","text":"<p>Parse annotations from an entry.</p> <p>Parameters:</p> Name Type Description Default <code>task</code> <code>dict</code> <p>Label Studio task to be parsed.</p> required <code>skeleton</code> <code>Skeleton</code> <p>Skeleton to use for parsing.</p> required <code>key</code> <code>str</code> <p>Key to use for parsing annotations. Defaults to \"annotations\".</p> <code>'annotations'</code> <p>Returns:</p> Type Description <code>LabeledFrame</code> <p>Parsed <code>LabeledFrame</code> instance.</p> Source code in <code>sleap_io/io/labelstudio.py</code> <pre><code>def task_to_labeled_frame(\n    task: dict, skeleton: Skeleton, key: str = \"annotations\"\n) -&gt; LabeledFrame:\n    \"\"\"Parse annotations from an entry.\n\n    Args:\n        task: Label Studio task to be parsed.\n        skeleton: Skeleton to use for parsing.\n        key: Key to use for parsing annotations. Defaults to \"annotations\".\n\n    Returns:\n        Parsed `LabeledFrame` instance.\n    \"\"\"\n    if len(task[key]) &gt; 1:\n        warnings.warn(\n            f\"Task {task.get('id', '??')}: Multiple annotations found, \"\n            \"only taking the first!\"\n        )\n\n    # only parse the first entry result\n    to_parse = task[key][0][\"result\"]\n\n    individuals = filter_and_index(to_parse, \"rectanglelabels\")\n    keypoints = filter_and_index(to_parse, \"keypointlabels\")\n    relations = build_relation_map(to_parse)\n    instances = []\n\n    if len(individuals) &gt; 0:\n        # multi animal case:\n        for indv_id, indv in individuals.items():\n            points = {}\n            for rel in relations[indv_id]:\n                kpt = keypoints.pop(rel)\n                node_name = kpt[\"value\"][\"keypointlabels\"][0]\n                x_pos = (kpt[\"value\"][\"x\"] * kpt[\"original_width\"]) / 100\n                y_pos = (kpt[\"value\"][\"y\"] * kpt[\"original_height\"]) / 100\n\n                # If the value is a NAN, the user did not mark this keypoint\n                if math.isnan(x_pos) or math.isnan(y_pos):\n                    continue\n\n                points[node_name] = (x_pos, y_pos)\n\n            if len(points) &gt; 0:\n                instances.append(Instance(points, skeleton))\n\n    # If this is multi-animal, any leftover keypoints should be unique bodyparts, and\n    # will be collected here if single-animal, we only have 'unique bodyparts' [in a\n    # way] and the process is identical\n    points = {}\n    for _, kpt in keypoints.items():\n        node_name = kpt[\"value\"][\"keypointlabels\"][0]\n        if node_name not in skeleton:\n            continue\n        points[node_name] = (\n            (kpt[\"value\"][\"x\"] * kpt[\"original_width\"]) / 100,\n            (kpt[\"value\"][\"y\"] * kpt[\"original_height\"]) / 100,\n        )\n    if len(points) &gt; 0:\n        instances.append(Instance(points, skeleton))\n\n    video, frame_idx = video_from_task(task)\n\n    return LabeledFrame(video, frame_idx, instances)\n</code></pre>"},{"location":"reference/sleap_io/io/labelstudio/#sleap_io.io.labelstudio.video_from_task","title":"<code>video_from_task(task)</code>","text":"<p>Given a Label Studio task, retrieve video information.</p> <p>Parameters:</p> Name Type Description Default <code>task</code> <code>dict</code> <p>Label Studio task</p> required <p>Returns:</p> Type Description <code>Tuple[Video, int]</code> <p>Video and frame index for this task</p> Source code in <code>sleap_io/io/labelstudio.py</code> <pre><code>def video_from_task(task: dict) -&gt; Tuple[Video, int]:\n    \"\"\"Given a Label Studio task, retrieve video information.\n\n    Args:\n        task: Label Studio task\n\n    Returns:\n        Video and frame index for this task\n    \"\"\"\n    if \"meta\" in task and \"video\" in task[\"meta\"]:\n        video = Video(task[\"meta\"][\"video\"][\"filename\"], task[\"meta\"][\"video\"][\"shape\"])\n        frame_idx = task[\"meta\"][\"video\"][\"frame_idx\"]\n        return video, frame_idx\n\n    else:\n        raise KeyError(\"Unable to locate video information for task!\", task)\n</code></pre>"},{"location":"reference/sleap_io/io/labelstudio/#sleap_io.io.labelstudio.write_labels","title":"<code>write_labels(labels, filename)</code>","text":"<p>Convert and save a SLEAP <code>Labels</code> object to a Label Studio <code>.json</code> file.</p> <p>Parameters:</p> Name Type Description Default <code>labels</code> <code>Labels</code> <p>SLEAP <code>Labels</code> to be converted to Label Studio task format.</p> required <code>filename</code> <code>str</code> <p>Path to save Label Studio annotations (<code>.json</code>).</p> required Source code in <code>sleap_io/io/labelstudio.py</code> <pre><code>def write_labels(labels: Labels, filename: str):\n    \"\"\"Convert and save a SLEAP `Labels` object to a Label Studio `.json` file.\n\n    Args:\n        labels: SLEAP `Labels` to be converted to Label Studio task format.\n        filename: Path to save Label Studio annotations (`.json`).\n    \"\"\"\n\n    def _encode(obj):\n        if type(obj).__name__ == \"uint64\":\n            return int(obj)\n\n    ls_dicts = convert_labels(labels)\n    with open(filename, \"w\") as f:\n        json.dump(ls_dicts, f, indent=4, default=_encode)\n</code></pre>"},{"location":"reference/sleap_io/io/leap/","title":"leap","text":""},{"location":"reference/sleap_io/io/leap/#sleap_io.io.leap","title":"<code>sleap_io.io.leap</code>","text":"<p>This module handles direct I/O operations for working with LEAP .mat files.</p> <p>Functions:</p> Name Description <code>read_labels</code> <p>Read LEAP pose data from a .mat file and return a <code>Labels</code> object.</p>"},{"location":"reference/sleap_io/io/leap/#sleap_io.io.leap.read_labels","title":"<code>read_labels(labels_path, skeleton=None)</code>","text":"<p>Read LEAP pose data from a .mat file and return a <code>Labels</code> object.</p> <p>Parameters:</p> Name Type Description Default <code>labels_path</code> <code>str</code> <p>Path to the LEAP .mat pose file.</p> required <code>skeleton</code> <code>Optional[Skeleton]</code> <p>An optional <code>Skeleton</code> object. If not provided, will be constructed from the data in the file.</p> <code>None</code> <p>Returns:</p> Type Description <code>Labels</code> <p>Parsed labels as a <code>Labels</code> instance.</p> Source code in <code>sleap_io/io/leap.py</code> <pre><code>def read_labels(labels_path: str, skeleton: Optional[Skeleton] = None) -&gt; Labels:\n    \"\"\"Read LEAP pose data from a .mat file and return a `Labels` object.\n\n    Args:\n        labels_path: Path to the LEAP .mat pose file.\n        skeleton: An optional `Skeleton` object. If not provided, will be constructed\n            from the data in the file.\n\n    Returns:\n        Parsed labels as a `Labels` instance.\n    \"\"\"\n    try:\n        from pymatreader import read_mat\n    except ImportError:\n        raise ImportError(\n            \"pymatreader is required to read LEAP .mat files. \"\n            \"Install it with: pip install sleap-io[mat]\"\n        )\n\n    # Load the MATLAB data\n    mat_data = read_mat(labels_path)\n\n    # Extract video path\n    video_path = mat_data.get(\"boxPath\", None)\n    if video_path is None:\n        # Try to infer video path from labels path\n        video_path = Path(labels_path).with_suffix(\".mp4\")\n\n    # Create Video object\n    video = Video.from_filename(str(video_path))\n\n    # Parse skeleton if not provided\n    if skeleton is None:\n        skeleton = _parse_skeleton(mat_data)\n\n    # Parse pose data\n    labeled_frames = _parse_pose_data(mat_data, video, skeleton)\n\n    # Create Labels object\n    labels = Labels(\n        labeled_frames=labeled_frames,\n        videos=[video],\n        skeletons=[skeleton],\n    )\n\n    return labels\n</code></pre>"},{"location":"reference/sleap_io/io/main/","title":"main","text":""},{"location":"reference/sleap_io/io/main/#sleap_io.io.main","title":"<code>sleap_io.io.main</code>","text":"<p>This module contains high-level wrappers for utilizing different I/O backends.</p> <p>Functions:</p> Name Description <code>load_alphatracker</code> <p>Read AlphaTracker annotations from a file and return a <code>Labels</code> object.</p> <code>load_coco</code> <p>Load a COCO-style pose dataset and return a Labels object.</p> <code>load_dlc</code> <p>Read DeepLabCut annotations from a CSV file and return a <code>Labels</code> object.</p> <code>load_file</code> <p>Load a file and return the appropriate object.</p> <code>load_jabs</code> <p>Read JABS-style predictions from a file and return a <code>Labels</code> object.</p> <code>load_labels_set</code> <p>Load a LabelsSet from multiple files.</p> <code>load_labelstudio</code> <p>Read Label Studio-style annotations from a file and return a <code>Labels</code> object.</p> <code>load_leap</code> <p>Load a LEAP dataset from a .mat file.</p> <code>load_nwb</code> <p>Load an NWB dataset as a SLEAP <code>Labels</code> object.</p> <code>load_skeleton</code> <p>Load skeleton(s) from a JSON, YAML, or SLP file.</p> <code>load_slp</code> <p>Load a SLEAP dataset.</p> <code>load_ultralytics</code> <p>Load an Ultralytics YOLO pose dataset as a SLEAP <code>Labels</code> object.</p> <code>load_video</code> <p>Load a video file.</p> <code>save_file</code> <p>Save a file based on the extension.</p> <code>save_jabs</code> <p>Save a SLEAP dataset to JABS pose file format.</p> <code>save_labelstudio</code> <p>Save a SLEAP dataset to Label Studio format.</p> <code>save_nwb</code> <p>Save a SLEAP dataset to NWB format.</p> <code>save_skeleton</code> <p>Save skeleton(s) to a JSON or YAML file.</p> <code>save_slp</code> <p>Save a SLEAP dataset to a <code>.slp</code> file.</p> <code>save_ultralytics</code> <p>Save a SLEAP dataset to Ultralytics YOLO pose format.</p> <code>save_video</code> <p>Write a list of frames to a video file.</p>"},{"location":"reference/sleap_io/io/main/#sleap_io.io.main.load_alphatracker","title":"<code>load_alphatracker(filename)</code>","text":"<p>Read AlphaTracker annotations from a file and return a <code>Labels</code> object.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>Path to the AlphaTracker annotation file in JSON format.</p> required <p>Returns:</p> Type Description <code>Labels</code> <p>Parsed labels as a <code>Labels</code> instance.</p> Source code in <code>sleap_io/io/main.py</code> <pre><code>def load_alphatracker(filename: str) -&gt; Labels:\n    \"\"\"Read AlphaTracker annotations from a file and return a `Labels` object.\n\n    Args:\n        filename: Path to the AlphaTracker annotation file in JSON format.\n\n    Returns:\n        Parsed labels as a `Labels` instance.\n    \"\"\"\n    return alphatracker.read_labels(filename)\n</code></pre>"},{"location":"reference/sleap_io/io/main/#sleap_io.io.main.load_coco","title":"<code>load_coco(json_path, dataset_root=None, grayscale=False, **kwargs)</code>","text":"<p>Load a COCO-style pose dataset and return a Labels object.</p> <p>Parameters:</p> Name Type Description Default <code>json_path</code> <code>str</code> <p>Path to the COCO annotation JSON file.</p> required <code>dataset_root</code> <code>Optional[str]</code> <p>Root directory of the dataset. If None, uses parent directory          of json_path.</p> <code>None</code> <code>grayscale</code> <code>bool</code> <p>If True, load images as grayscale (1 channel). If False, load as        RGB (3 channels). Default is False.</p> <code>False</code> <code>**kwargs</code> <p>Additional arguments (currently unused).</p> <code>{}</code> <p>Returns:</p> Type Description <code>Labels</code> <p>The dataset as a <code>Labels</code> object.</p> Source code in <code>sleap_io/io/main.py</code> <pre><code>def load_coco(\n    json_path: str,\n    dataset_root: Optional[str] = None,\n    grayscale: bool = False,\n    **kwargs,\n) -&gt; Labels:\n    \"\"\"Load a COCO-style pose dataset and return a Labels object.\n\n    Args:\n        json_path: Path to the COCO annotation JSON file.\n        dataset_root: Root directory of the dataset. If None, uses parent directory\n                     of json_path.\n        grayscale: If True, load images as grayscale (1 channel). If False, load as\n                   RGB (3 channels). Default is False.\n        **kwargs: Additional arguments (currently unused).\n\n    Returns:\n        The dataset as a `Labels` object.\n    \"\"\"\n    return coco.read_labels(json_path, dataset_root=dataset_root, grayscale=grayscale)\n</code></pre>"},{"location":"reference/sleap_io/io/main/#sleap_io.io.main.load_dlc","title":"<code>load_dlc(filename, video_search_paths=None, **kwargs)</code>","text":"<p>Read DeepLabCut annotations from a CSV file and return a <code>Labels</code> object.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>Path to DLC CSV file with annotations.</p> required <code>video_search_paths</code> <code>Optional[List[Union[str, Path]]]</code> <p>Optional list of paths to search for video files.</p> <code>None</code> <code>**kwargs</code> <p>Additional arguments passed to DLC loader.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Labels</code> <p>Parsed labels as a <code>Labels</code> instance.</p> Source code in <code>sleap_io/io/main.py</code> <pre><code>def load_dlc(\n    filename: str, video_search_paths: Optional[List[Union[str, Path]]] = None, **kwargs\n) -&gt; Labels:\n    \"\"\"Read DeepLabCut annotations from a CSV file and return a `Labels` object.\n\n    Args:\n        filename: Path to DLC CSV file with annotations.\n        video_search_paths: Optional list of paths to search for video files.\n        **kwargs: Additional arguments passed to DLC loader.\n\n    Returns:\n        Parsed labels as a `Labels` instance.\n    \"\"\"\n    return dlc.load_dlc(filename, video_search_paths=video_search_paths, **kwargs)\n</code></pre>"},{"location":"reference/sleap_io/io/main/#sleap_io.io.main.load_file","title":"<code>load_file(filename, format=None, **kwargs)</code>","text":"<p>Load a file and return the appropriate object.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str | Path</code> <p>Path to a file.</p> required <code>format</code> <code>Optional[str]</code> <p>Optional format to load as. If not provided, will be inferred from the file extension. Available formats are: \"slp\", \"nwb\", \"alphatracker\", \"labelstudio\", \"coco\", \"jabs\", \"dlc\", \"ultralytics\", \"leap\", and \"video\".</p> <code>None</code> <code>**kwargs</code> <p>Additional arguments passed to the format-specific loading function: - For \"slp\" format: No additional arguments. - For \"nwb\" format: No additional arguments. - For \"alphatracker\" format: No additional arguments. - For \"leap\" format: skeleton (Optional[Skeleton]): Skeleton to use if not   defined in the file. - For \"labelstudio\" format: skeleton (Optional[Skeleton]): Skeleton to   use for   the labels. - For \"coco\" format: dataset_root (Optional[str]): Root directory of the   dataset. grayscale (bool): If True, load images as grayscale (1 channel).   If False, load as RGB (3 channels). Default is False. - For \"jabs\" format: skeleton (Optional[Skeleton]): Skeleton to use for   the labels. - For \"dlc\" format: video_search_paths (Optional[List[str]]): Paths to   search for video files. - For \"ultralytics\" format: See <code>load_ultralytics</code> for supported arguments. - For \"video\" format: See <code>load_video</code> for supported arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Union[Labels, Video]</code> <p>A <code>Labels</code> or <code>Video</code> object.</p> Source code in <code>sleap_io/io/main.py</code> <pre><code>def load_file(\n    filename: str | Path, format: Optional[str] = None, **kwargs\n) -&gt; Union[Labels, Video]:\n    \"\"\"Load a file and return the appropriate object.\n\n    Args:\n        filename: Path to a file.\n        format: Optional format to load as. If not provided, will be inferred from the\n            file extension. Available formats are: \"slp\", \"nwb\", \"alphatracker\",\n            \"labelstudio\", \"coco\", \"jabs\", \"dlc\", \"ultralytics\", \"leap\", and \"video\".\n        **kwargs: Additional arguments passed to the format-specific loading function:\n            - For \"slp\" format: No additional arguments.\n            - For \"nwb\" format: No additional arguments.\n            - For \"alphatracker\" format: No additional arguments.\n            - For \"leap\" format: skeleton (Optional[Skeleton]): Skeleton to use if not\n              defined in the file.\n            - For \"labelstudio\" format: skeleton (Optional[Skeleton]): Skeleton to\n              use for\n              the labels.\n            - For \"coco\" format: dataset_root (Optional[str]): Root directory of the\n              dataset. grayscale (bool): If True, load images as grayscale (1 channel).\n              If False, load as RGB (3 channels). Default is False.\n            - For \"jabs\" format: skeleton (Optional[Skeleton]): Skeleton to use for\n              the labels.\n            - For \"dlc\" format: video_search_paths (Optional[List[str]]): Paths to\n              search for video files.\n            - For \"ultralytics\" format: See `load_ultralytics` for supported arguments.\n            - For \"video\" format: See `load_video` for supported arguments.\n\n    Returns:\n        A `Labels` or `Video` object.\n    \"\"\"\n    if isinstance(filename, Path):\n        filename = filename.as_posix()\n\n    if format is None:\n        if filename.endswith(\".slp\"):\n            format = \"slp\"\n        elif filename.endswith(\".nwb\"):\n            format = \"nwb\"\n        elif filename.endswith(\".mat\"):\n            format = \"leap\"\n        elif filename.endswith(\".json\"):\n            # Detect JSON format: AlphaTracker, COCO, or Label Studio\n            if _detect_alphatracker_format(filename):\n                format = \"alphatracker\"\n            elif _detect_coco_format(filename):\n                format = \"coco\"\n            else:\n                format = \"json\"\n        elif filename.endswith(\".h5\"):\n            format = \"jabs\"\n        elif filename.endswith(\"data.yaml\") or (\n            Path(filename).is_dir() and (Path(filename) / \"data.yaml\").exists()\n        ):\n            format = \"ultralytics\"\n        elif filename.endswith(\".csv\") and dlc.is_dlc_file(filename):\n            format = \"dlc\"\n        else:\n            for vid_ext in Video.EXTS:\n                if filename.endswith(vid_ext):\n                    format = \"video\"\n                    break\n        if format is None:\n            raise ValueError(f\"Could not infer format from filename: '{filename}'.\")\n\n    if filename.endswith(\".slp\"):\n        return load_slp(filename, **kwargs)\n    elif filename.endswith(\".nwb\"):\n        return load_nwb(filename, **kwargs)\n    elif filename.endswith(\".mat\"):\n        return load_leap(filename, **kwargs)\n    elif filename.endswith(\".json\"):\n        if format == \"alphatracker\":\n            return load_alphatracker(filename, **kwargs)\n        elif format == \"coco\":\n            return load_coco(filename, **kwargs)\n        else:\n            return load_labelstudio(filename, **kwargs)\n    elif filename.endswith(\".h5\"):\n        return load_jabs(filename, **kwargs)\n    elif format == \"dlc\":\n        return load_dlc(filename, **kwargs)\n    elif format == \"ultralytics\":\n        return load_ultralytics(filename, **kwargs)\n    elif format == \"video\":\n        return load_video(filename, **kwargs)\n</code></pre>"},{"location":"reference/sleap_io/io/main/#sleap_io.io.main.load_jabs","title":"<code>load_jabs(filename, skeleton=None)</code>","text":"<p>Read JABS-style predictions from a file and return a <code>Labels</code> object.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>Path to the jabs h5 pose file.</p> required <code>skeleton</code> <code>Optional[Skeleton]</code> <p>An optional <code>Skeleton</code> object.</p> <code>None</code> <p>Returns:</p> Type Description <code>Labels</code> <p>Parsed labels as a <code>Labels</code> instance.</p> Source code in <code>sleap_io/io/main.py</code> <pre><code>def load_jabs(filename: str, skeleton: Optional[Skeleton] = None) -&gt; Labels:\n    \"\"\"Read JABS-style predictions from a file and return a `Labels` object.\n\n    Args:\n        filename: Path to the jabs h5 pose file.\n        skeleton: An optional `Skeleton` object.\n\n    Returns:\n        Parsed labels as a `Labels` instance.\n    \"\"\"\n    return jabs.read_labels(filename, skeleton=skeleton)\n</code></pre>"},{"location":"reference/sleap_io/io/main/#sleap_io.io.main.load_labels_set","title":"<code>load_labels_set(path, format=None, open_videos=True, **kwargs)</code>","text":"<p>Load a LabelsSet from multiple files.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Union[str, Path, list[Union[str, Path]], dict[str, Union[str, Path]]]</code> <p>Can be one of: - A directory path containing label files - A list of file paths - A dictionary mapping names to file paths</p> required <code>format</code> <code>Optional[str]</code> <p>Optional format specification. If None, will try to infer from path. Supported formats: \"slp\", \"ultralytics\"</p> <code>None</code> <code>open_videos</code> <code>bool</code> <p>If <code>True</code> (the default), attempt to open video backends.</p> <code>True</code> <code>**kwargs</code> <p>Additional format-specific arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>LabelsSet</code> <p>A LabelsSet containing the loaded Labels objects.</p> <p>Examples:</p> <p>Load from SLP directory:</p> <pre><code>&gt;&gt;&gt; labels_set = load_labels_set(\"path/to/splits/\")\n</code></pre> <p>Load from list of SLP files:</p> <pre><code>&gt;&gt;&gt; labels_set = load_labels_set([\"train.slp\", \"val.slp\"])\n</code></pre> <p>Load from Ultralytics dataset:</p> <pre><code>&gt;&gt;&gt; labels_set = load_labels_set(\"path/to/yolo_dataset/\", format=\"ultralytics\")\n</code></pre> Source code in <code>sleap_io/io/main.py</code> <pre><code>def load_labels_set(\n    path: Union[str, Path, list[Union[str, Path]], dict[str, Union[str, Path]]],\n    format: Optional[str] = None,\n    open_videos: bool = True,\n    **kwargs,\n) -&gt; LabelsSet:\n    \"\"\"Load a LabelsSet from multiple files.\n\n    Args:\n        path: Can be one of:\n            - A directory path containing label files\n            - A list of file paths\n            - A dictionary mapping names to file paths\n        format: Optional format specification. If None, will try to infer from path.\n            Supported formats: \"slp\", \"ultralytics\"\n        open_videos: If `True` (the default), attempt to open video backends.\n        **kwargs: Additional format-specific arguments.\n\n    Returns:\n        A LabelsSet containing the loaded Labels objects.\n\n    Examples:\n        Load from SLP directory:\n        &gt;&gt;&gt; labels_set = load_labels_set(\"path/to/splits/\")\n\n        Load from list of SLP files:\n        &gt;&gt;&gt; labels_set = load_labels_set([\"train.slp\", \"val.slp\"])\n\n        Load from Ultralytics dataset:\n        &gt;&gt;&gt; labels_set = load_labels_set(\"path/to/yolo_dataset/\", format=\"ultralytics\")\n    \"\"\"\n    # Try to infer format if not specified\n    if format is None:\n        if isinstance(path, (str, Path)):\n            path_obj = Path(path)\n            if path_obj.is_dir():\n                # Check for ultralytics structure\n                if (path_obj / \"data.yaml\").exists() or any(\n                    (path_obj / split).exists() for split in [\"train\", \"val\", \"test\"]\n                ):\n                    format = \"ultralytics\"\n                else:\n                    # Default to SLP for directories\n                    format = \"slp\"\n            else:\n                # Single file path - check extension\n                if path_obj.suffix == \".slp\":\n                    format = \"slp\"\n        elif isinstance(path, list) and len(path) &gt; 0:\n            # Check first file in list\n            first_path = Path(path[0])\n            if first_path.suffix == \".slp\":\n                format = \"slp\"\n        elif isinstance(path, dict):\n            # Dictionary input defaults to SLP\n            format = \"slp\"\n\n    if format == \"slp\":\n        return slp.read_labels_set(path, open_videos=open_videos)\n    elif format == \"ultralytics\":\n        # Extract ultralytics-specific kwargs\n        splits = kwargs.pop(\"splits\", None)\n        skeleton = kwargs.pop(\"skeleton\", None)\n        image_size = kwargs.pop(\"image_size\", (480, 640))\n        # Remove verbose from kwargs if present (for backward compatibility)\n        kwargs.pop(\"verbose\", None)\n\n        if not isinstance(path, (str, Path)):\n            raise ValueError(\n                \"Ultralytics format requires a directory path, \"\n                f\"got {type(path).__name__}\"\n            )\n\n        return ultralytics.read_labels_set(\n            str(path),\n            splits=splits,\n            skeleton=skeleton,\n            image_size=image_size,\n        )\n    else:\n        raise ValueError(\n            f\"Unknown format: {format}. Supported formats: 'slp', 'ultralytics'\"\n        )\n</code></pre>"},{"location":"reference/sleap_io/io/main/#sleap_io.io.main.load_labelstudio","title":"<code>load_labelstudio(filename, skeleton=None)</code>","text":"<p>Read Label Studio-style annotations from a file and return a <code>Labels</code> object.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>Path to the label-studio annotation file in JSON format.</p> required <code>skeleton</code> <code>Optional[Union[Skeleton, list[str]]]</code> <p>An optional <code>Skeleton</code> object or list of node names. If not provided (the default), skeleton will be inferred from the data. It may be useful to provide this so the keypoint label types can be filtered to just the ones in the skeleton.</p> <code>None</code> <p>Returns:</p> Type Description <code>Labels</code> <p>Parsed labels as a <code>Labels</code> instance.</p> Source code in <code>sleap_io/io/main.py</code> <pre><code>def load_labelstudio(\n    filename: str, skeleton: Optional[Union[Skeleton, list[str]]] = None\n) -&gt; Labels:\n    \"\"\"Read Label Studio-style annotations from a file and return a `Labels` object.\n\n    Args:\n        filename: Path to the label-studio annotation file in JSON format.\n        skeleton: An optional `Skeleton` object or list of node names. If not provided\n            (the default), skeleton will be inferred from the data. It may be useful to\n            provide this so the keypoint label types can be filtered to just the ones in\n            the skeleton.\n\n    Returns:\n        Parsed labels as a `Labels` instance.\n    \"\"\"\n    return labelstudio.read_labels(filename, skeleton=skeleton)\n</code></pre>"},{"location":"reference/sleap_io/io/main/#sleap_io.io.main.load_leap","title":"<code>load_leap(filename, skeleton=None, **kwargs)</code>","text":"<p>Load a LEAP dataset from a .mat file.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>Path to a LEAP .mat file.</p> required <code>skeleton</code> <code>Optional[Skeleton]</code> <p>An optional <code>Skeleton</code> object. If not provided, will be constructed from the data in the file.</p> <code>None</code> <code>**kwargs</code> <p>Additional arguments (currently unused).</p> <code>{}</code> <p>Returns:</p> Type Description <code>Labels</code> <p>The dataset as a <code>Labels</code> object.</p> Source code in <code>sleap_io/io/main.py</code> <pre><code>def load_leap(\n    filename: str,\n    skeleton: Optional[Skeleton] = None,\n    **kwargs,\n) -&gt; Labels:\n    \"\"\"Load a LEAP dataset from a .mat file.\n\n    Args:\n        filename: Path to a LEAP .mat file.\n        skeleton: An optional `Skeleton` object. If not provided, will be constructed\n            from the data in the file.\n        **kwargs: Additional arguments (currently unused).\n\n    Returns:\n        The dataset as a `Labels` object.\n    \"\"\"\n    return leap.read_labels(filename, skeleton=skeleton)\n</code></pre>"},{"location":"reference/sleap_io/io/main/#sleap_io.io.main.load_nwb","title":"<code>load_nwb(filename)</code>","text":"<p>Load an NWB dataset as a SLEAP <code>Labels</code> object.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>Path to a NWB file (<code>.nwb</code>).</p> required <p>Returns:</p> Type Description <code>Labels</code> <p>The dataset as a <code>Labels</code> object.</p> Source code in <code>sleap_io/io/main.py</code> <pre><code>def load_nwb(filename: str) -&gt; Labels:\n    \"\"\"Load an NWB dataset as a SLEAP `Labels` object.\n\n    Args:\n        filename: Path to a NWB file (`.nwb`).\n\n    Returns:\n        The dataset as a `Labels` object.\n    \"\"\"\n    return nwb.load_nwb(filename)\n</code></pre>"},{"location":"reference/sleap_io/io/main/#sleap_io.io.main.load_skeleton","title":"<code>load_skeleton(filename)</code>","text":"<p>Load skeleton(s) from a JSON, YAML, or SLP file.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str | Path</code> <p>Path to a skeleton file. Supported formats: - JSON: Standalone skeleton or training config with embedded skeletons - YAML: Simplified skeleton format - SLP: SLEAP project file</p> required <p>Returns:</p> Type Description <code>Union[Skeleton, List[Skeleton]]</code> <p>A single <code>Skeleton</code> or list of <code>Skeleton</code> objects.</p> Notes <p>This function loads skeletons from various file types: - JSON files: Can be standalone skeleton files (jsonpickle format) or training   config files with embedded skeletons - YAML files: Use a simplified human-readable format - SLP files: Extracts skeletons from SLEAP project files The format is detected based on the file extension and content.</p> Source code in <code>sleap_io/io/main.py</code> <pre><code>def load_skeleton(filename: str | Path) -&gt; Union[Skeleton, List[Skeleton]]:\n    \"\"\"Load skeleton(s) from a JSON, YAML, or SLP file.\n\n    Args:\n        filename: Path to a skeleton file. Supported formats:\n            - JSON: Standalone skeleton or training config with embedded skeletons\n            - YAML: Simplified skeleton format\n            - SLP: SLEAP project file\n\n    Returns:\n        A single `Skeleton` or list of `Skeleton` objects.\n\n    Notes:\n        This function loads skeletons from various file types:\n        - JSON files: Can be standalone skeleton files (jsonpickle format) or training\n          config files with embedded skeletons\n        - YAML files: Use a simplified human-readable format\n        - SLP files: Extracts skeletons from SLEAP project files\n        The format is detected based on the file extension and content.\n    \"\"\"\n    if isinstance(filename, Path):\n        filename = str(filename)\n\n    # Detect format based on extension\n    if filename.lower().endswith(\".slp\"):\n        # SLP format - extract skeletons from SLEAP file\n        from sleap_io.io.slp import read_skeletons\n\n        return read_skeletons(filename)\n    elif filename.lower().endswith((\".yaml\", \".yml\")):\n        # YAML format\n        with open(filename, \"r\") as f:\n            yaml_data = f.read()\n        return decode_yaml_skeleton(yaml_data)\n    else:\n        # JSON format (default) - could be standalone or training config\n        with open(filename, \"r\") as f:\n            json_data = f.read()\n        return load_skeleton_from_json(json_data)\n</code></pre>"},{"location":"reference/sleap_io/io/main/#sleap_io.io.main.load_slp","title":"<code>load_slp(filename, open_videos=True)</code>","text":"<p>Load a SLEAP dataset.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>Path to a SLEAP labels file (<code>.slp</code>).</p> required <code>open_videos</code> <code>bool</code> <p>If <code>True</code> (the default), attempt to open the video backend for I/O. If <code>False</code>, the backend will not be opened (useful for reading metadata when the video files are not available).</p> <code>True</code> <p>Returns:</p> Type Description <code>Labels</code> <p>The dataset as a <code>Labels</code> object.</p> Source code in <code>sleap_io/io/main.py</code> <pre><code>def load_slp(filename: str, open_videos: bool = True) -&gt; Labels:\n    \"\"\"Load a SLEAP dataset.\n\n    Args:\n        filename: Path to a SLEAP labels file (`.slp`).\n        open_videos: If `True` (the default), attempt to open the video backend for\n            I/O. If `False`, the backend will not be opened (useful for reading metadata\n            when the video files are not available).\n\n    Returns:\n        The dataset as a `Labels` object.\n    \"\"\"\n    return slp.read_labels(filename, open_videos=open_videos)\n</code></pre>"},{"location":"reference/sleap_io/io/main/#sleap_io.io.main.load_ultralytics","title":"<code>load_ultralytics(dataset_path, split='train', skeleton=None, **kwargs)</code>","text":"<p>Load an Ultralytics YOLO pose dataset as a SLEAP <code>Labels</code> object.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_path</code> <code>str</code> <p>Path to the Ultralytics dataset root directory containing data.yaml.</p> required <code>split</code> <code>str</code> <p>Dataset split to read ('train', 'val', or 'test'). Defaults to 'train'.</p> <code>'train'</code> <code>skeleton</code> <code>Optional[Skeleton]</code> <p>Optional skeleton to use. If not provided, will be inferred from data.yaml.</p> <code>None</code> <code>**kwargs</code> <p>Additional arguments passed to <code>ultralytics.read_labels</code>. Currently supports: - image_size: Tuple of (height, width) for coordinate denormalization.   Defaults to   (480, 640). Will attempt to infer from actual images if available.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Labels</code> <p>The dataset as a <code>Labels</code> object.</p> Source code in <code>sleap_io/io/main.py</code> <pre><code>def load_ultralytics(\n    dataset_path: str,\n    split: str = \"train\",\n    skeleton: Optional[Skeleton] = None,\n    **kwargs,\n) -&gt; Labels:\n    \"\"\"Load an Ultralytics YOLO pose dataset as a SLEAP `Labels` object.\n\n    Args:\n        dataset_path: Path to the Ultralytics dataset root directory containing\n            data.yaml.\n        split: Dataset split to read ('train', 'val', or 'test'). Defaults to 'train'.\n        skeleton: Optional skeleton to use. If not provided, will be inferred from\n            data.yaml.\n        **kwargs: Additional arguments passed to `ultralytics.read_labels`.\n            Currently supports:\n            - image_size: Tuple of (height, width) for coordinate denormalization.\n              Defaults to\n              (480, 640). Will attempt to infer from actual images if available.\n\n    Returns:\n        The dataset as a `Labels` object.\n    \"\"\"\n    return ultralytics.read_labels(\n        dataset_path, split=split, skeleton=skeleton, **kwargs\n    )\n</code></pre>"},{"location":"reference/sleap_io/io/main/#sleap_io.io.main.load_video","title":"<code>load_video(filename, **kwargs)</code>","text":"<p>Load a video file.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>The filename(s) of the video. Supported extensions: \"mp4\", \"avi\", \"mov\", \"mj2\", \"mkv\", \"h5\", \"hdf5\", \"slp\", \"png\", \"jpg\", \"jpeg\", \"tif\", \"tiff\", \"bmp\". If the filename is a list, a list of image filenames are expected. If filename is a folder, it will be searched for images.</p> required <code>**kwargs</code> <p>Additional arguments passed to <code>Video.from_filename</code>. Currently supports: - dataset: Name of dataset in HDF5 file. - grayscale: Whether to force grayscale. If None, autodetect on first   frame load. - keep_open: Whether to keep the video reader open between calls to read   frames.   If False, will close the reader after each call. If True (the   default), it will   keep the reader open and cache it for subsequent calls which may   enhance the   performance of reading multiple frames. - source_video: Source video object if this is a proxy video. This is   metadata   and does not affect reading. - backend_metadata: Metadata to store on the video backend. This is   useful for   storing metadata that requires an open backend (e.g., shape   information) without   having to open the backend. - plugin: Video plugin to use for MediaVideo backend. One of \"opencv\",   \"FFMPEG\",   or \"pyav\". Also accepts aliases (case-insensitive):   * opencv: \"opencv\", \"cv\", \"cv2\", \"ocv\"   * FFMPEG: \"FFMPEG\", \"ffmpeg\", \"imageio-ffmpeg\", \"imageio_ffmpeg\"   * pyav: \"pyav\", \"av\"</p> <p>If not specified, uses the following priority:   1. Global default set via <code>sio.set_default_video_plugin()</code>   2. Auto-detection based on available packages</p> <p>To set a global default:</p> <p>import sleap_io as sio sio.set_default_video_plugin(\"opencv\") video = sio.load_video(\"video.mp4\")  # Uses opencv - input_format: Format of the data in HDF5 datasets. One of   \"channels_last\" (the   default) in (frames, height, width, channels) order or \"channels_first\" in   (frames, channels, width, height) order. - frame_map: Mapping from frame indices to indices in the HDF5 dataset.   This is   used to translate between frame indices of images within their source   video   and indices of images in the dataset. - source_filename: Path to the source video file for HDF5 embedded videos. - source_inds: Indices of frames in the source video file for HDF5   embedded videos. - image_format: Format of images in HDF5 embedded dataset.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Video</code> <p>A <code>Video</code> object.</p> See Also <p>set_default_video_plugin: Set the default video plugin globally. get_default_video_plugin: Get the current default video plugin.</p> Source code in <code>sleap_io/io/main.py</code> <pre><code>def load_video(filename: str, **kwargs) -&gt; Video:\n    \"\"\"Load a video file.\n\n    Args:\n        filename: The filename(s) of the video. Supported extensions: \"mp4\", \"avi\",\n            \"mov\", \"mj2\", \"mkv\", \"h5\", \"hdf5\", \"slp\", \"png\", \"jpg\", \"jpeg\", \"tif\",\n            \"tiff\", \"bmp\". If the filename is a list, a list of image filenames are\n            expected. If filename is a folder, it will be searched for images.\n        **kwargs: Additional arguments passed to `Video.from_filename`.\n            Currently supports:\n            - dataset: Name of dataset in HDF5 file.\n            - grayscale: Whether to force grayscale. If None, autodetect on first\n              frame load.\n            - keep_open: Whether to keep the video reader open between calls to read\n              frames.\n              If False, will close the reader after each call. If True (the\n              default), it will\n              keep the reader open and cache it for subsequent calls which may\n              enhance the\n              performance of reading multiple frames.\n            - source_video: Source video object if this is a proxy video. This is\n              metadata\n              and does not affect reading.\n            - backend_metadata: Metadata to store on the video backend. This is\n              useful for\n              storing metadata that requires an open backend (e.g., shape\n              information) without\n              having to open the backend.\n            - plugin: Video plugin to use for MediaVideo backend. One of \"opencv\",\n              \"FFMPEG\",\n              or \"pyav\". Also accepts aliases (case-insensitive):\n              * opencv: \"opencv\", \"cv\", \"cv2\", \"ocv\"\n              * FFMPEG: \"FFMPEG\", \"ffmpeg\", \"imageio-ffmpeg\", \"imageio_ffmpeg\"\n              * pyav: \"pyav\", \"av\"\n\n              If not specified, uses the following priority:\n              1. Global default set via `sio.set_default_video_plugin()`\n              2. Auto-detection based on available packages\n\n              To set a global default:\n              &gt;&gt;&gt; import sleap_io as sio\n              &gt;&gt;&gt; sio.set_default_video_plugin(\"opencv\")\n              &gt;&gt;&gt; video = sio.load_video(\"video.mp4\")  # Uses opencv\n            - input_format: Format of the data in HDF5 datasets. One of\n              \"channels_last\" (the\n              default) in (frames, height, width, channels) order or \"channels_first\" in\n              (frames, channels, width, height) order.\n            - frame_map: Mapping from frame indices to indices in the HDF5 dataset.\n              This is\n              used to translate between frame indices of images within their source\n              video\n              and indices of images in the dataset.\n            - source_filename: Path to the source video file for HDF5 embedded videos.\n            - source_inds: Indices of frames in the source video file for HDF5\n              embedded videos.\n            - image_format: Format of images in HDF5 embedded dataset.\n\n    Returns:\n        A `Video` object.\n\n    See Also:\n        set_default_video_plugin: Set the default video plugin globally.\n        get_default_video_plugin: Get the current default video plugin.\n    \"\"\"\n    return Video.from_filename(filename, **kwargs)\n</code></pre>"},{"location":"reference/sleap_io/io/main/#sleap_io.io.main.save_file","title":"<code>save_file(labels, filename, format=None, verbose=True, **kwargs)</code>","text":"<p>Save a file based on the extension.</p> <p>Parameters:</p> Name Type Description Default <code>labels</code> <code>Labels</code> <p>A SLEAP <code>Labels</code> object (see <code>load_slp</code>).</p> required <code>filename</code> <code>str | Path</code> <p>Path to save labels to.</p> required <code>format</code> <code>Optional[str]</code> <p>Optional format to save as. If not provided, will be inferred from the file extension. Available formats are: \"slp\", \"nwb\", \"labelstudio\", \"jabs\", and \"ultralytics\".</p> <code>None</code> <code>verbose</code> <code>bool</code> <p>If <code>True</code> (the default), display a progress bar when embedding frames (only applies to the SLP format).</p> <code>True</code> <code>**kwargs</code> <p>Additional arguments passed to the format-specific saving function: - For \"slp\" format: embed (bool | str | list[tuple[Video, int]] |   None): Frames   to embed in the saved labels file. One of None, True, \"all\", \"user\",   \"suggestions\", \"user+suggestions\", \"source\" or list of tuples of   (video, frame_idx). If False (the default), no frames are embedded. - For \"nwb\" format: pose_estimation_metadata (dict): Metadata to store   in the   NWB file. append (bool): If True, append to existing NWB file. - For \"labelstudio\" format: No additional arguments. - For \"jabs\" format: pose_version (int): JABS pose format version (1-6).   root_folder (Optional[str]): Root folder for JABS project structure. - For \"ultralytics\" format: See <code>save_ultralytics</code> for supported arguments.</p> <code>{}</code> Source code in <code>sleap_io/io/main.py</code> <pre><code>def save_file(\n    labels: Labels,\n    filename: str | Path,\n    format: Optional[str] = None,\n    verbose: bool = True,\n    **kwargs,\n):\n    \"\"\"Save a file based on the extension.\n\n    Args:\n        labels: A SLEAP `Labels` object (see `load_slp`).\n        filename: Path to save labels to.\n        format: Optional format to save as. If not provided, will be inferred from the\n            file extension. Available formats are: \"slp\", \"nwb\", \"labelstudio\", \"jabs\",\n            and \"ultralytics\".\n        verbose: If `True` (the default), display a progress bar when embedding frames\n            (only applies to the SLP format).\n        **kwargs: Additional arguments passed to the format-specific saving function:\n            - For \"slp\" format: embed (bool | str | list[tuple[Video, int]] |\n              None): Frames\n              to embed in the saved labels file. One of None, True, \"all\", \"user\",\n              \"suggestions\", \"user+suggestions\", \"source\" or list of tuples of\n              (video, frame_idx). If False (the default), no frames are embedded.\n            - For \"nwb\" format: pose_estimation_metadata (dict): Metadata to store\n              in the\n              NWB file. append (bool): If True, append to existing NWB file.\n            - For \"labelstudio\" format: No additional arguments.\n            - For \"jabs\" format: pose_version (int): JABS pose format version (1-6).\n              root_folder (Optional[str]): Root folder for JABS project structure.\n            - For \"ultralytics\" format: See `save_ultralytics` for supported arguments.\n    \"\"\"\n    if isinstance(filename, Path):\n        filename = str(filename)\n\n    if format is None:\n        if filename.endswith(\".slp\"):\n            format = \"slp\"\n        elif filename.endswith(\".nwb\"):\n            format = \"nwb\"\n        elif filename.endswith(\".json\"):\n            format = \"labelstudio\"\n        elif \"pose_version\" in kwargs:\n            format = \"jabs\"\n        elif \"split_ratios\" in kwargs or Path(filename).is_dir():\n            format = \"ultralytics\"\n\n    if format == \"slp\":\n        save_slp(labels, filename, verbose=verbose, **kwargs)\n    elif format == \"nwb\":\n        save_nwb(labels, filename, **kwargs)\n    elif format == \"labelstudio\":\n        save_labelstudio(labels, filename, **kwargs)\n    elif format == \"jabs\":\n        pose_version = kwargs.pop(\"pose_version\", 5)\n        root_folder = kwargs.pop(\"root_folder\", filename)\n        save_jabs(labels, pose_version=pose_version, root_folder=root_folder)\n    elif format == \"ultralytics\":\n        save_ultralytics(labels, filename, **kwargs)\n    else:\n        raise ValueError(f\"Unknown format '{format}' for filename: '{filename}'.\")\n</code></pre>"},{"location":"reference/sleap_io/io/main/#sleap_io.io.main.save_jabs","title":"<code>save_jabs(labels, pose_version, root_folder=None)</code>","text":"<p>Save a SLEAP dataset to JABS pose file format.</p> <p>Parameters:</p> Name Type Description Default <code>labels</code> <code>Labels</code> <p>SLEAP <code>Labels</code> object.</p> required <code>pose_version</code> <code>int</code> <p>The JABS pose version to write data out.</p> required <code>root_folder</code> <code>Optional[str]</code> <p>Optional root folder where the files should be saved.</p> <code>None</code> Note <p>Filenames for JABS poses are based on video filenames.</p> Source code in <code>sleap_io/io/main.py</code> <pre><code>def save_jabs(labels: Labels, pose_version: int, root_folder: Optional[str] = None):\n    \"\"\"Save a SLEAP dataset to JABS pose file format.\n\n    Args:\n        labels: SLEAP `Labels` object.\n        pose_version: The JABS pose version to write data out.\n        root_folder: Optional root folder where the files should be saved.\n\n    Note:\n        Filenames for JABS poses are based on video filenames.\n    \"\"\"\n    jabs.write_labels(labels, pose_version, root_folder)\n</code></pre>"},{"location":"reference/sleap_io/io/main/#sleap_io.io.main.save_labelstudio","title":"<code>save_labelstudio(labels, filename)</code>","text":"<p>Save a SLEAP dataset to Label Studio format.</p> <p>Parameters:</p> Name Type Description Default <code>labels</code> <code>Labels</code> <p>A SLEAP <code>Labels</code> object (see <code>load_slp</code>).</p> required <code>filename</code> <code>str</code> <p>Path to save labels to ending with <code>.json</code>.</p> required Source code in <code>sleap_io/io/main.py</code> <pre><code>def save_labelstudio(labels: Labels, filename: str):\n    \"\"\"Save a SLEAP dataset to Label Studio format.\n\n    Args:\n        labels: A SLEAP `Labels` object (see `load_slp`).\n        filename: Path to save labels to ending with `.json`.\n    \"\"\"\n    labelstudio.write_labels(labels, filename)\n</code></pre>"},{"location":"reference/sleap_io/io/main/#sleap_io.io.main.save_nwb","title":"<code>save_nwb(labels, filename, nwb_format=NwbFormat.AUTO, append=False)</code>","text":"<p>Save a SLEAP dataset to NWB format.</p> <p>Parameters:</p> Name Type Description Default <code>labels</code> <code>Labels</code> <p>A SLEAP <code>Labels</code> object (see <code>load_slp</code>).</p> required <code>filename</code> <code>Union[str, Path]</code> <p>Path to NWB file to save to. Must end in <code>.nwb</code>.</p> required <code>nwb_format</code> <code>Union[NwbFormat, str]</code> <p>Format to use for saving. Options are: - \"auto\" (default): Automatically detect based on data - \"annotations\": Save training annotations (PoseTraining) - \"annotations_export\": Export annotations with video frames - \"predictions\": Save predictions (PoseEstimation)</p> <code>AUTO</code> <code>append</code> <code>bool</code> <p>If True, append to existing NWB file. Only supported for predictions format. Defaults to False.</p> <code>False</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If an invalid format is specified.</p> Source code in <code>sleap_io/io/main.py</code> <pre><code>def save_nwb(\n    labels: Labels,\n    filename: Union[str, Path],\n    nwb_format: Union[NwbFormat, str] = NwbFormat.AUTO,\n    append: bool = False,\n) -&gt; None:\n    \"\"\"Save a SLEAP dataset to NWB format.\n\n    Args:\n        labels: A SLEAP `Labels` object (see `load_slp`).\n        filename: Path to NWB file to save to. Must end in `.nwb`.\n        nwb_format: Format to use for saving. Options are:\n            - \"auto\" (default): Automatically detect based on data\n            - \"annotations\": Save training annotations (PoseTraining)\n            - \"annotations_export\": Export annotations with video frames\n            - \"predictions\": Save predictions (PoseEstimation)\n        append: If True, append to existing NWB file. Only supported for\n            predictions format. Defaults to False.\n\n    Raises:\n        ValueError: If an invalid format is specified.\n    \"\"\"\n    nwb.save_nwb(labels, filename, nwb_format, append=append)\n</code></pre>"},{"location":"reference/sleap_io/io/main/#sleap_io.io.main.save_skeleton","title":"<code>save_skeleton(skeleton, filename)</code>","text":"<p>Save skeleton(s) to a JSON or YAML file.</p> <p>Parameters:</p> Name Type Description Default <code>skeleton</code> <code>Union[Skeleton, List[Skeleton]]</code> <p>A single <code>Skeleton</code> or list of <code>Skeleton</code> objects to save.</p> required <code>filename</code> <code>str | Path</code> <p>Path to save the skeleton file.</p> required Notes <p>This function saves skeletons in either JSON or YAML format based on the file extension. JSON files use the jsonpickle format compatible with SLEAP, while YAML files use a simplified human-readable format.</p> Source code in <code>sleap_io/io/main.py</code> <pre><code>def save_skeleton(skeleton: Union[Skeleton, List[Skeleton]], filename: str | Path):\n    \"\"\"Save skeleton(s) to a JSON or YAML file.\n\n    Args:\n        skeleton: A single `Skeleton` or list of `Skeleton` objects to save.\n        filename: Path to save the skeleton file.\n\n    Notes:\n        This function saves skeletons in either JSON or YAML format based on the\n        file extension. JSON files use the jsonpickle format compatible with SLEAP,\n        while YAML files use a simplified human-readable format.\n    \"\"\"\n    if isinstance(filename, Path):\n        filename = str(filename)\n\n    # Detect format based on extension\n    if filename.lower().endswith((\".yaml\", \".yml\")):\n        # YAML format\n        yaml_data = encode_yaml_skeleton(skeleton)\n        with open(filename, \"w\") as f:\n            f.write(yaml_data)\n    else:\n        # JSON format (default)\n        json_data = encode_skeleton(skeleton)\n        with open(filename, \"w\") as f:\n            f.write(json_data)\n</code></pre>"},{"location":"reference/sleap_io/io/main/#sleap_io.io.main.save_slp","title":"<code>save_slp(labels, filename, embed=False, restore_original_videos=True, verbose=True)</code>","text":"<p>Save a SLEAP dataset to a <code>.slp</code> file.</p> <p>Parameters:</p> Name Type Description Default <code>labels</code> <code>Labels</code> <p>A SLEAP <code>Labels</code> object (see <code>load_slp</code>).</p> required <code>filename</code> <code>str</code> <p>Path to save labels to ending with <code>.slp</code>.</p> required <code>embed</code> <code>bool | str | list[tuple[Video, int]] | None</code> <p>Frames to embed in the saved labels file. One of <code>None</code>, <code>True</code>, <code>\"all\"</code>, <code>\"user\"</code>, <code>\"suggestions\"</code>, <code>\"user+suggestions\"</code>, <code>\"source\"</code> or list of tuples of <code>(video, frame_idx)</code>.</p> <p>If <code>False</code> is specified (the default), the source video will be restored if available, otherwise the embedded frames will be re-saved.</p> <p>If <code>True</code> or <code>\"all\"</code>, all labeled frames and suggested frames will be embedded.</p> <p>If <code>\"source\"</code> is specified, no images will be embedded and the source video will be restored if available.</p> <p>This argument is only valid for the SLP backend.</p> <code>False</code> <code>restore_original_videos</code> <code>bool</code> <p>If <code>True</code> (default) and <code>embed=False</code>, use original video files. If <code>False</code> and <code>embed=False</code>, keep references to source <code>.pkg.slp</code> files. Only applies when <code>embed=False</code>.</p> <code>True</code> <code>verbose</code> <code>bool</code> <p>If <code>True</code> (the default), display a progress bar when embedding frames.</p> <code>True</code> Source code in <code>sleap_io/io/main.py</code> <pre><code>def save_slp(\n    labels: Labels,\n    filename: str,\n    embed: bool | str | list[tuple[Video, int]] | None = False,\n    restore_original_videos: bool = True,\n    verbose: bool = True,\n):\n    \"\"\"Save a SLEAP dataset to a `.slp` file.\n\n    Args:\n        labels: A SLEAP `Labels` object (see `load_slp`).\n        filename: Path to save labels to ending with `.slp`.\n        embed: Frames to embed in the saved labels file. One of `None`, `True`,\n            `\"all\"`, `\"user\"`, `\"suggestions\"`, `\"user+suggestions\"`, `\"source\"` or list\n            of tuples of `(video, frame_idx)`.\n\n            If `False` is specified (the default), the source video will be restored\n            if available, otherwise the embedded frames will be re-saved.\n\n            If `True` or `\"all\"`, all labeled frames and suggested frames will be\n            embedded.\n\n            If `\"source\"` is specified, no images will be embedded and the source video\n            will be restored if available.\n\n            This argument is only valid for the SLP backend.\n        restore_original_videos: If `True` (default) and `embed=False`, use original\n            video files. If `False` and `embed=False`, keep references to source\n            `.pkg.slp` files. Only applies when `embed=False`.\n        verbose: If `True` (the default), display a progress bar when embedding frames.\n    \"\"\"\n    return slp.write_labels(\n        filename,\n        labels,\n        embed=embed,\n        restore_original_videos=restore_original_videos,\n        verbose=verbose,\n    )\n</code></pre>"},{"location":"reference/sleap_io/io/main/#sleap_io.io.main.save_ultralytics","title":"<code>save_ultralytics(labels, dataset_path, split_ratios={'train': 0.8, 'val': 0.2}, **kwargs)</code>","text":"<p>Save a SLEAP dataset to Ultralytics YOLO pose format.</p> <p>Parameters:</p> Name Type Description Default <code>labels</code> <code>Labels</code> <p>A SLEAP <code>Labels</code> object.</p> required <code>dataset_path</code> <code>str</code> <p>Path to save the Ultralytics dataset.</p> required <code>split_ratios</code> <code>dict</code> <p>Dictionary mapping split names to ratios (must sum to 1.0).          Defaults to {\"train\": 0.8, \"val\": 0.2}.</p> <code>{'train': 0.8, 'val': 0.2}</code> <code>**kwargs</code> <p>Additional arguments passed to <code>ultralytics.write_labels</code>. Currently supports: - class_id: Class ID to use for all instances (default: 0). - image_format: Image format to use for saving frames. Either \"png\"   (default, lossless) or \"jpg\". - image_quality: Image quality for JPEG format (1-100). For PNG, this is   the compression   level (0-9). If None, uses default quality settings. - verbose: If True (default), show progress bars during export. - use_multiprocessing: If True, use multiprocessing for parallel image   saving. Default is False. - n_workers: Number of worker processes. If None, uses CPU count - 1.   Only used if   use_multiprocessing=True.</p> <code>{}</code> Source code in <code>sleap_io/io/main.py</code> <pre><code>def save_ultralytics(\n    labels: Labels,\n    dataset_path: str,\n    split_ratios: dict = {\"train\": 0.8, \"val\": 0.2},\n    **kwargs,\n):\n    \"\"\"Save a SLEAP dataset to Ultralytics YOLO pose format.\n\n    Args:\n        labels: A SLEAP `Labels` object.\n        dataset_path: Path to save the Ultralytics dataset.\n        split_ratios: Dictionary mapping split names to ratios (must sum to 1.0).\n                     Defaults to {\"train\": 0.8, \"val\": 0.2}.\n        **kwargs: Additional arguments passed to `ultralytics.write_labels`.\n            Currently supports:\n            - class_id: Class ID to use for all instances (default: 0).\n            - image_format: Image format to use for saving frames. Either \"png\"\n              (default, lossless) or \"jpg\".\n            - image_quality: Image quality for JPEG format (1-100). For PNG, this is\n              the compression\n              level (0-9). If None, uses default quality settings.\n            - verbose: If True (default), show progress bars during export.\n            - use_multiprocessing: If True, use multiprocessing for parallel image\n              saving. Default is False.\n            - n_workers: Number of worker processes. If None, uses CPU count - 1.\n              Only used if\n              use_multiprocessing=True.\n    \"\"\"\n    ultralytics.write_labels(labels, dataset_path, split_ratios=split_ratios, **kwargs)\n</code></pre>"},{"location":"reference/sleap_io/io/main/#sleap_io.io.main.save_video","title":"<code>save_video(frames, filename, fps=30, pixelformat='yuv420p', codec='libx264', crf=25, preset='superfast', output_params=None)</code>","text":"<p>Write a list of frames to a video file.</p> <p>Parameters:</p> Name Type Description Default <code>frames</code> <code>ndarray | Video</code> <p>Sequence of frames to write to video. Each frame should be a 2D or 3D numpy array with dimensions (height, width) or (height, width, channels).</p> required <code>filename</code> <code>str | Path</code> <p>Path to output video file.</p> required <code>fps</code> <code>float</code> <p>Frames per second. Defaults to 30.</p> <code>30</code> <code>pixelformat</code> <code>str</code> <p>Pixel format for video. Defaults to \"yuv420p\".</p> <code>'yuv420p'</code> <code>codec</code> <code>str</code> <p>Codec to use for encoding. Defaults to \"libx264\".</p> <code>'libx264'</code> <code>crf</code> <code>int</code> <p>Constant rate factor to control lossiness of video. Values go from 2 to 32, with numbers in the 18 to 30 range being most common. Lower values mean less compressed/higher quality. Defaults to 25. No effect if codec is not \"libx264\".</p> <code>25</code> <code>preset</code> <code>str</code> <p>H264 encoding preset. Defaults to \"superfast\". No effect if codec is not \"libx264\".</p> <code>'superfast'</code> <code>output_params</code> <code>list | None</code> <p>Additional output parameters for FFMPEG. This should be a list of strings corresponding to command line arguments for FFMPEG and libx264. Use <code>ffmpeg -h encoder=libx264</code> to see all options for libx264 output_params.</p> <code>None</code> <p>See also: <code>sio.VideoWriter</code></p> Source code in <code>sleap_io/io/main.py</code> <pre><code>def save_video(\n    frames: np.ndarray | Video,\n    filename: str | Path,\n    fps: float = 30,\n    pixelformat: str = \"yuv420p\",\n    codec: str = \"libx264\",\n    crf: int = 25,\n    preset: str = \"superfast\",\n    output_params: list | None = None,\n):\n    \"\"\"Write a list of frames to a video file.\n\n    Args:\n        frames: Sequence of frames to write to video. Each frame should be a 2D or 3D\n            numpy array with dimensions (height, width) or (height, width, channels).\n        filename: Path to output video file.\n        fps: Frames per second. Defaults to 30.\n        pixelformat: Pixel format for video. Defaults to \"yuv420p\".\n        codec: Codec to use for encoding. Defaults to \"libx264\".\n        crf: Constant rate factor to control lossiness of video. Values go from 2 to 32,\n            with numbers in the 18 to 30 range being most common. Lower values mean less\n            compressed/higher quality. Defaults to 25. No effect if codec is not\n            \"libx264\".\n        preset: H264 encoding preset. Defaults to \"superfast\". No effect if codec is not\n            \"libx264\".\n        output_params: Additional output parameters for FFMPEG. This should be a list of\n            strings corresponding to command line arguments for FFMPEG and libx264. Use\n            `ffmpeg -h encoder=libx264` to see all options for libx264 output_params.\n\n    See also: `sio.VideoWriter`\n    \"\"\"\n    if output_params is None:\n        output_params = []\n\n    with video_writing.VideoWriter(\n        filename,\n        fps=fps,\n        pixelformat=pixelformat,\n        codec=codec,\n        crf=crf,\n        preset=preset,\n        output_params=output_params,\n    ) as writer:\n        for frame in frames:\n            writer(frame)\n</code></pre>"},{"location":"reference/sleap_io/io/nwb/","title":"nwb","text":""},{"location":"reference/sleap_io/io/nwb/#sleap_io.io.nwb","title":"<code>sleap_io.io.nwb</code>","text":"<p>Harmonization layer for NWB I/O operations.</p> <p>This module provides a unified interface for reading and writing SLEAP data to/from NWB files, automatically detecting and routing to the appropriate backend based on the data format (annotations vs predictions).</p> <p>Classes:</p> Name Description <code>NwbFormat</code> <p>NWB format types for SLEAP data.</p> <p>Functions:</p> Name Description <code>append_nwb</code> <p>Append a SLEAP <code>Labels</code> object to an existing NWB data file.</p> <code>append_nwb_data</code> <p>Append data from a Labels object to an in-memory nwb file.</p> <code>load_nwb</code> <p>Load an NWB dataset as a SLEAP Labels object.</p> <code>read_nwb</code> <p>Read an NWB formatted file to a SLEAP <code>Labels</code> object.</p> <code>save_nwb</code> <p>Save a SLEAP dataset to NWB format.</p> <code>write_nwb</code> <p>Write labels to an nwb file and save it to the nwbfile_path given.</p>"},{"location":"reference/sleap_io/io/nwb/#sleap_io.io.nwb.NwbFormat","title":"<code>NwbFormat</code>","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>NWB format types for SLEAP data.</p> Source code in <code>sleap_io/io/nwb.py</code> <pre><code>class NwbFormat(str, Enum):\n    \"\"\"NWB format types for SLEAP data.\"\"\"\n\n    AUTO = \"auto\"\n    ANNOTATIONS = \"annotations\"\n    ANNOTATIONS_EXPORT = \"annotations_export\"\n    PREDICTIONS = \"predictions\"\n</code></pre>"},{"location":"reference/sleap_io/io/nwb/#sleap_io.io.nwb.append_nwb","title":"<code>append_nwb(labels, filename, pose_estimation_metadata=None)</code>","text":"<p>Append a SLEAP <code>Labels</code> object to an existing NWB data file.</p> <p>Parameters:</p> Name Type Description Default <code>labels</code> <code>Labels</code> <p>A general <code>Labels</code> object.</p> required <code>filename</code> <code>str</code> <p>The path to the NWB file.</p> required <code>pose_estimation_metadata</code> <code>Optional[dict]</code> <p>Metadata for pose estimation. See <code>append_nwb_data</code> for details.</p> <code>None</code> <p>See also: append_nwb_data</p> Source code in <code>sleap_io/io/nwb_predictions.py</code> <pre><code>def append_nwb(\n    labels: Labels, filename: str, pose_estimation_metadata: Optional[dict] = None\n):\n    \"\"\"Append a SLEAP `Labels` object to an existing NWB data file.\n\n    Args:\n        labels: A general `Labels` object.\n        filename: The path to the NWB file.\n        pose_estimation_metadata: Metadata for pose estimation. See `append_nwb_data`\n            for details.\n\n    See also: append_nwb_data\n    \"\"\"\n    with NWBHDF5IO(filename, mode=\"a\", load_namespaces=True) as io:\n        nwb_file = io.read()\n        nwb_file = append_nwb_data(\n            labels, nwb_file, pose_estimation_metadata=pose_estimation_metadata\n        )\n        io.write(nwb_file)\n</code></pre>"},{"location":"reference/sleap_io/io/nwb/#sleap_io.io.nwb.append_nwb_data","title":"<code>append_nwb_data(labels, nwbfile, pose_estimation_metadata=None, skeleton_map=None)</code>","text":"<p>Append data from a Labels object to an in-memory nwb file.</p> <p>Parameters:</p> Name Type Description Default <code>labels</code> <code>Labels</code> <p>A general labels object</p> required <code>nwbfile</code> <code>NWBFile</code> <p>And in-memory nwbfile where the data is to be appended.</p> required <code>pose_estimation_metadata</code> <code>Optional[dict]</code> <p>This argument has a dual purpose:</p> <p>1) It can be used to pass time information about the video which is necessary for synchronizing frames in pose estimation tracking to other modalities. Either the video timestamps can be passed to This can be used to pass the timestamps with the key <code>video_timestamps</code> or the sampling rate with key<code>video_sample_rate</code>.</p> <p>e.g. pose_estimation_metadata[\"video_timestamps\"] = np.array(timestamps) or   pose_estimation_metadata[\"video_sample_rate\"] = 15  # In Hz</p> <p>2) The other use of this dictionary is to overwrite sleap-io default arguments for the PoseEstimation container. see https://github.com/rly/ndx-pose for a full list or arguments.</p> <code>None</code> <code>skeleton_map</code> <code>Optional[Dict[str, Skeleton]]</code> <p>Mapping of skeleton names to NWB Skeleton objects.</p> <code>None</code> <p>Returns:</p> Type Description <code>NWBFile</code> <p>An in-memory nwbfile with the data from the labels object appended.</p> Source code in <code>sleap_io/io/nwb_predictions.py</code> <pre><code>def append_nwb_data(\n    labels: Labels,\n    nwbfile: NWBFile,\n    pose_estimation_metadata: Optional[dict] = None,\n    skeleton_map: Optional[Dict[str, Skeleton]] = None,\n) -&gt; NWBFile:\n    \"\"\"Append data from a Labels object to an in-memory nwb file.\n\n    Args:\n        labels: A general labels object\n        nwbfile: And in-memory nwbfile where the data is to be appended.\n        pose_estimation_metadata: This argument has a dual purpose:\n\n            1) It can be used to pass time information about the video which is\n            necessary for synchronizing frames in pose estimation tracking to other\n            modalities. Either the video timestamps can be passed to\n            This can be used to pass the timestamps with the key `video_timestamps`\n            or the sampling rate with key`video_sample_rate`.\n\n            e.g. pose_estimation_metadata[\"video_timestamps\"] = np.array(timestamps)\n            or   pose_estimation_metadata[\"video_sample_rate\"] = 15  # In Hz\n\n            2) The other use of this dictionary is to overwrite sleap-io default\n            arguments for the PoseEstimation container.\n            see https://github.com/rly/ndx-pose for a full list or arguments.\n        skeleton_map: Mapping of skeleton names to NWB Skeleton objects.\n\n    Returns:\n        An in-memory nwbfile with the data from the labels object appended.\n    \"\"\"\n    pose_estimation_metadata = pose_estimation_metadata or dict()\n    if skeleton_map is None:\n        skeleton_map = create_skeleton_container(labels=labels, nwbfile=nwbfile)\n\n    # Extract default metadata\n    provenance = labels.provenance\n    default_metadata = dict(scorer=str(provenance))\n    sleap_version = provenance.get(\"sleap_version\", None)\n    default_metadata[\"source_software_version\"] = sleap_version\n\n    labels_data_df = convert_predictions_to_dataframe(labels)\n\n    # For every video create a processing module\n    for video_index, video in enumerate(labels.videos):\n        video_path = Path(video.filename)\n        processing_module_name = f\"SLEAP_VIDEO_{video_index:03}_{video_path.stem}\"\n        nwb_processing_module = get_processing_module_for_video(\n            processing_module_name, nwbfile\n        )\n\n        device_name = f\"camera_{video_index}\"\n        if device_name in nwbfile.devices:\n            device = nwbfile.devices[device_name]\n        else:\n            device = nwbfile.create_device(\n                name=device_name,\n                description=f\"Camera for {video_path.name}\",\n                manufacturer=\"Unknown\",\n            )\n\n        # Propagate video metadata\n        default_metadata[\"original_videos\"] = [f\"{video.filename}\"]  # type: ignore\n        default_metadata[\"labeled_videos\"] = [f\"{video.filename}\"]  # type: ignore\n\n        # Overwrite default with the user provided metadata\n        default_metadata.update(pose_estimation_metadata)\n\n        # For every track in that video create a PoseEstimation container\n        name_of_tracks_in_video = (\n            labels_data_df[video.filename]\n            .columns.get_level_values(\"track_name\")\n            .unique()\n        )\n\n        for track_index, track_name in enumerate(name_of_tracks_in_video):\n            pose_estimation_container = build_pose_estimation_container_for_track(\n                labels_data_df,\n                labels,\n                track_name,\n                video,\n                default_metadata,\n                skeleton_map,\n                devices=[device],\n            )\n            nwb_processing_module.add(pose_estimation_container)\n\n    return nwbfile\n</code></pre>"},{"location":"reference/sleap_io/io/nwb/#sleap_io.io.nwb.load_nwb","title":"<code>load_nwb(filename)</code>","text":"<p>Load an NWB dataset as a SLEAP Labels object.</p> <p>Automatically detects whether the file contains PoseTraining (annotations) or PoseEstimation (predictions) data and uses the appropriate backend.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>Union[str, Path]</code> <p>Path to an NWB file (.nwb).</p> required <p>Returns:</p> Type Description <code>Labels</code> <p>The dataset as a Labels object.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the NWB file doesn't contain recognized pose data.</p> Source code in <code>sleap_io/io/nwb.py</code> <pre><code>def load_nwb(filename: Union[str, Path]) -&gt; Labels:\n    \"\"\"Load an NWB dataset as a SLEAP Labels object.\n\n    Automatically detects whether the file contains PoseTraining (annotations)\n    or PoseEstimation (predictions) data and uses the appropriate backend.\n\n    Args:\n        filename: Path to an NWB file (.nwb).\n\n    Returns:\n        The dataset as a Labels object.\n\n    Raises:\n        ValueError: If the NWB file doesn't contain recognized pose data.\n    \"\"\"\n    from sleap_io.io import nwb_annotations, nwb_predictions\n\n    filename = Path(filename)\n\n    # Check what type of data is in the file\n    with h5py.File(filename, \"r\") as f:\n        # Check for behavior processing module with PoseTraining (annotations)\n        if \"processing\" in f and \"behavior\" in f[\"processing\"]:\n            behavior = f[\"processing\"][\"behavior\"]\n\n            # Check for PoseTraining (annotations)\n            if \"PoseTraining\" in behavior:\n                return nwb_annotations.load_labels(filename)\n\n            # Check for PoseEstimation in behavior module (old format)\n            for key in behavior.keys():\n                if key not in [\"PoseTraining\", \"Skeletons\"]:\n                    if \"neurodata_type\" in behavior[key].attrs:\n                        if behavior[key].attrs[\"neurodata_type\"] == \"PoseEstimation\":\n                            return nwb_predictions.read_nwb(filename)\n\n        # Check for PoseEstimation in separate processing modules (predictions)\n        if \"processing\" in f:\n            for module_name in f[\"processing\"].keys():\n                if module_name != \"behavior\":  # Skip behavior module (already checked)\n                    module = f[\"processing\"][module_name]\n                    # Look for PoseEstimation containers\n                    for key in module.keys():\n                        if \"neurodata_type\" in module[key].attrs:\n                            if module[key].attrs[\"neurodata_type\"] == \"PoseEstimation\":\n                                return nwb_predictions.read_nwb(filename)\n\n    raise ValueError(\n        f\"NWB file '{filename}' does not contain recognized pose data \"\n        \"(neither PoseTraining nor PoseEstimation found in behavior module)\"\n    )\n</code></pre>"},{"location":"reference/sleap_io/io/nwb/#sleap_io.io.nwb.read_nwb","title":"<code>read_nwb(path)</code>","text":"<p>Read an NWB formatted file to a SLEAP <code>Labels</code> object.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Path to an NWB file (<code>.nwb</code>).</p> required <p>Returns:</p> Type Description <code>Labels</code> <p>A <code>Labels</code> object.</p> Source code in <code>sleap_io/io/nwb_predictions.py</code> <pre><code>def read_nwb(path: str) -&gt; Labels:\n    \"\"\"Read an NWB formatted file to a SLEAP `Labels` object.\n\n    Args:\n        path: Path to an NWB file (`.nwb`).\n\n    Returns:\n        A `Labels` object.\n    \"\"\"\n    with NWBHDF5IO(path, mode=\"r\", load_namespaces=True) as io:\n        read_nwbfile = io.read()\n        nwb_file_processing = read_nwbfile.processing\n\n        # Get list of videos\n        video_keys: List[str] = [\n            key for key in nwb_file_processing.keys() if \"SLEAP_VIDEO\" in key\n        ]\n        video_tracks = dict()\n\n        # Get track keys from first video's processing module\n        test_processing_module: ProcessingModule = nwb_file_processing[video_keys[0]]\n        track_keys: List[str] = list(test_processing_module.fields[\"data_interfaces\"])\n\n        # Get first track's skeleton\n        test_pose_estimation: PoseEstimation = test_processing_module[track_keys[0]]\n        skeleton = test_pose_estimation.skeleton\n        skeleton_nodes = skeleton.nodes[:]\n        skeleton_edges = skeleton.edges[:]\n\n        # Filtering out behavior module with skeletons\n        pose_estimation_container_modules = [\n            nwb_file_processing[key] for key in video_keys\n        ]\n\n        for processing_module in pose_estimation_container_modules:\n            # Get track keys\n            _track_keys: List[str] = list(processing_module.fields[\"data_interfaces\"])\n            is_tracked: bool = re.sub(\"[0-9]+\", \"\", _track_keys[0]) == \"track\"\n\n            # Figure out the max number of frames and the canonical timestamps\n            timestamps = np.empty(())\n            for track_key in _track_keys:\n                pose_estimation = processing_module[track_key]\n                for node_name in skeleton.nodes:\n                    pose_estimation_series = pose_estimation[node_name]\n                    timestamps = np.union1d(\n                        timestamps, get_timestamps(pose_estimation_series)\n                    )\n            timestamps = np.sort(timestamps)\n\n            # Recreate Labels numpy (same as output of Labels.numpy())\n            n_tracks = len(_track_keys)\n            n_frames = len(timestamps)\n            n_nodes = len(skeleton.nodes)\n            tracks_numpy = np.full((n_frames, n_tracks, n_nodes, 2), np.nan, np.float32)\n            confidence = np.full((n_frames, n_tracks, n_nodes), np.nan, np.float32)\n\n            for track_idx, track_key in enumerate(_track_keys):\n                pose_estimation = processing_module[track_key]\n                for node_idx, node_name in enumerate(skeleton.nodes):\n                    pose_estimation_series = pose_estimation[node_name]\n                    frame_inds = np.searchsorted(\n                        timestamps, get_timestamps(pose_estimation_series)\n                    )\n                    tracks_numpy[frame_inds, track_idx, node_idx, :] = (\n                        pose_estimation_series.data[:]\n                    )\n                    confidence[frame_inds, track_idx, node_idx] = (\n                        pose_estimation_series.confidence[:]\n                    )\n\n            video_tracks[Path(pose_estimation.original_videos[0]).as_posix()] = (\n                tracks_numpy,\n                confidence,\n                is_tracked,\n            )\n\n    # Create SLEAP skeleton from NWB skeleton\n    sleap_skeleton = SleapSkeleton(\n        nodes=skeleton_nodes,\n        edges=skeleton_edges.tolist(),\n    )\n\n    # Add instances to labeled frames\n    lfs = []\n    for video_fn, (tracks_numpy, confidence, is_tracked) in video_tracks.items():\n        video = Video(filename=video_fn)\n        n_frames, n_tracks, n_nodes, _ = tracks_numpy.shape\n        tracks = [Track(name=f\"track{track_idx}\") for track_idx in range(n_tracks)]\n\n        for frame_idx, (frame_pts, frame_confs) in enumerate(\n            zip(tracks_numpy, confidence)\n        ):\n            insts: List[Union[Instance, PredictedInstance]] = []\n            for track, (inst_pts, inst_confs) in zip(\n                tracks, zip(frame_pts, frame_confs)\n            ):\n                if np.isnan(inst_pts).all():\n                    continue\n                insts.append(\n                    PredictedInstance.from_numpy(\n                        points_data=np.column_stack(\n                            [inst_pts, inst_confs]\n                        ),  # (n_nodes, 3)\n                        score=inst_confs.mean(),  # ()\n                        skeleton=sleap_skeleton,\n                        track=track if is_tracked else None,\n                    )\n                )\n            if len(insts) &gt; 0:\n                lfs.append(\n                    LabeledFrame(video=video, frame_idx=frame_idx, instances=insts)\n                )\n\n    labels = Labels(lfs)\n    labels.provenance[\"filename\"] = path\n    return labels\n</code></pre>"},{"location":"reference/sleap_io/io/nwb/#sleap_io.io.nwb.save_nwb","title":"<code>save_nwb(labels, filename, nwb_format=NwbFormat.AUTO, append=False)</code>","text":"<p>Save a SLEAP dataset to NWB format.</p> <p>Parameters:</p> Name Type Description Default <code>labels</code> <code>Labels</code> <p>A SLEAP Labels object to save.</p> required <code>filename</code> <code>Union[str, Path]</code> <p>Path to NWB file to save to. Must end in '.nwb'.</p> required <code>nwb_format</code> <code>Union[NwbFormat, str]</code> <p>Format to use for saving. Options are: - \"auto\" (default): Automatically detect based on data - \"annotations\": Save training annotations (PoseTraining) - \"annotations_export\": Export annotations with video frames - \"predictions\": Save predictions (PoseEstimation)</p> <code>AUTO</code> <code>append</code> <code>bool</code> <p>If True, append to existing NWB file. Only supported for predictions format. Defaults to False.</p> <code>False</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If an invalid format is specified.</p> Source code in <code>sleap_io/io/nwb.py</code> <pre><code>def save_nwb(\n    labels: Labels,\n    filename: Union[str, Path],\n    nwb_format: Union[NwbFormat, str] = NwbFormat.AUTO,\n    append: bool = False,\n) -&gt; None:\n    \"\"\"Save a SLEAP dataset to NWB format.\n\n    Args:\n        labels: A SLEAP Labels object to save.\n        filename: Path to NWB file to save to. Must end in '.nwb'.\n        nwb_format: Format to use for saving. Options are:\n            - \"auto\" (default): Automatically detect based on data\n            - \"annotations\": Save training annotations (PoseTraining)\n            - \"annotations_export\": Export annotations with video frames\n            - \"predictions\": Save predictions (PoseEstimation)\n        append: If True, append to existing NWB file. Only supported for\n            predictions format. Defaults to False.\n\n    Raises:\n        ValueError: If an invalid format is specified.\n    \"\"\"\n    from sleap_io.io import nwb_annotations, nwb_predictions\n\n    filename = Path(filename)\n\n    # Convert string to enum if needed\n    if isinstance(nwb_format, str):\n        try:\n            nwb_format = NwbFormat(nwb_format)\n        except ValueError:\n            raise ValueError(\n                f\"Invalid NWB format: '{nwb_format}'. \"\n                f\"Must be one of: {', '.join(f.value for f in NwbFormat)}\"\n            )\n\n    # Auto-detect format if needed\n    if nwb_format == NwbFormat.AUTO:\n        # Check if there are any user instances\n        has_user_instances = any(lf.has_user_instances for lf in labels.labeled_frames)\n\n        if has_user_instances:\n            nwb_format = NwbFormat.ANNOTATIONS\n        else:\n            nwb_format = NwbFormat.PREDICTIONS\n\n    # Route to appropriate backend\n    if nwb_format == NwbFormat.ANNOTATIONS:\n        nwb_annotations.save_labels(labels, filename)\n    elif nwb_format == NwbFormat.ANNOTATIONS_EXPORT:\n        # Use export_labels for the export format\n        output_dir = filename.parent\n        nwb_filename = filename.name\n        nwb_annotations.export_labels(\n            labels,\n            output_dir=output_dir,\n            nwb_filename=nwb_filename,\n            clean=True,  # Clean up intermediate files\n        )\n    elif nwb_format == NwbFormat.PREDICTIONS:\n        if append:\n            nwb_predictions.append_nwb(labels, str(filename))\n        else:\n            nwb_predictions.write_nwb(labels, filename)\n    else:\n        raise ValueError(f\"Unexpected NWB format: {nwb_format}\")\n</code></pre>"},{"location":"reference/sleap_io/io/nwb/#sleap_io.io.nwb.write_nwb","title":"<code>write_nwb(labels, nwbfile_path, nwb_file_kwargs=None, pose_estimation_metadata=None)</code>","text":"<p>Write labels to an nwb file and save it to the nwbfile_path given.</p> <p>Parameters:</p> Name Type Description Default <code>labels</code> <code>Labels</code> <p>A general <code>Labels</code> object.</p> required <code>nwbfile_path</code> <code>str</code> <p>The path where the nwb file is to be written.</p> required <code>nwb_file_kwargs</code> <code>Optional[dict]</code> <p>A dict containing metadata to the nwbfile. Example: nwb_file_kwargs = {     'session_description: 'your_session_description',     'identifier': 'your session_identifier', } For a full list of possible values see: https://pynwb.readthedocs.io/en/stable/pynwb.file.html#pynwb.file.NWBFile</p> <p>Defaults to None and default values are used to generate the nwb file.</p> <code>None</code> <code>pose_estimation_metadata</code> <code>Optional[dict]</code> <p>This argument has a dual purpose:</p> <p>1) It can be used to pass time information about the video which is necessary for synchronizing frames in pose estimation tracking to other modalities. Either the video timestamps can be passed to This can be used to pass the timestamps with the key <code>video_timestamps</code> or the sampling rate with key<code>video_sample_rate</code>.</p> <p>e.g. pose_estimation_metadata[\"video_timestamps\"] = np.array(timestamps) or   pose_estimation_metadata[\"video_sample_rate] = 15  # In Hz</p> <p>2) The other use of this dictionary is to overwrite sleap-io default arguments for the PoseEstimation container. see https://github.com/rly/ndx-pose for a full list or arguments.</p> <code>None</code> Source code in <code>sleap_io/io/nwb_predictions.py</code> <pre><code>def write_nwb(\n    labels: Labels,\n    nwbfile_path: str,\n    nwb_file_kwargs: Optional[dict] = None,\n    pose_estimation_metadata: Optional[dict] = None,\n):\n    \"\"\"Write labels to an nwb file and save it to the nwbfile_path given.\n\n    Args:\n        labels: A general `Labels` object.\n        nwbfile_path: The path where the nwb file is to be written.\n        nwb_file_kwargs: A dict containing metadata to the nwbfile. Example:\n            nwb_file_kwargs = {\n                'session_description: 'your_session_description',\n                'identifier': 'your session_identifier',\n            }\n            For a full list of possible values see:\n            https://pynwb.readthedocs.io/en/stable/pynwb.file.html#pynwb.file.NWBFile\n\n            Defaults to None and default values are used to generate the nwb file.\n\n        pose_estimation_metadata: This argument has a dual purpose:\n\n            1) It can be used to pass time information about the video which is\n            necessary for synchronizing frames in pose estimation tracking to other\n            modalities. Either the video timestamps can be passed to\n            This can be used to pass the timestamps with the key `video_timestamps`\n            or the sampling rate with key`video_sample_rate`.\n\n            e.g. pose_estimation_metadata[\"video_timestamps\"] = np.array(timestamps)\n            or   pose_estimation_metadata[\"video_sample_rate] = 15  # In Hz\n\n            2) The other use of this dictionary is to overwrite sleap-io default\n            arguments for the PoseEstimation container.\n            see https://github.com/rly/ndx-pose for a full list or arguments.\n    \"\"\"\n    nwb_file_kwargs = nwb_file_kwargs or dict()\n\n    # Add required values for nwbfile if not present\n    session_description = nwb_file_kwargs.get(\n        \"session_description\", \"Processed SLEAP pose data\"\n    )\n    session_start_time = nwb_file_kwargs.get(\n        \"session_start_time\", datetime.datetime.now(datetime.timezone.utc)\n    )\n    identifier = nwb_file_kwargs.get(\"identifier\", str(uuid.uuid1()))\n\n    nwb_file_kwargs.update(\n        session_description=session_description,\n        session_start_time=session_start_time,\n        identifier=identifier,\n    )\n\n    nwbfile = NWBFile(**nwb_file_kwargs)\n\n    # Create skeleton containers first\n    skeleton_map = create_skeleton_container(labels, nwbfile)\n\n    # Then append pose data\n    nwbfile = append_nwb_data(labels, nwbfile, pose_estimation_metadata, skeleton_map)\n\n    with NWBHDF5IO(str(nwbfile_path), \"w\") as io:\n        io.write(nwbfile)\n</code></pre>"},{"location":"reference/sleap_io/io/nwb_annotations/","title":"nwb_annotations","text":""},{"location":"reference/sleap_io/io/nwb_annotations/#sleap_io.io.nwb_annotations","title":"<code>sleap_io.io.nwb_annotations</code>","text":"<p>NWB formatted annotations.</p> <p>Classes:</p> Name Description <code>FrameInfo</code> <p>Information about a single frame in the MJPEG video.</p> <code>FrameMap</code> <p>Map frames in an MJPEG video back to source videos for provenance tracking.</p> <p>Functions:</p> Name Description <code>create_nwb_to_slp_skeleton_map</code> <p>Create mapping from NWB Skeletons to sleap-io Skeletons.</p> <code>create_nwb_to_slp_video_map</code> <p>Create mapping from NWB ImageSeries to sleap-io Videos.</p> <code>create_slp_to_nwb_skeleton_map</code> <p>Create mapping from sleap-io Skeletons to NWB Skeletons.</p> <code>create_slp_to_nwb_video_map</code> <p>Create mapping from sleap-io Videos to NWB ImageSeries.</p> <code>export_labeled_frames</code> <p>Export labeled frames to an MJPEG video with provenance tracking.</p> <code>export_labels</code> <p>Export Labels to NWB format with MJPEG video and frame map.</p> <code>load_labels</code> <p>Load sleap-io Labels from an NWB file.</p> <code>nwb_image_series_to_sleap_video</code> <p>Convert a pynwb ImageSeries to sleap-io Video.</p> <code>nwb_pose_training_to_sleap_labels</code> <p>Convert ndx-pose PoseTraining and Skeletons to sleap-io Labels.</p> <code>nwb_skeleton_instance_to_sleap_instance</code> <p>Convert an ndx-pose SkeletonInstance to sleap-io Instance.</p> <code>nwb_skeleton_to_sleap_skeleton</code> <p>Convert an ndx-pose Skeleton to sleap-io Skeleton.</p> <code>nwb_source_videos_to_sleap_videos</code> <p>Convert ndx-pose SourceVideos to a list of sleap-io Videos.</p> <code>nwb_training_frame_to_sleap_labeled_frame</code> <p>Convert an ndx-pose TrainingFrame to sleap-io LabeledFrame.</p> <code>nwb_training_frames_to_sleap_labeled_frames</code> <p>Convert ndx-pose TrainingFrames to a list of sleap-io LabeledFrames.</p> <code>sanitize_nwb_name</code> <p>Sanitize a name for use in NWB files.</p> <code>save_labels</code> <p>Save sleap-io Labels to an NWB file.</p> <code>sleap_instance_to_nwb_skeleton_instance</code> <p>Convert a sleap-io Instance to ndx-pose SkeletonInstance.</p> <code>sleap_labeled_frame_to_nwb_training_frame</code> <p>Convert a sleap-io LabeledFrame to ndx-pose TrainingFrame.</p> <code>sleap_labeled_frames_to_nwb_training_frames</code> <p>Convert a list of sleap-io LabeledFrames to ndx-pose TrainingFrames container.</p> <code>sleap_labels_to_nwb_pose_training</code> <p>Convert sleap-io Labels to ndx-pose PoseTraining container and Skeletons.</p> <code>sleap_skeleton_to_nwb_skeleton</code> <p>Convert a sleap-io Skeleton to ndx-pose Skeleton.</p> <code>sleap_video_to_nwb_image_series</code> <p>Convert a sleap-io Video to pynwb ImageSeries.</p> <code>sleap_videos_to_nwb_source_videos</code> <p>Convert a list of sleap-io Videos to ndx-pose SourceVideos container.</p>"},{"location":"reference/sleap_io/io/nwb_annotations/#sleap_io.io.nwb_annotations.FrameInfo","title":"<code>FrameInfo</code>","text":"<p>Information about a single frame in the MJPEG video.</p> <p>Attributes:</p> Name Type Description <code>video_ind</code> <code>int</code> <p>Index into the videos list indicating which video this frame came from.</p> <code>frame_idx</code> <code>int</code> <p>Original frame index in the source video.</p> Source code in <code>sleap_io/io/nwb_annotations.py</code> <pre><code>@attrs.define\nclass FrameInfo:\n    \"\"\"Information about a single frame in the MJPEG video.\n\n    Attributes:\n        video_ind: Index into the videos list indicating which video this frame\n            came from.\n        frame_idx: Original frame index in the source video.\n    \"\"\"\n\n    video_ind: int\n    frame_idx: int\n</code></pre>"},{"location":"reference/sleap_io/io/nwb_annotations/#sleap_io.io.nwb_annotations.FrameMap","title":"<code>FrameMap</code>","text":"<p>Map frames in an MJPEG video back to source videos for provenance tracking.</p> <p>This class stores the mapping between frames in an exported MJPEG video and their original source videos. It is serialized to/from a frame_map.json file alongside the MJPEG video.</p> <p>Attributes:</p> Name Type Description <code>frame_map_filename</code> <code>Optional[str]</code> <p>Path to the frame_map.json file.</p> <code>sleap_labels_filename</code> <code>Optional[str]</code> <p>Path to the SLEAP labels (.slp) file.</p> <code>nwb_filename</code> <code>Optional[str]</code> <p>Path to the NWB file.</p> <code>mjpeg_filename</code> <code>Optional[str]</code> <p>Path to the MJPEG video file.</p> <code>videos</code> <code>List[Video]</code> <p>List of Video objects representing the source videos.</p> <code>frames</code> <code>List[FrameInfo]</code> <p>List of FrameInfo objects, one per frame in the MJPEG video, indicating which source video and frame index each MJPEG frame came from.</p> <p>Methods:</p> Name Description <code>from_labels</code> <p>Construct a FrameMap from a Labels object.</p> <code>load</code> <p>Load a frame map from a JSON file.</p> <code>save</code> <p>Save the frame map to a JSON file.</p> <code>to_json</code> <p>Convert the FrameMap to a JSON-serializable dictionary.</p> Source code in <code>sleap_io/io/nwb_annotations.py</code> <pre><code>@attrs.define\nclass FrameMap:\n    \"\"\"Map frames in an MJPEG video back to source videos for provenance tracking.\n\n    This class stores the mapping between frames in an exported MJPEG video and their\n    original source videos. It is serialized to/from a frame_map.json file alongside\n    the MJPEG video.\n\n    Attributes:\n        frame_map_filename: Path to the frame_map.json file.\n        sleap_labels_filename: Path to the SLEAP labels (.slp) file.\n        nwb_filename: Path to the NWB file.\n        mjpeg_filename: Path to the MJPEG video file.\n        videos: List of Video objects representing the source videos.\n        frames: List of FrameInfo objects, one per frame in the MJPEG video,\n            indicating which source video and frame index each MJPEG frame came from.\n    \"\"\"\n\n    frame_map_filename: Optional[str] = None\n    sleap_labels_filename: Optional[str] = None\n    nwb_filename: Optional[str] = None\n    mjpeg_filename: Optional[str] = None\n    videos: List[SleapVideo] = attrs.field(factory=list)\n    frames: List[FrameInfo] = attrs.field(factory=list)\n\n    @classmethod\n    def from_labels(cls, labels: SleapLabels) -&gt; \"FrameMap\":\n        \"\"\"Construct a FrameMap from a Labels object.\n\n        Args:\n            labels: Labels object containing labeled frames and videos.\n\n        Returns:\n            FrameMap instance with videos and frame mappings extracted from the\n                labels.\n        \"\"\"\n        # Copy videos from labels, preserving order\n        videos = []\n        for video in labels.videos:\n            video_copy = SleapVideo(\n                filename=video.filename,\n                backend_metadata=video.backend_metadata,\n                open_backend=False,\n            )\n            videos.append(video_copy)\n\n        # Build frames list following labeled_frames order\n        frames = []\n        for lf in labels.labeled_frames:\n            # Find video index in the videos list\n            video_ind = labels.videos.index(lf.video)\n            frame_info = FrameInfo(video_ind=video_ind, frame_idx=lf.frame_idx)\n            frames.append(frame_info)\n\n        return cls(videos=videos, frames=frames)\n\n    def to_json(self) -&gt; Dict[str, Any]:\n        \"\"\"Convert the FrameMap to a JSON-serializable dictionary.\n\n        Returns:\n            Dictionary representation of the FrameMap suitable for JSON serialization.\n        \"\"\"\n        return {\n            \"frame_map_filename\": self.frame_map_filename,\n            \"nwb_filename\": self.nwb_filename,\n            \"mjpeg_filename\": self.mjpeg_filename,\n            \"videos\": [\n                {\n                    \"filename\": video.filename,\n                    \"backend_metadata\": video.backend_metadata,\n                }\n                for video in self.videos\n            ],\n            \"frames\": [\n                {\"video_ind\": frame.video_ind, \"frame_idx\": frame.frame_idx}\n                for frame in self.frames\n            ],\n        }\n\n    def save(self, frame_map_filename: Union[str, Path]):\n        \"\"\"Save the frame map to a JSON file.\n\n        Args:\n            frame_map_filename: Path to save the frame_map.json file.\n        \"\"\"\n        # Update frame map filename with specified input.\n        frame_map_filename = Path(frame_map_filename)\n        self.frame_map_filename = sanitize_filename(frame_map_filename)\n\n        # Prepare data for JSON serialization.\n        json_data = self.to_json()\n\n        # Write to disk.\n        with open(self.frame_map_filename, \"w\") as f:\n            json.dump(json_data, f, indent=2)\n\n    @classmethod\n    def load(cls, path: Union[str, Path]) -&gt; \"FrameMap\":\n        \"\"\"Load a frame map from a JSON file.\n\n        Args:\n            path: Path to the frame_map.json file.\n\n        Returns:\n            FrameMap instance reconstructed from the JSON data.\n\n        Raises:\n            FileNotFoundError: If the frame_map.json file doesn't exist.\n            json.JSONDecodeError: If the JSON file is malformed.\n        \"\"\"\n        path = Path(path)\n\n        with open(path, \"r\") as f:\n            json_data = json.load(f)\n\n        # Reconstruct Video objects without opening backends\n        videos = []\n        for video_data in json_data[\"videos\"]:\n            video = SleapVideo(\n                filename=video_data[\"filename\"],\n                backend_metadata=video_data.get(\"backend_metadata\", {}),\n                open_backend=False,\n            )\n            videos.append(video)\n\n        # Reconstruct FrameInfo objects\n        frames = []\n        for frame_data in json_data[\"frames\"]:\n            frames.append(\n                FrameInfo(\n                    video_ind=frame_data[\"video_ind\"], frame_idx=frame_data[\"frame_idx\"]\n                )\n            )\n\n        return cls(\n            frame_map_filename=str(path),\n            nwb_filename=json_data.get(\"nwb_filename\", None),\n            mjpeg_filename=json_data.get(\"mjpeg_filename\", None),\n            videos=videos,\n            frames=frames,\n        )\n</code></pre>"},{"location":"reference/sleap_io/io/nwb_annotations/#sleap_io.io.nwb_annotations.FrameMap.from_labels","title":"<code>from_labels(labels)</code>  <code>classmethod</code>","text":"<p>Construct a FrameMap from a Labels object.</p> <p>Parameters:</p> Name Type Description Default <code>labels</code> <code>Labels</code> <p>Labels object containing labeled frames and videos.</p> required <p>Returns:</p> Type Description <code>FrameMap</code> <p>FrameMap instance with videos and frame mappings extracted from the     labels.</p> Source code in <code>sleap_io/io/nwb_annotations.py</code> <pre><code>@classmethod\ndef from_labels(cls, labels: SleapLabels) -&gt; \"FrameMap\":\n    \"\"\"Construct a FrameMap from a Labels object.\n\n    Args:\n        labels: Labels object containing labeled frames and videos.\n\n    Returns:\n        FrameMap instance with videos and frame mappings extracted from the\n            labels.\n    \"\"\"\n    # Copy videos from labels, preserving order\n    videos = []\n    for video in labels.videos:\n        video_copy = SleapVideo(\n            filename=video.filename,\n            backend_metadata=video.backend_metadata,\n            open_backend=False,\n        )\n        videos.append(video_copy)\n\n    # Build frames list following labeled_frames order\n    frames = []\n    for lf in labels.labeled_frames:\n        # Find video index in the videos list\n        video_ind = labels.videos.index(lf.video)\n        frame_info = FrameInfo(video_ind=video_ind, frame_idx=lf.frame_idx)\n        frames.append(frame_info)\n\n    return cls(videos=videos, frames=frames)\n</code></pre>"},{"location":"reference/sleap_io/io/nwb_annotations/#sleap_io.io.nwb_annotations.FrameMap.load","title":"<code>load(path)</code>  <code>classmethod</code>","text":"<p>Load a frame map from a JSON file.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Union[str, Path]</code> <p>Path to the frame_map.json file.</p> required <p>Returns:</p> Type Description <code>FrameMap</code> <p>FrameMap instance reconstructed from the JSON data.</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the frame_map.json file doesn't exist.</p> <code>JSONDecodeError</code> <p>If the JSON file is malformed.</p> Source code in <code>sleap_io/io/nwb_annotations.py</code> <pre><code>@classmethod\ndef load(cls, path: Union[str, Path]) -&gt; \"FrameMap\":\n    \"\"\"Load a frame map from a JSON file.\n\n    Args:\n        path: Path to the frame_map.json file.\n\n    Returns:\n        FrameMap instance reconstructed from the JSON data.\n\n    Raises:\n        FileNotFoundError: If the frame_map.json file doesn't exist.\n        json.JSONDecodeError: If the JSON file is malformed.\n    \"\"\"\n    path = Path(path)\n\n    with open(path, \"r\") as f:\n        json_data = json.load(f)\n\n    # Reconstruct Video objects without opening backends\n    videos = []\n    for video_data in json_data[\"videos\"]:\n        video = SleapVideo(\n            filename=video_data[\"filename\"],\n            backend_metadata=video_data.get(\"backend_metadata\", {}),\n            open_backend=False,\n        )\n        videos.append(video)\n\n    # Reconstruct FrameInfo objects\n    frames = []\n    for frame_data in json_data[\"frames\"]:\n        frames.append(\n            FrameInfo(\n                video_ind=frame_data[\"video_ind\"], frame_idx=frame_data[\"frame_idx\"]\n            )\n        )\n\n    return cls(\n        frame_map_filename=str(path),\n        nwb_filename=json_data.get(\"nwb_filename\", None),\n        mjpeg_filename=json_data.get(\"mjpeg_filename\", None),\n        videos=videos,\n        frames=frames,\n    )\n</code></pre>"},{"location":"reference/sleap_io/io/nwb_annotations/#sleap_io.io.nwb_annotations.FrameMap.save","title":"<code>save(frame_map_filename)</code>","text":"<p>Save the frame map to a JSON file.</p> <p>Parameters:</p> Name Type Description Default <code>frame_map_filename</code> <code>Union[str, Path]</code> <p>Path to save the frame_map.json file.</p> required Source code in <code>sleap_io/io/nwb_annotations.py</code> <pre><code>def save(self, frame_map_filename: Union[str, Path]):\n    \"\"\"Save the frame map to a JSON file.\n\n    Args:\n        frame_map_filename: Path to save the frame_map.json file.\n    \"\"\"\n    # Update frame map filename with specified input.\n    frame_map_filename = Path(frame_map_filename)\n    self.frame_map_filename = sanitize_filename(frame_map_filename)\n\n    # Prepare data for JSON serialization.\n    json_data = self.to_json()\n\n    # Write to disk.\n    with open(self.frame_map_filename, \"w\") as f:\n        json.dump(json_data, f, indent=2)\n</code></pre>"},{"location":"reference/sleap_io/io/nwb_annotations/#sleap_io.io.nwb_annotations.FrameMap.to_json","title":"<code>to_json()</code>","text":"<p>Convert the FrameMap to a JSON-serializable dictionary.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary representation of the FrameMap suitable for JSON serialization.</p> Source code in <code>sleap_io/io/nwb_annotations.py</code> <pre><code>def to_json(self) -&gt; Dict[str, Any]:\n    \"\"\"Convert the FrameMap to a JSON-serializable dictionary.\n\n    Returns:\n        Dictionary representation of the FrameMap suitable for JSON serialization.\n    \"\"\"\n    return {\n        \"frame_map_filename\": self.frame_map_filename,\n        \"nwb_filename\": self.nwb_filename,\n        \"mjpeg_filename\": self.mjpeg_filename,\n        \"videos\": [\n            {\n                \"filename\": video.filename,\n                \"backend_metadata\": video.backend_metadata,\n            }\n            for video in self.videos\n        ],\n        \"frames\": [\n            {\"video_ind\": frame.video_ind, \"frame_idx\": frame.frame_idx}\n            for frame in self.frames\n        ],\n    }\n</code></pre>"},{"location":"reference/sleap_io/io/nwb_annotations/#sleap_io.io.nwb_annotations.create_nwb_to_slp_skeleton_map","title":"<code>create_nwb_to_slp_skeleton_map(nwb_skeletons, sleap_skeletons)</code>","text":"<p>Create mapping from NWB Skeletons to sleap-io Skeletons.</p> <p>Parameters:</p> Name Type Description Default <code>nwb_skeletons</code> <code>Skeletons</code> <p>NWB Skeletons container with Skeleton objects.</p> required <code>sleap_skeletons</code> <code>List[Skeleton]</code> <p>List of sleap-io Skeleton objects.</p> required <p>Returns:</p> Type Description <code>Dict[Skeleton, Skeleton]</code> <p>Dictionary mapping each NWB Skeleton to its corresponding sleap-io Skeleton.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the number of skeletons doesn't match or mapping fails.</p> Source code in <code>sleap_io/io/nwb_annotations.py</code> <pre><code>def create_nwb_to_slp_skeleton_map(\n    nwb_skeletons: NwbSkeletons,\n    sleap_skeletons: List[SleapSkeleton],\n) -&gt; Dict[NwbSkeleton, SleapSkeleton]:\n    \"\"\"Create mapping from NWB Skeletons to sleap-io Skeletons.\n\n    Args:\n        nwb_skeletons: NWB Skeletons container with Skeleton objects.\n        sleap_skeletons: List of sleap-io Skeleton objects.\n\n    Returns:\n        Dictionary mapping each NWB Skeleton to its corresponding sleap-io Skeleton.\n\n    Raises:\n        ValueError: If the number of skeletons doesn't match or mapping fails.\n    \"\"\"\n    nwb_skeleton_list = list(nwb_skeletons.skeletons.values())\n\n    if len(nwb_skeleton_list) != len(sleap_skeletons):\n        raise ValueError(\n            f\"Number of NWB Skeletons ({len(nwb_skeleton_list)}) does not match \"\n            f\"number of sleap skeletons ({len(sleap_skeletons)})\"\n        )\n\n    # Create mapping based on order (assuming consistent ordering)\n    skeleton_map = {}\n    for nwb_skeleton, sleap_skeleton in zip(nwb_skeleton_list, sleap_skeletons):\n        skeleton_map[nwb_skeleton] = sleap_skeleton\n\n    return skeleton_map\n</code></pre>"},{"location":"reference/sleap_io/io/nwb_annotations/#sleap_io.io.nwb_annotations.create_nwb_to_slp_video_map","title":"<code>create_nwb_to_slp_video_map(nwb_image_series, sleap_videos)</code>","text":"<p>Create mapping from NWB ImageSeries to sleap-io Videos.</p> <p>Parameters:</p> Name Type Description Default <code>nwb_image_series</code> <code>List[ImageSeries]</code> <p>List of NWB ImageSeries objects.</p> required <code>sleap_videos</code> <code>List[Video]</code> <p>List of sleap-io Video objects.</p> required <p>Returns:</p> Type Description <code>Dict[ImageSeries, Video]</code> <p>Dictionary mapping each ImageSeries to its corresponding sleap-io Video.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the number of videos doesn't match or mapping fails.</p> Source code in <code>sleap_io/io/nwb_annotations.py</code> <pre><code>def create_nwb_to_slp_video_map(\n    nwb_image_series: List[ImageSeries],\n    sleap_videos: List[SleapVideo],\n) -&gt; Dict[ImageSeries, SleapVideo]:\n    \"\"\"Create mapping from NWB ImageSeries to sleap-io Videos.\n\n    Args:\n        nwb_image_series: List of NWB ImageSeries objects.\n        sleap_videos: List of sleap-io Video objects.\n\n    Returns:\n        Dictionary mapping each ImageSeries to its corresponding sleap-io Video.\n\n    Raises:\n        ValueError: If the number of videos doesn't match or mapping fails.\n    \"\"\"\n    if len(nwb_image_series) != len(sleap_videos):\n        raise ValueError(\n            f\"Number of NWB ImageSeries ({len(nwb_image_series)}) does not match \"\n            f\"number of sleap videos ({len(sleap_videos)})\"\n        )\n\n    # Create mapping based on order (assuming consistent ordering)\n    video_map = {}\n    for image_series, sleap_video in zip(nwb_image_series, sleap_videos):\n        video_map[image_series] = sleap_video\n\n    return video_map\n</code></pre>"},{"location":"reference/sleap_io/io/nwb_annotations/#sleap_io.io.nwb_annotations.create_slp_to_nwb_skeleton_map","title":"<code>create_slp_to_nwb_skeleton_map(sleap_skeletons, nwb_skeletons)</code>","text":"<p>Create mapping from sleap-io Skeletons to NWB Skeletons.</p> <p>Parameters:</p> Name Type Description Default <code>sleap_skeletons</code> <code>List[Skeleton]</code> <p>List of sleap-io Skeleton objects.</p> required <code>nwb_skeletons</code> <code>Skeletons</code> <p>NWB Skeletons container with Skeleton objects.</p> required <p>Returns:</p> Type Description <code>Dict[Skeleton, Skeleton]</code> <p>Dictionary mapping each sleap-io Skeleton to its corresponding NWB Skeleton.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the number of skeletons doesn't match or mapping fails.</p> Source code in <code>sleap_io/io/nwb_annotations.py</code> <pre><code>def create_slp_to_nwb_skeleton_map(\n    sleap_skeletons: List[SleapSkeleton],\n    nwb_skeletons: NwbSkeletons,\n) -&gt; Dict[SleapSkeleton, NwbSkeleton]:\n    \"\"\"Create mapping from sleap-io Skeletons to NWB Skeletons.\n\n    Args:\n        sleap_skeletons: List of sleap-io Skeleton objects.\n        nwb_skeletons: NWB Skeletons container with Skeleton objects.\n\n    Returns:\n        Dictionary mapping each sleap-io Skeleton to its corresponding NWB Skeleton.\n\n    Raises:\n        ValueError: If the number of skeletons doesn't match or mapping fails.\n    \"\"\"\n    nwb_skeleton_list = list(nwb_skeletons.skeletons.values())\n\n    if len(sleap_skeletons) != len(nwb_skeleton_list):\n        raise ValueError(\n            f\"Number of sleap skeletons ({len(sleap_skeletons)}) does not match \"\n            f\"number of NWB Skeletons ({len(nwb_skeleton_list)})\"\n        )\n\n    # Create mapping based on order (assuming skeletons were created consistently)\n    skeleton_map = {}\n    for sleap_skeleton, nwb_skeleton in zip(sleap_skeletons, nwb_skeleton_list):\n        skeleton_map[sleap_skeleton] = nwb_skeleton\n\n    return skeleton_map\n</code></pre>"},{"location":"reference/sleap_io/io/nwb_annotations/#sleap_io.io.nwb_annotations.create_slp_to_nwb_video_map","title":"<code>create_slp_to_nwb_video_map(sleap_videos, nwb_source_videos)</code>","text":"<p>Create mapping from sleap-io Videos to NWB ImageSeries.</p> <p>Parameters:</p> Name Type Description Default <code>sleap_videos</code> <code>List[Video]</code> <p>List of sleap-io Video objects.</p> required <code>nwb_source_videos</code> <code>SourceVideos</code> <p>NWB SourceVideos container with ImageSeries.</p> required <p>Returns:</p> Type Description <code>Dict[Video, ImageSeries]</code> <p>Dictionary mapping each sleap-io Video to its corresponding ImageSeries.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the number of videos doesn't match or mapping fails.</p> Source code in <code>sleap_io/io/nwb_annotations.py</code> <pre><code>def create_slp_to_nwb_video_map(\n    sleap_videos: List[SleapVideo],\n    nwb_source_videos: NwbSourceVideos,\n) -&gt; Dict[SleapVideo, ImageSeries]:\n    \"\"\"Create mapping from sleap-io Videos to NWB ImageSeries.\n\n    Args:\n        sleap_videos: List of sleap-io Video objects.\n        nwb_source_videos: NWB SourceVideos container with ImageSeries.\n\n    Returns:\n        Dictionary mapping each sleap-io Video to its corresponding ImageSeries.\n\n    Raises:\n        ValueError: If the number of videos doesn't match or mapping fails.\n    \"\"\"\n    # Create mapping based on order (assuming videos were created with\n    # sleap_videos_to_nwb_source_videos)\n    video_map = {}\n    for i, sleap_video in enumerate(sleap_videos):\n        video_name = f\"video_{i}\"\n        if video_name in nwb_source_videos.image_series:\n            video_map[sleap_video] = nwb_source_videos.image_series[video_name]\n        else:\n            raise ValueError(\n                f\"Could not find ImageSeries with name '{video_name}' in SourceVideos\"\n            )\n\n    return video_map\n</code></pre>"},{"location":"reference/sleap_io/io/nwb_annotations/#sleap_io.io.nwb_annotations.export_labeled_frames","title":"<code>export_labeled_frames(labels, frame_map_path, mjpeg_path, nwb_path=None)</code>","text":"<p>Export labeled frames to an MJPEG video with provenance tracking.</p> <p>This function exports all labeled frames from a Labels object to a seekable MJPEG video file, along with a JSON frame map that tracks the provenance of each frame back to its original source video and frame index.</p> <p>Parameters:</p> Name Type Description Default <code>labels</code> <code>Labels</code> <p>Labels object containing labeled frames and videos to export.</p> required <code>frame_map_path</code> <code>Union[str, Path]</code> <p>Path where the frame map JSON file will be saved.</p> required <code>mjpeg_path</code> <code>Union[str, Path]</code> <p>Path where the output MJPEG video file will be saved.</p> required <code>nwb_path</code> <code>Optional[Union[str, Path]]</code> <p>Optional path to associated NWB file for cross-referencing.</p> <code>None</code> <p>Returns:</p> Type Description <code>FrameMap</code> <p>FrameMap object containing all metadata and mappings for the exported video, including paths to output files and frame-to-video provenance.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If labels contain no labeled frames.</p> <code>OSError</code> <p>If output files cannot be written.</p> Example <pre><code>labels = load_file(\"dataset.slp\")\nframe_map = export_labeled_frames(\n    labels,\n    frame_map_path=\"exports/frame_map.json\",\n    mjpeg_path=\"exports/training_data.avi\",\n    nwb_path=\"exports/dataset.nwb\"\n)\nprint(f\"Exported {len(frame_map.frames)} frames to {frame_map.mjpeg_filename}\")\n</code></pre> Source code in <code>sleap_io/io/nwb_annotations.py</code> <pre><code>def export_labeled_frames(\n    labels: SleapLabels,\n    frame_map_path: Union[str, Path],\n    mjpeg_path: Union[str, Path],\n    nwb_path: Optional[Union[str, Path]] = None,\n) -&gt; FrameMap:\n    \"\"\"Export labeled frames to an MJPEG video with provenance tracking.\n\n    This function exports all labeled frames from a Labels object to a seekable\n    MJPEG video file, along with a JSON frame map that tracks the provenance of\n    each frame back to its original source video and frame index.\n\n    Args:\n        labels: Labels object containing labeled frames and videos to export.\n        frame_map_path: Path where the frame map JSON file will be saved.\n        mjpeg_path: Path where the output MJPEG video file will be saved.\n        nwb_path: Optional path to associated NWB file for cross-referencing.\n\n    Returns:\n        FrameMap object containing all metadata and mappings for the exported\n        video, including paths to output files and frame-to-video provenance.\n\n    Raises:\n        ValueError: If labels contain no labeled frames.\n        OSError: If output files cannot be written.\n\n    Example:\n        ```python\n        labels = load_file(\"dataset.slp\")\n        frame_map = export_labeled_frames(\n            labels,\n            frame_map_path=\"exports/frame_map.json\",\n            mjpeg_path=\"exports/training_data.avi\",\n            nwb_path=\"exports/dataset.nwb\"\n        )\n        print(f\"Exported {len(frame_map.frames)} frames to {frame_map.mjpeg_filename}\")\n        ```\n    \"\"\"\n    # Build FrameMap from labels and set metadata\n    frame_map = FrameMap.from_labels(labels)\n    frame_map.mjpeg_filename = sanitize_filename(mjpeg_path)\n    frame_map.frame_map_filename = sanitize_filename(frame_map_path)\n    frame_map.nwb_filename = (\n        sanitize_filename(nwb_path) if nwb_path is not None else None\n    )\n\n    # Export frames to MJPEG using MJPEGFrameWriter\n    with MJPEGFrameWriter(mjpeg_path) as writer:\n        for lf in labels.labeled_frames:\n            # Get frame data from the video at the specified frame index\n            frame_data = lf.video[lf.frame_idx]\n            writer.write_frame(frame_data)\n\n    # Save the frame map JSON alongside the MJPEG file\n    frame_map.save(frame_map_path)\n\n    return frame_map\n</code></pre>"},{"location":"reference/sleap_io/io/nwb_annotations/#sleap_io.io.nwb_annotations.export_labels","title":"<code>export_labels(labels, output_dir, mjpeg_filename='annotated_frames.avi', frame_map_filename='frame_map.json', nwb_filename='pose_training.nwb', clean=True)</code>","text":"<p>Export Labels to NWB format with MJPEG video and frame map.</p> <p>This function exports a Labels object to NWB format along with an MJPEG video containing all labeled frames and a JSON frame map for provenance tracking. The exported NWB file will reference the MJPEG video, allowing for efficient storage and retrieval of training data.</p> <p>Parameters:</p> Name Type Description Default <code>labels</code> <code>Labels</code> <p>Labels object containing labeled frames to export.</p> required <code>output_dir</code> <code>Union[Path, str]</code> <p>Directory path where all output files will be saved.</p> required <code>mjpeg_filename</code> <code>str</code> <p>Name of the output MJPEG video file. Defaults to \"annotated_frames.avi\".</p> <code>'annotated_frames.avi'</code> <code>frame_map_filename</code> <code>str</code> <p>Name of the frame map JSON file. Defaults to \"frame_map.json\".</p> <code>'frame_map.json'</code> <code>nwb_filename</code> <code>str</code> <p>Name of the output NWB file. Defaults to \"pose_training.nwb\".</p> <code>'pose_training.nwb'</code> <code>clean</code> <code>bool</code> <p>If True, remove empty frames and predictions before export using <code>Labels.remove_predictions(clean=True)</code>. Defaults to True.</p> <code>True</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If labels contain no labeled frames after cleaning.</p> Example <pre><code>labels = load_file(\"dataset.slp\")\nexport_labels(\n    labels,\n    output_dir=\"exports\",\n    mjpeg_filename=\"training_data.avi\",\n    nwb_filename=\"dataset.nwb\"\n)\n</code></pre> Notes <p>The function creates a copy of the labels before processing to avoid modifying the original data. All file paths are relative to the specified output directory, which will be created if it doesn't exist.</p> Source code in <code>sleap_io/io/nwb_annotations.py</code> <pre><code>def export_labels(\n    labels: SleapLabels,\n    output_dir: Union[Path, str],\n    mjpeg_filename: str = \"annotated_frames.avi\",\n    frame_map_filename: str = \"frame_map.json\",\n    nwb_filename: str = \"pose_training.nwb\",\n    clean: bool = True,\n) -&gt; None:\n    \"\"\"Export Labels to NWB format with MJPEG video and frame map.\n\n    This function exports a Labels object to NWB format along with an MJPEG video\n    containing all labeled frames and a JSON frame map for provenance tracking.\n    The exported NWB file will reference the MJPEG video, allowing for efficient\n    storage and retrieval of training data.\n\n    Args:\n        labels: Labels object containing labeled frames to export.\n        output_dir: Directory path where all output files will be saved.\n        mjpeg_filename: Name of the output MJPEG video file.\n            Defaults to \"annotated_frames.avi\".\n        frame_map_filename: Name of the frame map JSON file.\n            Defaults to \"frame_map.json\".\n        nwb_filename: Name of the output NWB file.\n            Defaults to \"pose_training.nwb\".\n        clean: If True, remove empty frames and predictions before export using\n            `Labels.remove_predictions(clean=True)`. Defaults to True.\n\n    Raises:\n        ValueError: If labels contain no labeled frames after cleaning.\n\n    Example:\n        ```python\n        labels = load_file(\"dataset.slp\")\n        export_labels(\n            labels,\n            output_dir=\"exports\",\n            mjpeg_filename=\"training_data.avi\",\n            nwb_filename=\"dataset.nwb\"\n        )\n        ```\n\n    Notes:\n        The function creates a copy of the labels before processing to avoid\n        modifying the original data. All file paths are relative to the specified\n        output directory, which will be created if it doesn't exist.\n    \"\"\"\n    # Make a copy of the labels since we'll be mutating them\n    labels = deepcopy(labels)\n\n    # Clean labels if requested to remove empty frames and predictions\n    if clean:\n        labels.remove_predictions(clean=True)\n\n    # Check that we have frames to export after cleaning\n    if len(labels.labeled_frames) == 0:\n        raise ValueError(\n            \"No labeled frames found to export (labels may be empty). \"\n            \"Try exporting with clean=False if you want to export empty frames.\"\n        )\n\n    # Convert paths to Path objects and create output directory\n    output_dir = Path(output_dir)\n    output_dir.mkdir(parents=True, exist_ok=True)\n\n    # Build full paths for output files\n    mjpeg_path = output_dir / mjpeg_filename\n    frame_map_path = output_dir / frame_map_filename\n    nwb_path = output_dir / nwb_filename\n\n    # Export labeled frames to MJPEG AVI file and create frame map\n    frame_map = export_labeled_frames(\n        labels, frame_map_path, mjpeg_path, nwb_path=nwb_path\n    )\n\n    # Update the labels to point to the new MJPEG video\n    mjpeg_video = SleapVideo.from_filename(mjpeg_path)\n    for lf_ind in range(len(labels)):\n        lf = labels[lf_ind]\n\n        # Sanity checks:\n        video_ind, frame_idx = labels.videos.index(lf.video), lf.frame_idx\n        frame_info = frame_map.frames[lf_ind]\n        assert video_ind == frame_info.video_ind\n        assert frame_idx == frame_info.frame_idx\n\n        lf.video = mjpeg_video\n        lf.frame_idx = lf_ind\n    labels.videos = [mjpeg_video]\n\n    # Now save the NWB file as normal\n    save_labels(labels, nwb_path)\n</code></pre>"},{"location":"reference/sleap_io/io/nwb_annotations/#sleap_io.io.nwb_annotations.load_labels","title":"<code>load_labels(path)</code>","text":"<p>Load sleap-io Labels from an NWB file.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Union[Path, str]</code> <p>Path to the NWB file to load.</p> required <p>Returns:</p> Type Description <code>Labels</code> <p>A sleap-io Labels object with data from the NWB file.</p> Source code in <code>sleap_io/io/nwb_annotations.py</code> <pre><code>def load_labels(path: Union[Path, str]) -&gt; SleapLabels:\n    \"\"\"Load sleap-io Labels from an NWB file.\n\n    Args:\n        path: Path to the NWB file to load.\n\n    Returns:\n        A sleap-io Labels object with data from the NWB file.\n    \"\"\"\n    with NWBHDF5IO(path, mode=\"r\") as io:\n        nwbfile = io.read()\n\n        # Get the behavior processing module\n        behavior_pm = nwbfile.processing[\"behavior\"]\n\n        # Get PoseTraining and Skeletons containers\n        pose_training = behavior_pm[\"PoseTraining\"]\n        skeletons = behavior_pm[\"Skeletons\"]\n\n        # Convert back to SLEAP format\n        labels = nwb_pose_training_to_sleap_labels(pose_training, skeletons)\n\n        return labels\n</code></pre>"},{"location":"reference/sleap_io/io/nwb_annotations/#sleap_io.io.nwb_annotations.nwb_image_series_to_sleap_video","title":"<code>nwb_image_series_to_sleap_video(image_series)</code>","text":"<p>Convert a pynwb ImageSeries to sleap-io Video.</p> <p>Parameters:</p> Name Type Description Default <code>image_series</code> <code>ImageSeries</code> <p>The pynwb ImageSeries object to convert.</p> required <p>Returns:</p> Type Description <code>Video</code> <p>A sleap-io Video object with equivalent data.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the ImageSeries format is not \"external\".</p> Source code in <code>sleap_io/io/nwb_annotations.py</code> <pre><code>def nwb_image_series_to_sleap_video(\n    image_series: ImageSeries,\n) -&gt; SleapVideo:\n    \"\"\"Convert a pynwb ImageSeries to sleap-io Video.\n\n    Args:\n        image_series: The pynwb ImageSeries object to convert.\n\n    Returns:\n        A sleap-io Video object with equivalent data.\n\n    Raises:\n        ValueError: If the ImageSeries format is not \"external\".\n    \"\"\"\n    # Check that this is an external file reference\n    if image_series.format != \"external\":\n        raise ValueError(\n            f\"Unsupported ImageSeries format: {image_series.format}. \"\n            f\"Only 'external' format is supported for conversion to sleap-io Video.\"\n        )\n\n    filename = image_series.external_file\n    if len(filename) == 1:\n        filename = filename[0]\n\n    # Create sleap-io Video\n    sleap_video = SleapVideo.from_filename(filename)\n\n    return sleap_video\n</code></pre>"},{"location":"reference/sleap_io/io/nwb_annotations/#sleap_io.io.nwb_annotations.nwb_pose_training_to_sleap_labels","title":"<code>nwb_pose_training_to_sleap_labels(nwb_pose_training, nwb_skeletons)</code>","text":"<p>Convert ndx-pose PoseTraining and Skeletons to sleap-io Labels.</p> <p>Parameters:</p> Name Type Description Default <code>nwb_pose_training</code> <code>PoseTraining</code> <p>The ndx-pose PoseTraining container to convert.</p> required <code>nwb_skeletons</code> <code>Skeletons</code> <p>The ndx-pose Skeletons container with skeleton definitions.</p> required <p>Returns:</p> Type Description <code>Labels</code> <p>A sleap-io Labels object with equivalent data.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If any ImageSeries format is not supported.</p> <code>KeyError</code> <p>If video or skeleton mapping fails.</p> Source code in <code>sleap_io/io/nwb_annotations.py</code> <pre><code>def nwb_pose_training_to_sleap_labels(\n    nwb_pose_training: NwbPoseTraining,\n    nwb_skeletons: NwbSkeletons,\n) -&gt; SleapLabels:\n    \"\"\"Convert ndx-pose PoseTraining and Skeletons to sleap-io Labels.\n\n    Args:\n        nwb_pose_training: The ndx-pose PoseTraining container to convert.\n        nwb_skeletons: The ndx-pose Skeletons container with skeleton definitions.\n\n    Returns:\n        A sleap-io Labels object with equivalent data.\n\n    Raises:\n        ValueError: If any ImageSeries format is not supported.\n        KeyError: If video or skeleton mapping fails.\n    \"\"\"\n    # Convert source videos back to sleap videos\n    sleap_videos = nwb_source_videos_to_sleap_videos(nwb_pose_training.source_videos)\n\n    # Convert all skeletons from NwbSkeletons container\n    sleap_skeletons = [\n        nwb_skeleton_to_sleap_skeleton(nwb_skeleton)\n        for nwb_skeleton in nwb_skeletons.skeletons.values()\n    ]\n\n    # Create video mapping for conversion back\n    nwb_to_slp_video_map = create_nwb_to_slp_video_map(\n        list(nwb_pose_training.source_videos.image_series.values()), sleap_videos\n    )\n\n    # Create skeleton mapping for conversion back\n    nwb_to_slp_skeleton_map = create_nwb_to_slp_skeleton_map(\n        nwb_skeletons,\n        sleap_skeletons,\n    )\n\n    # Convert training frames back to labeled frames\n    labeled_frames = nwb_training_frames_to_sleap_labeled_frames(\n        nwb_pose_training.training_frames,\n        nwb_to_slp_skeleton_map,\n        nwb_to_slp_video_map,\n    )\n\n    return SleapLabels(\n        skeletons=sleap_skeletons,\n        videos=sleap_videos,\n        labeled_frames=labeled_frames,\n    )\n</code></pre>"},{"location":"reference/sleap_io/io/nwb_annotations/#sleap_io.io.nwb_annotations.nwb_skeleton_instance_to_sleap_instance","title":"<code>nwb_skeleton_instance_to_sleap_instance(nwb_skeleton_instance, skeleton)</code>","text":"<p>Convert an ndx-pose SkeletonInstance to sleap-io Instance.</p> <p>Parameters:</p> Name Type Description Default <code>nwb_skeleton_instance</code> <code>SkeletonInstance</code> <p>The ndx-pose SkeletonInstance object to convert.</p> required <code>skeleton</code> <code>Skeleton</code> <p>The sleap-io Skeleton to associate with the instance.</p> required <p>Returns:</p> Type Description <code>Instance</code> <p>A sleap-io Instance object with equivalent data.</p> Source code in <code>sleap_io/io/nwb_annotations.py</code> <pre><code>def nwb_skeleton_instance_to_sleap_instance(\n    nwb_skeleton_instance: NwbInstance, skeleton: SleapSkeleton\n) -&gt; SleapInstance:\n    \"\"\"Convert an ndx-pose SkeletonInstance to sleap-io Instance.\n\n    Args:\n        nwb_skeleton_instance: The ndx-pose SkeletonInstance object to convert.\n        skeleton: The sleap-io Skeleton to associate with the instance.\n\n    Returns:\n        A sleap-io Instance object with equivalent data.\n    \"\"\"\n    # Get node locations and visibility\n    node_locations = np.array(nwb_skeleton_instance.node_locations)\n\n    # Handle visibility - use provided visibility or infer from NaN values\n    if nwb_skeleton_instance.node_visibility is not None:\n        node_visibility = np.array(nwb_skeleton_instance.node_visibility)\n    else:\n        # Infer visibility from non-NaN values\n        node_visibility = ~np.isnan(node_locations).any(axis=1)\n\n    # Create instance from numpy array - will handle visibility internally\n    # Set invisible points to NaN for proper handling\n    points_array = node_locations.copy()\n    points_array[~node_visibility] = np.nan\n\n    return SleapInstance.from_numpy(points_array, skeleton)\n</code></pre>"},{"location":"reference/sleap_io/io/nwb_annotations/#sleap_io.io.nwb_annotations.nwb_skeleton_to_sleap_skeleton","title":"<code>nwb_skeleton_to_sleap_skeleton(nwb_skeleton)</code>","text":"<p>Convert an ndx-pose Skeleton to sleap-io Skeleton.</p> <p>Parameters:</p> Name Type Description Default <code>nwb_skeleton</code> <code>Skeleton</code> <p>The ndx-pose Skeleton object to convert.</p> required <p>Returns:</p> Type Description <code>Skeleton</code> <p>A sleap-io Skeleton object with equivalent structure.</p> Source code in <code>sleap_io/io/nwb_annotations.py</code> <pre><code>def nwb_skeleton_to_sleap_skeleton(nwb_skeleton: NwbSkeleton) -&gt; SleapSkeleton:\n    \"\"\"Convert an ndx-pose Skeleton to sleap-io Skeleton.\n\n    Args:\n        nwb_skeleton: The ndx-pose Skeleton object to convert.\n\n    Returns:\n        A sleap-io Skeleton object with equivalent structure.\n    \"\"\"\n    # Convert nodes (already strings in ndx-pose)\n    nodes = list(nwb_skeleton.nodes)\n\n    # Convert edges from array of indices to list of tuples\n    edges = [(int(edge[0]), int(edge[1])) for edge in nwb_skeleton.edges]\n\n    # Create sleap-io skeleton\n    sleap_skeleton = SleapSkeleton(nodes=nodes, edges=edges, name=nwb_skeleton.name)\n\n    return sleap_skeleton\n</code></pre>"},{"location":"reference/sleap_io/io/nwb_annotations/#sleap_io.io.nwb_annotations.nwb_source_videos_to_sleap_videos","title":"<code>nwb_source_videos_to_sleap_videos(nwb_source_videos)</code>","text":"<p>Convert ndx-pose SourceVideos to a list of sleap-io Videos.</p> <p>Parameters:</p> Name Type Description Default <code>nwb_source_videos</code> <code>SourceVideos</code> <p>The ndx-pose SourceVideos container to convert.</p> required <p>Returns:</p> Type Description <code>List[Video]</code> <p>A list of sleap-io Video objects with equivalent data.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If any ImageSeries format is not supported.</p> Source code in <code>sleap_io/io/nwb_annotations.py</code> <pre><code>def nwb_source_videos_to_sleap_videos(\n    nwb_source_videos: NwbSourceVideos,\n) -&gt; List[SleapVideo]:\n    \"\"\"Convert ndx-pose SourceVideos to a list of sleap-io Videos.\n\n    Args:\n        nwb_source_videos: The ndx-pose SourceVideos container to convert.\n\n    Returns:\n        A list of sleap-io Video objects with equivalent data.\n\n    Raises:\n        ValueError: If any ImageSeries format is not supported.\n    \"\"\"\n    sleap_videos = []\n    for image_series in nwb_source_videos.image_series.values():\n        sleap_video = nwb_image_series_to_sleap_video(image_series)\n        sleap_videos.append(sleap_video)\n\n    return sleap_videos\n</code></pre>"},{"location":"reference/sleap_io/io/nwb_annotations/#sleap_io.io.nwb_annotations.nwb_training_frame_to_sleap_labeled_frame","title":"<code>nwb_training_frame_to_sleap_labeled_frame(nwb_training_frame, nwb_to_slp_skeleton_map, sleap_video)</code>","text":"<p>Convert an ndx-pose TrainingFrame to sleap-io LabeledFrame.</p> <p>Parameters:</p> Name Type Description Default <code>nwb_training_frame</code> <code>TrainingFrame</code> <p>The ndx-pose TrainingFrame object to convert.</p> required <code>nwb_to_slp_skeleton_map</code> <code>Dict[Skeleton, Skeleton]</code> <p>Required mapping from NWB Skeletons to sleap-io Skeletons.</p> required <code>sleap_video</code> <code>Video</code> <p>The sleap-io Video to associate with the frame.</p> required <p>Returns:</p> Type Description <code>LabeledFrame</code> <p>A sleap-io LabeledFrame object with equivalent data.</p> Source code in <code>sleap_io/io/nwb_annotations.py</code> <pre><code>def nwb_training_frame_to_sleap_labeled_frame(\n    nwb_training_frame: NwbTrainingFrame,\n    nwb_to_slp_skeleton_map: Dict[NwbSkeleton, SleapSkeleton],\n    sleap_video: SleapVideo,\n) -&gt; SleapLabeledFrame:\n    \"\"\"Convert an ndx-pose TrainingFrame to sleap-io LabeledFrame.\n\n    Args:\n        nwb_training_frame: The ndx-pose TrainingFrame object to convert.\n        nwb_to_slp_skeleton_map: Required mapping from NWB Skeletons to sleap-io\n            Skeletons.\n        sleap_video: The sleap-io Video to associate with the frame.\n\n    Returns:\n        A sleap-io LabeledFrame object with equivalent data.\n    \"\"\"\n    # Convert instances from NWB SkeletonInstances\n    sleap_instances = []\n    for (\n        nwb_instance\n    ) in nwb_training_frame.skeleton_instances.skeleton_instances.values():\n        # Get the appropriate sleap skeleton for this instance\n        sleap_skeleton = nwb_to_slp_skeleton_map[nwb_instance.skeleton]\n\n        sleap_instance = nwb_skeleton_instance_to_sleap_instance(\n            nwb_instance, sleap_skeleton\n        )\n        sleap_instances.append(sleap_instance)\n\n    # Get frame index - use source_video_frame_index if available, otherwise 0\n    frame_idx = (\n        int(nwb_training_frame.source_video_frame_index)\n        if nwb_training_frame.source_video_frame_index is not None\n        else 0\n    )\n\n    return SleapLabeledFrame(\n        video=sleap_video, frame_idx=frame_idx, instances=sleap_instances\n    )\n</code></pre>"},{"location":"reference/sleap_io/io/nwb_annotations/#sleap_io.io.nwb_annotations.nwb_training_frames_to_sleap_labeled_frames","title":"<code>nwb_training_frames_to_sleap_labeled_frames(nwb_training_frames, nwb_to_slp_skeleton_map, nwb_to_slp_video_map)</code>","text":"<p>Convert ndx-pose TrainingFrames to a list of sleap-io LabeledFrames.</p> <p>Parameters:</p> Name Type Description Default <code>nwb_training_frames</code> <code>TrainingFrames</code> <p>The ndx-pose TrainingFrames container to convert.</p> required <code>nwb_to_slp_skeleton_map</code> <code>Dict[Skeleton, Skeleton]</code> <p>Required mapping from NWB Skeletons to sleap-io Skeletons.</p> required <code>nwb_to_slp_video_map</code> <code>Dict[ImageSeries, Video]</code> <p>Required mapping from ImageSeries to sleap-io Videos.</p> required <p>Returns:</p> Type Description <code>List[LabeledFrame]</code> <p>A list of sleap-io LabeledFrame objects with equivalent data.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If a TrainingFrame's source_video is None.</p> <code>KeyError</code> <p>If a TrainingFrame's source_video is not found in the mapping.</p> Source code in <code>sleap_io/io/nwb_annotations.py</code> <pre><code>def nwb_training_frames_to_sleap_labeled_frames(\n    nwb_training_frames: NwbTrainingFrames,\n    nwb_to_slp_skeleton_map: Dict[NwbSkeleton, SleapSkeleton],\n    nwb_to_slp_video_map: Dict[ImageSeries, SleapVideo],\n) -&gt; List[SleapLabeledFrame]:\n    \"\"\"Convert ndx-pose TrainingFrames to a list of sleap-io LabeledFrames.\n\n    Args:\n        nwb_training_frames: The ndx-pose TrainingFrames container to convert.\n        nwb_to_slp_skeleton_map: Required mapping from NWB Skeletons to sleap-io\n            Skeletons.\n        nwb_to_slp_video_map: Required mapping from ImageSeries to sleap-io Videos.\n\n    Returns:\n        A list of sleap-io LabeledFrame objects with equivalent data.\n\n    Raises:\n        ValueError: If a TrainingFrame's source_video is None.\n        KeyError: If a TrainingFrame's source_video is not found in the mapping.\n    \"\"\"\n    sleap_labeled_frames = []\n\n    for nwb_training_frame in nwb_training_frames.training_frames.values():\n        # Get corresponding sleap video using the required mapping\n        if nwb_training_frame.source_video is None:\n            raise ValueError(\n                \"TrainingFrame must have a source_video to convert to sleap-io \"\n                \"LabeledFrame\"\n            )\n\n        sleap_video = nwb_to_slp_video_map[nwb_training_frame.source_video]\n\n        sleap_labeled_frame = nwb_training_frame_to_sleap_labeled_frame(\n            nwb_training_frame, nwb_to_slp_skeleton_map, sleap_video\n        )\n        sleap_labeled_frames.append(sleap_labeled_frame)\n\n    return sleap_labeled_frames\n</code></pre>"},{"location":"reference/sleap_io/io/nwb_annotations/#sleap_io.io.nwb_annotations.sanitize_nwb_name","title":"<code>sanitize_nwb_name(name)</code>","text":"<p>Sanitize a name for use in NWB files.</p> <p>NWB names cannot contain '/' or ':' characters.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name to sanitize.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The sanitized name with invalid characters replaced.</p> Source code in <code>sleap_io/io/nwb_annotations.py</code> <pre><code>def sanitize_nwb_name(name: str) -&gt; str:\n    \"\"\"Sanitize a name for use in NWB files.\n\n    NWB names cannot contain '/' or ':' characters.\n\n    Args:\n        name: The name to sanitize.\n\n    Returns:\n        The sanitized name with invalid characters replaced.\n    \"\"\"\n    if isinstance(name, Path):\n        name = sanitize_filename(name)\n\n    # Replace forward slashes and colons with underscores\n    sanitized = name.replace(\"/\", \"_\").replace(\":\", \"_\")\n    return sanitized\n</code></pre>"},{"location":"reference/sleap_io/io/nwb_annotations/#sleap_io.io.nwb_annotations.save_labels","title":"<code>save_labels(labels, path, session_description='SLEAP pose training data', identifier=None, session_start_time=None, annotator=None, nwb_kwargs=None)</code>","text":"<p>Save sleap-io Labels to an NWB file.</p> <p>Parameters:</p> Name Type Description Default <code>labels</code> <code>Labels</code> <p>The sleap-io Labels object to save.</p> required <code>path</code> <code>Union[Path, str]</code> <p>Path to save the NWB file.</p> required <code>session_description</code> <code>str</code> <p>Description of the session (required).</p> <code>'SLEAP pose training data'</code> <code>identifier</code> <code>Optional[str]</code> <p>Unique identifier for the NWB file. If None, auto-generated.</p> <code>None</code> <code>session_start_time</code> <code>Optional[str]</code> <p>Start time of session (ISO format string). If None, uses current time.</p> <code>None</code> <code>annotator</code> <code>Optional[str]</code> <p>Name of the annotator who labeled the data. Optional.</p> <code>None</code> <code>nwb_kwargs</code> <code>Optional[dict]</code> <p>Additional keyword arguments to pass to NWBFile constructor. Can include: session_id, experimenter, lab, institution, experiment_description, etc.</p> <code>None</code> Source code in <code>sleap_io/io/nwb_annotations.py</code> <pre><code>def save_labels(\n    labels: SleapLabels,\n    path: Union[Path, str],\n    session_description: str = \"SLEAP pose training data\",\n    identifier: Optional[str] = None,\n    session_start_time: Optional[str] = None,\n    annotator: Optional[str] = None,\n    nwb_kwargs: Optional[dict] = None,\n) -&gt; None:\n    \"\"\"Save sleap-io Labels to an NWB file.\n\n    Args:\n        labels: The sleap-io Labels object to save.\n        path: Path to save the NWB file.\n        session_description: Description of the session (required).\n        identifier: Unique identifier for the NWB file. If None, auto-generated.\n        session_start_time: Start time of session (ISO format string). If None,\n            uses current time.\n        annotator: Name of the annotator who labeled the data. Optional.\n        nwb_kwargs: Additional keyword arguments to pass to NWBFile constructor.\n            Can include: session_id, experimenter, lab, institution,\n            experiment_description, etc.\n    \"\"\"\n    # Set defaults for required fields\n    if session_start_time is None:\n        session_start_time = datetime.now().astimezone()\n    elif isinstance(session_start_time, str):\n        session_start_time = datetime.fromisoformat(session_start_time)\n\n    if identifier is None:\n        identifier = f\"sleap_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n\n    # Create NWB file with required parameters\n    nwbfile_kwargs = {\n        \"session_description\": session_description,\n        \"identifier\": identifier,\n        \"session_start_time\": session_start_time,\n    }\n\n    # Add any additional kwargs provided by user\n    if nwb_kwargs is not None:\n        nwbfile_kwargs.update(nwb_kwargs)\n\n    nwbfile = NWBFile(**nwbfile_kwargs)\n\n    # Convert SLEAP labels to NWB format\n    pose_training, skeletons = sleap_labels_to_nwb_pose_training(\n        labels, annotator=annotator\n    )\n\n    # Create behavior processing module\n    behavior_pm = nwbfile.create_processing_module(\n        name=\"behavior\",\n        description=\"processed behavioral data\",\n    )\n    behavior_pm.add(skeletons)\n    behavior_pm.add(pose_training)\n\n    # Write to file\n    with NWBHDF5IO(path, mode=\"w\") as io:\n        io.write(nwbfile)\n</code></pre>"},{"location":"reference/sleap_io/io/nwb_annotations/#sleap_io.io.nwb_annotations.sleap_instance_to_nwb_skeleton_instance","title":"<code>sleap_instance_to_nwb_skeleton_instance(sleap_instance, nwb_skeleton, name='skeleton_instance', id=None)</code>","text":"<p>Convert a sleap-io Instance to ndx-pose SkeletonInstance.</p> <p>Parameters:</p> Name Type Description Default <code>sleap_instance</code> <code>Instance</code> <p>The sleap-io Instance object to convert.</p> required <code>nwb_skeleton</code> <code>Skeleton</code> <p>The ndx-pose Skeleton object to associate with the instance.</p> required <code>name</code> <code>str</code> <p>String identifier for the skeleton instance. Default: \"skeleton_instance\".</p> <code>'skeleton_instance'</code> <code>id</code> <code>Optional[int]</code> <p>Optional unique identifier (integer) for the instance. Default: None.</p> <code>None</code> <p>Returns:</p> Type Description <code>SkeletonInstance</code> <p>An ndx-pose SkeletonInstance object with equivalent data.</p> Source code in <code>sleap_io/io/nwb_annotations.py</code> <pre><code>def sleap_instance_to_nwb_skeleton_instance(\n    sleap_instance: SleapInstance,\n    nwb_skeleton: NwbSkeleton,\n    name: str = \"skeleton_instance\",\n    id: Optional[int] = None,\n) -&gt; NwbInstance:\n    \"\"\"Convert a sleap-io Instance to ndx-pose SkeletonInstance.\n\n    Args:\n        sleap_instance: The sleap-io Instance object to convert.\n        nwb_skeleton: The ndx-pose Skeleton object to associate with the instance.\n        name: String identifier for the skeleton instance. Default: \"skeleton_instance\".\n        id: Optional unique identifier (integer) for the instance. Default: None.\n\n    Returns:\n        An ndx-pose SkeletonInstance object with equivalent data.\n    \"\"\"\n    # Get node locations as (n_nodes, 2) array\n    node_locations = sleap_instance.numpy(invisible_as_nan=True)\n\n    # Get node visibility - True where points are not NaN\n    node_visibility = ~np.isnan(node_locations).any(axis=1)\n\n    # Convert id to unsigned integer if provided\n    if id is not None:\n        id = np.uint8(id)\n\n    return NwbInstance(\n        node_locations=node_locations,\n        skeleton=nwb_skeleton,\n        name=name,\n        id=id,\n        node_visibility=node_visibility,\n    )\n</code></pre>"},{"location":"reference/sleap_io/io/nwb_annotations/#sleap_io.io.nwb_annotations.sleap_labeled_frame_to_nwb_training_frame","title":"<code>sleap_labeled_frame_to_nwb_training_frame(sleap_labeled_frame, slp_to_nwb_skeleton_map, source_video=None, name='training_frame', annotator=None)</code>","text":"<p>Convert a sleap-io LabeledFrame to ndx-pose TrainingFrame.</p> <p>Parameters:</p> Name Type Description Default <code>sleap_labeled_frame</code> <code>LabeledFrame</code> <p>The sleap-io LabeledFrame object to convert.</p> required <code>slp_to_nwb_skeleton_map</code> <code>Dict[Skeleton, Skeleton]</code> <p>Mapping from sleap-io Skeletons to NWB Skeletons.</p> required <code>source_video</code> <code>Optional[ImageSeries]</code> <p>Optional ImageSeries representing the source video.</p> <code>None</code> <code>name</code> <code>str</code> <p>String identifier for the TrainingFrame.</p> <code>'training_frame'</code> <code>annotator</code> <code>Optional[str]</code> <p>Optional name of annotator who labeled the frame.</p> <code>None</code> <p>Returns:</p> Type Description <code>TrainingFrame</code> <p>An ndx-pose TrainingFrame object with equivalent data.</p> Source code in <code>sleap_io/io/nwb_annotations.py</code> <pre><code>def sleap_labeled_frame_to_nwb_training_frame(\n    sleap_labeled_frame: SleapLabeledFrame,\n    slp_to_nwb_skeleton_map: Dict[SleapSkeleton, NwbSkeleton],\n    source_video: Optional[ImageSeries] = None,\n    name: str = \"training_frame\",\n    annotator: Optional[str] = None,\n) -&gt; NwbTrainingFrame:\n    \"\"\"Convert a sleap-io LabeledFrame to ndx-pose TrainingFrame.\n\n    Args:\n        sleap_labeled_frame: The sleap-io LabeledFrame object to convert.\n        slp_to_nwb_skeleton_map: Mapping from sleap-io Skeletons to NWB Skeletons.\n        source_video: Optional ImageSeries representing the source video.\n        name: String identifier for the TrainingFrame.\n        annotator: Optional name of annotator who labeled the frame.\n\n    Returns:\n        An ndx-pose TrainingFrame object with equivalent data.\n    \"\"\"\n    # Convert instances to NWB SkeletonInstances\n    nwb_instances = []\n    for i, sleap_instance in enumerate(sleap_labeled_frame.instances):\n        instance_name = f\"instance_{i}\"\n\n        # Get the appropriate NWB skeleton for this instance\n        nwb_skeleton = slp_to_nwb_skeleton_map[sleap_instance.skeleton]\n\n        nwb_instance = sleap_instance_to_nwb_skeleton_instance(\n            sleap_instance, nwb_skeleton, name=instance_name, id=i\n        )\n        nwb_instances.append(nwb_instance)\n\n    # Create SkeletonInstances container\n    skeleton_instances = NwbSkeletonInstances(\n        name=\"skeleton_instances\", skeleton_instances=nwb_instances\n    )\n\n    # Create TrainingFrame\n    training_frame_kwargs = {\n        \"name\": name,\n        \"skeleton_instances\": skeleton_instances,\n    }\n\n    # Add optional attributes\n    if annotator is not None:\n        training_frame_kwargs[\"annotator\"] = annotator\n\n    if source_video is not None:\n        training_frame_kwargs[\"source_video\"] = source_video\n        training_frame_kwargs[\"source_video_frame_index\"] = np.uint32(\n            sleap_labeled_frame.frame_idx\n        )\n\n    return NwbTrainingFrame(**training_frame_kwargs)\n</code></pre>"},{"location":"reference/sleap_io/io/nwb_annotations/#sleap_io.io.nwb_annotations.sleap_labeled_frames_to_nwb_training_frames","title":"<code>sleap_labeled_frames_to_nwb_training_frames(sleap_labeled_frames, slp_to_nwb_skeleton_map, slp_to_nwb_video_map, name='TrainingFrames', annotator=None)</code>","text":"<p>Convert a list of sleap-io LabeledFrames to ndx-pose TrainingFrames container.</p> <p>Parameters:</p> Name Type Description Default <code>sleap_labeled_frames</code> <code>List[LabeledFrame]</code> <p>List of sleap-io LabeledFrame objects to convert.</p> required <code>slp_to_nwb_skeleton_map</code> <code>Dict[Skeleton, Skeleton]</code> <p>Required mapping from sleap-io Skeletons to NWB Skeletons.</p> required <code>slp_to_nwb_video_map</code> <code>Dict[Video, ImageSeries]</code> <p>Required mapping from sleap-io Videos to ImageSeries.</p> required <code>name</code> <code>str</code> <p>String identifier for the TrainingFrames container.</p> <code>'TrainingFrames'</code> <code>annotator</code> <code>Optional[str]</code> <p>Optional name of annotator who labeled the frames.</p> <code>None</code> <p>Returns:</p> Type Description <code>TrainingFrames</code> <p>An ndx-pose TrainingFrames container with TrainingFrame objects.</p> Source code in <code>sleap_io/io/nwb_annotations.py</code> <pre><code>def sleap_labeled_frames_to_nwb_training_frames(\n    sleap_labeled_frames: List[SleapLabeledFrame],\n    slp_to_nwb_skeleton_map: Dict[SleapSkeleton, NwbSkeleton],\n    slp_to_nwb_video_map: Dict[SleapVideo, ImageSeries],\n    name: str = \"TrainingFrames\",\n    annotator: Optional[str] = None,\n) -&gt; NwbTrainingFrames:\n    \"\"\"Convert a list of sleap-io LabeledFrames to ndx-pose TrainingFrames container.\n\n    Args:\n        sleap_labeled_frames: List of sleap-io LabeledFrame objects to convert.\n        slp_to_nwb_skeleton_map: Required mapping from sleap-io Skeletons to NWB\n            Skeletons.\n        slp_to_nwb_video_map: Required mapping from sleap-io Videos to ImageSeries.\n        name: String identifier for the TrainingFrames container.\n        annotator: Optional name of annotator who labeled the frames.\n\n    Returns:\n        An ndx-pose TrainingFrames container with TrainingFrame objects.\n    \"\"\"\n    nwb_training_frames = []\n\n    for frame_ind, sleap_labeled_frame in enumerate(sleap_labeled_frames):\n        frame_name = f\"frame_{frame_ind}\"\n\n        # Get corresponding source video from the mapping\n        source_video = slp_to_nwb_video_map[sleap_labeled_frame.video]\n\n        nwb_training_frame = sleap_labeled_frame_to_nwb_training_frame(\n            sleap_labeled_frame,\n            slp_to_nwb_skeleton_map=slp_to_nwb_skeleton_map,\n            source_video=source_video,\n            name=frame_name,\n            annotator=annotator,\n        )\n        nwb_training_frames.append(nwb_training_frame)\n\n    return NwbTrainingFrames(name=name, training_frames=nwb_training_frames)\n</code></pre>"},{"location":"reference/sleap_io/io/nwb_annotations/#sleap_io.io.nwb_annotations.sleap_labels_to_nwb_pose_training","title":"<code>sleap_labels_to_nwb_pose_training(sleap_labels, name='PoseTraining', annotator=None)</code>","text":"<p>Convert sleap-io Labels to ndx-pose PoseTraining container and Skeletons.</p> <p>Parameters:</p> Name Type Description Default <code>sleap_labels</code> <code>Labels</code> <p>The sleap-io Labels object to convert.</p> required <code>name</code> <code>str</code> <p>String identifier for the PoseTraining container.</p> <code>'PoseTraining'</code> <code>annotator</code> <code>Optional[str]</code> <p>Optional name of annotator who labeled the data.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tuple[PoseTraining, Skeletons]</code> <p>A tuple containing: - An ndx-pose PoseTraining container with training frames and source videos - An ndx-pose Skeletons container with all skeletons</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If any video backend is not supported for NWB export.</p> Source code in <code>sleap_io/io/nwb_annotations.py</code> <pre><code>def sleap_labels_to_nwb_pose_training(\n    sleap_labels: SleapLabels,\n    name: str = \"PoseTraining\",\n    annotator: Optional[str] = None,\n) -&gt; Tuple[NwbPoseTraining, NwbSkeletons]:\n    \"\"\"Convert sleap-io Labels to ndx-pose PoseTraining container and Skeletons.\n\n    Args:\n        sleap_labels: The sleap-io Labels object to convert.\n        name: String identifier for the PoseTraining container.\n        annotator: Optional name of annotator who labeled the data.\n\n    Returns:\n        A tuple containing:\n        - An ndx-pose PoseTraining container with training frames and source videos\n        - An ndx-pose Skeletons container with all skeletons\n\n    Raises:\n        ValueError: If any video backend is not supported for NWB export.\n    \"\"\"\n    # Convert all skeletons\n    nwb_skeleton_list = []\n    for i, sleap_skeleton in enumerate(sleap_labels.skeletons):\n        # Ensure skeleton will have a unique name\n        skeleton_name = sleap_skeleton.name if sleap_skeleton.name else f\"skeleton_{i}\"\n        if skeleton_name == \"skeleton\":  # Default name, make it unique\n            skeleton_name = f\"skeleton_{i}\"\n\n        # Create temporary skeleton with the desired name\n        temp_skeleton = sleap_skeleton_to_nwb_skeleton(sleap_skeleton)\n        # Create new skeleton with proper name\n        nwb_skeleton = NwbSkeleton(\n            name=skeleton_name, nodes=temp_skeleton.nodes, edges=temp_skeleton.edges\n        )\n        nwb_skeleton_list.append(nwb_skeleton)\n\n    # Create NwbSkeletons container\n    nwb_skeletons = NwbSkeletons(name=\"Skeletons\", skeletons=nwb_skeleton_list)\n\n    # Convert videos to source videos container\n    source_videos = sleap_videos_to_nwb_source_videos(\n        sleap_labels.videos, name=\"source_videos\"\n    )\n\n    # Create video mapping\n    slp_to_nwb_video_map = create_slp_to_nwb_video_map(\n        sleap_labels.videos, source_videos\n    )\n\n    # Create skeleton mapping\n    slp_to_nwb_skeleton_map = create_slp_to_nwb_skeleton_map(\n        sleap_labels.skeletons, nwb_skeletons\n    )\n\n    # Convert labeled frames to training frames\n    training_frames = sleap_labeled_frames_to_nwb_training_frames(\n        sleap_labels.labeled_frames,\n        slp_to_nwb_skeleton_map=slp_to_nwb_skeleton_map,\n        slp_to_nwb_video_map=slp_to_nwb_video_map,\n        name=\"training_frames\",  # Must be named this for PoseTraining\n        annotator=annotator,\n    )\n\n    pose_training = NwbPoseTraining(\n        name=name,\n        training_frames=training_frames,\n        source_videos=source_videos,\n    )\n\n    return pose_training, nwb_skeletons\n</code></pre>"},{"location":"reference/sleap_io/io/nwb_annotations/#sleap_io.io.nwb_annotations.sleap_skeleton_to_nwb_skeleton","title":"<code>sleap_skeleton_to_nwb_skeleton(sleap_skeleton)</code>","text":"<p>Convert a sleap-io Skeleton to ndx-pose Skeleton.</p> <p>Parameters:</p> Name Type Description Default <code>sleap_skeleton</code> <code>Skeleton</code> <p>The sleap-io Skeleton object to convert.</p> required <p>Returns:</p> Type Description <code>Skeleton</code> <p>An ndx-pose Skeleton object with equivalent structure.</p> Source code in <code>sleap_io/io/nwb_annotations.py</code> <pre><code>def sleap_skeleton_to_nwb_skeleton(\n    sleap_skeleton: SleapSkeleton,\n) -&gt; NwbSkeleton:\n    \"\"\"Convert a sleap-io Skeleton to ndx-pose Skeleton.\n\n    Args:\n        sleap_skeleton: The sleap-io Skeleton object to convert.\n\n    Returns:\n        An ndx-pose Skeleton object with equivalent structure.\n    \"\"\"\n    # Convert node names to list of strings\n    nodes = sleap_skeleton.node_names\n\n    # Convert edges from Edge objects to array of node indices\n    edges = np.array(sleap_skeleton.edge_inds, dtype=np.uint8)\n    if edges.size == 0:\n        edges = edges.reshape(0, 2)\n\n    # Use skeleton name or default\n    name = sanitize_nwb_name(sleap_skeleton.name) if sleap_skeleton.name else \"skeleton\"\n\n    return NwbSkeleton(name=name, nodes=nodes, edges=edges)\n</code></pre>"},{"location":"reference/sleap_io/io/nwb_annotations/#sleap_io.io.nwb_annotations.sleap_video_to_nwb_image_series","title":"<code>sleap_video_to_nwb_image_series(sleap_video, name=None, description='no description')</code>","text":"<p>Convert a sleap-io Video to pynwb ImageSeries.</p> <p>Parameters:</p> Name Type Description Default <code>sleap_video</code> <code>Video</code> <p>The sleap-io Video object to convert.</p> required <code>name</code> <code>Optional[str]</code> <p>String identifier for the ImageSeries. If None, uses the filename.</p> <code>None</code> <code>description</code> <code>str</code> <p>String description for the ImageSeries.</p> <code>'no description'</code> <p>Returns:</p> Type Description <code>ImageSeries</code> <p>A pynwb ImageSeries object with external file references.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the video backend is not supported for NWB export.</p> Source code in <code>sleap_io/io/nwb_annotations.py</code> <pre><code>def sleap_video_to_nwb_image_series(\n    sleap_video: SleapVideo,\n    name: Optional[str] = None,\n    description: str = \"no description\",\n) -&gt; ImageSeries:\n    \"\"\"Convert a sleap-io Video to pynwb ImageSeries.\n\n    Args:\n        sleap_video: The sleap-io Video object to convert.\n        name: String identifier for the ImageSeries. If None, uses the filename.\n        description: String description for the ImageSeries.\n\n    Returns:\n        A pynwb ImageSeries object with external file references.\n\n    Raises:\n        ValueError: If the video backend is not supported for NWB export.\n    \"\"\"\n    # Validate supported backend\n    if not isinstance(sleap_video.backend, (MediaVideo, ImageVideo)):\n        raise ValueError(\n            f\"Unsupported video backend for NWB export: {type(sleap_video.backend)}. \"\n            f\"Supported backends: MediaVideo, ImageVideo\"\n        )\n\n    # Set default name if not provided\n    if name is None:\n        if isinstance(sleap_video.filename, list):\n            name = sanitize_nwb_name(sleap_video.filename[0])\n        else:\n            name = sanitize_nwb_name(sleap_video.filename)\n\n    # Pull out filename\n    filename = sanitize_filename(sleap_video.filename)\n    if isinstance(filename, str):\n        filename = [filename]\n\n    # Get video metadata\n    shape = sleap_video.shape\n    if shape is not None:\n        height, width = shape[1:3]\n    else:\n        height, width = 0, 0\n\n    fps = getattr(sleap_video, \"fps\", 30.0)\n\n    starting_frame = list(range(len(filename)))  # needs to match length of filenames\n\n    # Create ImageSeries with external file reference\n    image_series = ImageSeries(\n        name=name,\n        description=description,\n        unit=\"NA\",  # Standard for video data\n        format=\"external\",  # External file reference\n        external_file=filename,\n        dimension=[width, height],\n        rate=fps,\n        starting_frame=starting_frame,\n    )\n\n    return image_series\n</code></pre>"},{"location":"reference/sleap_io/io/nwb_annotations/#sleap_io.io.nwb_annotations.sleap_videos_to_nwb_source_videos","title":"<code>sleap_videos_to_nwb_source_videos(sleap_videos, name='SourceVideos')</code>","text":"<p>Convert a list of sleap-io Videos to ndx-pose SourceVideos container.</p> <p>Parameters:</p> Name Type Description Default <code>sleap_videos</code> <code>List[Video]</code> <p>List of sleap-io Video objects to convert.</p> required <code>name</code> <code>str</code> <p>String identifier for the SourceVideos container.</p> <code>'SourceVideos'</code> <p>Returns:</p> Type Description <code>SourceVideos</code> <p>An ndx-pose SourceVideos container with ImageSeries for each video.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If any video backend is not supported for NWB export.</p> Source code in <code>sleap_io/io/nwb_annotations.py</code> <pre><code>def sleap_videos_to_nwb_source_videos(\n    sleap_videos: List[SleapVideo],\n    name: str = \"SourceVideos\",\n) -&gt; NwbSourceVideos:\n    \"\"\"Convert a list of sleap-io Videos to ndx-pose SourceVideos container.\n\n    Args:\n        sleap_videos: List of sleap-io Video objects to convert.\n        name: String identifier for the SourceVideos container.\n\n    Returns:\n        An ndx-pose SourceVideos container with ImageSeries for each video.\n\n    Raises:\n        ValueError: If any video backend is not supported for NWB export.\n    \"\"\"\n    image_series_list = []\n    for video_ind, sleap_video in enumerate(sleap_videos):\n        video_name = f\"video_{video_ind}\"\n        image_series = sleap_video_to_nwb_image_series(sleap_video, name=video_name)\n        image_series_list.append(image_series)\n\n    return NwbSourceVideos(name=name, image_series=image_series_list)\n</code></pre>"},{"location":"reference/sleap_io/io/nwb_predictions/","title":"nwb_predictions","text":""},{"location":"reference/sleap_io/io/nwb_predictions/#sleap_io.io.nwb_predictions","title":"<code>sleap_io.io.nwb_predictions</code>","text":"<p>Functions to write and read from the neurodata without borders (NWB) format.</p> <p>Functions:</p> Name Description <code>append_nwb</code> <p>Append a SLEAP <code>Labels</code> object to an existing NWB data file.</p> <code>append_nwb_data</code> <p>Append data from a Labels object to an in-memory nwb file.</p> <code>build_pose_estimation_container_for_track</code> <p>Create a PoseEstimation container for a track.</p> <code>build_track_pose_estimation_list</code> <p>Build a list of PoseEstimationSeries from tracks.</p> <code>convert_predictions_to_dataframe</code> <p>Convert predictions data to a Pandas dataframe.</p> <code>create_skeleton_container</code> <p>Create NWB skeleton containers from SLEAP skeletons.</p> <code>get_processing_module_for_video</code> <p>Auxiliary function to create a processing module.</p> <code>get_timestamps</code> <p>Return a vector of timestamps for a <code>PoseEstimationSeries</code>.</p> <code>read_nwb</code> <p>Read an NWB formatted file to a SLEAP <code>Labels</code> object.</p> <code>write_nwb</code> <p>Write labels to an nwb file and save it to the nwbfile_path given.</p>"},{"location":"reference/sleap_io/io/nwb_predictions/#sleap_io.io.nwb_predictions.append_nwb","title":"<code>append_nwb(labels, filename, pose_estimation_metadata=None)</code>","text":"<p>Append a SLEAP <code>Labels</code> object to an existing NWB data file.</p> <p>Parameters:</p> Name Type Description Default <code>labels</code> <code>Labels</code> <p>A general <code>Labels</code> object.</p> required <code>filename</code> <code>str</code> <p>The path to the NWB file.</p> required <code>pose_estimation_metadata</code> <code>Optional[dict]</code> <p>Metadata for pose estimation. See <code>append_nwb_data</code> for details.</p> <code>None</code> <p>See also: append_nwb_data</p> Source code in <code>sleap_io/io/nwb_predictions.py</code> <pre><code>def append_nwb(\n    labels: Labels, filename: str, pose_estimation_metadata: Optional[dict] = None\n):\n    \"\"\"Append a SLEAP `Labels` object to an existing NWB data file.\n\n    Args:\n        labels: A general `Labels` object.\n        filename: The path to the NWB file.\n        pose_estimation_metadata: Metadata for pose estimation. See `append_nwb_data`\n            for details.\n\n    See also: append_nwb_data\n    \"\"\"\n    with NWBHDF5IO(filename, mode=\"a\", load_namespaces=True) as io:\n        nwb_file = io.read()\n        nwb_file = append_nwb_data(\n            labels, nwb_file, pose_estimation_metadata=pose_estimation_metadata\n        )\n        io.write(nwb_file)\n</code></pre>"},{"location":"reference/sleap_io/io/nwb_predictions/#sleap_io.io.nwb_predictions.append_nwb_data","title":"<code>append_nwb_data(labels, nwbfile, pose_estimation_metadata=None, skeleton_map=None)</code>","text":"<p>Append data from a Labels object to an in-memory nwb file.</p> <p>Parameters:</p> Name Type Description Default <code>labels</code> <code>Labels</code> <p>A general labels object</p> required <code>nwbfile</code> <code>NWBFile</code> <p>And in-memory nwbfile where the data is to be appended.</p> required <code>pose_estimation_metadata</code> <code>Optional[dict]</code> <p>This argument has a dual purpose:</p> <p>1) It can be used to pass time information about the video which is necessary for synchronizing frames in pose estimation tracking to other modalities. Either the video timestamps can be passed to This can be used to pass the timestamps with the key <code>video_timestamps</code> or the sampling rate with key<code>video_sample_rate</code>.</p> <p>e.g. pose_estimation_metadata[\"video_timestamps\"] = np.array(timestamps) or   pose_estimation_metadata[\"video_sample_rate\"] = 15  # In Hz</p> <p>2) The other use of this dictionary is to overwrite sleap-io default arguments for the PoseEstimation container. see https://github.com/rly/ndx-pose for a full list or arguments.</p> <code>None</code> <code>skeleton_map</code> <code>Optional[Dict[str, Skeleton]]</code> <p>Mapping of skeleton names to NWB Skeleton objects.</p> <code>None</code> <p>Returns:</p> Type Description <code>NWBFile</code> <p>An in-memory nwbfile with the data from the labels object appended.</p> Source code in <code>sleap_io/io/nwb_predictions.py</code> <pre><code>def append_nwb_data(\n    labels: Labels,\n    nwbfile: NWBFile,\n    pose_estimation_metadata: Optional[dict] = None,\n    skeleton_map: Optional[Dict[str, Skeleton]] = None,\n) -&gt; NWBFile:\n    \"\"\"Append data from a Labels object to an in-memory nwb file.\n\n    Args:\n        labels: A general labels object\n        nwbfile: And in-memory nwbfile where the data is to be appended.\n        pose_estimation_metadata: This argument has a dual purpose:\n\n            1) It can be used to pass time information about the video which is\n            necessary for synchronizing frames in pose estimation tracking to other\n            modalities. Either the video timestamps can be passed to\n            This can be used to pass the timestamps with the key `video_timestamps`\n            or the sampling rate with key`video_sample_rate`.\n\n            e.g. pose_estimation_metadata[\"video_timestamps\"] = np.array(timestamps)\n            or   pose_estimation_metadata[\"video_sample_rate\"] = 15  # In Hz\n\n            2) The other use of this dictionary is to overwrite sleap-io default\n            arguments for the PoseEstimation container.\n            see https://github.com/rly/ndx-pose for a full list or arguments.\n        skeleton_map: Mapping of skeleton names to NWB Skeleton objects.\n\n    Returns:\n        An in-memory nwbfile with the data from the labels object appended.\n    \"\"\"\n    pose_estimation_metadata = pose_estimation_metadata or dict()\n    if skeleton_map is None:\n        skeleton_map = create_skeleton_container(labels=labels, nwbfile=nwbfile)\n\n    # Extract default metadata\n    provenance = labels.provenance\n    default_metadata = dict(scorer=str(provenance))\n    sleap_version = provenance.get(\"sleap_version\", None)\n    default_metadata[\"source_software_version\"] = sleap_version\n\n    labels_data_df = convert_predictions_to_dataframe(labels)\n\n    # For every video create a processing module\n    for video_index, video in enumerate(labels.videos):\n        video_path = Path(video.filename)\n        processing_module_name = f\"SLEAP_VIDEO_{video_index:03}_{video_path.stem}\"\n        nwb_processing_module = get_processing_module_for_video(\n            processing_module_name, nwbfile\n        )\n\n        device_name = f\"camera_{video_index}\"\n        if device_name in nwbfile.devices:\n            device = nwbfile.devices[device_name]\n        else:\n            device = nwbfile.create_device(\n                name=device_name,\n                description=f\"Camera for {video_path.name}\",\n                manufacturer=\"Unknown\",\n            )\n\n        # Propagate video metadata\n        default_metadata[\"original_videos\"] = [f\"{video.filename}\"]  # type: ignore\n        default_metadata[\"labeled_videos\"] = [f\"{video.filename}\"]  # type: ignore\n\n        # Overwrite default with the user provided metadata\n        default_metadata.update(pose_estimation_metadata)\n\n        # For every track in that video create a PoseEstimation container\n        name_of_tracks_in_video = (\n            labels_data_df[video.filename]\n            .columns.get_level_values(\"track_name\")\n            .unique()\n        )\n\n        for track_index, track_name in enumerate(name_of_tracks_in_video):\n            pose_estimation_container = build_pose_estimation_container_for_track(\n                labels_data_df,\n                labels,\n                track_name,\n                video,\n                default_metadata,\n                skeleton_map,\n                devices=[device],\n            )\n            nwb_processing_module.add(pose_estimation_container)\n\n    return nwbfile\n</code></pre>"},{"location":"reference/sleap_io/io/nwb_predictions/#sleap_io.io.nwb_predictions.build_pose_estimation_container_for_track","title":"<code>build_pose_estimation_container_for_track(labels_data_df, labels, track_name, video, pose_estimation_metadata, skeleton_map, devices=None)</code>","text":"<p>Create a PoseEstimation container for a track.</p> <p>Parameters:</p> Name Type Description Default <code>labels_data_df</code> <code>DataFrame</code> <p>A pandas object with the data corresponding to the predicted instances associated to this labels object.</p> required <code>labels</code> <code>Labels</code> <p>A general labels object</p> required <code>track_name</code> <code>str</code> <p>The name of the track in labels.tracks</p> required <code>video</code> <code>Video</code> <p>The video to which data belongs to</p> required <code>pose_estimation_metadata</code> <code>dict</code> <p>(dict) Metadata for pose estimation. See <code>append_nwb_data</code></p> required <code>skeleton_map</code> <code>Dict[str, Skeleton]</code> <p>Mapping of skeleton names to NWB Skeleton objects</p> required <code>skeleton_map</code> <code>Dict[str, Skeleton]</code> <p>Mapping of skeleton names to NWB Skeleton objects</p> required <code>devices</code> <code>Optional[List]</code> <p>Optional list of recording devices</p> <code>None</code> <p>Returns:     PoseEstimation: A PoseEstimation multicontainer where the time series     of all the node trajectories in the track are stored. One time series per     node.</p> Source code in <code>sleap_io/io/nwb_predictions.py</code> <pre><code>def build_pose_estimation_container_for_track(\n    labels_data_df: pd.DataFrame,\n    labels: Labels,\n    track_name: str,\n    video: Video,\n    pose_estimation_metadata: dict,\n    skeleton_map: Dict[str, Skeleton],\n    devices: Optional[List] = None,\n) -&gt; PoseEstimation:\n    \"\"\"Create a PoseEstimation container for a track.\n\n    Args:\n        labels_data_df (pd.DataFrame): A pandas object with the data corresponding\n            to the predicted instances associated to this labels object.\n        labels (Labels): A general labels object\n        track_name (str): The name of the track in labels.tracks\n        video (Video): The video to which data belongs to\n        pose_estimation_metadata: (dict) Metadata for pose estimation.\n            See `append_nwb_data`\n        skeleton_map: Mapping of skeleton names to NWB Skeleton objects\n        skeleton_map: Mapping of skeleton names to NWB Skeleton objects\n        devices: Optional list of recording devices\n    Returns:\n        PoseEstimation: A PoseEstimation multicontainer where the time series\n        of all the node trajectories in the track are stored. One time series per\n        node.\n    \"\"\"\n    # Copy metadata for local use and modification\n    pose_estimation_metadata_copy = deepcopy(pose_estimation_metadata)\n    video_path = Path(video.filename)\n\n    all_track_skeletons = (\n        labels_data_df[video.filename]\n        .columns.get_level_values(\"skeleton_name\")\n        .unique()\n    )\n\n    # Assuming only one skeleton per track\n    skeleton_name = all_track_skeletons[0]\n    sleap_skeleton = next(\n        skeleton for skeleton in labels.skeletons if skeleton.name == skeleton_name\n    )\n    nwb_skeleton = skeleton_map[skeleton_name]\n\n    # Get track data\n    track_data_df = labels_data_df[\n        video.filename,\n        sleap_skeleton.name,\n        track_name,\n    ]\n\n    # Combine each node's PoseEstimationSeries to create a PoseEstimation container\n    timestamps = pose_estimation_metadata_copy.pop(\"video_timestamps\", None)\n    sample_rate = pose_estimation_metadata_copy.pop(\"video_sample_rate\", 1.0)\n    if timestamps is None:\n        # Keeps backward compatibility.\n        timestamps = np.arange(track_data_df.shape[0]) * sample_rate\n    else:\n        timestamps = np.asarray(timestamps)\n\n    pose_estimation_series_list = build_track_pose_estimation_list(\n        track_data_df, timestamps\n    )\n\n    # Arrange and mix metadata\n    pose_estimation_container_kwargs = dict(\n        name=f\"track={track_name}\",\n        description=(\n            f\"Estimated positions of {sleap_skeleton.name} in video {video_path.name}\"\n        ),\n        pose_estimation_series=pose_estimation_series_list,\n        skeleton=nwb_skeleton,\n        source_software=\"SLEAP\",\n        # dimensions=np.array([[video.height, video.width]], dtype=\"uint16\"),\n        devices=devices or [],\n    )\n\n    pose_estimation_container_kwargs.update(**pose_estimation_metadata_copy)\n    pose_estimation_container = PoseEstimation(**pose_estimation_container_kwargs)\n\n    return pose_estimation_container\n</code></pre>"},{"location":"reference/sleap_io/io/nwb_predictions/#sleap_io.io.nwb_predictions.build_track_pose_estimation_list","title":"<code>build_track_pose_estimation_list(track_data_df, timestamps)</code>","text":"<p>Build a list of PoseEstimationSeries from tracks.</p> <p>Parameters:</p> Name Type Description Default <code>track_data_df</code> <code>DataFrame</code> <p>A pandas DataFrame containing the trajectories for all the nodes associated with a specific track.</p> required <code>timestamps</code> <code>ArrayLike</code> <p>Array of timestamps for the data points</p> required <p>Returns:</p> Type Description <code>List[PoseEstimationSeries]</code> <p>List of PoseEstimationSeries, one for each node.</p> Source code in <code>sleap_io/io/nwb_predictions.py</code> <pre><code>def build_track_pose_estimation_list(\n    track_data_df: pd.DataFrame, timestamps: ArrayLike\n) -&gt; List[PoseEstimationSeries]:\n    \"\"\"Build a list of PoseEstimationSeries from tracks.\n\n    Args:\n        track_data_df: A pandas DataFrame containing the trajectories\n            for all the nodes associated with a specific track.\n        timestamps: Array of timestamps for the data points\n\n    Returns:\n        List of PoseEstimationSeries, one for each node.\n    \"\"\"\n    name_of_nodes_in_track = track_data_df.columns.get_level_values(\n        \"node_name\"\n    ).unique()\n\n    pose_estimation_series_list: List[PoseEstimationSeries] = []\n    for node_name in name_of_nodes_in_track:\n        # Drop data with missing values\n        data_for_node = track_data_df[node_name].dropna(axis=\"index\", how=\"any\")\n\n        node_trajectory = data_for_node[[\"x\", \"y\"]].to_numpy()\n        confidence = data_for_node[\"score\"].to_numpy()\n\n        reference_frame = (\n            \"The coordinates are in (x, y) relative to the top-left of the image. \"\n            \"Coordinates refer to the midpoint of the pixel. \"\n            \"That is, the midpoint of the top-left pixel is at (0, 0), whereas \"\n            \"the top-left corner of that same pixel is at (-0.5, -0.5).\"\n        )\n\n        pose_estimation_kwargs = dict(\n            name=f\"{node_name}\",\n            description=f\"Sequential trajectory of {node_name}.\",\n            data=node_trajectory,\n            unit=\"pixels\",\n            reference_frame=reference_frame,\n            confidence=confidence,\n            confidence_definition=\"Point-wise confidence scores.\",\n        )\n\n        # Add timestamps or only rate if the timestamps are uniform\n        frames = data_for_node.index.values\n        timestamps_for_data = timestamps[frames]  # type: ignore[index]\n        sample_periods = np.diff(timestamps_for_data)\n        if sample_periods.size == 0:\n            rate = None  # This is the case with only one data point\n        else:\n            # Difference below 0.1 ms do not matter for behavior in videos\n            uniform_samples = np.unique(sample_periods.round(5)).size == 1\n            rate = 1 / sample_periods[0] if uniform_samples else None\n\n        if rate:\n            # Video sample rates are ints but nwb expect floats\n            rate = float(int(rate))\n            pose_estimation_kwargs.update(\n                rate=rate, starting_time=timestamps_for_data[0]\n            )\n        else:\n            pose_estimation_kwargs.update(timestamps=timestamps_for_data)\n\n        # Build the pose estimation object and attach it to the list\n        pose_estimation_series = PoseEstimationSeries(**pose_estimation_kwargs)\n        pose_estimation_series_list.append(pose_estimation_series)\n\n    return pose_estimation_series_list\n</code></pre>"},{"location":"reference/sleap_io/io/nwb_predictions/#sleap_io.io.nwb_predictions.convert_predictions_to_dataframe","title":"<code>convert_predictions_to_dataframe(labels)</code>","text":"<p>Convert predictions data to a Pandas dataframe.</p> <p>Parameters:</p> Name Type Description Default <code>labels</code> <code>Labels</code> <p>A general label object.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: A pandas data frame with the structured data with hierarchical columns. The column hierarchy is:         \"video_path\",         \"skeleton_name\",         \"track_name\",         \"node_name\", And it is indexed by the frames.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If no frames in the label objects contain predicted instances.</p> Source code in <code>sleap_io/io/nwb_predictions.py</code> <pre><code>def convert_predictions_to_dataframe(labels: Labels) -&gt; pd.DataFrame:\n    \"\"\"Convert predictions data to a Pandas dataframe.\n\n    Args:\n        labels: A general label object.\n\n    Returns:\n        pd.DataFrame: A pandas data frame with the structured data with\n        hierarchical columns. The column hierarchy is:\n                \"video_path\",\n                \"skeleton_name\",\n                \"track_name\",\n                \"node_name\",\n        And it is indexed by the frames.\n\n    Raises:\n        ValueError: If no frames in the label objects contain predicted instances.\n    \"\"\"\n    # Form pairs of labeled_frames and predicted instances\n    labeled_frames = labels.labeled_frames\n    all_frame_instance_tuples = (\n        (label_frame, instance)  # type: ignore\n        for label_frame in labeled_frames\n        for instance in label_frame.predicted_instances\n    )\n\n    # Extract the data\n    data_list = list()\n    for labeled_frame, instance in all_frame_instance_tuples:\n        # Traverse the nodes of the instances's skeleton\n        skeleton = instance.skeleton\n        for node in skeleton.nodes:\n            row_dict = dict(\n                frame_idx=labeled_frame.frame_idx,\n                x=instance[node][\"xy\"][0],\n                y=instance[node][\"xy\"][1],\n                score=instance[node][\"score\"],\n                node_name=node.name,\n                skeleton_name=skeleton.name,\n                track_name=instance.track.name if instance.track else \"untracked\",\n                video_path=labeled_frame.video.filename,\n            )\n            data_list.append(row_dict)\n\n    if not data_list:\n        raise ValueError(\"No predicted instances found in labels object\")\n\n    labels_df = pd.DataFrame(data_list)\n\n    # Reformat the data with columns for dict-like hierarchical data access.\n    index = [\n        \"skeleton_name\",\n        \"track_name\",\n        \"node_name\",\n        \"video_path\",\n        \"frame_idx\",\n    ]\n\n    labels_tidy_df = (\n        labels_df.set_index(index)\n        .unstack(level=[0, 1, 2, 3])\n        .swaplevel(0, -1, axis=1)  # video_path on top while x, y score on bottom\n        .sort_index(axis=1)  # Better format for columns\n        .sort_index(axis=0)  # Sorts by frames\n    )\n\n    return labels_tidy_df\n</code></pre>"},{"location":"reference/sleap_io/io/nwb_predictions/#sleap_io.io.nwb_predictions.create_skeleton_container","title":"<code>create_skeleton_container(labels, nwbfile)</code>","text":"<p>Create NWB skeleton containers from SLEAP skeletons.</p> <p>Parameters:</p> Name Type Description Default <code>labels</code> <code>Labels</code> <p>SLEAP Labels object containing skeleton definitions</p> required <code>nwbfile</code> <code>NWBFile</code> <p>NWB file to add skeletons to</p> required <p>Returns:</p> Type Description <code>Dict[str, Skeleton]</code> <p>Dictionary mapping skeleton names to NWB Skeleton objects</p> Source code in <code>sleap_io/io/nwb_predictions.py</code> <pre><code>def create_skeleton_container(\n    labels: Labels,\n    nwbfile: NWBFile,\n) -&gt; Dict[str, Skeleton]:\n    \"\"\"Create NWB skeleton containers from SLEAP skeletons.\n\n    Args:\n        labels: SLEAP Labels object containing skeleton definitions\n        nwbfile: NWB file to add skeletons to\n\n    Returns:\n        Dictionary mapping skeleton names to NWB Skeleton objects\n    \"\"\"\n    skeleton_map = {}\n    nwb_skeletons = []\n\n    # Get or create behavior processing module\n    behavior_pm = nwbfile.processing.get(\"behavior\")\n    if behavior_pm is None:\n        behavior_pm = nwbfile.create_processing_module(\n            name=\"behavior\", description=\"processed behavioral data\"\n        )\n\n    # Check if Skeletons container already exists\n    existing_skeletons = None\n    if \"Skeletons\" in behavior_pm.data_interfaces:\n        existing_skeletons = behavior_pm.data_interfaces[\"Skeletons\"]\n        # Add existing skeletons to our map\n        for skeleton_name in existing_skeletons.skeletons:\n            nwb_skeleton = existing_skeletons.skeletons[skeleton_name]\n            skeleton_map[skeleton_name] = nwb_skeleton\n\n    # Create new skeletons for ones that don't exist yet\n    for sleap_skeleton in labels.skeletons:\n        if sleap_skeleton.name not in skeleton_map:\n            nwb_skeleton = Skeleton(\n                name=sleap_skeleton.name,\n                nodes=sleap_skeleton.node_names,\n                edges=np.array(sleap_skeleton.edge_inds, dtype=\"uint8\"),\n            )\n            nwb_skeletons.append(nwb_skeleton)\n            skeleton_map[sleap_skeleton.name] = nwb_skeleton\n\n    # If we have new skeletons to add\n    if nwb_skeletons:\n        if existing_skeletons is None:\n            # Create new Skeletons container if none exists\n            skeletons_container = Skeletons(skeletons=nwb_skeletons)\n            behavior_pm.add(skeletons_container)\n        else:\n            # Add new skeletons to existing container\n            for skeleton in nwb_skeletons:\n                existing_skeletons.add_skeleton(skeleton)\n\n    return skeleton_map\n</code></pre>"},{"location":"reference/sleap_io/io/nwb_predictions/#sleap_io.io.nwb_predictions.get_processing_module_for_video","title":"<code>get_processing_module_for_video(processing_module_name, nwbfile)</code>","text":"<p>Auxiliary function to create a processing module.</p> <p>Checks for the processing module existence and creates if not available.</p> <p>Parameters:</p> Name Type Description Default <code>processing_module_name</code> <code>str</code> <p>The name of the processing module.</p> required <code>nwbfile</code> <code>NWBFile</code> <p>The nwbfile to attach the processing module to.</p> required <p>Returns:</p> Name Type Description <code>ProcessingModule</code> <code>ProcessingModule</code> <p>An nwb processing module with the desired name.</p> Source code in <code>sleap_io/io/nwb_predictions.py</code> <pre><code>def get_processing_module_for_video(\n    processing_module_name: str, nwbfile: NWBFile\n) -&gt; ProcessingModule:\n    \"\"\"Auxiliary function to create a processing module.\n\n    Checks for the processing module existence and creates if not available.\n\n    Args:\n        processing_module_name (str): The name of the processing module.\n        nwbfile (NWBFile): The nwbfile to attach the processing module to.\n\n    Returns:\n        ProcessingModule: An nwb processing module with the desired name.\n    \"\"\"\n    description = \"Processed SLEAP data\"\n    processing_module = (\n        nwbfile.processing[processing_module_name]\n        if processing_module_name in nwbfile.processing\n        else nwbfile.create_processing_module(\n            name=processing_module_name, description=description\n        )\n    )\n    return processing_module\n</code></pre>"},{"location":"reference/sleap_io/io/nwb_predictions/#sleap_io.io.nwb_predictions.get_timestamps","title":"<code>get_timestamps(series)</code>","text":"<p>Return a vector of timestamps for a <code>PoseEstimationSeries</code>.</p> Source code in <code>sleap_io/io/nwb_predictions.py</code> <pre><code>def get_timestamps(series: PoseEstimationSeries) -&gt; np.ndarray:\n    \"\"\"Return a vector of timestamps for a `PoseEstimationSeries`.\"\"\"\n    if series.timestamps is not None:\n        return np.asarray(series.timestamps)\n    else:\n        return np.arange(series.data.shape[0]) * series.rate + series.starting_time\n</code></pre>"},{"location":"reference/sleap_io/io/nwb_predictions/#sleap_io.io.nwb_predictions.read_nwb","title":"<code>read_nwb(path)</code>","text":"<p>Read an NWB formatted file to a SLEAP <code>Labels</code> object.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Path to an NWB file (<code>.nwb</code>).</p> required <p>Returns:</p> Type Description <code>Labels</code> <p>A <code>Labels</code> object.</p> Source code in <code>sleap_io/io/nwb_predictions.py</code> <pre><code>def read_nwb(path: str) -&gt; Labels:\n    \"\"\"Read an NWB formatted file to a SLEAP `Labels` object.\n\n    Args:\n        path: Path to an NWB file (`.nwb`).\n\n    Returns:\n        A `Labels` object.\n    \"\"\"\n    with NWBHDF5IO(path, mode=\"r\", load_namespaces=True) as io:\n        read_nwbfile = io.read()\n        nwb_file_processing = read_nwbfile.processing\n\n        # Get list of videos\n        video_keys: List[str] = [\n            key for key in nwb_file_processing.keys() if \"SLEAP_VIDEO\" in key\n        ]\n        video_tracks = dict()\n\n        # Get track keys from first video's processing module\n        test_processing_module: ProcessingModule = nwb_file_processing[video_keys[0]]\n        track_keys: List[str] = list(test_processing_module.fields[\"data_interfaces\"])\n\n        # Get first track's skeleton\n        test_pose_estimation: PoseEstimation = test_processing_module[track_keys[0]]\n        skeleton = test_pose_estimation.skeleton\n        skeleton_nodes = skeleton.nodes[:]\n        skeleton_edges = skeleton.edges[:]\n\n        # Filtering out behavior module with skeletons\n        pose_estimation_container_modules = [\n            nwb_file_processing[key] for key in video_keys\n        ]\n\n        for processing_module in pose_estimation_container_modules:\n            # Get track keys\n            _track_keys: List[str] = list(processing_module.fields[\"data_interfaces\"])\n            is_tracked: bool = re.sub(\"[0-9]+\", \"\", _track_keys[0]) == \"track\"\n\n            # Figure out the max number of frames and the canonical timestamps\n            timestamps = np.empty(())\n            for track_key in _track_keys:\n                pose_estimation = processing_module[track_key]\n                for node_name in skeleton.nodes:\n                    pose_estimation_series = pose_estimation[node_name]\n                    timestamps = np.union1d(\n                        timestamps, get_timestamps(pose_estimation_series)\n                    )\n            timestamps = np.sort(timestamps)\n\n            # Recreate Labels numpy (same as output of Labels.numpy())\n            n_tracks = len(_track_keys)\n            n_frames = len(timestamps)\n            n_nodes = len(skeleton.nodes)\n            tracks_numpy = np.full((n_frames, n_tracks, n_nodes, 2), np.nan, np.float32)\n            confidence = np.full((n_frames, n_tracks, n_nodes), np.nan, np.float32)\n\n            for track_idx, track_key in enumerate(_track_keys):\n                pose_estimation = processing_module[track_key]\n                for node_idx, node_name in enumerate(skeleton.nodes):\n                    pose_estimation_series = pose_estimation[node_name]\n                    frame_inds = np.searchsorted(\n                        timestamps, get_timestamps(pose_estimation_series)\n                    )\n                    tracks_numpy[frame_inds, track_idx, node_idx, :] = (\n                        pose_estimation_series.data[:]\n                    )\n                    confidence[frame_inds, track_idx, node_idx] = (\n                        pose_estimation_series.confidence[:]\n                    )\n\n            video_tracks[Path(pose_estimation.original_videos[0]).as_posix()] = (\n                tracks_numpy,\n                confidence,\n                is_tracked,\n            )\n\n    # Create SLEAP skeleton from NWB skeleton\n    sleap_skeleton = SleapSkeleton(\n        nodes=skeleton_nodes,\n        edges=skeleton_edges.tolist(),\n    )\n\n    # Add instances to labeled frames\n    lfs = []\n    for video_fn, (tracks_numpy, confidence, is_tracked) in video_tracks.items():\n        video = Video(filename=video_fn)\n        n_frames, n_tracks, n_nodes, _ = tracks_numpy.shape\n        tracks = [Track(name=f\"track{track_idx}\") for track_idx in range(n_tracks)]\n\n        for frame_idx, (frame_pts, frame_confs) in enumerate(\n            zip(tracks_numpy, confidence)\n        ):\n            insts: List[Union[Instance, PredictedInstance]] = []\n            for track, (inst_pts, inst_confs) in zip(\n                tracks, zip(frame_pts, frame_confs)\n            ):\n                if np.isnan(inst_pts).all():\n                    continue\n                insts.append(\n                    PredictedInstance.from_numpy(\n                        points_data=np.column_stack(\n                            [inst_pts, inst_confs]\n                        ),  # (n_nodes, 3)\n                        score=inst_confs.mean(),  # ()\n                        skeleton=sleap_skeleton,\n                        track=track if is_tracked else None,\n                    )\n                )\n            if len(insts) &gt; 0:\n                lfs.append(\n                    LabeledFrame(video=video, frame_idx=frame_idx, instances=insts)\n                )\n\n    labels = Labels(lfs)\n    labels.provenance[\"filename\"] = path\n    return labels\n</code></pre>"},{"location":"reference/sleap_io/io/nwb_predictions/#sleap_io.io.nwb_predictions.write_nwb","title":"<code>write_nwb(labels, nwbfile_path, nwb_file_kwargs=None, pose_estimation_metadata=None)</code>","text":"<p>Write labels to an nwb file and save it to the nwbfile_path given.</p> <p>Parameters:</p> Name Type Description Default <code>labels</code> <code>Labels</code> <p>A general <code>Labels</code> object.</p> required <code>nwbfile_path</code> <code>str</code> <p>The path where the nwb file is to be written.</p> required <code>nwb_file_kwargs</code> <code>Optional[dict]</code> <p>A dict containing metadata to the nwbfile. Example: nwb_file_kwargs = {     'session_description: 'your_session_description',     'identifier': 'your session_identifier', } For a full list of possible values see: https://pynwb.readthedocs.io/en/stable/pynwb.file.html#pynwb.file.NWBFile</p> <p>Defaults to None and default values are used to generate the nwb file.</p> <code>None</code> <code>pose_estimation_metadata</code> <code>Optional[dict]</code> <p>This argument has a dual purpose:</p> <p>1) It can be used to pass time information about the video which is necessary for synchronizing frames in pose estimation tracking to other modalities. Either the video timestamps can be passed to This can be used to pass the timestamps with the key <code>video_timestamps</code> or the sampling rate with key<code>video_sample_rate</code>.</p> <p>e.g. pose_estimation_metadata[\"video_timestamps\"] = np.array(timestamps) or   pose_estimation_metadata[\"video_sample_rate] = 15  # In Hz</p> <p>2) The other use of this dictionary is to overwrite sleap-io default arguments for the PoseEstimation container. see https://github.com/rly/ndx-pose for a full list or arguments.</p> <code>None</code> Source code in <code>sleap_io/io/nwb_predictions.py</code> <pre><code>def write_nwb(\n    labels: Labels,\n    nwbfile_path: str,\n    nwb_file_kwargs: Optional[dict] = None,\n    pose_estimation_metadata: Optional[dict] = None,\n):\n    \"\"\"Write labels to an nwb file and save it to the nwbfile_path given.\n\n    Args:\n        labels: A general `Labels` object.\n        nwbfile_path: The path where the nwb file is to be written.\n        nwb_file_kwargs: A dict containing metadata to the nwbfile. Example:\n            nwb_file_kwargs = {\n                'session_description: 'your_session_description',\n                'identifier': 'your session_identifier',\n            }\n            For a full list of possible values see:\n            https://pynwb.readthedocs.io/en/stable/pynwb.file.html#pynwb.file.NWBFile\n\n            Defaults to None and default values are used to generate the nwb file.\n\n        pose_estimation_metadata: This argument has a dual purpose:\n\n            1) It can be used to pass time information about the video which is\n            necessary for synchronizing frames in pose estimation tracking to other\n            modalities. Either the video timestamps can be passed to\n            This can be used to pass the timestamps with the key `video_timestamps`\n            or the sampling rate with key`video_sample_rate`.\n\n            e.g. pose_estimation_metadata[\"video_timestamps\"] = np.array(timestamps)\n            or   pose_estimation_metadata[\"video_sample_rate] = 15  # In Hz\n\n            2) The other use of this dictionary is to overwrite sleap-io default\n            arguments for the PoseEstimation container.\n            see https://github.com/rly/ndx-pose for a full list or arguments.\n    \"\"\"\n    nwb_file_kwargs = nwb_file_kwargs or dict()\n\n    # Add required values for nwbfile if not present\n    session_description = nwb_file_kwargs.get(\n        \"session_description\", \"Processed SLEAP pose data\"\n    )\n    session_start_time = nwb_file_kwargs.get(\n        \"session_start_time\", datetime.datetime.now(datetime.timezone.utc)\n    )\n    identifier = nwb_file_kwargs.get(\"identifier\", str(uuid.uuid1()))\n\n    nwb_file_kwargs.update(\n        session_description=session_description,\n        session_start_time=session_start_time,\n        identifier=identifier,\n    )\n\n    nwbfile = NWBFile(**nwb_file_kwargs)\n\n    # Create skeleton containers first\n    skeleton_map = create_skeleton_container(labels, nwbfile)\n\n    # Then append pose data\n    nwbfile = append_nwb_data(labels, nwbfile, pose_estimation_metadata, skeleton_map)\n\n    with NWBHDF5IO(str(nwbfile_path), \"w\") as io:\n        io.write(nwbfile)\n</code></pre>"},{"location":"reference/sleap_io/io/skeleton/","title":"skeleton","text":""},{"location":"reference/sleap_io/io/skeleton/#sleap_io.io.skeleton","title":"<code>sleap_io.io.skeleton</code>","text":"<p>This module handles I/O operations for standalone skeleton JSON files.</p> <p>Classes:</p> Name Description <code>SkeletonDecoder</code> <p>Decode skeleton data from jsonpickle-encoded format.</p> <code>SkeletonEncoder</code> <p>Encode skeleton data to jsonpickle format.</p> <code>SkeletonSLPDecoder</code> <p>Decode skeleton data from SLP format.</p> <code>SkeletonSLPEncoder</code> <p>Encode skeleton data to SLP format.</p> <code>SkeletonYAMLDecoder</code> <p>Decode skeleton data from simplified YAML format.</p> <code>SkeletonYAMLEncoder</code> <p>Encode skeleton data to simplified YAML format.</p> <p>Functions:</p> Name Description <code>decode_skeleton</code> <p>Decode skeleton(s) from JSON data using the default decoder.</p> <code>decode_training_config</code> <p>Decode skeleton(s) from training config data.</p> <code>decode_yaml_skeleton</code> <p>Decode skeleton(s) from YAML data.</p> <code>encode_skeleton</code> <p>Encode skeleton(s) to JSON string using the default encoder.</p> <code>encode_yaml_skeleton</code> <p>Encode skeleton(s) to YAML string.</p> <code>load_skeleton_from_json</code> <p>Load skeleton(s) from JSON data, with automatic training config detection.</p>"},{"location":"reference/sleap_io/io/skeleton/#sleap_io.io.skeleton.SkeletonDecoder","title":"<code>SkeletonDecoder</code>","text":"<p>Decode skeleton data from jsonpickle-encoded format.</p> <p>This decoder handles the custom jsonpickle format used by SLEAP for standalone skeleton JSON files, which differs from the format used within .slp files.</p> <p>Methods:</p> Name Description <code>__init__</code> <p>Initialize the decoder.</p> <code>decode</code> <p>Decode skeleton(s) from JSON data.</p> Source code in <code>sleap_io/io/skeleton.py</code> <pre><code>class SkeletonDecoder:\n    \"\"\"Decode skeleton data from jsonpickle-encoded format.\n\n    This decoder handles the custom jsonpickle format used by SLEAP for\n    standalone skeleton JSON files, which differs from the format used\n    within .slp files.\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"Initialize the decoder.\"\"\"\n        self.decoded_objects: List[\n            Any\n        ] = []  # List of decoded objects indexed by py/id - 1\n\n    def decode(self, data: Union[str, Dict]) -&gt; Union[Skeleton, List[Skeleton]]:\n        \"\"\"Decode skeleton(s) from JSON data.\n\n        Args:\n            data: JSON string or pre-parsed dictionary containing skeleton data.\n\n        Returns:\n            A single Skeleton or list of Skeletons depending on input format.\n        \"\"\"\n        if isinstance(data, str):\n            data = json.loads(data)\n\n        # Reset decoded objects list for each decode operation\n        self.decoded_objects = []\n\n        # Check if this is a list of skeletons or a single skeleton\n        if isinstance(data, list):\n            return [self._decode_skeleton(skel_data) for skel_data in data]\n        else:\n            return self._decode_skeleton(data)\n\n    def _decode_skeleton(self, data: Dict) -&gt; Skeleton:\n        \"\"\"Decode a single skeleton from dictionary data.\n\n        Args:\n            data: Dictionary containing skeleton data in jsonpickle format.\n\n        Returns:\n            A Skeleton object.\n        \"\"\"\n        # Reset decoded objects list for this skeleton\n        self.decoded_objects = []\n\n        # Track edge types separately for formats that use separate py/id spaces\n        edge_type_ids = {}  # edge_type_value -&gt; py/id\n        next_edge_type_id = 1\n\n        # First pass: decode all objects in order of appearance\n        seen_nodes = set()  # Track node names we've already seen\n\n        for link in data.get(\"links\", []):\n            # Check each component of the link for new objects\n            for key in [\"source\", \"target\", \"type\"]:\n                value = link.get(key, {})\n                if isinstance(value, dict):\n                    if \"py/object\" in value:\n                        # New node object\n                        node = self._decode_node(value)\n                        if node.name not in seen_nodes:\n                            self.decoded_objects.append(node)\n                            seen_nodes.add(node.name)\n                    elif \"py/reduce\" in value:\n                        # New edge type\n                        edge_type_val = value[\"py/reduce\"][1][\"py/tuple\"][0]\n                        self.decoded_objects.append(edge_type_val)\n                        # Also track edge type IDs separately\n                        if edge_type_val not in edge_type_ids:\n                            edge_type_ids[edge_type_val] = next_edge_type_id\n                            next_edge_type_id += 1\n                    # py/id references are handled in second pass\n\n        # Also process nodes that are directly defined in the nodes array\n        # This is crucial for single-node skeletons with no edges\n        for node_ref in data.get(\"nodes\", []):\n            if isinstance(node_ref.get(\"id\"), dict) and \"py/object\" in node_ref[\"id\"]:\n                # New node object directly in nodes array\n                node = self._decode_node(node_ref[\"id\"])\n                if node.name not in seen_nodes:\n                    self.decoded_objects.append(node)\n                    seen_nodes.add(node.name)\n\n        # Store edge type mappings for second pass\n        self._edge_type_ids = edge_type_ids\n\n        # Second pass: build edges using the decoded objects\n        edges = []\n        symmetries = []\n        seen_symmetries = set()\n\n        for link in data.get(\"links\", []):\n            # Resolve references to build the edge\n            source_node = self._resolve_link_ref(link[\"source\"])\n            target_node = self._resolve_link_ref(link[\"target\"])\n            edge_type_val = self._resolve_edge_type_ref(link.get(\"type\", {}))\n\n            if edge_type_val == 1:  # Regular edge\n                edges.append(Edge(source=source_node, destination=target_node))\n            elif edge_type_val == 2:  # Symmetry edge\n                # Create a unique key for this symmetry pair (order-independent)\n                sym_key = tuple(sorted([source_node.name, target_node.name]))\n                if sym_key not in seen_symmetries:\n                    symmetries.append(Symmetry([source_node, target_node]))\n                    seen_symmetries.add(sym_key)\n\n        # Build nodes list from the nodes section\n        nodes = []\n        nodes_from_refs = []\n\n        # First collect nodes based on the nodes array\n        for node_ref in data.get(\"nodes\", []):\n            if isinstance(node_ref[\"id\"], dict) and \"py/id\" in node_ref[\"id\"]:\n                py_id = node_ref[\"id\"][\"py/id\"]\n                # Get node from decoded objects (py/id is 1-indexed)\n                if py_id &lt;= len(self.decoded_objects):\n                    obj = self.decoded_objects[py_id - 1]\n                    if isinstance(obj, Node):\n                        nodes_from_refs.append(obj)\n\n        # If we're missing nodes (due to malformed JSON), collect all Node objects\n        all_nodes = [obj for obj in self.decoded_objects if isinstance(obj, Node)]\n\n        if len(nodes_from_refs) &lt; len(all_nodes):\n            # The nodes array is incomplete or includes non-nodes\n            # Use all nodes in their natural order\n            nodes = all_nodes\n        else:\n            # Use the order from the nodes array\n            nodes = nodes_from_refs\n\n        # Get skeleton name\n        name = data.get(\"graph\", {}).get(\"name\", \"Skeleton\")\n\n        return Skeleton(nodes=nodes, edges=edges, symmetries=symmetries, name=name)\n\n    def _resolve_link_ref(self, node_ref: Union[Dict, int]) -&gt; Node:\n        \"\"\"Resolve a node reference.\n\n        Args:\n            node_ref: Node reference (can be embedded object or py/id reference).\n\n        Returns:\n            The resolved Node object.\n        \"\"\"\n        if isinstance(node_ref, dict):\n            if \"py/object\" in node_ref:\n                # Find the node in decoded objects by name\n                node = self._decode_node(node_ref)\n                for obj in self.decoded_objects:\n                    if isinstance(obj, Node) and obj.name == node.name:\n                        return obj\n                raise ValueError(f\"Node {node.name} not found in decoded objects\")\n            elif \"py/id\" in node_ref:\n                # Reference to existing object\n                py_id = node_ref[\"py/id\"]\n                if py_id &lt;= len(self.decoded_objects):\n                    obj = self.decoded_objects[py_id - 1]\n                    if isinstance(obj, Node):\n                        return obj\n                    raise ValueError(f\"py/id {py_id} is not a Node\")\n                raise ValueError(f\"py/id {py_id} not found\")\n        elif isinstance(node_ref, int):\n            # Direct index (used in SLP format, shouldn't happen in standalone)\n            raise ValueError(f\"Direct index reference not supported: {node_ref}\")\n\n        raise ValueError(f\"Unknown node reference format: {node_ref}\")\n\n    def _resolve_edge_type_ref(self, type_data: Dict) -&gt; int:\n        \"\"\"Resolve edge type reference.\n\n        Args:\n            type_data: Dictionary containing edge type data.\n\n        Returns:\n            Integer edge type (1 for regular edge, 2 for symmetry).\n        \"\"\"\n        if \"py/reduce\" in type_data:\n            # Return the value directly (already decoded in first pass)\n            return type_data[\"py/reduce\"][1][\"py/tuple\"][0]\n        elif \"py/id\" in type_data:\n            # Reference to existing edge type\n            py_id = type_data[\"py/id\"]\n\n            # First try to find in decoded objects (training config format)\n            if py_id &lt;= len(self.decoded_objects):\n                obj = self.decoded_objects[py_id - 1]\n                if isinstance(obj, int):\n                    return obj\n\n            # If not found, check if this is a separate edge type ID space\n            # (standalone skeleton format)\n            for edge_val, edge_id in self._edge_type_ids.items():\n                if edge_id == py_id:\n                    return edge_val\n\n            raise ValueError(f\"py/id {py_id} not found as edge type\")\n        else:\n            # Default to regular edge\n            return 1\n\n    def _decode_node(self, data: Dict) -&gt; Node:\n        \"\"\"Decode a node from jsonpickle format.\n\n        Args:\n            data: Dictionary containing node data.\n\n        Returns:\n            A Node object.\n        \"\"\"\n        if \"py/state\" in data:\n            state = data[\"py/state\"]\n            # Handle both tuple and dict formats\n            if \"py/tuple\" in state:\n                # Tuple format: [name, weight]\n                name = state[\"py/tuple\"][0]\n                # Note: weight is stored but not used in sleap-io Node objects\n            else:\n                # Dict format\n                name = state.get(\"name\", \"\")\n        else:\n            # Direct format\n            name = data.get(\"name\", \"\")\n\n        return Node(name=name)\n</code></pre>"},{"location":"reference/sleap_io/io/skeleton/#sleap_io.io.skeleton.SkeletonDecoder.__init__","title":"<code>__init__()</code>","text":"<p>Initialize the decoder.</p> Source code in <code>sleap_io/io/skeleton.py</code> <pre><code>def __init__(self):\n    \"\"\"Initialize the decoder.\"\"\"\n    self.decoded_objects: List[\n        Any\n    ] = []  # List of decoded objects indexed by py/id - 1\n</code></pre>"},{"location":"reference/sleap_io/io/skeleton/#sleap_io.io.skeleton.SkeletonDecoder.decode","title":"<code>decode(data)</code>","text":"<p>Decode skeleton(s) from JSON data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Union[str, Dict]</code> <p>JSON string or pre-parsed dictionary containing skeleton data.</p> required <p>Returns:</p> Type Description <code>Union[Skeleton, List[Skeleton]]</code> <p>A single Skeleton or list of Skeletons depending on input format.</p> Source code in <code>sleap_io/io/skeleton.py</code> <pre><code>def decode(self, data: Union[str, Dict]) -&gt; Union[Skeleton, List[Skeleton]]:\n    \"\"\"Decode skeleton(s) from JSON data.\n\n    Args:\n        data: JSON string or pre-parsed dictionary containing skeleton data.\n\n    Returns:\n        A single Skeleton or list of Skeletons depending on input format.\n    \"\"\"\n    if isinstance(data, str):\n        data = json.loads(data)\n\n    # Reset decoded objects list for each decode operation\n    self.decoded_objects = []\n\n    # Check if this is a list of skeletons or a single skeleton\n    if isinstance(data, list):\n        return [self._decode_skeleton(skel_data) for skel_data in data]\n    else:\n        return self._decode_skeleton(data)\n</code></pre>"},{"location":"reference/sleap_io/io/skeleton/#sleap_io.io.skeleton.SkeletonEncoder","title":"<code>SkeletonEncoder</code>","text":"<p>Encode skeleton data to jsonpickle format.</p> <p>This encoder produces the jsonpickle format used by SLEAP for standalone skeleton JSON files, ensuring backward compatibility with existing files.</p> <p>Methods:</p> Name Description <code>__init__</code> <p>Initialize the encoder.</p> <code>encode</code> <p>Encode skeleton(s) to JSON string.</p> Source code in <code>sleap_io/io/skeleton.py</code> <pre><code>class SkeletonEncoder:\n    \"\"\"Encode skeleton data to jsonpickle format.\n\n    This encoder produces the jsonpickle format used by SLEAP for standalone\n    skeleton JSON files, ensuring backward compatibility with existing files.\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"Initialize the encoder.\"\"\"\n        self._object_to_id: Dict[int, int] = {}  # id(object) -&gt; py/id\n        self._next_id = 1\n\n    def encode(self, skeletons: Union[Skeleton, List[Skeleton]]) -&gt; str:\n        \"\"\"Encode skeleton(s) to JSON string.\n\n        Args:\n            skeletons: A single Skeleton or list of Skeletons to encode.\n\n        Returns:\n            JSON string in jsonpickle format.\n        \"\"\"\n        # Reset state for each encode operation\n        self._object_to_id = {}\n        self._next_id = 1\n\n        # Handle single skeleton or list\n        if isinstance(skeletons, Skeleton):\n            data = self._encode_skeleton(skeletons)\n        else:\n            data = [self._encode_skeleton(skel) for skel in skeletons]\n\n        # Sort dictionaries recursively for consistency\n        data = self._recursively_sort_dict(data)\n\n        return json.dumps(data, separators=(\", \", \": \"))\n\n    def _encode_skeleton(self, skeleton: Skeleton) -&gt; Dict:\n        \"\"\"Encode a single skeleton to dictionary format.\n\n        Args:\n            skeleton: Skeleton object to encode.\n\n        Returns:\n            Dictionary in jsonpickle format.\n        \"\"\"\n        # Track nodes and their py/ids\n        node_to_py_id = {}\n\n        # Encode links (edges and symmetries)\n        links = []\n\n        # First, process edges to establish node references\n        for i, edge in enumerate(skeleton.edges):\n            # Encode edge\n            edge_dict = self._encode_edge(edge, i, edge_type=1)\n            links.append(edge_dict)\n\n            # Track node py/ids\n            if edge.source not in node_to_py_id:\n                node_to_py_id[edge.source] = self._get_or_create_py_id(edge.source)\n            if edge.destination not in node_to_py_id:\n                node_to_py_id[edge.destination] = self._get_or_create_py_id(\n                    edge.destination\n                )\n\n        # Then process symmetries\n        for i, symmetry in enumerate(skeleton.symmetries):\n            # Encode symmetry\n            sym_dict = self._encode_symmetry(symmetry, edge_type=2)\n            links.append(sym_dict)\n\n            # Track node py/ids\n            for node in symmetry.nodes:\n                if node not in node_to_py_id:\n                    node_to_py_id[node] = self._get_or_create_py_id(node)\n\n        # Ensure all skeleton nodes have py/ids\n        for node in skeleton.nodes:\n            if node not in node_to_py_id:\n                node_to_py_id[node] = self._get_or_create_py_id(node)\n\n        # Create nodes section with py/id references\n        nodes = []\n        for node in skeleton.nodes:\n            nodes.append({\"id\": {\"py/id\": node_to_py_id[node]}})\n\n        # Build final skeleton dict\n        return {\n            \"directed\": True,\n            \"graph\": {\"name\": skeleton.name, \"num_edges_inserted\": len(skeleton.edges)},\n            \"links\": links,\n            \"multigraph\": True,\n            \"nodes\": nodes,\n        }\n\n    def _encode_edge(self, edge: Edge, edge_idx: int, edge_type: int) -&gt; Dict:\n        \"\"\"Encode an edge to jsonpickle format.\n\n        Args:\n            edge: Edge object to encode.\n            edge_idx: Index of this edge.\n            edge_type: Type of edge (1 for regular, 2 for symmetry).\n\n        Returns:\n            Dictionary representing the edge.\n        \"\"\"\n        # Encode edge type - first occurrence uses py/reduce, subsequent use py/id\n        # For backward compatibility, always use type 1 for regular edges\n        if edge_type == 1:\n            if not hasattr(self, \"_edge_type_1_encoded\"):\n                type_dict = {\n                    \"py/reduce\": [\n                        {\"py/type\": \"sleap.skeleton.EdgeType\"},\n                        {\"py/tuple\": [1]},\n                    ]\n                }\n                self._edge_type_1_encoded = True\n            else:\n                type_dict = {\"py/id\": 1}\n        else:\n            if not hasattr(self, \"_edge_type_2_encoded\"):\n                type_dict = {\n                    \"py/reduce\": [\n                        {\"py/type\": \"sleap.skeleton.EdgeType\"},\n                        {\"py/tuple\": [2]},\n                    ]\n                }\n                self._edge_type_2_encoded = True\n            else:\n                type_dict = {\"py/id\": 2}\n\n        return {\n            \"edge_insert_idx\": edge_idx,\n            \"key\": 0,\n            \"source\": self._encode_node(edge.source),\n            \"target\": self._encode_node(edge.destination),\n            \"type\": type_dict,\n        }\n\n    def _encode_symmetry(self, symmetry: Symmetry, edge_type: int) -&gt; Dict:\n        \"\"\"Encode a symmetry to jsonpickle format.\n\n        Args:\n            symmetry: Symmetry object to encode.\n            edge_type: Type of edge (should be 2 for symmetry).\n\n        Returns:\n            Dictionary representing the symmetry.\n        \"\"\"\n        # Get source and target nodes (convert set to list for ordering)\n        nodes_list = list(symmetry.nodes)\n        source, target = nodes_list[0], nodes_list[1]\n\n        # Encode edge type\n        if not hasattr(self, \"_edge_type_2_encoded\"):\n            type_dict = {\n                \"py/reduce\": [{\"py/type\": \"sleap.skeleton.EdgeType\"}, {\"py/tuple\": [2]}]\n            }\n            self._edge_type_2_encoded = True\n        else:\n            type_dict = {\"py/id\": 2}\n\n        return {\n            \"key\": 0,\n            \"source\": self._encode_node(source),\n            \"target\": self._encode_node(target),\n            \"type\": type_dict,\n        }\n\n    def _encode_node(self, node: Node) -&gt; Dict:\n        \"\"\"Encode a node to jsonpickle format.\n\n        Args:\n            node: Node object to encode.\n\n        Returns:\n            Dictionary with py/object and py/state.\n        \"\"\"\n        return {\n            \"py/object\": \"sleap.skeleton.Node\",\n            \"py/state\": {\"py/tuple\": [node.name, 1.0]},  # name, weight (always 1.0)\n        }\n\n    def _get_or_create_py_id(self, obj: Any) -&gt; int:\n        \"\"\"Get or create a py/id for an object.\n\n        Args:\n            obj: Object to get/create ID for.\n\n        Returns:\n            The py/id integer.\n        \"\"\"\n        obj_id = id(obj)\n        if obj_id not in self._object_to_id:\n            self._object_to_id[obj_id] = self._next_id\n            self._next_id += 1\n        return self._object_to_id[obj_id]\n\n    def _recursively_sort_dict(self, obj: Any) -&gt; Any:\n        \"\"\"Recursively sort dictionary keys for consistent output.\n\n        Args:\n            obj: Object to sort (dict, list, or other).\n\n        Returns:\n            Sorted version of the object.\n        \"\"\"\n        if isinstance(obj, dict):\n            # Sort keys and recursively sort values\n            return {k: self._recursively_sort_dict(v) for k, v in sorted(obj.items())}\n        elif isinstance(obj, list):\n            # Recursively sort list elements\n            return [self._recursively_sort_dict(item) for item in obj]\n        else:\n            # Return as-is for non-dict/list types\n            return obj\n</code></pre>"},{"location":"reference/sleap_io/io/skeleton/#sleap_io.io.skeleton.SkeletonEncoder.__init__","title":"<code>__init__()</code>","text":"<p>Initialize the encoder.</p> Source code in <code>sleap_io/io/skeleton.py</code> <pre><code>def __init__(self):\n    \"\"\"Initialize the encoder.\"\"\"\n    self._object_to_id: Dict[int, int] = {}  # id(object) -&gt; py/id\n    self._next_id = 1\n</code></pre>"},{"location":"reference/sleap_io/io/skeleton/#sleap_io.io.skeleton.SkeletonEncoder.encode","title":"<code>encode(skeletons)</code>","text":"<p>Encode skeleton(s) to JSON string.</p> <p>Parameters:</p> Name Type Description Default <code>skeletons</code> <code>Union[Skeleton, List[Skeleton]]</code> <p>A single Skeleton or list of Skeletons to encode.</p> required <p>Returns:</p> Type Description <code>str</code> <p>JSON string in jsonpickle format.</p> Source code in <code>sleap_io/io/skeleton.py</code> <pre><code>def encode(self, skeletons: Union[Skeleton, List[Skeleton]]) -&gt; str:\n    \"\"\"Encode skeleton(s) to JSON string.\n\n    Args:\n        skeletons: A single Skeleton or list of Skeletons to encode.\n\n    Returns:\n        JSON string in jsonpickle format.\n    \"\"\"\n    # Reset state for each encode operation\n    self._object_to_id = {}\n    self._next_id = 1\n\n    # Handle single skeleton or list\n    if isinstance(skeletons, Skeleton):\n        data = self._encode_skeleton(skeletons)\n    else:\n        data = [self._encode_skeleton(skel) for skel in skeletons]\n\n    # Sort dictionaries recursively for consistency\n    data = self._recursively_sort_dict(data)\n\n    return json.dumps(data, separators=(\", \", \": \"))\n</code></pre>"},{"location":"reference/sleap_io/io/skeleton/#sleap_io.io.skeleton.SkeletonSLPDecoder","title":"<code>SkeletonSLPDecoder</code>","text":"<p>Decode skeleton data from SLP format.</p> <p>This decoder handles the SLP format used within .slp files, which uses integer indices for node references instead of embedded node objects.</p> <p>Methods:</p> Name Description <code>decode</code> <p>Decode skeletons from SLP metadata format.</p> Source code in <code>sleap_io/io/skeleton.py</code> <pre><code>class SkeletonSLPDecoder:\n    \"\"\"Decode skeleton data from SLP format.\n\n    This decoder handles the SLP format used within .slp files, which uses\n    integer indices for node references instead of embedded node objects.\n    \"\"\"\n\n    def decode(self, metadata: dict, node_names: list[str]) -&gt; list[Skeleton]:\n        \"\"\"Decode skeletons from SLP metadata format.\n\n        Args:\n            metadata: The metadata dict from an SLP file containing skeletons.\n            node_names: Global list of node names from the SLP file.\n\n        Returns:\n            List of Skeleton objects.\n        \"\"\"\n        skeleton_objects = []\n\n        for skel in metadata[\"skeletons\"]:\n            # Parse out the cattr-based serialization stuff from the skeleton links.\n            if \"nx_graph\" in skel:\n                # New format introduced in SLEAP v1.3.2\n                # TODO: Do something with the \"description\" and \"preview_image\" keys?\n                skel = skel[\"nx_graph\"]\n            edge_inds, symmetry_inds = [], []\n            for link in skel[\"links\"]:\n                if \"py/reduce\" in link[\"type\"]:\n                    edge_type = link[\"type\"][\"py/reduce\"][1][\"py/tuple\"][0]\n                else:\n                    edge_type = link[\"type\"][\"py/id\"]\n\n                if edge_type == 1:  # 1 -&gt; real edge, 2 -&gt; symmetry edge\n                    edge_inds.append((link[\"source\"], link[\"target\"]))\n                elif edge_type == 2:\n                    symmetry_inds.append((link[\"source\"], link[\"target\"]))\n\n            # Re-index correctly.\n            skeleton_node_inds = [node[\"id\"] for node in skel[\"nodes\"]]\n            sorted_node_names = [node_names[i] for i in skeleton_node_inds]\n\n            # Create nodes.\n            nodes = []\n            for name in sorted_node_names:\n                nodes.append(Node(name=name))\n\n            # Create edges.\n            edge_inds = [\n                (skeleton_node_inds.index(s), skeleton_node_inds.index(d))\n                for s, d in edge_inds\n            ]\n            edges = []\n            for edge in edge_inds:\n                edges.append(Edge(source=nodes[edge[0]], destination=nodes[edge[1]]))\n\n            # Create symmetries.\n            symmetry_inds = [\n                (skeleton_node_inds.index(s), skeleton_node_inds.index(d))\n                for s, d in symmetry_inds\n            ]\n\n            # Deduplicate symmetries - legacy files may have duplicates\n            # (one for each direction)\n            seen_symmetries = set()\n            symmetries = []\n            for symmetry in symmetry_inds:\n                # Create a unique key for this symmetry pair (order-independent)\n                sym_key = tuple(sorted([symmetry[0], symmetry[1]]))\n                if sym_key not in seen_symmetries:\n                    symmetries.append(\n                        Symmetry([nodes[symmetry[0]], nodes[symmetry[1]]])\n                    )\n                    seen_symmetries.add(sym_key)\n\n            # Create the full skeleton.\n            skel = Skeleton(\n                nodes=nodes,\n                edges=edges,\n                symmetries=symmetries,\n                name=skel[\"graph\"][\"name\"],\n            )\n            skeleton_objects.append(skel)\n\n        return skeleton_objects\n</code></pre>"},{"location":"reference/sleap_io/io/skeleton/#sleap_io.io.skeleton.SkeletonSLPDecoder.decode","title":"<code>decode(metadata, node_names)</code>","text":"<p>Decode skeletons from SLP metadata format.</p> <p>Parameters:</p> Name Type Description Default <code>metadata</code> <code>dict</code> <p>The metadata dict from an SLP file containing skeletons.</p> required <code>node_names</code> <code>list[str]</code> <p>Global list of node names from the SLP file.</p> required <p>Returns:</p> Type Description <code>list[Skeleton]</code> <p>List of Skeleton objects.</p> Source code in <code>sleap_io/io/skeleton.py</code> <pre><code>def decode(self, metadata: dict, node_names: list[str]) -&gt; list[Skeleton]:\n    \"\"\"Decode skeletons from SLP metadata format.\n\n    Args:\n        metadata: The metadata dict from an SLP file containing skeletons.\n        node_names: Global list of node names from the SLP file.\n\n    Returns:\n        List of Skeleton objects.\n    \"\"\"\n    skeleton_objects = []\n\n    for skel in metadata[\"skeletons\"]:\n        # Parse out the cattr-based serialization stuff from the skeleton links.\n        if \"nx_graph\" in skel:\n            # New format introduced in SLEAP v1.3.2\n            # TODO: Do something with the \"description\" and \"preview_image\" keys?\n            skel = skel[\"nx_graph\"]\n        edge_inds, symmetry_inds = [], []\n        for link in skel[\"links\"]:\n            if \"py/reduce\" in link[\"type\"]:\n                edge_type = link[\"type\"][\"py/reduce\"][1][\"py/tuple\"][0]\n            else:\n                edge_type = link[\"type\"][\"py/id\"]\n\n            if edge_type == 1:  # 1 -&gt; real edge, 2 -&gt; symmetry edge\n                edge_inds.append((link[\"source\"], link[\"target\"]))\n            elif edge_type == 2:\n                symmetry_inds.append((link[\"source\"], link[\"target\"]))\n\n        # Re-index correctly.\n        skeleton_node_inds = [node[\"id\"] for node in skel[\"nodes\"]]\n        sorted_node_names = [node_names[i] for i in skeleton_node_inds]\n\n        # Create nodes.\n        nodes = []\n        for name in sorted_node_names:\n            nodes.append(Node(name=name))\n\n        # Create edges.\n        edge_inds = [\n            (skeleton_node_inds.index(s), skeleton_node_inds.index(d))\n            for s, d in edge_inds\n        ]\n        edges = []\n        for edge in edge_inds:\n            edges.append(Edge(source=nodes[edge[0]], destination=nodes[edge[1]]))\n\n        # Create symmetries.\n        symmetry_inds = [\n            (skeleton_node_inds.index(s), skeleton_node_inds.index(d))\n            for s, d in symmetry_inds\n        ]\n\n        # Deduplicate symmetries - legacy files may have duplicates\n        # (one for each direction)\n        seen_symmetries = set()\n        symmetries = []\n        for symmetry in symmetry_inds:\n            # Create a unique key for this symmetry pair (order-independent)\n            sym_key = tuple(sorted([symmetry[0], symmetry[1]]))\n            if sym_key not in seen_symmetries:\n                symmetries.append(\n                    Symmetry([nodes[symmetry[0]], nodes[symmetry[1]]])\n                )\n                seen_symmetries.add(sym_key)\n\n        # Create the full skeleton.\n        skel = Skeleton(\n            nodes=nodes,\n            edges=edges,\n            symmetries=symmetries,\n            name=skel[\"graph\"][\"name\"],\n        )\n        skeleton_objects.append(skel)\n\n    return skeleton_objects\n</code></pre>"},{"location":"reference/sleap_io/io/skeleton/#sleap_io.io.skeleton.SkeletonSLPEncoder","title":"<code>SkeletonSLPEncoder</code>","text":"<p>Encode skeleton data to SLP format.</p> <p>This encoder produces the SLP format used within .slp files, which uses integer indices for node references instead of embedded node objects.</p> <p>Methods:</p> Name Description <code>encode_skeletons</code> <p>Serialize a list of Skeleton objects to SLP format.</p> Source code in <code>sleap_io/io/skeleton.py</code> <pre><code>class SkeletonSLPEncoder:\n    \"\"\"Encode skeleton data to SLP format.\n\n    This encoder produces the SLP format used within .slp files, which uses\n    integer indices for node references instead of embedded node objects.\n    \"\"\"\n\n    def encode_skeletons(\n        self, skeletons: list[Skeleton]\n    ) -&gt; tuple[list[dict], list[dict]]:\n        \"\"\"Serialize a list of Skeleton objects to SLP format.\n\n        Args:\n            skeletons: A list of Skeleton objects.\n\n        Returns:\n            A tuple of (skeletons_dicts, nodes_dicts).\n\n            nodes_dicts is a list of dicts containing the nodes in all the skeletons.\n            skeletons_dicts is a list of dicts containing the skeletons.\n        \"\"\"\n        # Create global list of nodes with all nodes from all skeletons.\n        nodes_dicts = []\n        node_to_id = {}\n        for skeleton in skeletons:\n            for node in skeleton.nodes:\n                if node not in node_to_id:\n                    node_to_id[node] = len(node_to_id)\n                    nodes_dicts.append({\"name\": node.name, \"weight\": 1.0})\n\n        skeletons_dicts = []\n        for skeleton in skeletons:\n            # Build links dicts for normal edges.\n            edges_dicts = []\n            for edge_ind, edge in enumerate(skeleton.edges):\n                if edge_ind == 0:\n                    edge_type = {\n                        \"py/reduce\": [\n                            {\"py/type\": \"sleap.skeleton.EdgeType\"},\n                            {\"py/tuple\": [1]},  # 1 = real edge, 2 = symmetry edge\n                        ]\n                    }\n                else:\n                    edge_type = {\"py/id\": 1}\n\n                edges_dicts.append(\n                    {\n                        \"edge_insert_idx\": edge_ind,\n                        \"key\": 0,  # Always 0.\n                        \"source\": node_to_id[edge.source],\n                        \"target\": node_to_id[edge.destination],\n                        \"type\": edge_type,\n                    }\n                )\n\n            # Build links dicts for symmetry edges.\n            for symmetry_ind, symmetry in enumerate(skeleton.symmetries):\n                if symmetry_ind == 0:\n                    edge_type = {\n                        \"py/reduce\": [\n                            {\"py/type\": \"sleap.skeleton.EdgeType\"},\n                            {\"py/tuple\": [2]},  # 1 = real edge, 2 = symmetry edge\n                        ]\n                    }\n                else:\n                    edge_type = {\"py/id\": 2}\n\n                src, dst = tuple(symmetry.nodes)\n                edges_dicts.append(\n                    {\n                        \"key\": 0,\n                        \"source\": node_to_id[src],\n                        \"target\": node_to_id[dst],\n                        \"type\": edge_type,\n                    }\n                )\n\n            # Create skeleton dict.\n            skeletons_dicts.append(\n                {\n                    \"directed\": True,\n                    \"graph\": {\n                        \"name\": skeleton.name,\n                        \"num_edges_inserted\": len(skeleton.edges),\n                    },\n                    \"links\": edges_dicts,\n                    \"multigraph\": True,\n                    \"nodes\": [{\"id\": node_to_id[node]} for node in skeleton.nodes],\n                }\n            )\n\n        return skeletons_dicts, nodes_dicts\n</code></pre>"},{"location":"reference/sleap_io/io/skeleton/#sleap_io.io.skeleton.SkeletonSLPEncoder.encode_skeletons","title":"<code>encode_skeletons(skeletons)</code>","text":"<p>Serialize a list of Skeleton objects to SLP format.</p> <p>Parameters:</p> Name Type Description Default <code>skeletons</code> <code>list[Skeleton]</code> <p>A list of Skeleton objects.</p> required <p>Returns:</p> Type Description <code>tuple[list[dict], list[dict]]</code> <p>A tuple of (skeletons_dicts, nodes_dicts).</p> <p>nodes_dicts is a list of dicts containing the nodes in all the skeletons. skeletons_dicts is a list of dicts containing the skeletons.</p> Source code in <code>sleap_io/io/skeleton.py</code> <pre><code>def encode_skeletons(\n    self, skeletons: list[Skeleton]\n) -&gt; tuple[list[dict], list[dict]]:\n    \"\"\"Serialize a list of Skeleton objects to SLP format.\n\n    Args:\n        skeletons: A list of Skeleton objects.\n\n    Returns:\n        A tuple of (skeletons_dicts, nodes_dicts).\n\n        nodes_dicts is a list of dicts containing the nodes in all the skeletons.\n        skeletons_dicts is a list of dicts containing the skeletons.\n    \"\"\"\n    # Create global list of nodes with all nodes from all skeletons.\n    nodes_dicts = []\n    node_to_id = {}\n    for skeleton in skeletons:\n        for node in skeleton.nodes:\n            if node not in node_to_id:\n                node_to_id[node] = len(node_to_id)\n                nodes_dicts.append({\"name\": node.name, \"weight\": 1.0})\n\n    skeletons_dicts = []\n    for skeleton in skeletons:\n        # Build links dicts for normal edges.\n        edges_dicts = []\n        for edge_ind, edge in enumerate(skeleton.edges):\n            if edge_ind == 0:\n                edge_type = {\n                    \"py/reduce\": [\n                        {\"py/type\": \"sleap.skeleton.EdgeType\"},\n                        {\"py/tuple\": [1]},  # 1 = real edge, 2 = symmetry edge\n                    ]\n                }\n            else:\n                edge_type = {\"py/id\": 1}\n\n            edges_dicts.append(\n                {\n                    \"edge_insert_idx\": edge_ind,\n                    \"key\": 0,  # Always 0.\n                    \"source\": node_to_id[edge.source],\n                    \"target\": node_to_id[edge.destination],\n                    \"type\": edge_type,\n                }\n            )\n\n        # Build links dicts for symmetry edges.\n        for symmetry_ind, symmetry in enumerate(skeleton.symmetries):\n            if symmetry_ind == 0:\n                edge_type = {\n                    \"py/reduce\": [\n                        {\"py/type\": \"sleap.skeleton.EdgeType\"},\n                        {\"py/tuple\": [2]},  # 1 = real edge, 2 = symmetry edge\n                    ]\n                }\n            else:\n                edge_type = {\"py/id\": 2}\n\n            src, dst = tuple(symmetry.nodes)\n            edges_dicts.append(\n                {\n                    \"key\": 0,\n                    \"source\": node_to_id[src],\n                    \"target\": node_to_id[dst],\n                    \"type\": edge_type,\n                }\n            )\n\n        # Create skeleton dict.\n        skeletons_dicts.append(\n            {\n                \"directed\": True,\n                \"graph\": {\n                    \"name\": skeleton.name,\n                    \"num_edges_inserted\": len(skeleton.edges),\n                },\n                \"links\": edges_dicts,\n                \"multigraph\": True,\n                \"nodes\": [{\"id\": node_to_id[node]} for node in skeleton.nodes],\n            }\n        )\n\n    return skeletons_dicts, nodes_dicts\n</code></pre>"},{"location":"reference/sleap_io/io/skeleton/#sleap_io.io.skeleton.SkeletonYAMLDecoder","title":"<code>SkeletonYAMLDecoder</code>","text":"<p>Decode skeleton data from simplified YAML format.</p> <p>This decoder handles a simplified YAML format that is more human-readable than the jsonpickle format.</p> <p>Methods:</p> Name Description <code>decode</code> <p>Decode skeleton(s) from YAML data.</p> <code>decode_dict</code> <p>Decode a single skeleton from a dictionary.</p> Source code in <code>sleap_io/io/skeleton.py</code> <pre><code>class SkeletonYAMLDecoder:\n    \"\"\"Decode skeleton data from simplified YAML format.\n\n    This decoder handles a simplified YAML format that is more human-readable\n    than the jsonpickle format.\n    \"\"\"\n\n    def decode(self, data: Union[str, Dict]) -&gt; Union[Skeleton, List[Skeleton]]:\n        \"\"\"Decode skeleton(s) from YAML data.\n\n        Args:\n            data: YAML string or pre-parsed dictionary containing skeleton data.\n                  If a dict is provided with skeleton names as keys, returns list.\n                  If a dict is provided with nodes/edges/symmetries, returns single\n                  skeleton.\n\n        Returns:\n            A single Skeleton or list of Skeletons depending on input format.\n        \"\"\"\n        if isinstance(data, str):\n            import yaml\n\n            data = yaml.safe_load(data)\n\n        # Check if this is a single skeleton dict or multiple skeletons\n        if isinstance(data, dict):\n            # If it has nodes/edges keys, it's a single skeleton\n            if \"nodes\" in data:\n                return self._decode_skeleton(data)\n            else:\n                # Multiple skeletons with names as keys\n                skeletons = []\n                for name, skeleton_data in data.items():\n                    skeleton = self._decode_skeleton(skeleton_data, name)\n                    skeletons.append(skeleton)\n                return skeletons\n\n        raise ValueError(f\"Unexpected data format: {type(data)}\")\n\n    def decode_dict(self, skeleton_data: Dict, name: str = \"Skeleton\") -&gt; Skeleton:\n        \"\"\"Decode a single skeleton from a dictionary.\n\n        This is useful when the skeleton data is embedded in a larger YAML structure.\n\n        Args:\n            skeleton_data: Dictionary containing nodes, edges, and symmetries.\n            name: Name for the skeleton (default: \"Skeleton\").\n\n        Returns:\n            A Skeleton object.\n        \"\"\"\n        return self._decode_skeleton(skeleton_data, name)\n\n    def _decode_skeleton(self, data: Dict, name: Optional[str] = None) -&gt; Skeleton:\n        \"\"\"Decode a single skeleton from dictionary data.\n\n        Args:\n            data: Dictionary containing skeleton data in simplified format.\n            name: Optional name override for the skeleton.\n\n        Returns:\n            A Skeleton object.\n        \"\"\"\n        # Create nodes\n        nodes = []\n        node_map = {}\n        for node_data in data.get(\"nodes\", []):\n            node = Node(name=node_data[\"name\"])\n            nodes.append(node)\n            node_map[node.name] = node\n\n        # Create edges\n        edges = []\n        for edge_data in data.get(\"edges\", []):\n            source_name = edge_data[\"source\"][\"name\"]\n            dest_name = edge_data[\"destination\"][\"name\"]\n            edge = Edge(source=node_map[source_name], destination=node_map[dest_name])\n            edges.append(edge)\n\n        # Create symmetries\n        symmetries = []\n        for sym_data in data.get(\"symmetries\", []):\n            # Each symmetry is a list of 2 node specifications\n            node1_name = sym_data[0][\"name\"]\n            node2_name = sym_data[1][\"name\"]\n            symmetry = Symmetry([node_map[node1_name], node_map[node2_name]])\n            symmetries.append(symmetry)\n\n        # Use provided name or get from data\n        if name is None:\n            name = data.get(\"name\", \"Skeleton\")\n\n        return Skeleton(nodes=nodes, edges=edges, symmetries=symmetries, name=name)\n</code></pre>"},{"location":"reference/sleap_io/io/skeleton/#sleap_io.io.skeleton.SkeletonYAMLDecoder.decode","title":"<code>decode(data)</code>","text":"<p>Decode skeleton(s) from YAML data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Union[str, Dict]</code> <p>YAML string or pre-parsed dictionary containing skeleton data.   If a dict is provided with skeleton names as keys, returns list.   If a dict is provided with nodes/edges/symmetries, returns single   skeleton.</p> required <p>Returns:</p> Type Description <code>Union[Skeleton, List[Skeleton]]</code> <p>A single Skeleton or list of Skeletons depending on input format.</p> Source code in <code>sleap_io/io/skeleton.py</code> <pre><code>def decode(self, data: Union[str, Dict]) -&gt; Union[Skeleton, List[Skeleton]]:\n    \"\"\"Decode skeleton(s) from YAML data.\n\n    Args:\n        data: YAML string or pre-parsed dictionary containing skeleton data.\n              If a dict is provided with skeleton names as keys, returns list.\n              If a dict is provided with nodes/edges/symmetries, returns single\n              skeleton.\n\n    Returns:\n        A single Skeleton or list of Skeletons depending on input format.\n    \"\"\"\n    if isinstance(data, str):\n        import yaml\n\n        data = yaml.safe_load(data)\n\n    # Check if this is a single skeleton dict or multiple skeletons\n    if isinstance(data, dict):\n        # If it has nodes/edges keys, it's a single skeleton\n        if \"nodes\" in data:\n            return self._decode_skeleton(data)\n        else:\n            # Multiple skeletons with names as keys\n            skeletons = []\n            for name, skeleton_data in data.items():\n                skeleton = self._decode_skeleton(skeleton_data, name)\n                skeletons.append(skeleton)\n            return skeletons\n\n    raise ValueError(f\"Unexpected data format: {type(data)}\")\n</code></pre>"},{"location":"reference/sleap_io/io/skeleton/#sleap_io.io.skeleton.SkeletonYAMLDecoder.decode_dict","title":"<code>decode_dict(skeleton_data, name='Skeleton')</code>","text":"<p>Decode a single skeleton from a dictionary.</p> <p>This is useful when the skeleton data is embedded in a larger YAML structure.</p> <p>Parameters:</p> Name Type Description Default <code>skeleton_data</code> <code>Dict</code> <p>Dictionary containing nodes, edges, and symmetries.</p> required <code>name</code> <code>str</code> <p>Name for the skeleton (default: \"Skeleton\").</p> <code>'Skeleton'</code> <p>Returns:</p> Type Description <code>Skeleton</code> <p>A Skeleton object.</p> Source code in <code>sleap_io/io/skeleton.py</code> <pre><code>def decode_dict(self, skeleton_data: Dict, name: str = \"Skeleton\") -&gt; Skeleton:\n    \"\"\"Decode a single skeleton from a dictionary.\n\n    This is useful when the skeleton data is embedded in a larger YAML structure.\n\n    Args:\n        skeleton_data: Dictionary containing nodes, edges, and symmetries.\n        name: Name for the skeleton (default: \"Skeleton\").\n\n    Returns:\n        A Skeleton object.\n    \"\"\"\n    return self._decode_skeleton(skeleton_data, name)\n</code></pre>"},{"location":"reference/sleap_io/io/skeleton/#sleap_io.io.skeleton.SkeletonYAMLEncoder","title":"<code>SkeletonYAMLEncoder</code>","text":"<p>Encode skeleton data to simplified YAML format.</p> <p>This encoder produces a human-readable YAML format that is easier to edit manually than the jsonpickle format.</p> <p>Methods:</p> Name Description <code>encode</code> <p>Encode skeleton(s) to YAML string.</p> <code>encode_dict</code> <p>Encode a single skeleton to a dictionary.</p> Source code in <code>sleap_io/io/skeleton.py</code> <pre><code>class SkeletonYAMLEncoder:\n    \"\"\"Encode skeleton data to simplified YAML format.\n\n    This encoder produces a human-readable YAML format that is easier to\n    edit manually than the jsonpickle format.\n    \"\"\"\n\n    def encode(self, skeletons: Union[Skeleton, List[Skeleton]]) -&gt; str:\n        \"\"\"Encode skeleton(s) to YAML string.\n\n        Args:\n            skeletons: A single Skeleton or list of Skeletons to encode.\n\n        Returns:\n            YAML string with skeleton names as top-level keys.\n        \"\"\"\n        import yaml\n\n        if isinstance(skeletons, Skeleton):\n            skeletons = [skeletons]\n\n        data = {}\n        for skeleton in skeletons:\n            skeleton_data = self.encode_dict(skeleton)\n            data[skeleton.name] = skeleton_data\n\n        return yaml.dump(data, default_flow_style=False, sort_keys=False)\n\n    def encode_dict(self, skeleton: Skeleton) -&gt; Dict:\n        \"\"\"Encode a single skeleton to a dictionary.\n\n        This is useful when embedding skeleton data in a larger YAML structure.\n\n        Args:\n            skeleton: Skeleton object to encode.\n\n        Returns:\n            Dictionary with nodes, edges, and symmetries.\n        \"\"\"\n        # Encode nodes\n        nodes = []\n        for node in skeleton.nodes:\n            nodes.append({\"name\": node.name})\n\n        # Encode edges\n        edges = []\n        for edge in skeleton.edges:\n            edges.append(\n                {\n                    \"source\": {\"name\": edge.source.name},\n                    \"destination\": {\"name\": edge.destination.name},\n                }\n            )\n\n        # Encode symmetries\n        symmetries = []\n        for symmetry in skeleton.symmetries:\n            # Convert set to list and encode as pairs\n            node_list = list(symmetry.nodes)\n            symmetries.append(\n                [{\"name\": node_list[0].name}, {\"name\": node_list[1].name}]\n            )\n\n        return {\"nodes\": nodes, \"edges\": edges, \"symmetries\": symmetries}\n</code></pre>"},{"location":"reference/sleap_io/io/skeleton/#sleap_io.io.skeleton.SkeletonYAMLEncoder.encode","title":"<code>encode(skeletons)</code>","text":"<p>Encode skeleton(s) to YAML string.</p> <p>Parameters:</p> Name Type Description Default <code>skeletons</code> <code>Union[Skeleton, List[Skeleton]]</code> <p>A single Skeleton or list of Skeletons to encode.</p> required <p>Returns:</p> Type Description <code>str</code> <p>YAML string with skeleton names as top-level keys.</p> Source code in <code>sleap_io/io/skeleton.py</code> <pre><code>def encode(self, skeletons: Union[Skeleton, List[Skeleton]]) -&gt; str:\n    \"\"\"Encode skeleton(s) to YAML string.\n\n    Args:\n        skeletons: A single Skeleton or list of Skeletons to encode.\n\n    Returns:\n        YAML string with skeleton names as top-level keys.\n    \"\"\"\n    import yaml\n\n    if isinstance(skeletons, Skeleton):\n        skeletons = [skeletons]\n\n    data = {}\n    for skeleton in skeletons:\n        skeleton_data = self.encode_dict(skeleton)\n        data[skeleton.name] = skeleton_data\n\n    return yaml.dump(data, default_flow_style=False, sort_keys=False)\n</code></pre>"},{"location":"reference/sleap_io/io/skeleton/#sleap_io.io.skeleton.SkeletonYAMLEncoder.encode_dict","title":"<code>encode_dict(skeleton)</code>","text":"<p>Encode a single skeleton to a dictionary.</p> <p>This is useful when embedding skeleton data in a larger YAML structure.</p> <p>Parameters:</p> Name Type Description Default <code>skeleton</code> <code>Skeleton</code> <p>Skeleton object to encode.</p> required <p>Returns:</p> Type Description <code>Dict</code> <p>Dictionary with nodes, edges, and symmetries.</p> Source code in <code>sleap_io/io/skeleton.py</code> <pre><code>def encode_dict(self, skeleton: Skeleton) -&gt; Dict:\n    \"\"\"Encode a single skeleton to a dictionary.\n\n    This is useful when embedding skeleton data in a larger YAML structure.\n\n    Args:\n        skeleton: Skeleton object to encode.\n\n    Returns:\n        Dictionary with nodes, edges, and symmetries.\n    \"\"\"\n    # Encode nodes\n    nodes = []\n    for node in skeleton.nodes:\n        nodes.append({\"name\": node.name})\n\n    # Encode edges\n    edges = []\n    for edge in skeleton.edges:\n        edges.append(\n            {\n                \"source\": {\"name\": edge.source.name},\n                \"destination\": {\"name\": edge.destination.name},\n            }\n        )\n\n    # Encode symmetries\n    symmetries = []\n    for symmetry in skeleton.symmetries:\n        # Convert set to list and encode as pairs\n        node_list = list(symmetry.nodes)\n        symmetries.append(\n            [{\"name\": node_list[0].name}, {\"name\": node_list[1].name}]\n        )\n\n    return {\"nodes\": nodes, \"edges\": edges, \"symmetries\": symmetries}\n</code></pre>"},{"location":"reference/sleap_io/io/skeleton/#sleap_io.io.skeleton.decode_skeleton","title":"<code>decode_skeleton(data)</code>","text":"<p>Decode skeleton(s) from JSON data using the default decoder.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Union[str, Dict]</code> <p>JSON string or pre-parsed dictionary containing skeleton data.</p> required <p>Returns:</p> Type Description <code>Union[Skeleton, List[Skeleton]]</code> <p>A single Skeleton or list of Skeletons depending on input format.</p> Source code in <code>sleap_io/io/skeleton.py</code> <pre><code>def decode_skeleton(data: Union[str, Dict]) -&gt; Union[Skeleton, List[Skeleton]]:\n    \"\"\"Decode skeleton(s) from JSON data using the default decoder.\n\n    Args:\n        data: JSON string or pre-parsed dictionary containing skeleton data.\n\n    Returns:\n        A single Skeleton or list of Skeletons depending on input format.\n    \"\"\"\n    decoder = SkeletonDecoder()\n    return decoder.decode(data)\n</code></pre>"},{"location":"reference/sleap_io/io/skeleton/#sleap_io.io.skeleton.decode_training_config","title":"<code>decode_training_config(data)</code>","text":"<p>Decode skeleton(s) from training config data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>dict</code> <p>Dictionary containing training config with embedded skeletons.</p> required <p>Returns:</p> Type Description <code>Union[Skeleton, List[Skeleton]]</code> <p>A single Skeleton or list of Skeletons from the training config.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the data is not a valid training config format.</p> Source code in <code>sleap_io/io/skeleton.py</code> <pre><code>def decode_training_config(data: dict) -&gt; Union[Skeleton, List[Skeleton]]:\n    \"\"\"Decode skeleton(s) from training config data.\n\n    Args:\n        data: Dictionary containing training config with embedded skeletons.\n\n    Returns:\n        A single Skeleton or list of Skeletons from the training config.\n\n    Raises:\n        ValueError: If the data is not a valid training config format.\n    \"\"\"\n    if isinstance(data, dict) and \"data\" in data:\n        if \"labels\" in data[\"data\"] and \"skeletons\" in data[\"data\"][\"labels\"]:\n            # This is a training config file with embedded skeletons\n            decoder = SkeletonDecoder()\n            return decoder.decode(data[\"data\"][\"labels\"][\"skeletons\"])\n\n    # If not a valid training config, raise an exception\n    raise ValueError(\n        \"Invalid training config format. Expected dictionary with \"\n        \"'data.labels.skeletons' structure.\"\n    )\n</code></pre>"},{"location":"reference/sleap_io/io/skeleton/#sleap_io.io.skeleton.decode_yaml_skeleton","title":"<code>decode_yaml_skeleton(yaml_data)</code>","text":"<p>Decode skeleton(s) from YAML data.</p> <p>Parameters:</p> Name Type Description Default <code>yaml_data</code> <code>str</code> <p>YAML string containing skeleton data.</p> required <p>Returns:</p> Type Description <code>Union[Skeleton, List[Skeleton]]</code> <p>A single Skeleton or list of Skeletons depending on input format.</p> Source code in <code>sleap_io/io/skeleton.py</code> <pre><code>def decode_yaml_skeleton(yaml_data: str) -&gt; Union[Skeleton, List[Skeleton]]:\n    \"\"\"Decode skeleton(s) from YAML data.\n\n    Args:\n        yaml_data: YAML string containing skeleton data.\n\n    Returns:\n        A single Skeleton or list of Skeletons depending on input format.\n    \"\"\"\n    decoder = SkeletonYAMLDecoder()\n    return decoder.decode(yaml_data)\n</code></pre>"},{"location":"reference/sleap_io/io/skeleton/#sleap_io.io.skeleton.encode_skeleton","title":"<code>encode_skeleton(skeletons)</code>","text":"<p>Encode skeleton(s) to JSON string using the default encoder.</p> <p>Parameters:</p> Name Type Description Default <code>skeletons</code> <code>Union[Skeleton, List[Skeleton]]</code> <p>A single Skeleton or list of Skeletons to encode.</p> required <p>Returns:</p> Type Description <code>str</code> <p>JSON string in jsonpickle format.</p> Source code in <code>sleap_io/io/skeleton.py</code> <pre><code>def encode_skeleton(skeletons: Union[Skeleton, List[Skeleton]]) -&gt; str:\n    \"\"\"Encode skeleton(s) to JSON string using the default encoder.\n\n    Args:\n        skeletons: A single Skeleton or list of Skeletons to encode.\n\n    Returns:\n        JSON string in jsonpickle format.\n    \"\"\"\n    encoder = SkeletonEncoder()\n    return encoder.encode(skeletons)\n</code></pre>"},{"location":"reference/sleap_io/io/skeleton/#sleap_io.io.skeleton.encode_yaml_skeleton","title":"<code>encode_yaml_skeleton(skeletons)</code>","text":"<p>Encode skeleton(s) to YAML string.</p> <p>Parameters:</p> Name Type Description Default <code>skeletons</code> <code>Union[Skeleton, List[Skeleton]]</code> <p>A single Skeleton or list of Skeletons to encode.</p> required <p>Returns:</p> Type Description <code>str</code> <p>YAML string with skeleton names as top-level keys.</p> Source code in <code>sleap_io/io/skeleton.py</code> <pre><code>def encode_yaml_skeleton(skeletons: Union[Skeleton, List[Skeleton]]) -&gt; str:\n    \"\"\"Encode skeleton(s) to YAML string.\n\n    Args:\n        skeletons: A single Skeleton or list of Skeletons to encode.\n\n    Returns:\n        YAML string with skeleton names as top-level keys.\n    \"\"\"\n    encoder = SkeletonYAMLEncoder()\n    return encoder.encode(skeletons)\n</code></pre>"},{"location":"reference/sleap_io/io/skeleton/#sleap_io.io.skeleton.load_skeleton_from_json","title":"<code>load_skeleton_from_json(json_data)</code>","text":"<p>Load skeleton(s) from JSON data, with automatic training config detection.</p> <p>Parameters:</p> Name Type Description Default <code>json_data</code> <code>str</code> <p>JSON string that could be standalone skeleton or training config.</p> required <p>Returns:</p> Type Description <code>Union[Skeleton, List[Skeleton]]</code> <p>A single Skeleton or list of Skeletons.</p> Source code in <code>sleap_io/io/skeleton.py</code> <pre><code>def load_skeleton_from_json(json_data: str) -&gt; Union[Skeleton, List[Skeleton]]:\n    \"\"\"Load skeleton(s) from JSON data, with automatic training config detection.\n\n    Args:\n        json_data: JSON string that could be standalone skeleton or training config.\n\n    Returns:\n        A single Skeleton or list of Skeletons.\n    \"\"\"\n    # Try to detect if this is a training config file\n    try:\n        data = json.loads(json_data)\n        if isinstance(data, dict) and \"data\" in data:\n            if \"labels\" in data[\"data\"] and \"skeletons\" in data[\"data\"][\"labels\"]:\n                # This is a training config file with embedded skeletons\n                return decode_training_config(data)\n    except (json.JSONDecodeError, KeyError, TypeError):\n        # Not a training config or invalid JSON structure\n        pass\n\n    # Fall back to regular skeleton JSON decoding\n    return decode_skeleton(json_data)\n</code></pre>"},{"location":"reference/sleap_io/io/slp/","title":"slp","text":""},{"location":"reference/sleap_io/io/slp/#sleap_io.io.slp","title":"<code>sleap_io.io.slp</code>","text":"<p>This module handles direct I/O operations for working with .slp files.</p> <p>Classes:</p> Name Description <code>InstanceType</code> <p>Enumeration of instance types to integers.</p> <code>VideoReferenceMode</code> <p>How to handle video references when saving.</p> <p>Functions:</p> Name Description <code>camera_group_to_dict</code> <p>Convert <code>camera_group</code> to dictionary.</p> <code>camera_to_dict</code> <p>Convert <code>camera</code> to dictionary.</p> <code>embed_frames</code> <p>Embed frames in a SLEAP labels file.</p> <code>embed_video</code> <p>Embed frames of a video in a SLEAP labels file.</p> <code>embed_videos</code> <p>Embed videos in a SLEAP labels file.</p> <code>frame_group_to_dict</code> <p>Convert <code>frame_group</code> to a dictionary.</p> <code>instance_group_to_dict</code> <p>Convert <code>instance_group</code> to a dictionary.</p> <code>make_camera</code> <p>Create <code>Camera</code> from a dictionary.</p> <code>make_camera_group</code> <p>Create a <code>CameraGroup</code> from a calibration dictionary.</p> <code>make_frame_group</code> <p>Create a <code>FrameGroup</code> object from a dictionary.</p> <code>make_instance_group</code> <p>Creates an <code>InstanceGroup</code> object from a dictionary.</p> <code>make_session</code> <p>Create a <code>RecordingSession</code> from a dictionary.</p> <code>make_video</code> <p>Create a <code>Video</code> object from a JSON dictionary.</p> <code>prepare_frames_to_embed</code> <p>Prepare frames to embed by gathering all metadata needed for embedding.</p> <code>process_and_embed_frames</code> <p>Process and embed frames into a SLEAP labels file.</p> <code>read_instances</code> <p>Read <code>Instance</code> dataset in a SLEAP labels file.</p> <code>read_labels</code> <p>Read a SLEAP labels file.</p> <code>read_labels_set</code> <p>Load a LabelsSet from multiple SLP files.</p> <code>read_metadata</code> <p>Read metadata from a SLEAP labels file.</p> <code>read_points</code> <p>Read points dataset from a SLEAP labels file.</p> <code>read_pred_points</code> <p>Read predicted points dataset from a SLEAP labels file.</p> <code>read_sessions</code> <p>Read <code>RecordingSession</code> dataset from a SLEAP labels file.</p> <code>read_skeletons</code> <p>Read <code>Skeleton</code> dataset from a SLEAP labels file.</p> <code>read_suggestions</code> <p>Read <code>SuggestionFrame</code> dataset in a SLEAP labels file.</p> <code>read_tracks</code> <p>Read <code>Track</code> dataset in a SLEAP labels file.</p> <code>read_videos</code> <p>Read <code>Video</code> dataset in a SLEAP labels file.</p> <code>serialize_skeletons</code> <p>Serialize a list of <code>Skeleton</code> objects to JSON-compatible dicts.</p> <code>session_to_dict</code> <p>Convert <code>RecordingSession</code> to a dictionary.</p> <code>video_to_dict</code> <p>Convert a <code>Video</code> object to a JSON-compatible dictionary.</p> <code>write_labels</code> <p>Write a SLEAP labels file.</p> <code>write_lfs</code> <p>Write labeled frames, instances and points to a SLEAP labels file.</p> <code>write_metadata</code> <p>Write metadata to a SLEAP labels file.</p> <code>write_sessions</code> <p>Write <code>RecordingSession</code> metadata to a SLEAP labels file.</p> <code>write_suggestions</code> <p>Write track metadata to a SLEAP labels file.</p> <code>write_tracks</code> <p>Write track metadata to a SLEAP labels file.</p> <code>write_videos</code> <p>Write video metadata to a SLEAP labels file.</p>"},{"location":"reference/sleap_io/io/slp/#sleap_io.io.slp.InstanceType","title":"<code>InstanceType</code>","text":"<p>               Bases: <code>IntEnum</code></p> <p>Enumeration of instance types to integers.</p> Source code in <code>sleap_io/io/slp.py</code> <pre><code>class InstanceType(IntEnum):\n    \"\"\"Enumeration of instance types to integers.\"\"\"\n\n    USER = 0\n    PREDICTED = 1\n</code></pre>"},{"location":"reference/sleap_io/io/slp/#sleap_io.io.slp.VideoReferenceMode","title":"<code>VideoReferenceMode</code>","text":"<p>               Bases: <code>Enum</code></p> <p>How to handle video references when saving.</p> Source code in <code>sleap_io/io/slp.py</code> <pre><code>class VideoReferenceMode(Enum):\n    \"\"\"How to handle video references when saving.\"\"\"\n\n    EMBED = \"embed\"  # Embed frames in the file\n    RESTORE_ORIGINAL = \"restore_original\"  # Use original video if available\n    PRESERVE_SOURCE = \"preserve_source\"  # Keep reference to source file (.pkg.slp)\n</code></pre>"},{"location":"reference/sleap_io/io/slp/#sleap_io.io.slp.camera_group_to_dict","title":"<code>camera_group_to_dict(camera_group)</code>","text":"<p>Convert <code>camera_group</code> to dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>camera_group</code> <code>CameraGroup</code> <p><code>CameraGroup</code> object to convert to a dictionary.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary containing camera group information with the following keys:     - cam_n: Camera dictionary containing information for camera at index \"n\"         with the following keys:         name: Camera name.         size: Image size (height, width) of camera in pixels of size (2,)             and type int.         matrix: Intrinsic camera matrix of size (3, 3) and type float64.         distortions: Radial-tangential distortion coefficients             [k_1, k_2, p_1, p_2, k_3] of size (5,) and type float64.         rotation: Rotation vector in unnormalized axis-angle representation             of size (3,) and type float64.         translation: Translation vector of size (3,) and type float64.     - \"metadata\": Dictionary of optional metadata.</p> Source code in <code>sleap_io/io/slp.py</code> <pre><code>def camera_group_to_dict(camera_group: CameraGroup) -&gt; dict:\n    \"\"\"Convert `camera_group` to dictionary.\n\n    Args:\n        camera_group: `CameraGroup` object to convert to a dictionary.\n\n    Returns:\n        Dictionary containing camera group information with the following keys:\n            - cam_n: Camera dictionary containing information for camera at index \"n\"\n                with the following keys:\n                name: Camera name.\n                size: Image size (height, width) of camera in pixels of size (2,)\n                    and type int.\n                matrix: Intrinsic camera matrix of size (3, 3) and type float64.\n                distortions: Radial-tangential distortion coefficients\n                    [k_1, k_2, p_1, p_2, k_3] of size (5,) and type float64.\n                rotation: Rotation vector in unnormalized axis-angle representation\n                    of size (3,) and type float64.\n                translation: Translation vector of size (3,) and type float64.\n            - \"metadata\": Dictionary of optional metadata.\n    \"\"\"\n    calibration_dict = {}\n    for cam_idx, camera in enumerate(camera_group.cameras):\n        camera_dict = camera_to_dict(camera)\n        calibration_dict[f\"cam_{cam_idx}\"] = camera_dict\n\n    calibration_dict[\"metadata\"] = camera_group.metadata.copy()\n\n    return calibration_dict\n</code></pre>"},{"location":"reference/sleap_io/io/slp/#sleap_io.io.slp.camera_to_dict","title":"<code>camera_to_dict(camera)</code>","text":"<p>Convert <code>camera</code> to dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>camera</code> <code>Camera</code> <p><code>Camera</code> object to convert to a dictionary.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary containing camera information with the following keys:     - \"name\": Camera name.     - \"size\": Image size (width, height) of camera in pixels of size (2,) and       type         int.     - \"matrix\": Intrinsic camera matrix of size (3, 3) and type float64.     - \"distortions\": Radial-tangential distortion coefficients         [k_1, k_2, p_1, p_2, k_3] of size (5,) and type float64.     - \"rotation\": Rotation vector in unnormalized axis-angle representation of         size (3,) and type float64.     - \"translation\": Translation vector of size (3,) and type float64.     - Any optional keys containing metadata.</p> Source code in <code>sleap_io/io/slp.py</code> <pre><code>def camera_to_dict(camera: Camera) -&gt; dict:\n    \"\"\"Convert `camera` to dictionary.\n\n    Args:\n        camera: `Camera` object to convert to a dictionary.\n\n    Returns:\n        Dictionary containing camera information with the following keys:\n            - \"name\": Camera name.\n            - \"size\": Image size (width, height) of camera in pixels of size (2,) and\n              type\n                int.\n            - \"matrix\": Intrinsic camera matrix of size (3, 3) and type float64.\n            - \"distortions\": Radial-tangential distortion coefficients\n                [k_1, k_2, p_1, p_2, k_3] of size (5,) and type float64.\n            - \"rotation\": Rotation vector in unnormalized axis-angle representation of\n                size (3,) and type float64.\n            - \"translation\": Translation vector of size (3,) and type float64.\n            - Any optional keys containing metadata.\n\n    \"\"\"\n    # Handle optional attributes\n    name = \"\" if camera.name is None else camera.name\n    size = \"\" if camera.size is None else list(camera.size)\n\n    camera_dict = {\n        \"name\": name,\n        \"size\": size,\n        \"matrix\": camera.matrix.tolist(),\n        \"distortions\": camera.dist.tolist(),\n        \"rotation\": camera.rvec.tolist(),\n        \"translation\": camera.tvec.tolist(),\n    }\n    camera_dict.update(camera.metadata)\n\n    return camera_dict\n</code></pre>"},{"location":"reference/sleap_io/io/slp/#sleap_io.io.slp.embed_frames","title":"<code>embed_frames(labels_path, labels, embed, image_format='png', verbose=True)</code>","text":"<p>Embed frames in a SLEAP labels file.</p> <p>Parameters:</p> Name Type Description Default <code>labels_path</code> <code>str</code> <p>A string path to the SLEAP labels file.</p> required <code>labels</code> <code>Labels</code> <p>A <code>Labels</code> object to embed in the labels file.</p> required <code>embed</code> <code>list[tuple[Video, int]]</code> <p>A list of tuples of <code>(video, frame_idx)</code> specifying the frames to embed.</p> required <code>image_format</code> <code>str</code> <p>The image format to use for embedding. Valid formats are \"png\" (the default), \"jpg\" or \"hdf5\".</p> <code>'png'</code> <code>verbose</code> <code>bool</code> <p>If <code>True</code> (the default), display a progress bar for the embedding process.</p> <code>True</code> Notes <p>This function will embed the frames in the labels file and update the <code>Videos</code> and <code>Labels</code> objects in place.</p> Source code in <code>sleap_io/io/slp.py</code> <pre><code>def embed_frames(\n    labels_path: str,\n    labels: Labels,\n    embed: list[tuple[Video, int]],\n    image_format: str = \"png\",\n    verbose: bool = True,\n):\n    \"\"\"Embed frames in a SLEAP labels file.\n\n    Args:\n        labels_path: A string path to the SLEAP labels file.\n        labels: A `Labels` object to embed in the labels file.\n        embed: A list of tuples of `(video, frame_idx)` specifying the frames to embed.\n        image_format: The image format to use for embedding. Valid formats are \"png\"\n            (the default), \"jpg\" or \"hdf5\".\n        verbose: If `True` (the default), display a progress bar for the embedding\n            process.\n\n    Notes:\n        This function will embed the frames in the labels file and update the `Videos`\n        and `Labels` objects in place.\n    \"\"\"\n    frames_metadata = prepare_frames_to_embed(labels_path, labels, embed)\n    replaced_videos = process_and_embed_frames(\n        labels_path, frames_metadata, image_format=image_format, verbose=verbose\n    )\n\n    if len(replaced_videos) &gt; 0:\n        labels.replace_videos(video_map=replaced_videos)\n</code></pre>"},{"location":"reference/sleap_io/io/slp/#sleap_io.io.slp.embed_video","title":"<code>embed_video(labels_path, video, group, frame_inds, image_format='png', fixed_length=True)</code>","text":"<p>Embed frames of a video in a SLEAP labels file.</p> <p>.. deprecated:: 1.0.0     This function is deprecated. Use <code>process_and_embed_frames</code> instead.</p> <p>Parameters:</p> Name Type Description Default <code>labels_path</code> <code>str</code> <p>A string path to the SLEAP labels file.</p> required <code>video</code> <code>Video</code> <p>A <code>Video</code> object to embed in the labels file.</p> required <code>group</code> <code>str</code> <p>The name of the group to store the embedded video in. Image data will be stored in a dataset named <code>{group}/video</code>. Frame indices will be stored in a data set named <code>{group}/frame_numbers</code>.</p> required <code>frame_inds</code> <code>list[int]</code> <p>A list of frame indices to embed.</p> required <code>image_format</code> <code>str</code> <p>The image format to use for embedding. Valid formats are \"png\" (the default), \"jpg\" or \"hdf5\".</p> <code>'png'</code> <code>fixed_length</code> <code>bool</code> <p>If <code>True</code> (the default), the embedded images will be padded to the length of the largest image. If <code>False</code>, the images will be stored as variable length, which is smaller but may not be supported by all readers.</p> <code>True</code> <p>Returns:</p> Type Description <code>Video</code> <p>An embedded <code>Video</code> object.</p> <p>If the video is already embedded, the original video will be returned. If not, a new <code>Video</code> object will be created with the embedded data.</p> Source code in <code>sleap_io/io/slp.py</code> <pre><code>def embed_video(\n    labels_path: str,\n    video: Video,\n    group: str,\n    frame_inds: list[int],\n    image_format: str = \"png\",\n    fixed_length: bool = True,\n) -&gt; Video:\n    \"\"\"Embed frames of a video in a SLEAP labels file.\n\n    .. deprecated:: 1.0.0\n        This function is deprecated. Use `process_and_embed_frames` instead.\n\n    Args:\n        labels_path: A string path to the SLEAP labels file.\n        video: A `Video` object to embed in the labels file.\n        group: The name of the group to store the embedded video in. Image data will be\n            stored in a dataset named `{group}/video`. Frame indices will be stored\n            in a data set named `{group}/frame_numbers`.\n        frame_inds: A list of frame indices to embed.\n        image_format: The image format to use for embedding. Valid formats are \"png\"\n            (the default), \"jpg\" or \"hdf5\".\n        fixed_length: If `True` (the default), the embedded images will be padded to the\n            length of the largest image. If `False`, the images will be stored as\n            variable length, which is smaller but may not be supported by all readers.\n\n    Returns:\n        An embedded `Video` object.\n\n        If the video is already embedded, the original video will be returned. If not,\n        a new `Video` object will be created with the embedded data.\n    \"\"\"\n    # Load the image data and optionally encode it.\n    imgs_data = []\n    for frame_idx in frame_inds:\n        frame = video[frame_idx]\n\n        if image_format == \"hdf5\":\n            img_data = frame\n        else:\n            if \"cv2\" in sys.modules:\n                img_data = np.squeeze(\n                    cv2.imencode(\".\" + image_format, frame)[1]\n                ).astype(\"int8\")\n            else:\n                if frame.shape[-1] == 1:\n                    frame = frame.squeeze(axis=-1)\n                img_data = np.frombuffer(\n                    iio.imwrite(\"&lt;bytes&gt;\", frame, extension=\".\" + image_format),\n                    dtype=\"int8\",\n                )\n\n        imgs_data.append(img_data)\n\n    # Write the image data to the labels file.\n    with h5py.File(labels_path, \"a\") as f:\n        if image_format == \"hdf5\":\n            f.create_dataset(\n                f\"{group}/video\", data=imgs_data, compression=\"gzip\", chunks=True\n            )\n        else:\n            if fixed_length:\n                img_bytes_len = 0\n                for img in imgs_data:\n                    img_bytes_len = max(img_bytes_len, len(img))\n                ds = f.create_dataset(\n                    f\"{group}/video\",\n                    shape=(len(imgs_data), img_bytes_len),\n                    dtype=\"int8\",\n                    compression=\"gzip\",\n                )\n                for i, img in enumerate(imgs_data):\n                    ds[i, : len(img)] = img\n            else:\n                ds = f.create_dataset(\n                    f\"{group}/video\",\n                    shape=(len(imgs_data),),\n                    dtype=h5py.special_dtype(vlen=np.dtype(\"int8\")),\n                )\n                for i, img in enumerate(imgs_data):\n                    ds[i] = img\n\n        # Store metadata.\n        ds.attrs[\"format\"] = image_format\n        video_shape = video.shape\n        (\n            ds.attrs[\"frames\"],\n            ds.attrs[\"height\"],\n            ds.attrs[\"width\"],\n            ds.attrs[\"channels\"],\n        ) = video_shape\n\n        # Store frame indices.\n        f.create_dataset(f\"{group}/frame_numbers\", data=frame_inds)\n\n        # Store source video.\n        if video.source_video is not None:\n            # If this is already an embedded dataset, retain the previous source video.\n            source_video = video.source_video\n        else:\n            source_video = video\n\n        # Create a new video object with the embedded data.\n        embedded_video = Video(\n            filename=labels_path,\n            backend=VideoBackend.from_filename(\n                labels_path,\n                dataset=f\"{group}/video\",\n                grayscale=video.grayscale,\n                keep_open=False,\n            ),\n            source_video=source_video,\n        )\n\n        grp = f.require_group(f\"{group}/source_video\")\n        grp.attrs[\"json\"] = json.dumps(\n            video_to_dict(source_video, labels_path), separators=(\",\", \":\")\n        )\n\n    return embedded_video\n</code></pre>"},{"location":"reference/sleap_io/io/slp/#sleap_io.io.slp.embed_videos","title":"<code>embed_videos(labels_path, labels, embed, verbose=True)</code>","text":"<p>Embed videos in a SLEAP labels file.</p> <p>Parameters:</p> Name Type Description Default <code>labels_path</code> <code>str</code> <p>A string path to the SLEAP labels file to save.</p> required <code>labels</code> <code>Labels</code> <p>A <code>Labels</code> object to save.</p> required <code>embed</code> <code>bool | str | list[tuple[Video, int]]</code> <p>Frames to embed in the saved labels file. One of <code>None</code>, <code>True</code>, <code>\"all\"</code>, <code>\"user\"</code>, <code>\"suggestions\"</code>, <code>\"user+suggestions\"</code>, <code>\"source\"</code> or list of tuples of <code>(video, frame_idx)</code>.</p> <p>If <code>None</code> is specified (the default) and the labels contains embedded frames, those embedded frames will be re-saved to the new file.</p> <p>If <code>True</code> or <code>\"all\"</code>, all labeled frames and suggested frames will be embedded.</p> required <code>verbose</code> <code>bool</code> <p>If <code>True</code> (the default), display a progress bar for the embedding process.</p> <p>If <code>\"source\"</code> is specified, no images will be embedded and the source video will be restored if available.</p> <p>This argument is only valid for the SLP backend.</p> <code>True</code> Source code in <code>sleap_io/io/slp.py</code> <pre><code>def embed_videos(\n    labels_path: str,\n    labels: Labels,\n    embed: bool | str | list[tuple[Video, int]],\n    verbose: bool = True,\n):\n    \"\"\"Embed videos in a SLEAP labels file.\n\n    Args:\n        labels_path: A string path to the SLEAP labels file to save.\n        labels: A `Labels` object to save.\n        embed: Frames to embed in the saved labels file. One of `None`, `True`,\n            `\"all\"`, `\"user\"`, `\"suggestions\"`, `\"user+suggestions\"`, `\"source\"` or list\n            of tuples of `(video, frame_idx)`.\n\n            If `None` is specified (the default) and the labels contains embedded\n            frames, those embedded frames will be re-saved to the new file.\n\n            If `True` or `\"all\"`, all labeled frames and suggested frames will be\n            embedded.\n        verbose: If `True` (the default), display a progress bar for the embedding\n            process.\n\n            If `\"source\"` is specified, no images will be embedded and the source video\n            will be restored if available.\n\n            This argument is only valid for the SLP backend.\n    \"\"\"\n    if embed is True:\n        embed = \"all\"\n    if embed == \"user\":\n        embed = [(lf.video, lf.frame_idx) for lf in labels.user_labeled_frames]\n    elif embed == \"suggestions\":\n        embed = [(sf.video, sf.frame_idx) for sf in labels.suggestions]\n    elif embed == \"user+suggestions\":\n        embed = [(lf.video, lf.frame_idx) for lf in labels.user_labeled_frames]\n        embed += [(sf.video, sf.frame_idx) for sf in labels.suggestions]\n    elif embed == \"all\":\n        embed = [(lf.video, lf.frame_idx) for lf in labels]\n        embed += [(sf.video, sf.frame_idx) for sf in labels.suggestions]\n    elif embed == \"source\":\n        embed = []\n    elif isinstance(embed, list):\n        embed = embed\n    else:\n        raise ValueError(f\"Invalid value for embed: {embed}\")\n\n    embed_frames(labels_path, labels, embed, verbose=verbose)\n</code></pre>"},{"location":"reference/sleap_io/io/slp/#sleap_io.io.slp.frame_group_to_dict","title":"<code>frame_group_to_dict(frame_group, labeled_frame_to_idx, camera_group)</code>","text":"<p>Convert <code>frame_group</code> to a dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>frame_group</code> <code>FrameGroup</code> <p><code>FrameGroup</code> object to convert to a dictionary.</p> required <code>labeled_frame_to_idx</code> <code>dict[LabeledFrame, int]</code> <p>Dictionary of <code>LabeledFrame</code> to index in <code>Labels.labeled_frames</code>.</p> required <code>camera_group</code> <code>CameraGroup</code> <p><code>CameraGroup</code> object that determines the order of the <code>Camera</code> objects when converting to a dictionary.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary of the <code>FrameGroup</code> with keys:     - \"instance_groups\": List of dictionaries for each <code>InstanceGroup</code> in the         <code>FrameGroup</code>. See <code>instance_group_to_dict</code> for what each dictionary         contains.     - \"frame_idx\": Frame index for the <code>FrameGroup</code>.     - Any optional keys containing metadata.</p> Source code in <code>sleap_io/io/slp.py</code> <pre><code>def frame_group_to_dict(\n    frame_group: FrameGroup,\n    labeled_frame_to_idx: dict[LabeledFrame, int],\n    camera_group: CameraGroup,\n) -&gt; dict:\n    \"\"\"Convert `frame_group` to a dictionary.\n\n    Args:\n        frame_group: `FrameGroup` object to convert to a dictionary.\n        labeled_frame_to_idx: Dictionary of `LabeledFrame` to index in\n            `Labels.labeled_frames`.\n        camera_group: `CameraGroup` object that determines the order of the `Camera`\n            objects when converting to a dictionary.\n\n    Returns:\n        Dictionary of the `FrameGroup` with keys:\n            - \"instance_groups\": List of dictionaries for each `InstanceGroup` in the\n                `FrameGroup`. See `instance_group_to_dict` for what each dictionary\n                contains.\n            - \"frame_idx\": Frame index for the `FrameGroup`.\n            - Any optional keys containing metadata.\n    \"\"\"\n    # Create dictionary of `Instance` to `LabeledFrame` index (in\n    # `Labels.labeled_frames`) and `Instance` index in `LabeledFrame.instances`.\n    instance_to_lf_and_inst_idx: dict[Instance, tuple[int, int]] = {\n        inst: (labeled_frame_to_idx[labeled_frame], inst_idx)\n        for labeled_frame in frame_group.labeled_frames\n        for inst_idx, inst in enumerate(labeled_frame.instances)\n    }\n\n    frame_group_dict = {\n        \"instance_groups\": [\n            instance_group_to_dict(\n                instance_group,\n                instance_to_lf_and_inst_idx=instance_to_lf_and_inst_idx,\n                camera_group=camera_group,\n            )\n            for instance_group in frame_group.instance_groups\n        ],\n    }\n    frame_group_dict[\"frame_idx\"] = frame_group.frame_idx\n    frame_group_dict.update(frame_group.metadata)\n\n    return frame_group_dict\n</code></pre>"},{"location":"reference/sleap_io/io/slp/#sleap_io.io.slp.instance_group_to_dict","title":"<code>instance_group_to_dict(instance_group, instance_to_lf_and_inst_idx, camera_group)</code>","text":"<p>Convert <code>instance_group</code> to a dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>instance_group</code> <code>InstanceGroup</code> <p><code>InstanceGroup</code> object to convert to a dictionary.</p> required <code>instance_to_lf_and_inst_idx</code> <code>dict[Instance, tuple[int, int]]</code> <p>Dictionary mapping <code>Instance</code> objects to <code>LabeledFrame</code> indices (in <code>Labels.labeled_frames</code>) and <code>Instance</code> indices (in containing <code>LabeledFrame.instances</code>).</p> required <code>camera_group</code> <code>CameraGroup</code> <p><code>CameraGroup</code> object that determines the order of the <code>Camera</code> objects when converting to a dictionary.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary of the <code>InstanceGroup</code> with keys:     - \"camcorder_to_lf_and_inst_idx_map\": Dictionary mapping <code>Camera</code> indices         (in <code>InstanceGroup.camera_cluster.cameras</code>) to a tuple of <code>LabeledFrame</code>         and <code>Instance</code> indices (from <code>instance_to_lf_and_inst_idx</code>)     - Any optional keys containing metadata.</p> Source code in <code>sleap_io/io/slp.py</code> <pre><code>def instance_group_to_dict(\n    instance_group: InstanceGroup,\n    instance_to_lf_and_inst_idx: dict[Instance, tuple[int, int]],\n    camera_group: CameraGroup,\n) -&gt; dict:\n    \"\"\"Convert `instance_group` to a dictionary.\n\n    Args:\n        instance_group: `InstanceGroup` object to convert to a dictionary.\n        instance_to_lf_and_inst_idx: Dictionary mapping `Instance` objects to\n            `LabeledFrame` indices (in `Labels.labeled_frames`) and `Instance` indices\n            (in containing `LabeledFrame.instances`).\n        camera_group: `CameraGroup` object that determines the order of the `Camera`\n            objects when converting to a dictionary.\n\n    Returns:\n        Dictionary of the `InstanceGroup` with keys:\n            - \"camcorder_to_lf_and_inst_idx_map\": Dictionary mapping `Camera` indices\n                (in `InstanceGroup.camera_cluster.cameras`) to a tuple of `LabeledFrame`\n                and `Instance` indices (from `instance_to_lf_and_inst_idx`)\n            - Any optional keys containing metadata.\n    \"\"\"\n    camera_to_lf_and_inst_idx_map: dict[int, tuple[int, int]] = {\n        camera_group.cameras.index(cam): instance_to_lf_and_inst_idx[instance]\n        for cam, instance in instance_group.instance_by_camera.items()\n    }\n\n    # Only required key is camcorder_to_lf_and_inst_idx_map\n    instance_group_dict = {\n        \"camcorder_to_lf_and_inst_idx_map\": camera_to_lf_and_inst_idx_map,\n    }\n\n    # Optionally add score, points, and metadata if they are non-default values\n    if instance_group.score is not None:\n        instance_group_dict[\"score\"] = instance_group.score\n    if instance_group.points is not None:\n        instance_group_dict[\"points\"] = instance_group.points.tolist()\n    instance_group_dict.update(instance_group.metadata)\n\n    return instance_group_dict\n</code></pre>"},{"location":"reference/sleap_io/io/slp/#sleap_io.io.slp.make_camera","title":"<code>make_camera(camera_dict)</code>","text":"<p>Create <code>Camera</code> from a dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>camera_dict</code> <code>dict</code> <p>Dictionary containing camera information with the following necessary keys: - \"name\": Camera name. - \"size\": Image size (width, height) of camera in pixels of size (2,) and     type int. - \"matrix\": Intrinsic camera matrix of size (3, 3) and type float64. - \"distortions\": Radial-tangential distortion coefficients     [k_1, k_2, p_1, p_2, k_3] of size (5,) and type float64. - \"rotation\": Rotation vector in unnormalized axis-angle representation of     size (3,) and type float64. - \"translation\": Translation vector of size (3,) and type float64. and optional keys containing metadata.</p> required <p>Returns:</p> Type Description <code>Camera</code> <p><code>Camera</code> object created from dictionary.</p> Source code in <code>sleap_io/io/slp.py</code> <pre><code>def make_camera(camera_dict: dict) -&gt; Camera:\n    \"\"\"Create `Camera` from a dictionary.\n\n    Args:\n        camera_dict: Dictionary containing camera information with the following\n            necessary keys:\n            - \"name\": Camera name.\n            - \"size\": Image size (width, height) of camera in pixels of size (2,) and\n                type int.\n            - \"matrix\": Intrinsic camera matrix of size (3, 3) and type float64.\n            - \"distortions\": Radial-tangential distortion coefficients\n                [k_1, k_2, p_1, p_2, k_3] of size (5,) and type float64.\n            - \"rotation\": Rotation vector in unnormalized axis-angle representation of\n                size (3,) and type float64.\n            - \"translation\": Translation vector of size (3,) and type float64.\n            and optional keys containing metadata.\n\n    Returns:\n        `Camera` object created from dictionary.\n    \"\"\"\n    # Avoid mutating the dictionary.\n    camera_dict = camera_dict.copy()\n\n    # Get all attributes we deserialize.\n    name = camera_dict.pop(\"name\")\n    size = camera_dict.pop(\"size\")\n    camera = Camera(\n        name=name if len(name) &gt; 0 else None,\n        size=size if len(size) &gt; 0 else None,\n        matrix=camera_dict.pop(\"matrix\"),\n        dist=camera_dict.pop(\"distortions\"),\n        rvec=camera_dict.pop(\"rotation\"),\n        tvec=camera_dict.pop(\"translation\"),\n    )\n\n    # Add remaining metadata to `Camera`\n    camera.metadata = camera_dict\n\n    return camera\n</code></pre>"},{"location":"reference/sleap_io/io/slp/#sleap_io.io.slp.make_camera_group","title":"<code>make_camera_group(calibration_dict)</code>","text":"<p>Create a <code>CameraGroup</code> from a calibration dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>calibration_dict</code> <code>dict</code> <p>Dictionary containing calibration information for cameras with optional keys: - \"metadata\": Dictionary containing metadata for the <code>CameraGroup</code>. - Arbitrary (but unique) keys for every <code>Camera</code>, each containing a     dictionary with camera information (see <code>make_camera</code> for what each     dictionary contains).</p> required <p>Returns:</p> Type Description <code>CameraGroup</code> <p><code>CameraGroup</code> object created from calibration dictionary.</p> Source code in <code>sleap_io/io/slp.py</code> <pre><code>def make_camera_group(calibration_dict: dict) -&gt; CameraGroup:\n    \"\"\"Create a `CameraGroup` from a calibration dictionary.\n\n    Args:\n        calibration_dict: Dictionary containing calibration information for cameras\n            with optional keys:\n            - \"metadata\": Dictionary containing metadata for the `CameraGroup`.\n            - Arbitrary (but unique) keys for every `Camera`, each containing a\n                dictionary with camera information (see `make_camera` for what each\n                dictionary contains).\n\n    Returns:\n        `CameraGroup` object created from calibration dictionary.\n    \"\"\"\n    cameras = []\n    metadata = {}\n    for dict_name, camera_dict in calibration_dict.items():\n        if dict_name == \"metadata\":\n            metadata = camera_dict\n            continue\n        camera = make_camera(camera_dict)\n        cameras.append(camera)\n\n    return CameraGroup(cameras=cameras, metadata=metadata)\n</code></pre>"},{"location":"reference/sleap_io/io/slp/#sleap_io.io.slp.make_frame_group","title":"<code>make_frame_group(frame_group_dict, labeled_frames, camera_group)</code>","text":"<p>Create a <code>FrameGroup</code> object from a dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>frame_group_dict</code> <code>dict</code> <p>Dictionary representing a <code>FrameGroup</code> object with the following necessary key: - \"instance_groups\": List of dictionaries containing <code>InstanceGroup</code>     information (see <code>make_instance_group</code> for what each dictionary     contains). and optional keys: - \"frame_idx\": Frame index. - Any keys containing metadata.</p> required <code>labeled_frames</code> <code>list[LabeledFrame]</code> <p>List of <code>LabeledFrame</code> objects (expecting <code>Labels.labeled_frames</code>).</p> required <code>camera_group</code> <code>CameraGroup</code> <p><code>CameraGroup</code> object used to retrieve <code>Camera</code> objects.</p> required <p>Returns:</p> Type Description <code>FrameGroup</code> <p><code>FrameGroup</code> object.</p> Source code in <code>sleap_io/io/slp.py</code> <pre><code>def make_frame_group(\n    frame_group_dict: dict,\n    labeled_frames: list[LabeledFrame],\n    camera_group: CameraGroup,\n) -&gt; FrameGroup:\n    \"\"\"Create a `FrameGroup` object from a dictionary.\n\n    Args:\n        frame_group_dict: Dictionary representing a `FrameGroup` object with the\n            following necessary key:\n            - \"instance_groups\": List of dictionaries containing `InstanceGroup`\n                information (see `make_instance_group` for what each dictionary\n                contains).\n            and optional keys:\n            - \"frame_idx\": Frame index.\n            - Any keys containing metadata.\n        labeled_frames: List of `LabeledFrame` objects (expecting\n            `Labels.labeled_frames`).\n        camera_group: `CameraGroup` object used to retrieve `Camera` objects.\n\n    Returns:\n        `FrameGroup` object.\n    \"\"\"\n    # Avoid mutating the dictionary\n    frame_group_dict = frame_group_dict.copy()\n\n    frame_idx = None\n\n    # Get `InstanceGroup` objects\n    instance_groups_info = frame_group_dict.pop(\"instance_groups\")\n    instance_groups = []\n    labeled_frame_by_camera = {}\n    for instance_group_dict in instance_groups_info:\n        instance_group = make_instance_group(\n            instance_group_dict=instance_group_dict,\n            labeled_frames=labeled_frames,\n            camera_group=camera_group,\n        )\n        instance_groups.append(instance_group)\n\n        # Also retrieve the `LabeledFrame` by `Camera`. We do this for each\n        # `InstanceGroup` to ensure that we have don't miss a `LabeledFrame`.\n        camera_to_lf_and_inst_idx_map = instance_group_dict[\n            \"camcorder_to_lf_and_inst_idx_map\"\n        ]\n        for cam_idx, (lf_idx, _) in camera_to_lf_and_inst_idx_map.items():\n            # Retrieve the `Camera`\n            camera = camera_group.cameras[int(cam_idx)]\n\n            # Retrieve the `LabeledFrame`\n            labeled_frame = labeled_frames[int(lf_idx)]\n            labeled_frame_by_camera[camera] = labeled_frame\n\n            # We can get the frame index from the `LabeledFrame` if any.\n            frame_idx = labeled_frame.frame_idx\n\n    # Get the frame index explicitly from the dictionary if it exists.\n    if \"frame_idx\" in frame_group_dict:\n        frame_idx = frame_group_dict.pop(\"frame_idx\")\n\n    # Metadata contains any information that the class doesn't deserialize.\n    metadata = frame_group_dict  # Remaining keys are metadata.\n\n    return FrameGroup(\n        frame_idx=frame_idx,\n        instance_groups=instance_groups,\n        labeled_frame_by_camera=labeled_frame_by_camera,\n        metadata=metadata,\n    )\n</code></pre>"},{"location":"reference/sleap_io/io/slp/#sleap_io.io.slp.make_instance_group","title":"<code>make_instance_group(instance_group_dict, labeled_frames, camera_group)</code>","text":"<p>Creates an <code>InstanceGroup</code> object from a dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>instance_group_dict</code> <code>dict</code> <p>Dictionary with the following necessary key: - \"camcorder_to_lf_and_inst_idx_map\": Dictionary mapping <code>Camera</code> indices to     a tuple of <code>LabeledFrame</code> index (in <code>labeled_frames</code>) and <code>Instance</code>     index (in containing <code>LabeledFrame.instances</code>). and optional keys: - \"score\": A float representing the reprojection score for the     <code>InstanceGroup</code>. - \"points\": 3D points for the <code>InstanceGroup</code>. - Any keys containing metadata.</p> required <code>labeled_frames</code> <code>list[LabeledFrame]</code> <p>List of <code>LabeledFrame</code> objects (expecting <code>Labels.labeled_frames</code>) used to retrieve <code>Instance</code> objects.</p> required <code>camera_group</code> <code>CameraGroup</code> <p><code>CameraGroup</code> object used to retrieve <code>Camera</code> objects.</p> required <p>Returns:</p> Type Description <code>InstanceGroup</code> <p><code>InstanceGroup</code> object.</p> Source code in <code>sleap_io/io/slp.py</code> <pre><code>def make_instance_group(\n    instance_group_dict: dict,\n    labeled_frames: list[LabeledFrame],\n    camera_group: CameraGroup,\n) -&gt; InstanceGroup:\n    \"\"\"Creates an `InstanceGroup` object from a dictionary.\n\n    Args:\n        instance_group_dict: Dictionary with the following necessary key:\n            - \"camcorder_to_lf_and_inst_idx_map\": Dictionary mapping `Camera` indices to\n                a tuple of `LabeledFrame` index (in `labeled_frames`) and `Instance`\n                index (in containing `LabeledFrame.instances`).\n            and optional keys:\n            - \"score\": A float representing the reprojection score for the\n                `InstanceGroup`.\n            - \"points\": 3D points for the `InstanceGroup`.\n            - Any keys containing metadata.\n        labeled_frames: List of `LabeledFrame` objects (expecting\n            `Labels.labeled_frames`) used to retrieve `Instance` objects.\n        camera_group: `CameraGroup` object used to retrieve `Camera` objects.\n\n    Returns:\n        `InstanceGroup` object.\n    \"\"\"\n    # Avoid mutating the dictionary\n    instance_group_dict = instance_group_dict.copy()\n\n    # Get the `Instance` objects\n    camera_to_lf_and_inst_idx_map: dict[str, tuple[str, str]] = instance_group_dict.pop(\n        \"camcorder_to_lf_and_inst_idx_map\"\n    )\n\n    instance_by_camera: dict[Camera, Instance] = {}\n    for cam_idx, (lf_idx, inst_idx) in camera_to_lf_and_inst_idx_map.items():\n        # Retrieve the `Camera`\n        camera = camera_group.cameras[int(cam_idx)]\n\n        # Retrieve the `Instance` from the `LabeledFrame\n        labeled_frame = labeled_frames[int(lf_idx)]\n        instance = labeled_frame.instances[int(inst_idx)]\n\n        # Link the `Instance` to the `Camera`\n        instance_by_camera[camera] = instance\n\n    # Get all optional attributes\n    score = None\n    if \"score\" in instance_group_dict:\n        score = instance_group_dict.pop(\"score\")\n    points = None\n    if \"points\" in instance_group_dict:\n        points = instance_group_dict.pop(\"points\")\n\n    # Metadata contains any information that the class does not deserialize.\n    metadata = instance_group_dict  # Remaining keys are metadata.\n\n    return InstanceGroup(\n        instance_by_camera=instance_by_camera,\n        score=score,\n        points=points,\n        metadata=metadata,\n    )\n</code></pre>"},{"location":"reference/sleap_io/io/slp/#sleap_io.io.slp.make_session","title":"<code>make_session(session_dict, videos, labeled_frames)</code>","text":"<p>Create a <code>RecordingSession</code> from a dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>session_dict</code> <code>dict</code> <p>Dictionary with keys: - \"calibration\": Dictionary containing calibration information for cameras. - \"camcorder_to_video_idx_map\": Dictionary mapping camera index to video     index. - \"frame_group_dicts\": List of dictionaries containing <code>FrameGroup</code>     information. See <code>make_frame_group</code> for what each dictionary contains. - Any optional keys containing metadata.</p> required <code>videos</code> <code>list[Video]</code> <p>List containing <code>Video</code> objects (expected <code>Labels.videos</code>).</p> required <code>labeled_frames</code> <code>list[LabeledFrame]</code> <p>List containing <code>LabeledFrame</code> objects (expected <code>Labels.labeled_frames</code>).</p> required <p>Returns:</p> Type Description <code>RecordingSession</code> <p><code>RecordingSession</code> object.</p> Source code in <code>sleap_io/io/slp.py</code> <pre><code>def make_session(\n    session_dict: dict, videos: list[Video], labeled_frames: list[LabeledFrame]\n) -&gt; RecordingSession:\n    \"\"\"Create a `RecordingSession` from a dictionary.\n\n    Args:\n        session_dict: Dictionary with keys:\n            - \"calibration\": Dictionary containing calibration information for cameras.\n            - \"camcorder_to_video_idx_map\": Dictionary mapping camera index to video\n                index.\n            - \"frame_group_dicts\": List of dictionaries containing `FrameGroup`\n                information. See `make_frame_group` for what each dictionary contains.\n            - Any optional keys containing metadata.\n        videos: List containing `Video` objects (expected `Labels.videos`).\n        labeled_frames: List containing `LabeledFrame` objects (expected\n            `Labels.labeled_frames`).\n\n    Returns:\n        `RecordingSession` object.\n    \"\"\"\n    # Avoid modifying original dictionary\n    session_dict = session_dict.copy()\n\n    # Restructure `RecordingSession` without `Video` to `Camera` mapping\n    calibration_dict = session_dict.pop(\"calibration\")\n    camera_group = make_camera_group(calibration_dict)\n\n    # Retrieve all `Camera` and `Video` objects, then add to `RecordingSession`\n    camcorder_to_video_idx_map = session_dict.pop(\"camcorder_to_video_idx_map\")\n    video_by_camera = {}\n    camera_by_video = {}\n    for cam_idx, video_idx in camcorder_to_video_idx_map.items():\n        camera = camera_group.cameras[int(cam_idx)]\n        video = videos[int(video_idx)]\n        video_by_camera[camera] = video\n        camera_by_video[video] = camera\n\n    # Reconstruct all `FrameGroup` objects and add to `RecordingSession`\n    frame_group_dicts = []\n    if \"frame_group_dicts\" in session_dict:\n        frame_group_dicts = session_dict.pop(\"frame_group_dicts\")\n    frame_group_by_frame_idx = {}\n    for frame_group_dict in frame_group_dicts:\n        try:\n            # Add `FrameGroup` to `RecordingSession`\n            frame_group = make_frame_group(\n                frame_group_dict=frame_group_dict,\n                labeled_frames=labeled_frames,\n                camera_group=camera_group,\n            )\n            frame_group_by_frame_idx[frame_group.frame_idx] = frame_group\n        except ValueError as e:\n            print(\n                f\"Error reconstructing FrameGroup: {frame_group_dict}. Skipping...\\n{e}\"\n            )\n\n    session = RecordingSession(\n        camera_group=camera_group,\n        video_by_camera=video_by_camera,\n        camera_by_video=camera_by_video,\n        frame_group_by_frame_idx=frame_group_by_frame_idx,\n        metadata=session_dict,\n    )\n\n    return session\n</code></pre>"},{"location":"reference/sleap_io/io/slp/#sleap_io.io.slp.make_video","title":"<code>make_video(labels_path, video_json, open_backend=True)</code>","text":"<p>Create a <code>Video</code> object from a JSON dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>labels_path</code> <code>str</code> <p>A string path to the SLEAP labels file.</p> required <code>video_json</code> <code>dict</code> <p>A dictionary containing the video metadata.</p> required <code>open_backend</code> <code>bool</code> <p>If <code>True</code> (the default), attempt to open the video backend for I/O. If <code>False</code>, the backend will not be opened (useful for reading metadata when the video files are not available).</p> <code>True</code> Source code in <code>sleap_io/io/slp.py</code> <pre><code>def make_video(\n    labels_path: str,\n    video_json: dict,\n    open_backend: bool = True,\n) -&gt; Video:\n    \"\"\"Create a `Video` object from a JSON dictionary.\n\n    Args:\n        labels_path: A string path to the SLEAP labels file.\n        video_json: A dictionary containing the video metadata.\n        open_backend: If `True` (the default), attempt to open the video backend for\n            I/O. If `False`, the backend will not be opened (useful for reading metadata\n            when the video files are not available).\n    \"\"\"\n    backend_metadata = video_json[\"backend\"]\n    video_path = backend_metadata[\"filename\"]\n\n    # Marker for embedded videos.\n    source_video = None\n    is_embedded = False\n    if video_path == \".\":\n        video_path = labels_path\n        is_embedded = True\n\n    # Basic path resolution.\n    video_path = Path(sanitize_filename(video_path))\n\n    original_video = None\n    if is_embedded:\n        # Try to recover the source video and original video from HDF5 attrs.\n        with h5py.File(labels_path, \"r\") as f:\n            dataset = backend_metadata[\"dataset\"]\n            if dataset.endswith(\"/video\"):\n                dataset = dataset[:-6]\n\n            # Load source_video metadata\n            if dataset in f and \"source_video\" in f[dataset]:\n                source_video_json = json.loads(\n                    f[f\"{dataset}/source_video\"].attrs[\"json\"]\n                )\n                source_video = make_video(\n                    labels_path,\n                    source_video_json,\n                    open_backend=open_backend,\n                )\n\n            # Load original_video metadata\n            if f\"{dataset}/original_video\" in f:\n                original_video_json = json.loads(\n                    f[f\"{dataset}/original_video\"].attrs[\"json\"]\n                )\n                original_video = make_video(\n                    labels_path,\n                    original_video_json,\n                    open_backend=False,  # Original videos are often not available\n                )\n    else:\n        # For non-embedded videos, check if metadata is in videos_json\n        if \"source_video\" in video_json:\n            source_video = make_video(\n                labels_path,\n                video_json[\"source_video\"],\n                open_backend=open_backend,\n            )\n\n        if \"original_video\" in video_json:\n            original_video = make_video(\n                labels_path,\n                video_json[\"original_video\"],\n                open_backend=False,  # Original videos are often not available\n            )\n\n    backend = None\n    if open_backend:\n        try:\n            if not is_file_accessible(video_path):\n                # Check for the same filename in the same directory as the labels file.\n                candidate_video_path = Path(labels_path).parent / video_path.name\n                if is_file_accessible(candidate_video_path):\n                    video_path = candidate_video_path\n                else:\n                    # TODO (TP): Expand capabilities of path resolution to support more\n                    # complex path finding strategies.\n                    pass\n        except (OSError, PermissionError, FileNotFoundError):\n            pass\n\n        # Convert video path to string.\n        video_path = video_path.as_posix()\n\n        if \"filenames\" in backend_metadata:\n            # This is an ImageVideo.\n            # TODO: Path resolution.\n            video_path = backend_metadata[\"filenames\"]\n            video_path = [Path(sanitize_filename(p)) for p in video_path]\n\n        try:\n            grayscale = None\n            if \"grayscale\" in backend_metadata:\n                grayscale = backend_metadata[\"grayscale\"]\n            elif \"shape\" in backend_metadata:\n                grayscale = backend_metadata[\"shape\"][-1] == 1\n            backend = VideoBackend.from_filename(\n                video_path,\n                dataset=backend_metadata.get(\"dataset\", None),\n                grayscale=grayscale,\n                input_format=backend_metadata.get(\"input_format\", None),\n                format=backend_metadata.get(\"format\", None),\n            )\n        except Exception:\n            backend = None\n\n    return Video(\n        filename=video_path,\n        backend=backend,\n        backend_metadata=backend_metadata,\n        source_video=source_video,\n        original_video=original_video,\n        open_backend=open_backend,\n    )\n</code></pre>"},{"location":"reference/sleap_io/io/slp/#sleap_io.io.slp.prepare_frames_to_embed","title":"<code>prepare_frames_to_embed(labels_path, labels, frames_to_embed)</code>","text":"<p>Prepare frames to embed by gathering all metadata needed for embedding.</p> <p>Parameters:</p> Name Type Description Default <code>labels_path</code> <code>str</code> <p>A string path to the SLEAP labels file.</p> required <code>labels</code> <code>Labels</code> <p>A <code>Labels</code> object containing the videos.</p> required <code>frames_to_embed</code> <code>list[tuple[Video, int]]</code> <p>A list of tuples of <code>(video, frame_idx)</code> specifying the frames to embed.</p> required <p>Returns:</p> Type Description <code>list[dict]</code> <p>A list of dictionaries, each containing metadata for a frame to embed:     - video: The Video object     - frame_idx: The index of the frame to embed     - video_ind: The index of the video in labels.videos     - group: The HDF5 group to store the embedded data in</p> Source code in <code>sleap_io/io/slp.py</code> <pre><code>def prepare_frames_to_embed(\n    labels_path: str,\n    labels: Labels,\n    frames_to_embed: list[tuple[Video, int]],\n) -&gt; list[dict]:\n    \"\"\"Prepare frames to embed by gathering all metadata needed for embedding.\n\n    Args:\n        labels_path: A string path to the SLEAP labels file.\n        labels: A `Labels` object containing the videos.\n        frames_to_embed: A list of tuples of `(video, frame_idx)` specifying the\n            frames to embed.\n\n    Returns:\n        A list of dictionaries, each containing metadata for a frame to embed:\n            - video: The Video object\n            - frame_idx: The index of the frame to embed\n            - video_ind: The index of the video in labels.videos\n            - group: The HDF5 group to store the embedded data in\n    \"\"\"\n    # First, group frames by video\n    to_embed_by_video = {}\n    for video, frame_idx in frames_to_embed:\n        if video not in to_embed_by_video:\n            to_embed_by_video[video] = []\n        to_embed_by_video[video].append(frame_idx)\n\n    # Remove duplicates and sort\n    for video in to_embed_by_video:\n        to_embed_by_video[video] = sorted(list(set(to_embed_by_video[video])))\n\n    # Create a list of frame metadata for embedding\n    frames_metadata = []\n    for video, frame_inds in to_embed_by_video.items():\n        video_ind = labels.videos.index(video)\n        group = f\"video{video_ind}\"\n        for frame_idx in frame_inds:\n            frames_metadata.append(\n                {\n                    \"video\": video,\n                    \"frame_idx\": frame_idx,\n                    \"video_ind\": video_ind,\n                    \"group\": group,\n                }\n            )\n\n    return frames_metadata\n</code></pre>"},{"location":"reference/sleap_io/io/slp/#sleap_io.io.slp.process_and_embed_frames","title":"<code>process_and_embed_frames(labels_path, frames_metadata, image_format='png', fixed_length=True, verbose=True)</code>","text":"<p>Process and embed frames into a SLEAP labels file.</p> <p>This function loads, encodes, and writes frames to the HDF5 file in a single loop, making it easier to add progress monitoring.</p> <p>Parameters:</p> Name Type Description Default <code>labels_path</code> <code>str</code> <p>A string path to the SLEAP labels file.</p> required <code>frames_metadata</code> <code>list[dict]</code> <p>A list of dictionaries with frame metadata from prepare_frames_to_embed.</p> required <code>image_format</code> <code>str</code> <p>The image format to use for embedding. Valid formats are \"png\" (the default), \"jpg\" or \"hdf5\".</p> <code>'png'</code> <code>fixed_length</code> <code>bool</code> <p>If <code>True</code> (the default), the embedded images will be padded to the length of the largest image. If <code>False</code>, the images will be stored as variable length, which is smaller but may not be supported by all readers.</p> <code>True</code> <code>verbose</code> <code>bool</code> <p>If <code>True</code> (the default), display a progress bar for the embedding process.</p> <code>True</code> <p>Returns:</p> Type Description <code>dict[Video, Video]</code> <p>A dictionary mapping original Video objects to their embedded versions.</p> Source code in <code>sleap_io/io/slp.py</code> <pre><code>def process_and_embed_frames(\n    labels_path: str,\n    frames_metadata: list[dict],\n    image_format: str = \"png\",\n    fixed_length: bool = True,\n    verbose: bool = True,\n) -&gt; dict[Video, Video]:\n    \"\"\"Process and embed frames into a SLEAP labels file.\n\n    This function loads, encodes, and writes frames to the HDF5 file in a single loop,\n    making it easier to add progress monitoring.\n\n    Args:\n        labels_path: A string path to the SLEAP labels file.\n        frames_metadata: A list of dictionaries with frame metadata from\n            prepare_frames_to_embed.\n        image_format: The image format to use for embedding. Valid formats are \"png\"\n            (the default), \"jpg\" or \"hdf5\".\n        fixed_length: If `True` (the default), the embedded images will be padded to the\n            length of the largest image. If `False`, the images will be stored as\n            variable length, which is smaller but may not be supported by all readers.\n        verbose: If `True` (the default), display a progress bar for the embedding\n            process.\n\n    Returns:\n        A dictionary mapping original Video objects to their embedded versions.\n    \"\"\"\n    # Initialize a dictionary to store data by group\n    data_by_group = {}\n\n    # Process all frames in a single flat loop with progress bar if verbose\n    frame_iter = (\n        tqdm(frames_metadata, desc=\"Embedding frames\", disable=not verbose)\n        if verbose\n        else frames_metadata\n    )\n    for frame_meta in frame_iter:\n        video = frame_meta[\"video\"]\n        frame_idx = frame_meta[\"frame_idx\"]\n        group = frame_meta[\"group\"]\n\n        # Initialize group data structure if this is the first frame for this group\n        if group not in data_by_group:\n            data_by_group[group] = {\n                \"video\": video,  # All frames in a group are from the same video\n                \"frame_inds\": [],\n                \"imgs_data\": [],\n            }\n\n        # Load the frame\n        frame = video[frame_idx]\n\n        # Encode the frame\n        if image_format == \"hdf5\":\n            img_data = frame\n        else:\n            if \"cv2\" in sys.modules:\n                img_data = np.squeeze(\n                    cv2.imencode(\".\" + image_format, frame)[1]\n                ).astype(\"int8\")\n            else:\n                if frame.shape[-1] == 1:\n                    frame = frame.squeeze(axis=-1)\n                img_data = np.frombuffer(\n                    iio.imwrite(\"&lt;bytes&gt;\", frame, extension=\".\" + image_format),\n                    dtype=\"int8\",\n                )\n\n        # Store frame data in the appropriate group\n        data_by_group[group][\"imgs_data\"].append(img_data)\n        data_by_group[group][\"frame_inds\"].append(frame_idx)\n\n    # Write all frame data to the HDF5 file\n    replaced_videos = {}\n    with h5py.File(labels_path, \"a\") as f:\n        for group, data in data_by_group.items():\n            video = data[\"video\"]\n            frame_inds = data[\"frame_inds\"]\n            imgs_data = data[\"imgs_data\"]\n\n            if image_format == \"hdf5\":\n                f.create_dataset(\n                    f\"{group}/video\", data=imgs_data, compression=\"gzip\", chunks=True\n                )\n                ds = f[f\"{group}/video\"]\n            else:\n                if fixed_length:\n                    img_bytes_len = 0\n                    for img in imgs_data:\n                        img_bytes_len = max(img_bytes_len, len(img))\n                    ds = f.create_dataset(\n                        f\"{group}/video\",\n                        shape=(len(imgs_data), img_bytes_len),\n                        dtype=\"int8\",\n                        compression=\"gzip\",\n                    )\n                    for i, img in enumerate(imgs_data):\n                        ds[i, : len(img)] = img\n                else:\n                    ds = f.create_dataset(\n                        f\"{group}/video\",\n                        shape=(len(imgs_data),),\n                        dtype=h5py.special_dtype(vlen=np.dtype(\"int8\")),\n                    )\n                    for i, img in enumerate(imgs_data):\n                        ds[i] = img\n\n            # Store metadata\n            ds.attrs[\"format\"] = image_format\n            video_shape = video.shape\n            (\n                ds.attrs[\"frames\"],\n                ds.attrs[\"height\"],\n                ds.attrs[\"width\"],\n                ds.attrs[\"channels\"],\n            ) = video_shape\n\n            # Store frame indices\n            f.create_dataset(f\"{group}/frame_numbers\", data=frame_inds)\n\n            # Store source video\n            if video.source_video is not None:\n                source_video = video.source_video\n            else:\n                source_video = video\n\n            # Create embedded video object\n            embedded_video = Video(\n                filename=labels_path,\n                backend=VideoBackend.from_filename(\n                    labels_path,\n                    dataset=f\"{group}/video\",\n                    grayscale=video.grayscale,\n                    keep_open=False,\n                ),\n                source_video=source_video,\n            )\n\n            # Store source video metadata\n            grp = f.require_group(f\"{group}/source_video\")\n            grp.attrs[\"json\"] = json.dumps(\n                video_to_dict(source_video, labels_path), separators=(\",\", \":\")\n            )\n\n            # Store the embedded video for return\n            replaced_videos[video] = embedded_video\n\n    return replaced_videos\n</code></pre>"},{"location":"reference/sleap_io/io/slp/#sleap_io.io.slp.read_instances","title":"<code>read_instances(labels_path, skeletons, tracks, points, pred_points, format_id)</code>","text":"<p>Read <code>Instance</code> dataset in a SLEAP labels file.</p> <p>Parameters:</p> Name Type Description Default <code>labels_path</code> <code>str</code> <p>A string path to the SLEAP labels file.</p> required <code>skeletons</code> <code>list[Skeleton]</code> <p>A list of <code>Skeleton</code> objects (see <code>read_skeletons</code>).</p> required <code>tracks</code> <code>list[Track]</code> <p>A list of <code>Track</code> objects (see <code>read_tracks</code>).</p> required <code>points</code> <code>ndarray</code> <p>A structured array of point data (see <code>read_points</code>).</p> required <code>pred_points</code> <code>ndarray</code> <p>A structured array of predicted point data (see <code>read_pred_points</code>).</p> required <code>format_id</code> <code>float</code> <p>The format version identifier used to specify the format of the input file.</p> required <p>Returns:</p> Type Description <code>list[Union[Instance, PredictedInstance]]</code> <p>A list of <code>Instance</code> and/or <code>PredictedInstance</code> objects.</p> Source code in <code>sleap_io/io/slp.py</code> <pre><code>def read_instances(\n    labels_path: str,\n    skeletons: list[Skeleton],\n    tracks: list[Track],\n    points: np.ndarray,\n    pred_points: np.ndarray,\n    format_id: float,\n) -&gt; list[Union[Instance, PredictedInstance]]:\n    \"\"\"Read `Instance` dataset in a SLEAP labels file.\n\n    Args:\n        labels_path: A string path to the SLEAP labels file.\n        skeletons: A list of `Skeleton` objects (see `read_skeletons`).\n        tracks: A list of `Track` objects (see `read_tracks`).\n        points: A structured array of point data (see `read_points`).\n        pred_points: A structured array of predicted point data (see\n            `read_pred_points`).\n        format_id: The format version identifier used to specify the format of the input\n            file.\n\n    Returns:\n        A list of `Instance` and/or `PredictedInstance` objects.\n    \"\"\"\n    instances_data = read_hdf5_dataset(labels_path, \"instances\")\n\n    instances = {}\n    from_predicted_pairs = []\n    for instance_data in instances_data:\n        if format_id &lt; 1.2:\n            (\n                instance_id,\n                instance_type,\n                frame_id,\n                skeleton_id,\n                track_id,\n                from_predicted,\n                instance_score,\n                point_id_start,\n                point_id_end,\n            ) = instance_data\n            tracking_score = 0.0\n        elif format_id &gt;= 1.2:\n            (\n                instance_id,\n                instance_type,\n                frame_id,\n                skeleton_id,\n                track_id,\n                from_predicted,\n                instance_score,\n                point_id_start,\n                point_id_end,\n                tracking_score,\n            ) = instance_data\n\n        skeleton = skeletons[skeleton_id]\n        track = tracks[track_id] if track_id &gt;= 0 else None\n\n        if instance_type == InstanceType.USER:\n            pts_data = points[point_id_start:point_id_end]\n            coords = np.column_stack([pts_data[\"x\"], pts_data[\"y\"]])\n            if format_id &lt; 1.1:\n                # Legacy coordinate system: top-left of pixel is (0, 0)\n                # Adjust to new system: center of pixel is (0, 0)\n                coords = coords - 0.5\n            inst = Instance(\n                coords,\n                skeleton=skeleton,\n                track=track,\n                tracking_score=tracking_score,\n            )\n            inst.points[\"visible\"] = pts_data[\"visible\"]\n            inst.points[\"complete\"] = pts_data[\"complete\"]\n            instances[instance_id] = inst\n\n        elif instance_type == InstanceType.PREDICTED:\n            pts_data = pred_points[point_id_start:point_id_end]\n            coords = np.column_stack([pts_data[\"x\"], pts_data[\"y\"]])\n            if format_id &lt; 1.1:\n                # Legacy coordinate system: top-left of pixel is (0, 0)\n                # Adjust to new system: center of pixel is (0, 0)\n                coords = coords - 0.5\n            inst = PredictedInstance(\n                coords,\n                skeleton=skeleton,\n                track=track,\n                score=instance_score,\n                tracking_score=tracking_score,\n            )\n            inst.points[\"score\"] = pts_data[\"score\"]\n            inst.points[\"visible\"] = pts_data[\"visible\"]\n            inst.points[\"complete\"] = pts_data[\"complete\"]\n            instances[instance_id] = inst\n\n        if from_predicted &gt;= 0:\n            from_predicted_pairs.append((instance_id, from_predicted))\n\n    # Link instances based on from_predicted field.\n    for instance_id, from_predicted in from_predicted_pairs:\n        instances[instance_id].from_predicted = instances[from_predicted]\n\n    # Convert instances back to list.\n    instances = list(instances.values())\n\n    return instances\n</code></pre>"},{"location":"reference/sleap_io/io/slp/#sleap_io.io.slp.read_labels","title":"<code>read_labels(labels_path, open_videos=True)</code>","text":"<p>Read a SLEAP labels file.</p> <p>Parameters:</p> Name Type Description Default <code>labels_path</code> <code>str</code> <p>A string path to the SLEAP labels file.</p> required <code>open_videos</code> <code>bool</code> <p>If <code>True</code> (the default), attempt to open the video backend for I/O. If <code>False</code>, the backend will not be opened (useful for reading metadata when the video files are not available).</p> <code>True</code> <p>Returns:</p> Type Description <code>Labels</code> <p>The processed <code>Labels</code> object.</p> Source code in <code>sleap_io/io/slp.py</code> <pre><code>def read_labels(labels_path: str, open_videos: bool = True) -&gt; Labels:\n    \"\"\"Read a SLEAP labels file.\n\n    Args:\n        labels_path: A string path to the SLEAP labels file.\n        open_videos: If `True` (the default), attempt to open the video backend for\n            I/O. If `False`, the backend will not be opened (useful for reading metadata\n            when the video files are not available).\n\n    Returns:\n        The processed `Labels` object.\n    \"\"\"\n    tracks = read_tracks(labels_path)\n    videos = read_videos(labels_path, open_backend=open_videos)\n    skeletons = read_skeletons(labels_path)\n    points = read_points(labels_path)\n    pred_points = read_pred_points(labels_path)\n    format_id = read_hdf5_attrs(labels_path, \"metadata\", \"format_id\")\n    instances = read_instances(\n        labels_path, skeletons, tracks, points, pred_points, format_id\n    )\n    suggestions = read_suggestions(labels_path, videos)\n    metadata = read_metadata(labels_path)\n    provenance = metadata.get(\"provenance\", dict())\n\n    frames = read_hdf5_dataset(labels_path, \"frames\")\n    labeled_frames = []\n    for _, video_id, frame_idx, instance_id_start, instance_id_end in frames:\n        labeled_frames.append(\n            LabeledFrame(\n                video=videos[video_id],\n                frame_idx=int(frame_idx),\n                instances=instances[instance_id_start:instance_id_end],\n            )\n        )\n\n    sessions = read_sessions(labels_path, videos, labeled_frames)\n\n    labels = Labels(\n        labeled_frames=labeled_frames,\n        videos=videos,\n        skeletons=skeletons,\n        tracks=tracks,\n        suggestions=suggestions,\n        sessions=sessions,\n        provenance=provenance,\n    )\n    labels.provenance[\"filename\"] = labels_path\n\n    return labels\n</code></pre>"},{"location":"reference/sleap_io/io/slp/#sleap_io.io.slp.read_labels_set","title":"<code>read_labels_set(path, open_videos=True)</code>","text":"<p>Load a LabelsSet from multiple SLP files.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Union[str, Path, list[Union[str, Path]], dict[str, Union[str, Path]]]</code> <p>Can be one of: - A directory path containing .slp files - A list of .slp file paths - A dictionary mapping names to .slp file paths</p> required <code>open_videos</code> <code>bool</code> <p>If <code>True</code> (the default), attempt to open the video backend for I/O. If <code>False</code>, the backend will not be opened.</p> <code>True</code> <p>Returns:</p> Type Description <code>LabelsSet</code> <p>A LabelsSet containing the loaded Labels objects.</p> <p>Examples:</p> <p>Load from directory:</p> <pre><code>&gt;&gt;&gt; labels_set = read_labels_set(\"path/to/splits/\")\n</code></pre> <p>Load from list:</p> <pre><code>&gt;&gt;&gt; labels_set = read_labels_set([\"train.slp\", \"val.slp\", \"test.slp\"])\n</code></pre> <p>Load from dictionary:</p> <pre><code>&gt;&gt;&gt; labels_set = read_labels_set({\"train\": \"train.slp\", \"val\": \"val.slp\"})\n</code></pre> Source code in <code>sleap_io/io/slp.py</code> <pre><code>def read_labels_set(\n    path: Union[str, Path, list[Union[str, Path]], dict[str, Union[str, Path]]],\n    open_videos: bool = True,\n) -&gt; LabelsSet:\n    \"\"\"Load a LabelsSet from multiple SLP files.\n\n    Args:\n        path: Can be one of:\n            - A directory path containing .slp files\n            - A list of .slp file paths\n            - A dictionary mapping names to .slp file paths\n        open_videos: If `True` (the default), attempt to open the video backend for\n            I/O. If `False`, the backend will not be opened.\n\n    Returns:\n        A LabelsSet containing the loaded Labels objects.\n\n    Examples:\n        Load from directory:\n        &gt;&gt;&gt; labels_set = read_labels_set(\"path/to/splits/\")\n\n        Load from list:\n        &gt;&gt;&gt; labels_set = read_labels_set([\"train.slp\", \"val.slp\", \"test.slp\"])\n\n        Load from dictionary:\n        &gt;&gt;&gt; labels_set = read_labels_set({\"train\": \"train.slp\", \"val\": \"val.slp\"})\n    \"\"\"\n    from sleap_io.model.labels_set import LabelsSet\n\n    labels_dict = {}\n\n    if isinstance(path, dict):\n        # Dictionary of name -&gt; path mappings\n        for name, file_path in path.items():\n            labels_dict[name] = read_labels(str(file_path), open_videos=open_videos)\n\n    elif isinstance(path, list):\n        # List of paths - auto-generate names\n        for i, file_path in enumerate(path):\n            file_path = Path(file_path)\n            # Use filename without extension as key, or fall back to generic name\n            name = file_path.stem if file_path.stem else f\"labels_{i}\"\n            labels_dict[name] = read_labels(str(file_path), open_videos=open_videos)\n\n    else:\n        # Directory path - find all .slp files\n        path = Path(path)\n        if not path.is_dir():\n            raise ValueError(f\"Path must be a directory, list, or dict. Got: {path}\")\n\n        slp_files = sorted(path.glob(\"*.slp\"))\n        if not slp_files:\n            raise ValueError(f\"No .slp files found in directory: {path}\")\n\n        for slp_file in slp_files:\n            # Use filename without extension as key\n            name = slp_file.stem\n            labels_dict[name] = read_labels(str(slp_file), open_videos=open_videos)\n\n    return LabelsSet(labels=labels_dict)\n</code></pre>"},{"location":"reference/sleap_io/io/slp/#sleap_io.io.slp.read_metadata","title":"<code>read_metadata(labels_path)</code>","text":"<p>Read metadata from a SLEAP labels file.</p> <p>Parameters:</p> Name Type Description Default <code>labels_path</code> <code>str</code> <p>A string path to the SLEAP labels file.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>A dict containing the metadata from a SLEAP labels file.</p> Source code in <code>sleap_io/io/slp.py</code> <pre><code>def read_metadata(labels_path: str) -&gt; dict:\n    \"\"\"Read metadata from a SLEAP labels file.\n\n    Args:\n        labels_path: A string path to the SLEAP labels file.\n\n    Returns:\n        A dict containing the metadata from a SLEAP labels file.\n    \"\"\"\n    md = read_hdf5_attrs(labels_path, \"metadata\", \"json\")\n    return json.loads(md.decode())\n</code></pre>"},{"location":"reference/sleap_io/io/slp/#sleap_io.io.slp.read_points","title":"<code>read_points(labels_path)</code>","text":"<p>Read points dataset from a SLEAP labels file.</p> <p>Parameters:</p> Name Type Description Default <code>labels_path</code> <code>str</code> <p>A string path to the SLEAP labels file.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>A structured array of point data.</p> Source code in <code>sleap_io/io/slp.py</code> <pre><code>def read_points(labels_path: str) -&gt; np.ndarray:\n    \"\"\"Read points dataset from a SLEAP labels file.\n\n    Args:\n        labels_path: A string path to the SLEAP labels file.\n\n    Returns:\n        A structured array of point data.\n    \"\"\"\n    pts = read_hdf5_dataset(labels_path, \"points\")\n    return pts\n</code></pre>"},{"location":"reference/sleap_io/io/slp/#sleap_io.io.slp.read_pred_points","title":"<code>read_pred_points(labels_path)</code>","text":"<p>Read predicted points dataset from a SLEAP labels file.</p> <p>Parameters:</p> Name Type Description Default <code>labels_path</code> <code>str</code> <p>A string path to the SLEAP labels file.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>A structured array of predicted point data.</p> Source code in <code>sleap_io/io/slp.py</code> <pre><code>def read_pred_points(labels_path: str) -&gt; np.ndarray:\n    \"\"\"Read predicted points dataset from a SLEAP labels file.\n\n    Args:\n        labels_path: A string path to the SLEAP labels file.\n\n    Returns:\n        A structured array of predicted point data.\n    \"\"\"\n    pred_pts = read_hdf5_dataset(labels_path, \"pred_points\")\n    return pred_pts\n</code></pre>"},{"location":"reference/sleap_io/io/slp/#sleap_io.io.slp.read_sessions","title":"<code>read_sessions(labels_path, videos, labeled_frames)</code>","text":"<p>Read <code>RecordingSession</code> dataset from a SLEAP labels file.</p> <p>Expects a \"sessions_json\" dataset in the <code>labels_path</code> file, but will return an empty list if the dataset is not found.</p> <p>Parameters:</p> Name Type Description Default <code>labels_path</code> <code>str</code> <p>A string path to the SLEAP labels file.</p> required <code>videos</code> <code>list[Video]</code> <p>A list of <code>Video</code> objects.</p> required <code>labeled_frames</code> <code>list[LabeledFrame]</code> <p>A list of <code>LabeledFrame</code> objects.</p> required <p>Returns:</p> Type Description <code>list[RecordingSession]</code> <p>A list of <code>RecordingSession</code> objects.</p> Source code in <code>sleap_io/io/slp.py</code> <pre><code>def read_sessions(\n    labels_path: str, videos: list[Video], labeled_frames: list[LabeledFrame]\n) -&gt; list[RecordingSession]:\n    \"\"\"Read `RecordingSession` dataset from a SLEAP labels file.\n\n    Expects a \"sessions_json\" dataset in the `labels_path` file, but will return an\n    empty list if the dataset is not found.\n\n    Args:\n        labels_path: A string path to the SLEAP labels file.\n        videos: A list of `Video` objects.\n        labeled_frames: A list of `LabeledFrame` objects.\n\n    Returns:\n        A list of `RecordingSession` objects.\n    \"\"\"\n    try:\n        sessions = read_hdf5_dataset(labels_path, \"sessions_json\")\n    except KeyError:\n        return []\n    sessions = [json.loads(x) for x in sessions]\n    session_objects = []\n    for session in sessions:\n        session_objects.append(make_session(session, videos, labeled_frames))\n    return session_objects\n</code></pre>"},{"location":"reference/sleap_io/io/slp/#sleap_io.io.slp.read_skeletons","title":"<code>read_skeletons(labels_path)</code>","text":"<p>Read <code>Skeleton</code> dataset from a SLEAP labels file.</p> <p>Parameters:</p> Name Type Description Default <code>labels_path</code> <code>str</code> <p>A string that contains the path to the labels file.</p> required <p>Returns:</p> Type Description <code>list[Skeleton]</code> <p>A list of <code>Skeleton</code> objects.</p> Source code in <code>sleap_io/io/slp.py</code> <pre><code>def read_skeletons(labels_path: str) -&gt; list[Skeleton]:\n    \"\"\"Read `Skeleton` dataset from a SLEAP labels file.\n\n    Args:\n        labels_path: A string that contains the path to the labels file.\n\n    Returns:\n        A list of `Skeleton` objects.\n    \"\"\"\n    metadata = read_metadata(labels_path)\n\n    # Get node names. This is a superset of all nodes across all skeletons. Note that\n    # node ordering is specific to each skeleton, so we'll need to fix this afterwards.\n    node_names = [x[\"name\"] for x in metadata[\"nodes\"]]\n\n    # Use the SLP skeleton decoder\n    decoder = SkeletonSLPDecoder()\n    return decoder.decode(metadata, node_names)\n</code></pre>"},{"location":"reference/sleap_io/io/slp/#sleap_io.io.slp.read_suggestions","title":"<code>read_suggestions(labels_path, videos)</code>","text":"<p>Read <code>SuggestionFrame</code> dataset in a SLEAP labels file.</p> <p>Parameters:</p> Name Type Description Default <code>labels_path</code> <code>str</code> <p>A string path to the SLEAP labels file.</p> required <code>videos</code> <code>list[Video]</code> <p>A list of <code>Video</code> objects.</p> required <p>Returns:</p> Type Description <code>list[SuggestionFrame]</code> <p>A list of <code>SuggestionFrame</code> objects.</p> Source code in <code>sleap_io/io/slp.py</code> <pre><code>def read_suggestions(labels_path: str, videos: list[Video]) -&gt; list[SuggestionFrame]:\n    \"\"\"Read `SuggestionFrame` dataset in a SLEAP labels file.\n\n    Args:\n        labels_path: A string path to the SLEAP labels file.\n        videos: A list of `Video` objects.\n\n    Returns:\n        A list of `SuggestionFrame` objects.\n    \"\"\"\n    try:\n        suggestions = read_hdf5_dataset(labels_path, \"suggestions_json\")\n    except KeyError:\n        return []\n    suggestions = [json.loads(x) for x in suggestions]\n    suggestions_objects = []\n    for suggestion in suggestions:\n        suggestions_objects.append(\n            SuggestionFrame(\n                video=videos[int(suggestion[\"video\"])],\n                frame_idx=suggestion[\"frame_idx\"],\n            )\n        )\n    return suggestions_objects\n</code></pre>"},{"location":"reference/sleap_io/io/slp/#sleap_io.io.slp.read_tracks","title":"<code>read_tracks(labels_path)</code>","text":"<p>Read <code>Track</code> dataset in a SLEAP labels file.</p> <p>Parameters:</p> Name Type Description Default <code>labels_path</code> <code>str</code> <p>A string path to the SLEAP labels file.</p> required <p>Returns:</p> Type Description <code>list[Track]</code> <p>A list of <code>Track</code> objects.</p> Source code in <code>sleap_io/io/slp.py</code> <pre><code>def read_tracks(labels_path: str) -&gt; list[Track]:\n    \"\"\"Read `Track` dataset in a SLEAP labels file.\n\n    Args:\n        labels_path: A string path to the SLEAP labels file.\n\n    Returns:\n        A list of `Track` objects.\n    \"\"\"\n    tracks = [json.loads(x) for x in read_hdf5_dataset(labels_path, \"tracks_json\")]\n    track_objects = []\n    for track in tracks:\n        track_objects.append(Track(name=track[1]))\n    return track_objects\n</code></pre>"},{"location":"reference/sleap_io/io/slp/#sleap_io.io.slp.read_videos","title":"<code>read_videos(labels_path, open_backend=True)</code>","text":"<p>Read <code>Video</code> dataset in a SLEAP labels file.</p> <p>Parameters:</p> Name Type Description Default <code>labels_path</code> <code>str</code> <p>A string path to the SLEAP labels file.</p> required <code>open_backend</code> <code>bool</code> <p>If <code>True</code> (the default), attempt to open the video backend for I/O. If <code>False</code>, the backend will not be opened (useful for reading metadata when the video files are not available).</p> <code>True</code> <p>Returns:</p> Type Description <code>list[Video]</code> <p>A list of <code>Video</code> objects.</p> Source code in <code>sleap_io/io/slp.py</code> <pre><code>def read_videos(labels_path: str, open_backend: bool = True) -&gt; list[Video]:\n    \"\"\"Read `Video` dataset in a SLEAP labels file.\n\n    Args:\n        labels_path: A string path to the SLEAP labels file.\n        open_backend: If `True` (the default), attempt to open the video backend for\n            I/O. If `False`, the backend will not be opened (useful for reading metadata\n            when the video files are not available).\n\n    Returns:\n        A list of `Video` objects.\n    \"\"\"\n    videos = []\n    videos_metadata = read_hdf5_dataset(labels_path, \"videos_json\")\n    for video_data in videos_metadata:\n        video_json = json.loads(video_data)\n        video = make_video(labels_path, video_json, open_backend=open_backend)\n        videos.append(video)\n    return videos\n</code></pre>"},{"location":"reference/sleap_io/io/slp/#sleap_io.io.slp.serialize_skeletons","title":"<code>serialize_skeletons(skeletons)</code>","text":"<p>Serialize a list of <code>Skeleton</code> objects to JSON-compatible dicts.</p> <p>Parameters:</p> Name Type Description Default <code>skeletons</code> <code>list[Skeleton]</code> <p>A list of <code>Skeleton</code> objects.</p> required <p>Returns:</p> Type Description <code>tuple[list[dict], list[dict]]</code> <p>A tuple of <code>skeletons_dicts, nodes_dicts</code>.</p> <p><code>nodes_dicts</code> is a list of dicts containing the nodes in all the skeletons.</p> <p><code>skeletons_dicts</code> is a list of dicts containing the skeletons.</p> Notes <p>This function attempts to replicate the serialization of skeletons in legacy SLEAP which relies on a combination of networkx's graph serialization and our own metadata used to store nodes and edges independent of the graph structure.</p> <p>However, because sleap-io does not currently load in the legacy metadata, this function will not produce byte-level compatible serialization with legacy formats, even though the ordering and all attributes of nodes and edges should match up.</p> Source code in <code>sleap_io/io/slp.py</code> <pre><code>def serialize_skeletons(skeletons: list[Skeleton]) -&gt; tuple[list[dict], list[dict]]:\n    \"\"\"Serialize a list of `Skeleton` objects to JSON-compatible dicts.\n\n    Args:\n        skeletons: A list of `Skeleton` objects.\n\n    Returns:\n        A tuple of `skeletons_dicts, nodes_dicts`.\n\n        `nodes_dicts` is a list of dicts containing the nodes in all the skeletons.\n\n        `skeletons_dicts` is a list of dicts containing the skeletons.\n\n    Notes:\n        This function attempts to replicate the serialization of skeletons in legacy\n        SLEAP which relies on a combination of networkx's graph serialization and our\n        own metadata used to store nodes and edges independent of the graph structure.\n\n        However, because sleap-io does not currently load in the legacy metadata, this\n        function will not produce byte-level compatible serialization with legacy\n        formats, even though the ordering and all attributes of nodes and edges should\n        match up.\n    \"\"\"\n    # Use the SLP skeleton encoder\n    encoder = SkeletonSLPEncoder()\n    return encoder.encode_skeletons(skeletons)\n</code></pre>"},{"location":"reference/sleap_io/io/slp/#sleap_io.io.slp.session_to_dict","title":"<code>session_to_dict(session, video_to_idx, labeled_frame_to_idx)</code>","text":"<p>Convert <code>RecordingSession</code> to a dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>session</code> <code>RecordingSession</code> <p><code>RecordingSession</code> object to convert to a dictionary.</p> required <code>video_to_idx</code> <code>dict[Video, int]</code> <p>Dictionary of <code>Video</code> to index in <code>Labels.videos</code>.</p> required <code>labeled_frame_to_idx</code> <code>dict[LabeledFrame, int]</code> <p>Dictionary of <code>LabeledFrame</code> to index in <code>Labels.labeled_frames</code>.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary of <code>RecordingSession</code> with the following keys:     - \"calibration\": Dictionary containing calibration information for cameras.     - \"camcorder_to_video_idx_map\": Dictionary mapping camera index to video         index.     - \"frame_group_dicts\": List of dictionaries containing <code>FrameGroup</code>         information. See <code>frame_group_to_dict</code> for what each dictionary         contains.     - Any optional keys containing metadata.</p> Source code in <code>sleap_io/io/slp.py</code> <pre><code>def session_to_dict(\n    session: RecordingSession,\n    video_to_idx: dict[Video, int],\n    labeled_frame_to_idx: dict[LabeledFrame, int],\n) -&gt; dict:\n    \"\"\"Convert `RecordingSession` to a dictionary.\n\n    Args:\n        session: `RecordingSession` object to convert to a dictionary.\n        video_to_idx: Dictionary of `Video` to index in `Labels.videos`.\n        labeled_frame_to_idx: Dictionary of `LabeledFrame` to index in\n            `Labels.labeled_frames`.\n\n    Returns:\n        Dictionary of `RecordingSession` with the following keys:\n            - \"calibration\": Dictionary containing calibration information for cameras.\n            - \"camcorder_to_video_idx_map\": Dictionary mapping camera index to video\n                index.\n            - \"frame_group_dicts\": List of dictionaries containing `FrameGroup`\n                information. See `frame_group_to_dict` for what each dictionary\n                contains.\n            - Any optional keys containing metadata.\n    \"\"\"\n    # Unstructure `CameraCluster` and `metadata`\n    calibration_dict = camera_group_to_dict(session.camera_group)\n\n    # Store camera-to-video indices map where key is camera index\n    # and value is video index from `Labels.videos`\n    camera_to_video_idx_map = {}\n    for cam_idx, camera in enumerate(session.camera_group.cameras):\n        # Skip if Camera is not linked to any Video\n\n        if camera not in session.cameras:\n            continue\n\n        # Get video index from `Labels.videos`\n        video = session.get_video(camera)\n        video_idx = video_to_idx.get(video, None)\n\n        if video_idx is not None:\n            camera_to_video_idx_map[cam_idx] = video_idx\n        else:\n            print(\n                f\"Video {video} not found in `Labels.videos`. \"\n                \"Not saving to `RecordingSession` serialization.\"\n            )\n\n    # Store frame groups by frame index\n    frame_group_dicts = []\n    if len(labeled_frame_to_idx) &gt; 0:  # Don't save if skipping labeled frames\n        for frame_group in session.frame_groups.values():\n            # Only save `FrameGroup` if it has `InstanceGroup`s\n            if len(frame_group.instance_groups) &gt; 0:\n                frame_group_dict = frame_group_to_dict(\n                    frame_group,\n                    labeled_frame_to_idx=labeled_frame_to_idx,\n                    camera_group=session.camera_group,\n                )\n                frame_group_dicts.append(frame_group_dict)\n\n    session_dict = {\n        \"calibration\": calibration_dict,\n        \"camcorder_to_video_idx_map\": camera_to_video_idx_map,\n        \"frame_group_dicts\": frame_group_dicts,\n    }\n    session_dict.update(session.metadata)\n\n    return session_dict\n</code></pre>"},{"location":"reference/sleap_io/io/slp/#sleap_io.io.slp.video_to_dict","title":"<code>video_to_dict(video, labels_path=None)</code>","text":"<p>Convert a <code>Video</code> object to a JSON-compatible dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>video</code> <code>Video</code> <p>A <code>Video</code> object to convert.</p> required <code>labels_path</code> <code>Optional[str]</code> <p>Path to the labels file being written. Used to determine if the video should use a self-reference (\".\") or external reference.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict</code> <p>A dictionary containing the video metadata.</p> Source code in <code>sleap_io/io/slp.py</code> <pre><code>def video_to_dict(video: Video, labels_path: Optional[str] = None) -&gt; dict:\n    \"\"\"Convert a `Video` object to a JSON-compatible dictionary.\n\n    Args:\n        video: A `Video` object to convert.\n        labels_path: Path to the labels file being written. Used to determine if the\n            video should use a self-reference (\".\") or external reference.\n\n    Returns:\n        A dictionary containing the video metadata.\n    \"\"\"\n    video_filename = sanitize_filename(video.filename)\n    result = {\"filename\": video_filename}\n\n    # Add backend metadata\n    if video.backend is None:\n        result[\"backend\"] = video.backend_metadata\n    elif type(video.backend) is MediaVideo:\n        result[\"backend\"] = {\n            \"type\": \"MediaVideo\",\n            \"shape\": video.shape,\n            \"filename\": video_filename,\n            \"grayscale\": video.grayscale,\n            \"bgr\": True,\n            \"dataset\": \"\",\n            \"input_format\": \"\",\n        }\n    elif type(video.backend) is HDF5Video:\n        # Determine if we should use self-reference or external reference\n        use_self_reference = (\n            video.backend.has_embedded_images\n            and labels_path is not None\n            and Path(sanitize_filename(video.filename)).resolve()\n            == Path(sanitize_filename(labels_path)).resolve()\n        )\n\n        result[\"backend\"] = {\n            \"type\": \"HDF5Video\",\n            \"shape\": video.shape,\n            \"filename\": (\".\" if use_self_reference else video_filename),\n            \"dataset\": video.backend.dataset,\n            \"input_format\": video.backend.input_format,\n            \"convert_range\": False,\n            \"has_embedded_images\": video.backend.has_embedded_images,\n            \"grayscale\": video.grayscale,\n        }\n    elif type(video.backend) is ImageVideo:\n        if video.shape is not None:\n            height, width, channels = video.shape[1:4]\n        else:\n            height, width, channels = None, None, 3\n        result[\"backend\"] = {\n            \"type\": \"ImageVideo\",\n            \"shape\": video.shape,\n            \"filename\": sanitize_filename(video.backend.filename[0]),\n            \"filenames\": sanitize_filename(video.backend.filename),\n            \"height_\": height,\n            \"width_\": width,\n            \"channels_\": channels,\n            \"grayscale\": video.grayscale,\n        }\n    elif type(video.backend) is TiffVideo:\n        result[\"backend\"] = {\n            \"type\": \"TiffVideo\",\n            \"shape\": video.shape,\n            \"filename\": video_filename,\n            \"grayscale\": video.grayscale,\n            \"keep_open\": video.backend.keep_open,\n            \"format\": video.backend.format,\n        }\n\n    # Add source_video metadata if present\n    if hasattr(video, \"source_video\") and video.source_video is not None:\n        result[\"source_video\"] = video_to_dict(video.source_video, labels_path)\n\n    # Add original_video metadata if present\n    if hasattr(video, \"original_video\") and video.original_video is not None:\n        result[\"original_video\"] = video_to_dict(video.original_video, labels_path)\n\n    return result\n</code></pre>"},{"location":"reference/sleap_io/io/slp/#sleap_io.io.slp.write_labels","title":"<code>write_labels(labels_path, labels, embed=None, restore_original_videos=True, verbose=True)</code>","text":"<p>Write a SLEAP labels file.</p> <p>Parameters:</p> Name Type Description Default <code>labels_path</code> <code>str</code> <p>A string path to the SLEAP labels file to save.</p> required <code>labels</code> <code>Labels</code> <p>A <code>Labels</code> object to save.</p> required <code>embed</code> <code>bool | str | list[tuple[Video, int]] | None</code> <p>Frames to embed in the saved labels file. One of <code>None</code>, <code>True</code>, <code>\"all\"</code>, <code>\"user\"</code>, <code>\"suggestions\"</code>, <code>\"user+suggestions\"</code>, <code>\"source\"</code> or list of tuples of <code>(video, frame_idx)</code>.</p> <p>If <code>None</code> is specified (the default) and the labels contains embedded frames, those embedded frames will be re-saved to the new file.</p> <p>If <code>True</code> or <code>\"all\"</code>, all labeled frames and suggested frames will be embedded.</p> <p>If <code>\"source\"</code> is specified, no images will be embedded and the source video will be restored if available.</p> <p>This argument is only valid for the SLP backend.</p> <code>None</code> <code>restore_original_videos</code> <code>bool</code> <p>If <code>True</code> (default) and <code>embed=False</code>, use original video files. If <code>False</code> and <code>embed=False</code>, keep references to source <code>.pkg.slp</code> files. Only applies when <code>embed=False</code>.</p> <code>True</code> <code>verbose</code> <code>bool</code> <p>If <code>True</code> (the default), display a progress bar when embedding frames.</p> <code>True</code> Source code in <code>sleap_io/io/slp.py</code> <pre><code>def write_labels(\n    labels_path: str,\n    labels: Labels,\n    embed: bool | str | list[tuple[Video, int]] | None = None,\n    restore_original_videos: bool = True,\n    verbose: bool = True,\n):\n    \"\"\"Write a SLEAP labels file.\n\n    Args:\n        labels_path: A string path to the SLEAP labels file to save.\n        labels: A `Labels` object to save.\n        embed: Frames to embed in the saved labels file. One of `None`, `True`,\n            `\"all\"`, `\"user\"`, `\"suggestions\"`, `\"user+suggestions\"`, `\"source\"` or list\n            of tuples of `(video, frame_idx)`.\n\n            If `None` is specified (the default) and the labels contains embedded\n            frames, those embedded frames will be re-saved to the new file.\n\n            If `True` or `\"all\"`, all labeled frames and suggested frames will be\n            embedded.\n\n            If `\"source\"` is specified, no images will be embedded and the source video\n            will be restored if available.\n\n            This argument is only valid for the SLP backend.\n        restore_original_videos: If `True` (default) and `embed=False`, use original\n            video files. If `False` and `embed=False`, keep references to source\n            `.pkg.slp` files. Only applies when `embed=False`.\n        verbose: If `True` (the default), display a progress bar when embedding frames.\n    \"\"\"\n    if Path(labels_path).exists():\n        Path(labels_path).unlink()\n\n    # Store original videos before embedding modifies them\n    # We need to make a copy of the actual video objects, not just the list\n    original_videos = [v for v in labels.videos] if embed else None\n\n    if embed:\n        embed_videos(labels_path, labels, embed, verbose=verbose)\n\n    # Determine reference mode based on parameters\n    if embed == \"source\" or (embed is False and restore_original_videos):\n        reference_mode = VideoReferenceMode.RESTORE_ORIGINAL\n    elif embed is False and not restore_original_videos:\n        reference_mode = VideoReferenceMode.PRESERVE_SOURCE\n    else:\n        reference_mode = VideoReferenceMode.EMBED\n\n    write_videos(\n        labels_path,\n        labels.videos,\n        reference_mode=reference_mode,\n        original_videos=original_videos,\n        verbose=verbose,\n    )\n    write_tracks(labels_path, labels.tracks)\n    write_suggestions(labels_path, labels.suggestions, labels.videos)\n    write_sessions(labels_path, labels.sessions, labels.videos, labels.labeled_frames)\n    write_metadata(labels_path, labels)\n    write_lfs(labels_path, labels)\n</code></pre>"},{"location":"reference/sleap_io/io/slp/#sleap_io.io.slp.write_lfs","title":"<code>write_lfs(labels_path, labels)</code>","text":"<p>Write labeled frames, instances and points to a SLEAP labels file.</p> <p>Parameters:</p> Name Type Description Default <code>labels_path</code> <code>str</code> <p>A string path to the SLEAP labels file.</p> required <code>labels</code> <code>Labels</code> <p>A <code>Labels</code> object to store the metadata for.</p> required Source code in <code>sleap_io/io/slp.py</code> <pre><code>def write_lfs(labels_path: str, labels: Labels):\n    \"\"\"Write labeled frames, instances and points to a SLEAP labels file.\n\n    Args:\n        labels_path: A string path to the SLEAP labels file.\n        labels: A `Labels` object to store the metadata for.\n    \"\"\"\n    # We store the data in structured arrays for performance, so we first define the\n    # dtype fields.\n    instance_dtype = np.dtype(\n        [\n            (\"instance_id\", \"i8\"),\n            (\"instance_type\", \"u1\"),\n            (\"frame_id\", \"u8\"),\n            (\"skeleton\", \"u4\"),\n            (\"track\", \"i4\"),\n            (\"from_predicted\", \"i8\"),\n            (\"score\", \"f4\"),\n            (\"point_id_start\", \"u8\"),\n            (\"point_id_end\", \"u8\"),\n            (\"tracking_score\", \"f4\"),  # FORMAT_ID &gt;= 1.2 (1.3 adds explicit handling)\n        ]\n    )\n    frame_dtype = np.dtype(\n        [\n            (\"frame_id\", \"u8\"),\n            (\"video\", \"u4\"),\n            (\"frame_idx\", \"u8\"),\n            (\"instance_id_start\", \"u8\"),\n            (\"instance_id_end\", \"u8\"),\n        ]\n    )\n    point_dtype = np.dtype(\n        [(\"x\", \"f8\"), (\"y\", \"f8\"), (\"visible\", \"?\"), (\"complete\", \"?\")]\n    )\n    predicted_point_dtype = np.dtype(\n        [(\"x\", \"f8\"), (\"y\", \"f8\"), (\"visible\", \"?\"), (\"complete\", \"?\"), (\"score\", \"f8\")]\n    )\n\n    # Next, we extract the data from the labels object into lists with the same fields.\n    frames, instances, points, predicted_points, to_link = [], [], [], [], []\n    inst_to_id = {}\n    for lf in labels:\n        frame_id = len(frames)\n        instance_id_start = len(instances)\n        for inst in lf:\n            instance_id = len(instances)\n            inst_to_id[id(inst)] = instance_id\n            skeleton_id = labels.skeletons.index(inst.skeleton)\n            track = labels.tracks.index(inst.track) if inst.track else -1\n            from_predicted = -1\n            if inst.from_predicted:\n                to_link.append((instance_id, inst.from_predicted))\n            score = 0.0\n\n            if type(inst) is Instance:\n                instance_type = InstanceType.USER\n                tracking_score = inst.tracking_score\n                point_id_start = len(points)\n\n                for pt in inst.points:\n                    points.append(\n                        [pt[\"xy\"][0], pt[\"xy\"][1], pt[\"visible\"], pt[\"complete\"]]\n                    )\n\n                point_id_end = len(points)\n\n            elif type(inst) is PredictedInstance:\n                instance_type = InstanceType.PREDICTED\n                score = inst.score\n                tracking_score = inst.tracking_score\n                point_id_start = len(predicted_points)\n\n                for pt in inst.points:\n                    predicted_points.append(\n                        [\n                            pt[\"xy\"][0],\n                            pt[\"xy\"][1],\n                            pt[\"visible\"],\n                            pt[\"complete\"],\n                            pt[\"score\"],\n                        ]\n                    )\n\n                point_id_end = len(predicted_points)\n\n            else:\n                raise ValueError(f\"Unknown instance type: {type(inst)}\")\n\n            instances.append(\n                [\n                    instance_id,\n                    int(instance_type),\n                    frame_id,\n                    skeleton_id,\n                    track,\n                    from_predicted,\n                    score,\n                    point_id_start,\n                    point_id_end,\n                    tracking_score,\n                ]\n            )\n\n        instance_id_end = len(instances)\n\n        frames.append(\n            [\n                frame_id,\n                labels.videos.index(lf.video),\n                lf.frame_idx,\n                instance_id_start,\n                instance_id_end,\n            ]\n        )\n\n    # Link instances based on from_predicted field.\n    for instance_id, from_predicted in to_link:\n        # Source instance may be missing if predictions were removed from the labels, in\n        # which case, remove the link.\n        instances[instance_id][5] = inst_to_id.get(id(from_predicted), -1)\n\n    # Create structured arrays.\n    points = np.array([tuple(x) for x in points], dtype=point_dtype)\n    predicted_points = np.array(\n        [tuple(x) for x in predicted_points], dtype=predicted_point_dtype\n    )\n    instances = np.array([tuple(x) for x in instances], dtype=instance_dtype)\n    frames = np.array([tuple(x) for x in frames], dtype=frame_dtype)\n\n    # Write to file.\n    with h5py.File(labels_path, \"a\") as f:\n        f.create_dataset(\"points\", data=points, dtype=points.dtype)\n        f.create_dataset(\n            \"pred_points\",\n            data=predicted_points,\n            dtype=predicted_points.dtype,\n        )\n        f.create_dataset(\n            \"instances\",\n            data=instances,\n            dtype=instances.dtype,\n        )\n        f.create_dataset(\n            \"frames\",\n            data=frames,\n            dtype=frames.dtype,\n        )\n</code></pre>"},{"location":"reference/sleap_io/io/slp/#sleap_io.io.slp.write_metadata","title":"<code>write_metadata(labels_path, labels)</code>","text":"<p>Write metadata to a SLEAP labels file.</p> <p>This function will write the skeletons and provenance for the labels.</p> <p>Parameters:</p> Name Type Description Default <code>labels_path</code> <code>str</code> <p>A string path to the SLEAP labels file.</p> required <code>labels</code> <code>Labels</code> <p>A <code>Labels</code> object to store the metadata for.</p> required <p>See also: serialize_skeletons</p> Source code in <code>sleap_io/io/slp.py</code> <pre><code>def write_metadata(labels_path: str, labels: Labels):\n    \"\"\"Write metadata to a SLEAP labels file.\n\n    This function will write the skeletons and provenance for the labels.\n\n    Args:\n        labels_path: A string path to the SLEAP labels file.\n        labels: A `Labels` object to store the metadata for.\n\n    See also: serialize_skeletons\n    \"\"\"\n    skeletons_dicts, nodes_dicts = serialize_skeletons(labels.skeletons)\n\n    md = {\n        \"version\": \"2.0.0\",\n        \"skeletons\": skeletons_dicts,\n        \"nodes\": nodes_dicts,\n        \"videos\": [],\n        \"tracks\": [],\n        \"suggestions\": [],  # TODO: Handle suggestions metadata.\n        \"negative_anchors\": {},\n        \"provenance\": labels.provenance,\n    }\n\n    # Custom encoding.\n    for k in md[\"provenance\"]:\n        if isinstance(md[\"provenance\"][k], Path):\n            # Path -&gt; str\n            md[\"provenance\"][k] = md[\"provenance\"][k].as_posix()\n\n    with h5py.File(labels_path, \"a\") as f:\n        grp = f.require_group(\"metadata\")\n        grp.attrs[\"format_id\"] = 1.3\n        grp.attrs[\"json\"] = np.bytes_(json.dumps(md, separators=(\",\", \":\")))\n</code></pre>"},{"location":"reference/sleap_io/io/slp/#sleap_io.io.slp.write_sessions","title":"<code>write_sessions(labels_path, sessions, videos, labeled_frames)</code>","text":"<p>Write <code>RecordingSession</code> metadata to a SLEAP labels file.</p> <p>Creates a new dataset \"sessions_json\" in the <code>labels_path</code> file to store the sessions data.</p> <p>Parameters:</p> Name Type Description Default <code>labels_path</code> <code>str</code> <p>A string path to the SLEAP labels file.</p> required <code>sessions</code> <code>list[RecordingSession]</code> <p>A list of <code>RecordingSession</code> objects to store in the <code>labels_path</code> file.</p> required <code>videos</code> <code>list[Video]</code> <p>A list of <code>Video</code> objects referenced in the <code>RecordingSession</code>s (expecting <code>Labels.videos</code>).</p> required <code>labeled_frames</code> <code>list[LabeledFrame]</code> <p>A list of <code>LabeledFrame</code> objects referenced in the <code>RecordingSession</code>s (expecting <code>Labels.labeled_frames</code>).</p> required Source code in <code>sleap_io/io/slp.py</code> <pre><code>def write_sessions(\n    labels_path: str,\n    sessions: list[RecordingSession],\n    videos: list[Video],\n    labeled_frames: list[LabeledFrame],\n):\n    \"\"\"Write `RecordingSession` metadata to a SLEAP labels file.\n\n    Creates a new dataset \"sessions_json\" in the `labels_path` file to store the\n    sessions data.\n\n    Args:\n        labels_path: A string path to the SLEAP labels file.\n        sessions: A list of `RecordingSession` objects to store in the `labels_path`\n            file.\n        videos: A list of `Video` objects referenced in the `RecordingSession`s\n            (expecting `Labels.videos`).\n        labeled_frames: A list of `LabeledFrame` objects referenced in the\n            `RecordingSession`s (expecting `Labels.labeled_frames`).\n    \"\"\"\n    sessions_json = []\n    if len(sessions) &gt; 0:\n        labeled_frame_to_idx = {lf: i for i, lf in enumerate(labeled_frames)}\n        video_to_idx = {video: i for i, video in enumerate(videos)}\n    for session in sessions:\n        session_json = session_to_dict(\n            session=session,\n            video_to_idx=video_to_idx,\n            labeled_frame_to_idx=labeled_frame_to_idx,\n        )\n        sessions_json.append(np.bytes_(json.dumps(session_json, separators=(\",\", \":\"))))\n\n    with h5py.File(labels_path, \"a\") as f:\n        f.create_dataset(\"sessions_json\", data=sessions_json, maxshape=(None,))\n</code></pre>"},{"location":"reference/sleap_io/io/slp/#sleap_io.io.slp.write_suggestions","title":"<code>write_suggestions(labels_path, suggestions, videos)</code>","text":"<p>Write track metadata to a SLEAP labels file.</p> <p>Parameters:</p> Name Type Description Default <code>labels_path</code> <code>str</code> <p>A string path to the SLEAP labels file.</p> required <code>suggestions</code> <code>list[SuggestionFrame]</code> <p>A list of <code>SuggestionFrame</code> objects to store the metadata for.</p> required <code>videos</code> <code>list[Video]</code> <p>A list of <code>Video</code> objects.</p> required Source code in <code>sleap_io/io/slp.py</code> <pre><code>def write_suggestions(\n    labels_path: str, suggestions: list[SuggestionFrame], videos: list[Video]\n):\n    \"\"\"Write track metadata to a SLEAP labels file.\n\n    Args:\n        labels_path: A string path to the SLEAP labels file.\n        suggestions: A list of `SuggestionFrame` objects to store the metadata for.\n        videos: A list of `Video` objects.\n    \"\"\"\n    GROUP = 0  # TODO: Handle storing extraneous metadata.\n    suggestions_json = []\n    for suggestion in suggestions:\n        suggestion_dict = {\n            \"video\": str(videos.index(suggestion.video)),\n            \"frame_idx\": suggestion.frame_idx,\n            \"group\": GROUP,\n        }\n        suggestion_json = np.bytes_(json.dumps(suggestion_dict, separators=(\",\", \":\")))\n        suggestions_json.append(suggestion_json)\n\n    with h5py.File(labels_path, \"a\") as f:\n        f.create_dataset(\"suggestions_json\", data=suggestions_json, maxshape=(None,))\n</code></pre>"},{"location":"reference/sleap_io/io/slp/#sleap_io.io.slp.write_tracks","title":"<code>write_tracks(labels_path, tracks)</code>","text":"<p>Write track metadata to a SLEAP labels file.</p> <p>Parameters:</p> Name Type Description Default <code>labels_path</code> <code>str</code> <p>A string path to the SLEAP labels file.</p> required <code>tracks</code> <code>list[Track]</code> <p>A list of <code>Track</code> objects to store the metadata for.</p> required Source code in <code>sleap_io/io/slp.py</code> <pre><code>def write_tracks(labels_path: str, tracks: list[Track]):\n    \"\"\"Write track metadata to a SLEAP labels file.\n\n    Args:\n        labels_path: A string path to the SLEAP labels file.\n        tracks: A list of `Track` objects to store the metadata for.\n    \"\"\"\n    # TODO: Add support for track metadata like spawned on frame.\n    SPAWNED_ON = 0\n    tracks_json = [\n        np.bytes_(json.dumps([SPAWNED_ON, track.name], separators=(\",\", \":\")))\n        for track in tracks\n    ]\n    with h5py.File(labels_path, \"a\") as f:\n        f.create_dataset(\"tracks_json\", data=tracks_json, maxshape=(None,))\n</code></pre>"},{"location":"reference/sleap_io/io/slp/#sleap_io.io.slp.write_videos","title":"<code>write_videos(labels_path, videos, restore_source=False, reference_mode=None, original_videos=None, verbose=True)</code>","text":"<p>Write video metadata to a SLEAP labels file.</p> <p>Parameters:</p> Name Type Description Default <code>labels_path</code> <code>str</code> <p>A string path to the SLEAP labels file.</p> required <code>videos</code> <code>list[Video]</code> <p>A list of <code>Video</code> objects to store the metadata for.</p> required <code>restore_source</code> <code>bool</code> <p>Deprecated. Use reference_mode instead. If <code>True</code>, restore source videos if available and will not re-embed the embedded images. If <code>False</code> (the default), will re-embed images that were previously embedded.</p> <code>False</code> <code>reference_mode</code> <code>Optional[VideoReferenceMode]</code> <p>How to handle video references: - EMBED: Re-embed frames that were previously embedded - RESTORE_ORIGINAL: Use original video if available - PRESERVE_SOURCE: Keep reference to source file (e.g., .pkg.slp)</p> <code>None</code> <code>original_videos</code> <code>list[Video] | None</code> <p>Optional list of original video objects before embedding. Used when reference_mode is EMBED to preserve metadata.</p> <code>None</code> <code>verbose</code> <code>bool</code> <p>If <code>True</code> (the default), display a progress bar when embedding frames.</p> <code>True</code> Source code in <code>sleap_io/io/slp.py</code> <pre><code>def write_videos(\n    labels_path: str,\n    videos: list[Video],\n    restore_source: bool = False,\n    reference_mode: Optional[VideoReferenceMode] = None,\n    original_videos: list[Video] | None = None,\n    verbose: bool = True,\n):\n    \"\"\"Write video metadata to a SLEAP labels file.\n\n    Args:\n        labels_path: A string path to the SLEAP labels file.\n        videos: A list of `Video` objects to store the metadata for.\n        restore_source: Deprecated. Use reference_mode instead. If `True`, restore\n            source videos if available and will not re-embed the embedded images.\n            If `False` (the default), will re-embed images that were previously\n            embedded.\n        reference_mode: How to handle video references:\n            - EMBED: Re-embed frames that were previously embedded\n            - RESTORE_ORIGINAL: Use original video if available\n            - PRESERVE_SOURCE: Keep reference to source file (e.g., .pkg.slp)\n        original_videos: Optional list of original video objects before embedding.\n            Used when reference_mode is EMBED to preserve metadata.\n        verbose: If `True` (the default), display a progress bar when embedding frames.\n    \"\"\"\n    # Handle backwards compatibility\n    if reference_mode is None:\n        if restore_source:\n            reference_mode = VideoReferenceMode.RESTORE_ORIGINAL\n        else:\n            reference_mode = VideoReferenceMode.EMBED\n\n    videos_to_embed = []\n    videos_to_write = []\n\n    # First determine which videos need embedding\n    for video_ind, video in enumerate(videos):\n        if type(video.backend) is HDF5Video and video.backend.has_embedded_images:\n            if reference_mode == VideoReferenceMode.RESTORE_ORIGINAL:\n                if video.source_video is None:\n                    # No source video available, reference the current embedded video\n                    # file\n                    videos_to_write.append((video_ind, video))\n                else:\n                    # Use the source video\n                    videos_to_write.append((video_ind, video.source_video))\n            elif reference_mode == VideoReferenceMode.PRESERVE_SOURCE:\n                # Keep the reference to the source .pkg.slp file\n                videos_to_write.append((video_ind, video))\n            else:  # EMBED mode\n                # If the video has embedded images, check if we need to re-embed them\n                already_embedded = False\n                if Path(labels_path).exists():\n                    with h5py.File(labels_path, \"r\") as f:\n                        already_embedded = f\"video{video_ind}/video\" in f\n\n                if already_embedded:\n                    videos_to_write.append((video_ind, video))\n                else:\n                    # Collect information for embedding\n                    frames_to_embed = [\n                        (video, frame_idx) for frame_idx in video.backend.source_inds\n                    ]\n                    videos_to_embed.append((video_ind, video, frames_to_embed))\n        else:\n            videos_to_write.append((video_ind, video))\n\n    # Process videos that need embedding\n    if videos_to_embed:\n        # Prepare all frames to embed\n        all_frames_to_embed = []\n        for video_ind, video, frames in videos_to_embed:\n            for frame in frames:\n                all_frames_to_embed.append(frame)\n\n        # Create a temporary Labels object for embedding\n        temp_labels = Labels(\n            videos=[v for _, v, _ in videos_to_embed], labeled_frames=[]\n        )\n\n        # Prepare and embed all frames in a single process\n        frames_metadata = prepare_frames_to_embed(\n            labels_path, temp_labels, all_frames_to_embed\n        )\n        replaced_videos = process_and_embed_frames(\n            labels_path,\n            frames_metadata,\n            image_format=[\n                v.backend.image_format if hasattr(v.backend, \"image_format\") else \"png\"\n                for _, v, _ in videos_to_embed\n            ][0],  # Use the first video's format\n            verbose=verbose,\n        )\n\n        # Add the embedded videos to the list\n        for video_ind, video, _ in videos_to_embed:\n            if video in replaced_videos:\n                videos_to_write.append((video_ind, replaced_videos[video]))\n\n    # Write video metadata\n    video_jsons = []\n    for video_ind, video in sorted(videos_to_write, key=lambda x: x[0]):\n        video_json = video_to_dict(video, labels_path)\n        video_jsons.append(np.bytes_(json.dumps(video_json, separators=(\",\", \":\"))))\n\n    with h5py.File(labels_path, \"a\") as f:\n        if \"videos_json\" not in f:\n            f.create_dataset(\"videos_json\", data=video_jsons, maxshape=(None,))\n\n    # Save lineage metadata in a separate pass to ensure video groups exist\n    with h5py.File(labels_path, \"a\") as f:\n        for video_ind, video in enumerate(videos):\n            dataset = f\"video{video_ind}\"\n\n            # If original_videos is provided (e.g., during embedding), use those\n            original_video = original_videos[video_ind] if original_videos else video\n\n            # Determine what metadata to save based on reference mode and video\n            # structure\n            original_to_save = None\n            source_to_save = None\n\n            # Handle original_video metadata\n            if reference_mode != VideoReferenceMode.RESTORE_ORIGINAL:\n                if original_video.original_video:\n                    original_to_save = original_video.original_video\n                elif (\n                    original_video.source_video is not None\n                    and hasattr(original_video.source_video, \"original_video\")\n                    and original_video.source_video.original_video is not None\n                ):\n                    # If source_video has original_video, use that (it's the true\n                    # original)\n                    original_to_save = original_video.source_video.original_video\n                elif (\n                    original_video.source_video is not None\n                    and reference_mode == VideoReferenceMode.EMBED\n                ):\n                    # For embed mode, if we only have source_video, that becomes the\n                    # original\n                    original_to_save = original_video.source_video\n\n            # Handle source_video metadata\n            if reference_mode != VideoReferenceMode.PRESERVE_SOURCE:\n                if reference_mode == VideoReferenceMode.EMBED and original_videos:\n                    # For embed mode, save the original video as source (it's the\n                    # .pkg.slp)\n                    source_to_save = original_video\n                elif original_video.source_video is not None:\n                    source_to_save = original_video.source_video\n\n            # Write metadata as datasets in the video group\n            if dataset in f:\n                video_group = f[dataset]\n\n                if original_to_save is not None:\n                    # Store original_video metadata as a group (consistent with\n                    # source_video)\n                    original_grp = video_group.require_group(\"original_video\")\n                    original_json = video_to_dict(original_to_save, labels_path)\n                    original_grp.attrs[\"json\"] = json.dumps(\n                        original_json, separators=(\",\", \":\")\n                    )\n\n                if source_to_save is not None:\n                    # For EMBED mode with original_videos, we need to overwrite\n                    # source_video\n                    # because embed_videos saves the wrong metadata\n                    if (\n                        reference_mode == VideoReferenceMode.EMBED\n                        and original_videos\n                        and \"source_video\" in video_group\n                    ):\n                        # Remove the existing source_video group\n                        del video_group[\"source_video\"]\n\n                    if \"source_video\" not in video_group:\n                        # Create source_video group\n                        source_grp = video_group.require_group(\"source_video\")\n                        source_json = video_to_dict(source_to_save, labels_path)\n                        source_grp.attrs[\"json\"] = json.dumps(\n                            source_json, separators=(\",\", \":\")\n                        )\n</code></pre>"},{"location":"reference/sleap_io/io/ultralytics/","title":"ultralytics","text":""},{"location":"reference/sleap_io/io/ultralytics/#sleap_io.io.ultralytics","title":"<code>sleap_io.io.ultralytics</code>","text":"<p>Handles direct I/O operations for working with Ultralytics YOLO pose format.</p> <p>Ultralytics YOLO pose format specification: - Directory structure: dataset_root/split/images/ and dataset_root/split/labels/ - Configuration: data.yaml file defining skeleton and dataset structure - Annotation format: Each .txt file contains lines with format:   class_id x_center y_center width height x1 y1 v1 x2 y2 v2 ... xn yn vn - Coordinates: Normalized to [0,1] range, origin at top-left - Visibility: 0=not visible, 1=visible but occluded, 2=visible and not occluded</p> <p>Functions:</p> Name Description <code>create_data_yaml</code> <p>Create Ultralytics data.yaml configuration file.</p> <code>create_skeleton_from_config</code> <p>Create a Skeleton object from Ultralytics configuration.</p> <code>create_splits_from_labels</code> <p>Create dataset splits from Labels using the built-in splitting functionality.</p> <code>denormalize_coordinates</code> <p>Denormalize coordinates from [0,1] range to pixel coordinates.</p> <code>normalize_coordinates</code> <p>Normalize instance point coordinates to [0,1] range.</p> <code>parse_data_yaml</code> <p>Parse Ultralytics data.yaml configuration file.</p> <code>parse_label_file</code> <p>Parse a single Ultralytics label file and return instances.</p> <code>read_labels</code> <p>Read Ultralytics YOLO pose dataset and return a <code>Labels</code> object.</p> <code>read_labels_set</code> <p>Read multiple splits from an Ultralytics dataset as a LabelsSet.</p> <code>write_label_file</code> <p>Write a single Ultralytics label file for a frame.</p> <code>write_labels</code> <p>Write Labels to Ultralytics YOLO pose format.</p>"},{"location":"reference/sleap_io/io/ultralytics/#sleap_io.io.ultralytics.create_data_yaml","title":"<code>create_data_yaml(yaml_path, skeleton, split_ratios)</code>","text":"<p>Create Ultralytics data.yaml configuration file.</p> Source code in <code>sleap_io/io/ultralytics.py</code> <pre><code>def create_data_yaml(\n    yaml_path: Path, skeleton: Skeleton, split_ratios: Dict[str, float]\n) -&gt; None:\n    \"\"\"Create Ultralytics data.yaml configuration file.\"\"\"\n    # Build skeleton connections\n    skeleton_connections = []\n    for edge in skeleton.edges:\n        src_idx = skeleton.nodes.index(edge.source)\n        dst_idx = skeleton.nodes.index(edge.destination)\n        skeleton_connections.append([src_idx, dst_idx])\n\n    # Create flip indices (identity mapping by default)\n    flip_idx = list(range(len(skeleton.nodes)))\n\n    config = {\n        \"path\": \".\",\n        \"names\": {0: \"animal\"},\n        \"kpt_shape\": [len(skeleton.nodes), 3],\n        \"flip_idx\": flip_idx,\n        \"skeleton\": skeleton_connections,\n        \"node_names\": [node.name for node in skeleton.nodes],\n    }\n\n    # Add split paths\n    for split_name in split_ratios.keys():\n        config[split_name] = f\"{split_name}/images\"\n\n    with open(yaml_path, \"w\") as f:\n        yaml.dump(config, f, default_flow_style=False)\n</code></pre>"},{"location":"reference/sleap_io/io/ultralytics/#sleap_io.io.ultralytics.create_skeleton_from_config","title":"<code>create_skeleton_from_config(config)</code>","text":"<p>Create a Skeleton object from Ultralytics configuration.</p> Source code in <code>sleap_io/io/ultralytics.py</code> <pre><code>def create_skeleton_from_config(config: Dict) -&gt; Skeleton:\n    \"\"\"Create a Skeleton object from Ultralytics configuration.\"\"\"\n    kpt_shape = config.get(\"kpt_shape\", [1, 3])\n    num_keypoints = kpt_shape[0]\n\n    # Create nodes - use generic names if not specified\n    node_names = config.get(\"node_names\", [f\"point_{i}\" for i in range(num_keypoints)])\n    nodes = [Node(name) for name in node_names[:num_keypoints]]\n\n    # Create edges from skeleton connections\n    edges = []\n    skeleton_connections = config.get(\"skeleton\", [])\n    for connection in skeleton_connections:\n        if len(connection) == 2:\n            src_idx, dst_idx = connection\n            if 0 &lt;= src_idx &lt; len(nodes) and 0 &lt;= dst_idx &lt; len(nodes):\n                edges.append(Edge(nodes[src_idx], nodes[dst_idx]))\n\n    return Skeleton(nodes=nodes, edges=edges, name=\"ultralytics_skeleton\")\n</code></pre>"},{"location":"reference/sleap_io/io/ultralytics/#sleap_io.io.ultralytics.create_splits_from_labels","title":"<code>create_splits_from_labels(labels, split_ratios)</code>","text":"<p>Create dataset splits from Labels using the built-in splitting functionality.</p> Source code in <code>sleap_io/io/ultralytics.py</code> <pre><code>def create_splits_from_labels(\n    labels: Labels, split_ratios: Dict[str, float]\n) -&gt; Dict[str, Labels]:\n    \"\"\"Create dataset splits from Labels using the built-in splitting functionality.\"\"\"\n    split_names = list(split_ratios.keys())\n\n    if len(split_names) == 2:\n        # Two-way split\n        ratio = split_ratios[split_names[0]]\n        split1, split2 = labels.split(ratio)\n        return {split_names[0]: split1, split_names[1]: split2}\n\n    elif len(split_names) == 3:\n        # Three-way split using make_training_splits\n        train_ratio = split_ratios.get(\"train\", 0.6)\n        val_ratio = split_ratios.get(\"val\", 0.2)\n        test_ratio = split_ratios.get(\"test\", 0.2)\n\n        try:\n            train_split, val_split, test_split = labels.make_training_splits(\n                n_train=train_ratio, n_val=val_ratio, n_test=test_ratio\n            )\n            return {\"train\": train_split, \"val\": val_split, \"test\": test_split}\n        except Exception:\n            # Fallback to manual splitting\n            first_split = train_ratio + val_ratio\n            temp_split, test_split = labels.split(first_split)\n            train_split, val_split = temp_split.split(train_ratio / first_split)\n            return {\"train\": train_split, \"val\": val_split, \"test\": test_split}\n\n    else:\n        # Single split or custom splits\n        return {split_names[0]: labels}\n</code></pre>"},{"location":"reference/sleap_io/io/ultralytics/#sleap_io.io.ultralytics.denormalize_coordinates","title":"<code>denormalize_coordinates(normalized_points, image_shape)</code>","text":"<p>Denormalize coordinates from [0,1] range to pixel coordinates.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>A numpy array of shape (n_points, 3) with columns [x, y, visible].</p> Source code in <code>sleap_io/io/ultralytics.py</code> <pre><code>def denormalize_coordinates(\n    normalized_points: List[Tuple[float, float, int]], image_shape: Tuple[int, int]\n) -&gt; np.ndarray:\n    \"\"\"Denormalize coordinates from [0,1] range to pixel coordinates.\n\n    Returns:\n        A numpy array of shape (n_points, 3) with columns [x, y, visible].\n    \"\"\"\n    height, width = image_shape\n    points = []\n\n    for x_norm, y_norm, visibility in normalized_points:\n        if visibility &gt; 0:\n            x_px = x_norm * width\n            y_px = y_norm * height\n            is_visible = True\n        else:\n            x_px = np.nan\n            y_px = np.nan\n            is_visible = False\n\n        points.append([x_px, y_px, is_visible])\n\n    return np.array(points, dtype=np.float32)\n</code></pre>"},{"location":"reference/sleap_io/io/ultralytics/#sleap_io.io.ultralytics.normalize_coordinates","title":"<code>normalize_coordinates(instance, image_shape)</code>","text":"<p>Normalize instance point coordinates to [0,1] range.</p> Source code in <code>sleap_io/io/ultralytics.py</code> <pre><code>def normalize_coordinates(\n    instance: Instance, image_shape: Tuple[int, int]\n) -&gt; List[Tuple[float, float, int]]:\n    \"\"\"Normalize instance point coordinates to [0,1] range.\"\"\"\n    height, width = image_shape\n    normalized = []\n\n    for point in instance.points:\n        x, y = point[\"xy\"]\n        if point[\"visible\"] and not np.isnan(x):\n            x_norm = x / width\n            y_norm = y / height\n            visibility = 2  # visible\n        else:\n            x_norm = 0.0\n            y_norm = 0.0\n            visibility = 0  # not visible\n\n        normalized.append((x_norm, y_norm, visibility))\n\n    return normalized\n</code></pre>"},{"location":"reference/sleap_io/io/ultralytics/#sleap_io.io.ultralytics.parse_data_yaml","title":"<code>parse_data_yaml(yaml_path)</code>","text":"<p>Parse Ultralytics data.yaml configuration file.</p> Source code in <code>sleap_io/io/ultralytics.py</code> <pre><code>def parse_data_yaml(yaml_path: Path) -&gt; Dict:\n    \"\"\"Parse Ultralytics data.yaml configuration file.\"\"\"\n    with open(yaml_path, \"r\") as f:\n        config = yaml.safe_load(f)\n    return config\n</code></pre>"},{"location":"reference/sleap_io/io/ultralytics/#sleap_io.io.ultralytics.parse_label_file","title":"<code>parse_label_file(label_path, skeleton, image_shape)</code>","text":"<p>Parse a single Ultralytics label file and return instances.</p> Source code in <code>sleap_io/io/ultralytics.py</code> <pre><code>def parse_label_file(\n    label_path: Path, skeleton: Skeleton, image_shape: Tuple[int, int]\n) -&gt; List[Instance]:\n    \"\"\"Parse a single Ultralytics label file and return instances.\"\"\"\n    instances = []\n\n    with open(label_path, \"r\") as f:\n        for line_num, line in enumerate(f):\n            line = line.strip()\n            if not line or line.startswith(\"#\"):\n                continue\n\n            try:\n                parts = line.split()\n                if len(parts) &lt; 5:\n                    warnings.warn(\n                        f\"Invalid line {line_num} in {label_path}: insufficient data\"\n                    )\n                    continue\n\n                _ = int(parts[0])  # class_id - not used but part of YOLO format\n                x_center, y_center, width, height = map(float, parts[1:5])\n\n                # Parse keypoints\n                keypoint_data = parts[5:]\n                if len(keypoint_data) % 3 != 0:\n                    warnings.warn(\n                        f\"Invalid keypoint data in {label_path} line {line_num}\"\n                    )\n                    continue\n\n                num_keypoints = len(keypoint_data) // 3\n                if num_keypoints != len(skeleton.nodes):\n                    warnings.warn(\n                        f\"Keypoint count mismatch: expected {len(skeleton.nodes)}, \"\n                        f\"got {num_keypoints} in {label_path} line {line_num}\"\n                    )\n                    continue\n\n                # Convert normalized coordinates to pixel coordinates\n                height_px, width_px = image_shape\n                points = []\n\n                for i in range(num_keypoints):\n                    x_norm = float(keypoint_data[i * 3])\n                    y_norm = float(keypoint_data[i * 3 + 1])\n                    visibility = int(keypoint_data[i * 3 + 2])\n\n                    # Denormalize coordinates\n                    x_px = x_norm * width_px\n                    y_px = y_norm * height_px\n\n                    # Convert visibility: 0=not visible, 1=occluded, 2=visible\n                    is_visible = visibility &gt; 0\n\n                    if visibility == 0:\n                        # Not visible - use NaN coordinates\n                        points.append([np.nan, np.nan, False])\n                    else:\n                        points.append([x_px, y_px, is_visible])\n\n                # Create instance from numpy array\n                points_array = np.array(points, dtype=np.float32)\n                instance = Instance.from_numpy(\n                    points_data=points_array, skeleton=skeleton\n                )\n                instances.append(instance)\n\n            except (ValueError, IndexError) as e:\n                warnings.warn(f\"Error parsing line {line_num} in {label_path}: {e}\")\n                continue\n\n    return instances\n</code></pre>"},{"location":"reference/sleap_io/io/ultralytics/#sleap_io.io.ultralytics.read_labels","title":"<code>read_labels(dataset_path, split='train', skeleton=None, image_size=(480, 640))</code>","text":"<p>Read Ultralytics YOLO pose dataset and return a <code>Labels</code> object.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_path</code> <code>str</code> <p>Path to the Ultralytics dataset root directory containing data.yaml.</p> required <code>split</code> <code>str</code> <p>Dataset split to read ('train', 'val', or 'test'). Defaults to 'train'.</p> <code>'train'</code> <code>skeleton</code> <code>Optional[Skeleton]</code> <p>Optional skeleton to use. If not provided, will be inferred from data.yaml.</p> <code>None</code> <code>image_size</code> <code>Tuple[int, int]</code> <p>Image dimensions (height, width) for coordinate denormalization.        Defaults to (480, 640). Will attempt to infer from actual images if        available.</p> <code>(480, 640)</code> <p>Returns:</p> Type Description <code>Labels</code> <p>Parsed labels as a <code>Labels</code> instance.</p> Source code in <code>sleap_io/io/ultralytics.py</code> <pre><code>def read_labels(\n    dataset_path: str,\n    split: str = \"train\",\n    skeleton: Optional[Skeleton] = None,\n    image_size: Tuple[int, int] = (480, 640),\n) -&gt; Labels:\n    \"\"\"Read Ultralytics YOLO pose dataset and return a `Labels` object.\n\n    Args:\n        dataset_path: Path to the Ultralytics dataset root directory containing\n            data.yaml.\n        split: Dataset split to read ('train', 'val', or 'test'). Defaults to 'train'.\n        skeleton: Optional skeleton to use. If not provided, will be inferred from\n            data.yaml.\n        image_size: Image dimensions (height, width) for coordinate denormalization.\n                   Defaults to (480, 640). Will attempt to infer from actual images if\n                   available.\n\n    Returns:\n        Parsed labels as a `Labels` instance.\n    \"\"\"\n    dataset_path = Path(dataset_path)\n\n    # Parse data.yaml configuration\n    if dataset_path.name == \"data.yaml\":\n        # If path already points to data.yaml, use its parent as dataset path\n        data_yaml_path = dataset_path\n        dataset_path = dataset_path.parent\n    else:\n        data_yaml_path = dataset_path / \"data.yaml\"\n\n    if not data_yaml_path.exists():\n        raise FileNotFoundError(f\"data.yaml not found at {data_yaml_path}\")\n\n    config = parse_data_yaml(data_yaml_path)\n\n    # Use provided skeleton or create from config\n    if skeleton is None:\n        skeleton = create_skeleton_from_config(config)\n\n    # Get paths for the specified split\n    split_path = config.get(split, f\"{split}/images\")\n    images_dir = dataset_path / split_path\n    labels_dir = dataset_path / split_path.replace(\"/images\", \"/labels\")\n\n    if not images_dir.exists():\n        raise FileNotFoundError(f\"Images directory not found: {images_dir}\")\n    if not labels_dir.exists():\n        raise FileNotFoundError(f\"Labels directory not found: {labels_dir}\")\n\n    # Process all image/label pairs\n    labeled_frames = []\n    tracks = {}  # Track synthetic tracks by instance order\n\n    for image_file in sorted(images_dir.glob(\"*\")):\n        if image_file.suffix.lower() in [\".jpg\", \".jpeg\", \".png\", \".tiff\", \".bmp\"]:\n            label_file = labels_dir / f\"{image_file.stem}.txt\"\n\n            # Create video object for this image\n            video = Video.from_filename(str(image_file))\n\n            # Parse label file if it exists\n            instances = []\n            if label_file.exists():\n                # Get image dimensions - try from video shape first, fallback to reading\n                # image\n                if video.shape is not None:\n                    img_shape = video.shape[:2]\n                else:\n                    # Read first frame to get dimensions\n                    img = video[0]\n                    img_shape = img.shape[:2]\n\n                instances = parse_label_file(label_file, skeleton, img_shape)\n\n                # Assign tracks to instances based on order\n                for i, instance in enumerate(instances):\n                    track_name = f\"track_{i}\"\n                    if track_name not in tracks:\n                        tracks[track_name] = Track(name=track_name)\n                    instance.track = tracks[track_name]\n\n            # Create labeled frame\n            frame = LabeledFrame(video=video, frame_idx=0, instances=instances)\n            labeled_frames.append(frame)\n\n    return Labels(\n        labeled_frames=labeled_frames,\n        skeletons=[skeleton],\n        tracks=list(tracks.values()),\n        provenance={\"source\": str(dataset_path), \"split\": split},\n    )\n</code></pre>"},{"location":"reference/sleap_io/io/ultralytics/#sleap_io.io.ultralytics.read_labels_set","title":"<code>read_labels_set(dataset_path, splits=None, skeleton=None, image_size=(480, 640))</code>","text":"<p>Read multiple splits from an Ultralytics dataset as a LabelsSet.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_path</code> <code>str</code> <p>Path to the root directory of the Ultralytics dataset.</p> required <code>splits</code> <code>Optional[List[str]]</code> <p>List of split names to load (e.g., [\"train\", \"val\", \"test\"]). If None, will attempt to load all available splits.</p> <code>None</code> <code>skeleton</code> <code>Optional[Skeleton]</code> <p>Skeleton to use for the dataset. If None, will attempt to load from data.yaml file in the dataset root.</p> <code>None</code> <code>image_size</code> <code>Tuple[int, int]</code> <p>Default image size (height, width) to use if unable to determine from the actual images. Default: (480, 640).</p> <code>(480, 640)</code> <p>Returns:</p> Type Description <code>LabelsSet</code> <p>A LabelsSet containing Labels objects for each split.</p> Example <p>labels_set = read_labels_set(\"path/to/yolo_dataset/\") train_labels = labels_set[\"train\"] val_labels = labels_set[\"val\"]</p> Source code in <code>sleap_io/io/ultralytics.py</code> <pre><code>def read_labels_set(\n    dataset_path: str,\n    splits: Optional[List[str]] = None,\n    skeleton: Optional[Skeleton] = None,\n    image_size: Tuple[int, int] = (480, 640),\n) -&gt; LabelsSet:\n    \"\"\"Read multiple splits from an Ultralytics dataset as a LabelsSet.\n\n    Args:\n        dataset_path: Path to the root directory of the Ultralytics dataset.\n        splits: List of split names to load (e.g., [\"train\", \"val\", \"test\"]).\n            If None, will attempt to load all available splits.\n        skeleton: Skeleton to use for the dataset. If None, will attempt to\n            load from data.yaml file in the dataset root.\n        image_size: Default image size (height, width) to use if unable to\n            determine from the actual images. Default: (480, 640).\n\n    Returns:\n        A LabelsSet containing Labels objects for each split.\n\n    Example:\n        &gt;&gt;&gt; labels_set = read_labels_set(\"path/to/yolo_dataset/\")\n        &gt;&gt;&gt; train_labels = labels_set[\"train\"]\n        &gt;&gt;&gt; val_labels = labels_set[\"val\"]\n    \"\"\"\n    from sleap_io.model.labels_set import LabelsSet\n\n    dataset_path = Path(dataset_path)\n\n    # If no splits specified, try to detect available splits\n    if splits is None:\n        splits = []\n        for split_name in [\"train\", \"val\", \"test\", \"valid\"]:\n            if (dataset_path / split_name).exists():\n                splits.append(split_name)\n\n        if not splits:\n            raise ValueError(f\"No splits found in dataset path: {dataset_path}\")\n\n    # Try to load skeleton from data.yaml if not provided\n    if skeleton is None:\n        data_yaml_path = dataset_path / \"data.yaml\"\n        if data_yaml_path.exists():\n            with open(data_yaml_path, \"r\") as f:\n                data_config = yaml.safe_load(f)\n\n            # Try to create skeleton from our custom metadata first\n            if \"node_names\" in data_config and \"skeleton\" in data_config:\n                try:\n                    node_names = data_config[\"node_names\"]\n                    skeleton_connections = data_config[\"skeleton\"]\n\n                    # Create nodes from names\n                    nodes = [Node(name) for name in node_names]\n\n                    # Create edges from skeleton connections\n                    edges = []\n                    for connection in skeleton_connections:\n                        if len(connection) == 2:\n                            src_idx, dst_idx = connection\n                            if 0 &lt;= src_idx &lt; len(nodes) and 0 &lt;= dst_idx &lt; len(nodes):\n                                edges.append(Edge(nodes[src_idx], nodes[dst_idx]))\n\n                    skeleton = Skeleton(nodes=nodes, edges=edges)\n                except (KeyError, IndexError, TypeError):\n                    # Fall back to basic skeleton creation\n                    pass\n\n            # Fall back to basic skeleton creation if metadata approach failed\n            if skeleton is None and \"kpt_shape\" in data_config:\n                kpt_shape = data_config[\"kpt_shape\"]\n                if isinstance(kpt_shape, list) and len(kpt_shape) &gt;= 2:\n                    n_keypoints = kpt_shape[0]\n                    # Create a basic skeleton with numbered nodes\n                    nodes = [Node(name=str(i)) for i in range(n_keypoints)]\n                    skeleton = Skeleton(nodes=nodes)\n\n    labels_dict = {}\n\n    for split in splits:\n        try:\n            labels = read_labels(\n                dataset_path=str(dataset_path),\n                split=split,\n                skeleton=skeleton,\n                image_size=image_size,\n            )\n            labels_dict[split] = labels\n        except Exception:\n            continue\n\n    if not labels_dict:\n        raise ValueError(f\"Could not load any splits from dataset: {dataset_path}\")\n\n    return LabelsSet(labels=labels_dict)\n</code></pre>"},{"location":"reference/sleap_io/io/ultralytics/#sleap_io.io.ultralytics.write_label_file","title":"<code>write_label_file(label_path, frame, skeleton, image_shape, class_id=0)</code>","text":"<p>Write a single Ultralytics label file for a frame.</p> Source code in <code>sleap_io/io/ultralytics.py</code> <pre><code>def write_label_file(\n    label_path: Path,\n    frame: LabeledFrame,\n    skeleton: Skeleton,\n    image_shape: Tuple[int, int],\n    class_id: int = 0,\n) -&gt; None:\n    \"\"\"Write a single Ultralytics label file for a frame.\"\"\"\n    height_px, width_px = image_shape\n\n    with open(label_path, \"w\") as f:\n        for instance in frame.instances:\n            if len(instance.points) != len(skeleton.nodes):\n                warnings.warn(\n                    f\"Instance has {len(instance.points)} points, \"\n                    f\"skeleton has {len(skeleton.nodes)} nodes. Skipping.\"\n                )\n                continue\n\n            # Calculate bounding box from visible keypoints\n            visible_mask = instance.points[\"visible\"] &amp; ~np.isnan(\n                instance.points[\"xy\"][:, 0]\n            )\n            if not visible_mask.any():\n                continue  # Skip instances with no visible points\n\n            visible_xy = instance.points[\"xy\"][visible_mask]\n            x_coords = visible_xy[:, 0]\n            y_coords = visible_xy[:, 1]\n\n            x_min, x_max = min(x_coords), max(x_coords)\n            y_min, y_max = min(y_coords), max(y_coords)\n\n            # Add padding to bounding box\n            padding = 10  # pixels\n            x_min = max(0, x_min - padding)\n            y_min = max(0, y_min - padding)\n            x_max = min(width_px, x_max + padding)\n            y_max = min(height_px, y_max + padding)\n\n            # Convert to normalized YOLO format\n            x_center_norm = ((x_min + x_max) / 2) / width_px\n            y_center_norm = ((y_min + y_max) / 2) / height_px\n            width_norm = (x_max - x_min) / width_px\n            height_norm = (y_max - y_min) / height_px\n\n            # Build line: class_id x_center y_center width height x1 y1 v1 x2 y2 v2 ...\n            line_parts = [\n                str(class_id),\n                f\"{x_center_norm:.6f}\",\n                f\"{y_center_norm:.6f}\",\n                f\"{width_norm:.6f}\",\n                f\"{height_norm:.6f}\",\n            ]\n\n            # Add keypoints\n            for point in instance.points:\n                x, y = point[\"xy\"]\n                if point[\"visible\"] and not np.isnan(x):\n                    x_norm = x / width_px\n                    y_norm = y / height_px\n                    visibility = 2  # visible and not occluded\n                else:\n                    x_norm = 0.0\n                    y_norm = 0.0\n                    visibility = 0  # not visible\n\n                line_parts.extend([f\"{x_norm:.6f}\", f\"{y_norm:.6f}\", str(visibility)])\n\n            f.write(\" \".join(line_parts) + \"\\n\")\n</code></pre>"},{"location":"reference/sleap_io/io/ultralytics/#sleap_io.io.ultralytics.write_labels","title":"<code>write_labels(labels, dataset_path, split_ratios={'train': 0.8, 'val': 0.2}, class_id=0, image_format='png', image_quality=None, verbose=True, use_multiprocessing=False, n_workers=None, **kwargs)</code>","text":"<p>Write Labels to Ultralytics YOLO pose format.</p> <p>Parameters:</p> Name Type Description Default <code>labels</code> <code>Labels</code> <p>SLEAP Labels object to export.</p> required <code>dataset_path</code> <code>str</code> <p>Path to write the Ultralytics dataset.</p> required <code>split_ratios</code> <code>Dict[str, float]</code> <p>Dictionary mapping split names to ratios (must sum to 1.0).</p> <code>{'train': 0.8, 'val': 0.2}</code> <code>class_id</code> <code>int</code> <p>Class ID to use for all instances (default: 0).</p> <code>0</code> <code>image_format</code> <code>str</code> <p>Image format to use for saving frames. Either \"png\" (default, lossless) or \"jpg\".</p> <code>'png'</code> <code>image_quality</code> <code>Optional[int]</code> <p>Image quality for JPEG format (1-100). For PNG, this is the compression level (0-9). If None, uses default quality settings.</p> <code>None</code> <code>verbose</code> <code>bool</code> <p>If True (default), show progress bars during export.</p> <code>True</code> <code>use_multiprocessing</code> <code>bool</code> <p>If True, use multiprocessing for parallel image saving. Default is False.</p> <code>False</code> <code>n_workers</code> <code>Optional[int]</code> <p>Number of worker processes. If None, uses CPU count - 1. Only used if use_multiprocessing=True.</p> <code>None</code> <code>**kwargs</code> <p>Additional arguments (unused, for compatibility).</p> <code>{}</code> Source code in <code>sleap_io/io/ultralytics.py</code> <pre><code>def write_labels(\n    labels: Labels,\n    dataset_path: str,\n    split_ratios: Dict[str, float] = {\"train\": 0.8, \"val\": 0.2},\n    class_id: int = 0,\n    image_format: str = \"png\",\n    image_quality: Optional[int] = None,\n    verbose: bool = True,\n    use_multiprocessing: bool = False,\n    n_workers: Optional[int] = None,\n    **kwargs,\n) -&gt; None:\n    \"\"\"Write Labels to Ultralytics YOLO pose format.\n\n    Args:\n        labels: SLEAP Labels object to export.\n        dataset_path: Path to write the Ultralytics dataset.\n        split_ratios: Dictionary mapping split names to ratios (must sum to 1.0).\n        class_id: Class ID to use for all instances (default: 0).\n        image_format: Image format to use for saving frames. Either \"png\" (default,\n            lossless) or \"jpg\".\n        image_quality: Image quality for JPEG format (1-100). For PNG, this is the\n            compression level (0-9).\n            If None, uses default quality settings.\n        verbose: If True (default), show progress bars during export.\n        use_multiprocessing: If True, use multiprocessing for parallel image saving.\n            Default is False.\n        n_workers: Number of worker processes. If None, uses CPU count - 1. Only used\n            if use_multiprocessing=True.\n        **kwargs: Additional arguments (unused, for compatibility).\n    \"\"\"\n    dataset_path = Path(dataset_path)\n    dataset_path.mkdir(parents=True, exist_ok=True)\n\n    # Validate split ratios\n    total_ratio = sum(split_ratios.values())\n    if not np.isclose(total_ratio, 1.0):\n        raise ValueError(f\"Split ratios must sum to 1.0, got {total_ratio}\")\n\n    if len(labels.skeletons) == 0:\n        raise ValueError(\"Labels must have at least one skeleton\")\n\n    skeleton = labels.skeletons[0]\n\n    # Create data.yaml configuration\n    create_data_yaml(dataset_path / \"data.yaml\", skeleton, split_ratios)\n\n    # Split the labels if multiple splits requested\n    if len(split_ratios) == 1:\n        split_name = list(split_ratios.keys())[0]\n        split_labels = {split_name: labels}\n    else:\n        split_labels = create_splits_from_labels(labels, split_ratios)\n\n    # Write each split\n    for split_name, split_data in split_labels.items():\n        images_dir = dataset_path / split_name / \"images\"\n        labels_dir = dataset_path / split_name / \"labels\"\n        images_dir.mkdir(parents=True, exist_ok=True)\n        labels_dir.mkdir(parents=True, exist_ok=True)\n\n        if use_multiprocessing:\n            # Prepare frame data for multiprocessing\n            frame_data_list = []\n            for lf_idx, frame in enumerate(split_data.labeled_frames):\n                image_filename = f\"{lf_idx:07d}.{image_format}\"\n                image_path = images_dir / image_filename\n\n                frame_data = {\n                    \"video_path\": str(frame.video.filename),\n                    \"frame_idx\": frame.frame_idx,\n                    \"lf_idx\": lf_idx,\n                    \"output_path\": str(image_path),\n                    \"frame\": frame,  # Keep reference for annotation writing\n                }\n                frame_data_list.append(frame_data)\n\n            # Set up worker pool\n            if n_workers is None:\n                n_workers = max(1, multiprocessing.cpu_count() - 1)\n\n            # Process frames in parallel\n            with Pool(processes=n_workers) as pool:\n                # Create args for each frame\n                args_list = [\n                    (fd, image_format, image_quality) for fd in frame_data_list\n                ]\n\n                # Use imap for progress tracking\n                if verbose:\n                    results = list(\n                        tqdm(\n                            pool.imap(_save_frame_image, args_list),\n                            total=len(args_list),\n                            desc=f\"Writing {split_name} images (parallel)\",\n                        )\n                    )\n                else:\n                    results = pool.map(_save_frame_image, args_list)\n\n            # Write annotations for successfully saved images\n            for frame_data, result in zip(frame_data_list, results):\n                if result is not None:\n                    frame = frame_data[\"frame\"]\n                    # Get image shape from saved file\n                    img = iio.imread(result)\n                    label_filename = f\"{frame_data['lf_idx']:07d}.txt\"\n                    label_path = labels_dir / label_filename\n                    write_label_file(\n                        label_path, frame, skeleton, img.shape[:2], class_id\n                    )\n        else:\n            # Sequential processing (original implementation)\n            frame_iterator = (\n                tqdm(\n                    split_data.labeled_frames,\n                    desc=f\"Writing {split_name} images\",\n                    disable=not verbose,\n                )\n                if verbose\n                else split_data.labeled_frames\n            )\n\n            for lf_idx, frame in enumerate(frame_iterator):\n                # Extract frame image\n                try:\n                    frame_img = frame.image\n                    if frame_img is None:\n                        warnings.warn(\n                            f\"Could not load frame {frame.frame_idx} from video, \"\n                            f\"skipping.\"\n                        )\n                        continue\n\n                    # Use labeled frame index for filename\n                    image_filename = f\"{lf_idx:07d}.{image_format}\"\n                    image_path = images_dir / image_filename\n\n                    # Handle grayscale conversion if needed\n                    if frame_img.ndim == 3 and frame_img.shape[-1] == 1:\n                        # Squeeze single channel dimension for grayscale\n                        frame_img = np.squeeze(frame_img, axis=-1)\n\n                    # Save image with appropriate quality settings\n                    save_kwargs = {}\n                    if image_format.lower() in [\"jpg\", \"jpeg\"]:\n                        if image_quality is not None:\n                            save_kwargs[\"quality\"] = image_quality\n                    elif image_format.lower() == \"png\":\n                        if image_quality is not None:\n                            # PNG uses compress_level (0-9)\n                            save_kwargs[\"compress_level\"] = min(\n                                9, max(0, image_quality)\n                            )\n\n                    # Save the image\n                    iio.imwrite(image_path, frame_img, **save_kwargs)\n\n                    # Save annotations with same base filename\n                    label_filename = f\"{lf_idx:07d}.txt\"\n                    label_path = labels_dir / label_filename\n                    write_label_file(\n                        label_path, frame, skeleton, frame_img.shape[:2], class_id\n                    )\n\n                except Exception as e:\n                    warnings.warn(\n                        f\"Error processing frame {frame.frame_idx}: {str(e)}, skipping.\"\n                    )\n                    continue\n</code></pre>"},{"location":"reference/sleap_io/io/utils/","title":"utils","text":""},{"location":"reference/sleap_io/io/utils/#sleap_io.io.utils","title":"<code>sleap_io.io.utils</code>","text":"<p>Miscellaneous utilities for working with different I/O formats.</p> <p>Functions:</p> Name Description <code>is_file_accessible</code> <p>Check if a file is accessible.</p> <code>read_hdf5_attrs</code> <p>Read attributes from an HDF5 dataset.</p> <code>read_hdf5_dataset</code> <p>Read data from an HDF5 file.</p> <code>read_hdf5_group</code> <p>Read an entire group from an HDF5 file.</p> <code>sanitize_filename</code> <p>Sanitize a filename to a canonical posix-compatible format.</p> <code>write_hdf5_attrs</code> <p>Write attributes to an HDF5 dataset.</p> <code>write_hdf5_dataset</code> <p>Write data to an HDF5 file.</p> <code>write_hdf5_group</code> <p>Write an entire group to an HDF5 file.</p>"},{"location":"reference/sleap_io/io/utils/#sleap_io.io.utils.is_file_accessible","title":"<code>is_file_accessible(filename)</code>","text":"<p>Check if a file is accessible.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str | Path</code> <p>Path to a file.</p> required <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if the file is accessible, <code>False</code> otherwise.</p> Notes <p>This checks if the file readable by the current user by reading one byte from the file.</p> Source code in <code>sleap_io/io/utils.py</code> <pre><code>def is_file_accessible(filename: str | Path) -&gt; bool:\n    \"\"\"Check if a file is accessible.\n\n    Args:\n        filename: Path to a file.\n\n    Returns:\n        `True` if the file is accessible, `False` otherwise.\n\n    Notes:\n        This checks if the file readable by the current user by reading one byte from\n        the file.\n    \"\"\"\n    filename = Path(filename)\n    try:\n        with open(filename, \"rb\") as f:\n            f.read(1)\n        return True\n    except (FileNotFoundError, PermissionError, OSError, ValueError):\n        return False\n</code></pre>"},{"location":"reference/sleap_io/io/utils/#sleap_io.io.utils.read_hdf5_attrs","title":"<code>read_hdf5_attrs(filename, dataset='/', attribute=None)</code>","text":"<p>Read attributes from an HDF5 dataset.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>Path to an HDF5 file.</p> required <code>dataset</code> <code>str</code> <p>Path to a dataset or group from which attributes will be read.</p> <code>'/'</code> <code>attribute</code> <code>Optional[str]</code> <p>If specified, the attribute name to read. If <code>None</code> (the default), all attributes for the dataset will be returned.</p> <code>None</code> <p>Returns:</p> Type Description <code>Union[Any, dict[str, Any]]</code> <p>The attributes in a dictionary, or the attribute field if <code>attribute</code> was provided.</p> Source code in <code>sleap_io/io/utils.py</code> <pre><code>def read_hdf5_attrs(\n    filename: str, dataset: str = \"/\", attribute: Optional[str] = None\n) -&gt; Union[Any, dict[str, Any]]:\n    \"\"\"Read attributes from an HDF5 dataset.\n\n    Args:\n        filename: Path to an HDF5 file.\n        dataset: Path to a dataset or group from which attributes will be read.\n        attribute: If specified, the attribute name to read. If `None` (the default),\n            all attributes for the dataset will be returned.\n\n    Returns:\n        The attributes in a dictionary, or the attribute field if `attribute` was\n        provided.\n    \"\"\"\n    with h5py.File(filename, \"r\") as f:\n        ds = f[dataset]\n        if attribute is None:\n            data = dict(ds.attrs)\n        else:\n            data = ds.attrs[attribute]\n    return data\n</code></pre>"},{"location":"reference/sleap_io/io/utils/#sleap_io.io.utils.read_hdf5_dataset","title":"<code>read_hdf5_dataset(filename, dataset)</code>","text":"<p>Read data from an HDF5 file.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>Path to an HDF5 file.</p> required <code>dataset</code> <code>str</code> <p>Path to a dataset.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>The data as an array.</p> Source code in <code>sleap_io/io/utils.py</code> <pre><code>def read_hdf5_dataset(filename: str, dataset: str) -&gt; np.ndarray:\n    \"\"\"Read data from an HDF5 file.\n\n    Args:\n        filename: Path to an HDF5 file.\n        dataset: Path to a dataset.\n\n    Returns:\n        The data as an array.\n    \"\"\"\n    with h5py.File(filename, \"r\") as f:\n        data = f[dataset][()]\n    return data\n</code></pre>"},{"location":"reference/sleap_io/io/utils/#sleap_io.io.utils.read_hdf5_group","title":"<code>read_hdf5_group(filename, group='/')</code>","text":"<p>Read an entire group from an HDF5 file.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>Path an HDF5 file.</p> required <code>group</code> <code>str</code> <p>Path to a group within the HDF5 file. Defaults to \"/\" (read the entire file).</p> <code>'/'</code> <p>Returns:</p> Type Description <code>dict[str, ndarray]</code> <p>A flat dictionary with keys corresponding to dataset paths and values corresponding to the datasets as arrays.</p> Source code in <code>sleap_io/io/utils.py</code> <pre><code>def read_hdf5_group(filename: str, group: str = \"/\") -&gt; dict[str, np.ndarray]:\n    \"\"\"Read an entire group from an HDF5 file.\n\n    Args:\n        filename: Path an HDF5 file.\n        group: Path to a group within the HDF5 file. Defaults to \"/\" (read the entire\n            file).\n\n    Returns:\n        A flat dictionary with keys corresponding to dataset paths and values\n        corresponding to the datasets as arrays.\n    \"\"\"\n    data = {}\n\n    def read_datasets(k, v):\n        if type(v) is h5py.Dataset:\n            data[v.name] = v[()]\n\n    with h5py.File(filename, \"r\") as f:\n        f[group].visititems(read_datasets)\n\n    return data\n</code></pre>"},{"location":"reference/sleap_io/io/utils/#sleap_io.io.utils.sanitize_filename","title":"<code>sanitize_filename(filename)</code>","text":"<p>Sanitize a filename to a canonical posix-compatible format.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str | Path | list[str] | list[Path]</code> <p>A string or <code>Path</code> object or list of either to sanitize.</p> required <p>Returns:</p> Type Description <code>str | list[str]</code> <p>A sanitized filename as a string (or list of strings if a list was provided) with forward slashes and posix-formatted.</p> Source code in <code>sleap_io/io/utils.py</code> <pre><code>def sanitize_filename(\n    filename: str | Path | list[str] | list[Path],\n) -&gt; str | list[str]:\n    \"\"\"Sanitize a filename to a canonical posix-compatible format.\n\n    Args:\n        filename: A string or `Path` object or list of either to sanitize.\n\n    Returns:\n        A sanitized filename as a string (or list of strings if a list was provided)\n        with forward slashes and posix-formatted.\n    \"\"\"\n    if isinstance(filename, list):\n        return [sanitize_filename(f) for f in filename]\n    return Path(filename).as_posix().replace(\"\\\\\", \"/\")\n</code></pre>"},{"location":"reference/sleap_io/io/utils/#sleap_io.io.utils.write_hdf5_attrs","title":"<code>write_hdf5_attrs(filename, dataset, attributes)</code>","text":"<p>Write attributes to an HDF5 dataset.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>Path to an HDF5 file.</p> required <code>dataset</code> <code>str</code> <p>Path to a dataset or group to which attributes will be written.</p> required <code>attributes</code> <code>dict[str, Any]</code> <p>The attributes in a dictionary with the keys as the attribute names.</p> required Source code in <code>sleap_io/io/utils.py</code> <pre><code>def write_hdf5_attrs(filename: str, dataset: str, attributes: dict[str, Any]):\n    \"\"\"Write attributes to an HDF5 dataset.\n\n    Args:\n        filename: Path to an HDF5 file.\n        dataset: Path to a dataset or group to which attributes will be written.\n        attributes: The attributes in a dictionary with the keys as the attribute names.\n    \"\"\"\n\n    def _overwrite_hdf5_attr(\n        group_or_dataset: Union[h5py.Group, h5py.Dataset], attr_name: str, data: Any\n    ):\n        \"\"\"Overwrite attribute for group or dataset in HDF5 file.\n\n        Args:\n            group_or_dataset: Path to group or dataset in HDF5 file.\n            attr_name: Name of attribute.\n            data: Data to write to attribute.\n        \"\"\"\n        try:\n            del group_or_dataset.attrs[attr_name]\n        except KeyError:\n            pass\n        group_or_dataset.attrs.create(attr_name, data)\n\n    with h5py.File(filename, \"a\") as f:  # \"a\": read/write if exists, create otherwise\n        ds = f[dataset]\n        for attr_name, attr_value in attributes.items():\n            _overwrite_hdf5_attr(ds, attr_name, attr_value)\n</code></pre>"},{"location":"reference/sleap_io/io/utils/#sleap_io.io.utils.write_hdf5_dataset","title":"<code>write_hdf5_dataset(filename, dataset, data)</code>","text":"<p>Write data to an HDF5 file.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>Path to an HDF5 file.</p> required <code>dataset</code> <code>str</code> <p>Path to a dataset.</p> required <code>data</code> <code>ndarray</code> <p>Data to write to dataset.</p> required Source code in <code>sleap_io/io/utils.py</code> <pre><code>def write_hdf5_dataset(filename: str, dataset: str, data: np.ndarray):\n    \"\"\"Write data to an HDF5 file.\n\n    Args:\n        filename: Path to an HDF5 file.\n        dataset: Path to a dataset.\n        data: Data to write to dataset.\n    \"\"\"\n    with h5py.File(filename, \"a\") as f:  # \"a\": read/write if exists, create otherwise\n        _overwrite_hdf5_dataset(f, dataset, data)\n</code></pre>"},{"location":"reference/sleap_io/io/utils/#sleap_io.io.utils.write_hdf5_group","title":"<code>write_hdf5_group(filename, data)</code>","text":"<p>Write an entire group to an HDF5 file.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>Path an HDF5 file.</p> required <code>data</code> <code>dict[str, ndarray]</code> <p>A dictionary with keys corresponding to dataset/group paths and values corresponding to either sub group paths or the datasets as arrays.</p> required Source code in <code>sleap_io/io/utils.py</code> <pre><code>def write_hdf5_group(filename: str, data: dict[str, np.ndarray]):\n    \"\"\"Write an entire group to an HDF5 file.\n\n    Args:\n        filename: Path an HDF5 file.\n        data: A dictionary with keys corresponding to dataset/group paths and values\n            corresponding to either sub group paths or the datasets as arrays.\n    \"\"\"\n\n    def overwrite_hdf5_group(\n        file_or_group: Union[h5py.File, h5py.Group], group_name: str\n    ) -&gt; h5py.Group:\n        \"\"\"Overwrite group in HDF5 file.\n\n        Args:\n            file_or_group: Path to an HDF5 file or parent group.\n            group_name: Path to a group.\n\n        Return:\n            group: (Sub-)group under specified file or parent group.\n        \"\"\"\n        try:\n            del file_or_group[group_name]\n        except KeyError:\n            pass\n        group = file_or_group.create_group(group_name)\n        return group\n\n    def write_group(parent_group, data_to_write):\n        for name, dataset_or_group in data_to_write.items():\n            if isinstance(dataset_or_group, dict):\n                # Create (sub-)group under parent group (top level being the file)\n                group = overwrite_hdf5_group(parent_group, name)\n                write_group(group, dataset_or_group)  # Recall with new parent\n            else:\n                # Create dataset if dataset_or_group is a dataset\n                _overwrite_hdf5_dataset(\n                    f=parent_group, dataset=name, data=dataset_or_group\n                )\n\n    with h5py.File(filename, \"a\") as f:  # \"a\": read/write if exists, create otherwise\n        write_group(f, data)\n</code></pre>"},{"location":"reference/sleap_io/io/video_reading/","title":"video_reading","text":""},{"location":"reference/sleap_io/io/video_reading/#sleap_io.io.video_reading","title":"<code>sleap_io.io.video_reading</code>","text":"<p>Backends for reading videos.</p> <p>Classes:</p> Name Description <code>HDF5Video</code> <p>Video backend for reading videos stored in HDF5 files.</p> <code>ImageVideo</code> <p>Video backend for reading videos stored as image files.</p> <code>MediaVideo</code> <p>Video backend for reading videos stored as common media files.</p> <code>TiffVideo</code> <p>Video backend for reading multi-page TIFF stacks.</p> <code>VideoBackend</code> <p>Base class for video backends.</p> <p>Functions:</p> Name Description <code>get_default_video_plugin</code> <p>Get the current default video plugin.</p> <code>normalize_plugin_name</code> <p>Normalize plugin names to standard format.</p> <code>set_default_video_plugin</code> <p>Set the default video plugin for all subsequently loaded videos.</p>"},{"location":"reference/sleap_io/io/video_reading/#sleap_io.io.video_reading.HDF5Video","title":"<code>HDF5Video</code>","text":"<p>               Bases: <code>VideoBackend</code></p> <p>Video backend for reading videos stored in HDF5 files.</p> <p>This backend supports reading videos stored in HDF5 files, both in rank-4 datasets as well as in datasets with lists of binary-encoded images.</p> <p>Embedded image datasets are used in SLEAP when exporting package files (<code>.pkg.slp</code>) with videos embedded in them. This is useful for bundling training or inference data without having to worry about the videos (or frame images) being moved or deleted. It is expected that these types of datasets will be in a <code>Group</code> with a <code>int8</code> variable length dataset called <code>\"video\"</code>. This dataset must also contain an attribute called \"format\" with a string describing the image format (e.g., \"png\" or \"jpg\") which will be used to decode it appropriately.</p> <p>If a <code>frame_numbers</code> dataset is present in the group, it will be used to map from source video frames to the frames in the dataset. This is useful to preserve frame indexing when exporting a subset of frames in the video. It will also be used to populate <code>frame_map</code> and <code>source_inds</code> attributes.</p> <p>Attributes:</p> Name Type Description <code>filename</code> <code>str | Path | list[str] | list[Path]</code> <p>Path to HDF5 file (.h5, .hdf5 or .slp).</p> <code>grayscale</code> <code>Optional[bool]</code> <p>Whether to force grayscale. If None, autodetect on first frame load.</p> <code>keep_open</code> <code>bool</code> <p>Whether to keep the video reader open between calls to read frames. If False, will close the reader after each call. If True (the default), it will keep the reader open and cache it for subsequent calls which may enhance the performance of reading multiple frames.</p> <code>dataset</code> <code>Optional[str]</code> <p>Name of dataset to read from. If <code>None</code>, will try to find a rank-4 dataset by iterating through datasets in the file. If specifying an embedded dataset, this can be the group containing a \"video\" dataset or the dataset itself (e.g., \"video0\" or \"video0/video\").</p> <code>input_format</code> <code>str</code> <p>Format of the data in the dataset. One of \"channels_last\" (the default) in <code>(frames, height, width, channels)</code> order or \"channels_first\" in <code>(frames, channels, width, height)</code> order. Embedded datasets should use the \"channels_last\" format.</p> <code>frame_map</code> <code>dict[int, int]</code> <p>Mapping from frame indices to indices in the dataset. This is used to translate between the frame indices of the images within their source video and the indices of the images in the dataset. This is only used when reading embedded image datasets.</p> <code>source_filename</code> <code>Optional[str]</code> <p>Path to the source video file. This is metadata and only used when reading embedded image datasets.</p> <code>source_inds</code> <code>Optional[ndarray]</code> <p>Indices of the frames in the source video file. This is metadata and only used when reading embedded image datasets.</p> <code>image_format</code> <code>str</code> <p>Format of the images in the embedded dataset. This is metadata and only used when reading embedded image datasets.</p> <p>Methods:</p> Name Description <code>__attrs_post_init__</code> <p>Auto-detect dataset and frame map heuristically.</p> <code>decode_embedded</code> <p>Decode an embedded image string into a numpy array.</p> <code>has_frame</code> <p>Check if a frame index is contained in the video.</p> <code>read_test_frame</code> <p>Read a single frame from the video to test for grayscale.</p> Source code in <code>sleap_io/io/video_reading.py</code> <pre><code>@attrs.define\nclass HDF5Video(VideoBackend):\n    \"\"\"Video backend for reading videos stored in HDF5 files.\n\n    This backend supports reading videos stored in HDF5 files, both in rank-4 datasets\n    as well as in datasets with lists of binary-encoded images.\n\n    Embedded image datasets are used in SLEAP when exporting package files (`.pkg.slp`)\n    with videos embedded in them. This is useful for bundling training or inference data\n    without having to worry about the videos (or frame images) being moved or deleted.\n    It is expected that these types of datasets will be in a `Group` with a `int8`\n    variable length dataset called `\"video\"`. This dataset must also contain an\n    attribute called \"format\" with a string describing the image format (e.g., \"png\" or\n    \"jpg\") which will be used to decode it appropriately.\n\n    If a `frame_numbers` dataset is present in the group, it will be used to map from\n    source video frames to the frames in the dataset. This is useful to preserve frame\n    indexing when exporting a subset of frames in the video. It will also be used to\n    populate `frame_map` and `source_inds` attributes.\n\n    Attributes:\n        filename: Path to HDF5 file (.h5, .hdf5 or .slp).\n        grayscale: Whether to force grayscale. If None, autodetect on first frame load.\n        keep_open: Whether to keep the video reader open between calls to read frames.\n            If False, will close the reader after each call. If True (the default), it\n            will keep the reader open and cache it for subsequent calls which may\n            enhance the performance of reading multiple frames.\n        dataset: Name of dataset to read from. If `None`, will try to find a rank-4\n            dataset by iterating through datasets in the file. If specifying an embedded\n            dataset, this can be the group containing a \"video\" dataset or the dataset\n            itself (e.g., \"video0\" or \"video0/video\").\n        input_format: Format of the data in the dataset. One of \"channels_last\" (the\n            default) in `(frames, height, width, channels)` order or \"channels_first\" in\n            `(frames, channels, width, height)` order. Embedded datasets should use the\n            \"channels_last\" format.\n        frame_map: Mapping from frame indices to indices in the dataset. This is used to\n            translate between the frame indices of the images within their source video\n            and the indices of the images in the dataset. This is only used when reading\n            embedded image datasets.\n        source_filename: Path to the source video file. This is metadata and only used\n            when reading embedded image datasets.\n        source_inds: Indices of the frames in the source video file. This is metadata\n            and only used when reading embedded image datasets.\n        image_format: Format of the images in the embedded dataset. This is metadata and\n            only used when reading embedded image datasets.\n    \"\"\"\n\n    dataset: Optional[str] = None\n    input_format: str = attrs.field(\n        default=\"channels_last\",\n        validator=attrs.validators.in_([\"channels_last\", \"channels_first\"]),\n    )\n    frame_map: dict[int, int] = attrs.field(init=False, default=attrs.Factory(dict))\n    source_filename: Optional[str] = None\n    source_inds: Optional[np.ndarray] = None\n    image_format: str = \"hdf5\"\n\n    EXTS = (\"h5\", \"hdf5\", \"slp\")\n\n    def __attrs_post_init__(self):\n        \"\"\"Auto-detect dataset and frame map heuristically.\"\"\"\n        # Check if the file accessible before applying heuristics.\n        try:\n            f = h5py.File(self.filename, \"r\")\n        except OSError:\n            return\n\n        if self.dataset is None:\n            # Iterate through datasets to find a rank 4 array.\n            def find_movies(name, obj):\n                if isinstance(obj, h5py.Dataset) and obj.ndim == 4:\n                    self.dataset = name\n                    return True\n\n            f.visititems(find_movies)\n\n        if self.dataset is None:\n            # Iterate through datasets to find an embedded video dataset.\n            def find_embedded(name, obj):\n                if isinstance(obj, h5py.Dataset) and name.endswith(\"/video\"):\n                    self.dataset = name\n                    return True\n\n            f.visititems(find_embedded)\n\n        if self.dataset is None:\n            # Couldn't find video datasets.\n            return\n\n        if isinstance(f[self.dataset], h5py.Group):\n            # If this is a group, assume it's an embedded video dataset.\n            if \"video\" in f[self.dataset]:\n                self.dataset = f\"{self.dataset}/video\"\n\n        if self.dataset.split(\"/\")[-1] == \"video\":\n            # This may be an embedded video dataset. Check for frame map.\n            ds = f[self.dataset]\n\n            if \"format\" in ds.attrs:\n                self.image_format = ds.attrs[\"format\"]\n\n            if \"frame_numbers\" in ds.parent:\n                frame_numbers = ds.parent[\"frame_numbers\"][:].astype(int)\n                self.frame_map = {frame: idx for idx, frame in enumerate(frame_numbers)}\n                self.source_inds = frame_numbers\n\n            if \"source_video\" in ds.parent:\n                self.source_filename = json.loads(\n                    ds.parent[\"source_video\"].attrs[\"json\"]\n                )[\"backend\"][\"filename\"]\n\n        f.close()\n\n    @property\n    def num_frames(self) -&gt; int:\n        \"\"\"Number of frames in the video.\"\"\"\n        with h5py.File(self.filename, \"r\") as f:\n            return f[self.dataset].shape[0]\n\n    @property\n    def img_shape(self) -&gt; Tuple[int, int, int]:\n        \"\"\"Shape of a single frame in the video as `(height, width, channels)`.\"\"\"\n        with h5py.File(self.filename, \"r\") as f:\n            ds = f[self.dataset]\n\n            img_shape = None\n            if \"height\" in ds.attrs:\n                # Try to get shape from the attributes.\n                img_shape = (\n                    ds.attrs[\"height\"],\n                    ds.attrs[\"width\"],\n                    ds.attrs[\"channels\"],\n                )\n\n                if img_shape[0] == 0 or img_shape[1] == 0:\n                    # Invalidate the shape if the attributes are zero.\n                    img_shape = None\n\n            if img_shape is None and self.image_format == \"hdf5\" and ds.ndim == 4:\n                # Use the dataset shape if just stored as a rank-4 array.\n                img_shape = ds.shape[1:]\n\n                if self.input_format == \"channels_first\":\n                    img_shape = img_shape[::-1]\n\n        if img_shape is None:\n            # Fall back to reading a test frame.\n            return super().img_shape\n\n        return int(img_shape[0]), int(img_shape[1]), int(img_shape[2])\n\n    def read_test_frame(self) -&gt; np.ndarray:\n        \"\"\"Read a single frame from the video to test for grayscale.\"\"\"\n        if self.frame_map:\n            frame_idx = list(self.frame_map.keys())[0]\n        else:\n            frame_idx = 0\n        return self._read_frame(frame_idx)\n\n    @property\n    def has_embedded_images(self) -&gt; bool:\n        \"\"\"Return True if the dataset contains embedded images.\"\"\"\n        return self.image_format is not None and self.image_format != \"hdf5\"\n\n    @property\n    def embedded_frame_inds(self) -&gt; list[int]:\n        \"\"\"Return the frame indices of the embedded images.\"\"\"\n        return list(self.frame_map.keys())\n\n    def decode_embedded(self, img_string: np.ndarray) -&gt; np.ndarray:\n        \"\"\"Decode an embedded image string into a numpy array.\n\n        Args:\n            img_string: Binary string of the image as a `int8` numpy vector with the\n                bytes as values corresponding to the format-encoded image.\n\n        Returns:\n            The decoded image as a numpy array of shape `(height, width, channels)`. If\n            a rank-2 image is decoded, it will be expanded such that channels will be 1.\n\n            This method does not apply grayscale conversion as per the `grayscale`\n            attribute. Use the `get_frame` or `get_frames` methods of the `VideoBackend`\n            to apply grayscale conversion rather than calling this function directly.\n        \"\"\"\n        if \"cv2\" in sys.modules:\n            img = cv2.imdecode(img_string, cv2.IMREAD_UNCHANGED)\n        else:\n            img = iio.imread(BytesIO(img_string), extension=f\".{self.image_format}\")\n\n        if img.ndim == 2:\n            img = np.expand_dims(img, axis=-1)\n        return img\n\n    def has_frame(self, frame_idx: int) -&gt; bool:\n        \"\"\"Check if a frame index is contained in the video.\n\n        Args:\n            frame_idx: Index of frame to check.\n\n        Returns:\n            `True` if the index is contained in the video, otherwise `False`.\n        \"\"\"\n        if self.frame_map:\n            return frame_idx in self.frame_map\n        else:\n            return frame_idx &lt; len(self)\n\n    def _read_frame(self, frame_idx: int) -&gt; np.ndarray:\n        \"\"\"Read a single frame from the video.\n\n        Args:\n            frame_idx: Index of frame to read.\n\n        Returns:\n            The frame as a numpy array of shape `(height, width, channels)`.\n\n        Notes:\n            This does not apply grayscale conversion. It is recommended to use the\n            `get_frame` method of the `VideoBackend` class instead.\n        \"\"\"\n        if self.keep_open:\n            if self._open_reader is None:\n                self._open_reader = h5py.File(self.filename, \"r\")\n            f = self._open_reader\n        else:\n            f = h5py.File(self.filename, \"r\")\n\n        ds = f[self.dataset]\n\n        if self.frame_map:\n            frame_idx = self.frame_map[frame_idx]\n\n        img = ds[frame_idx]\n\n        if self.has_embedded_images:\n            img = self.decode_embedded(img)\n\n        if self.input_format == \"channels_first\":\n            img = np.transpose(img, (2, 1, 0))\n\n        if not self.keep_open:\n            f.close()\n        return img\n\n    def _read_frames(self, frame_inds: list) -&gt; np.ndarray:\n        \"\"\"Read a list of frames from the video.\n\n        Args:\n            frame_inds: List of indices of frames to read.\n\n        Returns:\n            The frame as a numpy array of shape `(frames, height, width, channels)`.\n\n        Notes:\n            This does not apply grayscale conversion. It is recommended to use the\n            `get_frames` method of the `VideoBackend` class instead.\n        \"\"\"\n        if self.keep_open:\n            if self._open_reader is None:\n                self._open_reader = h5py.File(self.filename, \"r\")\n            f = self._open_reader\n        else:\n            f = h5py.File(self.filename, \"r\")\n\n        if self.frame_map:\n            frame_inds = [self.frame_map[idx] for idx in frame_inds]\n\n        ds = f[self.dataset]\n        imgs = ds[frame_inds]\n\n        if \"format\" in ds.attrs:\n            imgs = np.stack(\n                [self.decode_embedded(img) for img in imgs],\n                axis=0,\n            )\n\n        if self.input_format == \"channels_first\":\n            imgs = np.transpose(imgs, (0, 3, 2, 1))\n\n        if not self.keep_open:\n            f.close()\n\n        return imgs\n</code></pre>"},{"location":"reference/sleap_io/io/video_reading/#sleap_io.io.video_reading.HDF5Video.embedded_frame_inds","title":"<code>embedded_frame_inds</code>  <code>property</code>","text":"<p>Return the frame indices of the embedded images.</p>"},{"location":"reference/sleap_io/io/video_reading/#sleap_io.io.video_reading.HDF5Video.has_embedded_images","title":"<code>has_embedded_images</code>  <code>property</code>","text":"<p>Return True if the dataset contains embedded images.</p>"},{"location":"reference/sleap_io/io/video_reading/#sleap_io.io.video_reading.HDF5Video.img_shape","title":"<code>img_shape</code>  <code>property</code>","text":"<p>Shape of a single frame in the video as <code>(height, width, channels)</code>.</p>"},{"location":"reference/sleap_io/io/video_reading/#sleap_io.io.video_reading.HDF5Video.num_frames","title":"<code>num_frames</code>  <code>property</code>","text":"<p>Number of frames in the video.</p>"},{"location":"reference/sleap_io/io/video_reading/#sleap_io.io.video_reading.HDF5Video.__attrs_post_init__","title":"<code>__attrs_post_init__()</code>","text":"<p>Auto-detect dataset and frame map heuristically.</p> Source code in <code>sleap_io/io/video_reading.py</code> <pre><code>def __attrs_post_init__(self):\n    \"\"\"Auto-detect dataset and frame map heuristically.\"\"\"\n    # Check if the file accessible before applying heuristics.\n    try:\n        f = h5py.File(self.filename, \"r\")\n    except OSError:\n        return\n\n    if self.dataset is None:\n        # Iterate through datasets to find a rank 4 array.\n        def find_movies(name, obj):\n            if isinstance(obj, h5py.Dataset) and obj.ndim == 4:\n                self.dataset = name\n                return True\n\n        f.visititems(find_movies)\n\n    if self.dataset is None:\n        # Iterate through datasets to find an embedded video dataset.\n        def find_embedded(name, obj):\n            if isinstance(obj, h5py.Dataset) and name.endswith(\"/video\"):\n                self.dataset = name\n                return True\n\n        f.visititems(find_embedded)\n\n    if self.dataset is None:\n        # Couldn't find video datasets.\n        return\n\n    if isinstance(f[self.dataset], h5py.Group):\n        # If this is a group, assume it's an embedded video dataset.\n        if \"video\" in f[self.dataset]:\n            self.dataset = f\"{self.dataset}/video\"\n\n    if self.dataset.split(\"/\")[-1] == \"video\":\n        # This may be an embedded video dataset. Check for frame map.\n        ds = f[self.dataset]\n\n        if \"format\" in ds.attrs:\n            self.image_format = ds.attrs[\"format\"]\n\n        if \"frame_numbers\" in ds.parent:\n            frame_numbers = ds.parent[\"frame_numbers\"][:].astype(int)\n            self.frame_map = {frame: idx for idx, frame in enumerate(frame_numbers)}\n            self.source_inds = frame_numbers\n\n        if \"source_video\" in ds.parent:\n            self.source_filename = json.loads(\n                ds.parent[\"source_video\"].attrs[\"json\"]\n            )[\"backend\"][\"filename\"]\n\n    f.close()\n</code></pre>"},{"location":"reference/sleap_io/io/video_reading/#sleap_io.io.video_reading.HDF5Video.decode_embedded","title":"<code>decode_embedded(img_string)</code>","text":"<p>Decode an embedded image string into a numpy array.</p> <p>Parameters:</p> Name Type Description Default <code>img_string</code> <code>ndarray</code> <p>Binary string of the image as a <code>int8</code> numpy vector with the bytes as values corresponding to the format-encoded image.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>The decoded image as a numpy array of shape <code>(height, width, channels)</code>. If a rank-2 image is decoded, it will be expanded such that channels will be 1.</p> <p>This method does not apply grayscale conversion as per the <code>grayscale</code> attribute. Use the <code>get_frame</code> or <code>get_frames</code> methods of the <code>VideoBackend</code> to apply grayscale conversion rather than calling this function directly.</p> Source code in <code>sleap_io/io/video_reading.py</code> <pre><code>def decode_embedded(self, img_string: np.ndarray) -&gt; np.ndarray:\n    \"\"\"Decode an embedded image string into a numpy array.\n\n    Args:\n        img_string: Binary string of the image as a `int8` numpy vector with the\n            bytes as values corresponding to the format-encoded image.\n\n    Returns:\n        The decoded image as a numpy array of shape `(height, width, channels)`. If\n        a rank-2 image is decoded, it will be expanded such that channels will be 1.\n\n        This method does not apply grayscale conversion as per the `grayscale`\n        attribute. Use the `get_frame` or `get_frames` methods of the `VideoBackend`\n        to apply grayscale conversion rather than calling this function directly.\n    \"\"\"\n    if \"cv2\" in sys.modules:\n        img = cv2.imdecode(img_string, cv2.IMREAD_UNCHANGED)\n    else:\n        img = iio.imread(BytesIO(img_string), extension=f\".{self.image_format}\")\n\n    if img.ndim == 2:\n        img = np.expand_dims(img, axis=-1)\n    return img\n</code></pre>"},{"location":"reference/sleap_io/io/video_reading/#sleap_io.io.video_reading.HDF5Video.has_frame","title":"<code>has_frame(frame_idx)</code>","text":"<p>Check if a frame index is contained in the video.</p> <p>Parameters:</p> Name Type Description Default <code>frame_idx</code> <code>int</code> <p>Index of frame to check.</p> required <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if the index is contained in the video, otherwise <code>False</code>.</p> Source code in <code>sleap_io/io/video_reading.py</code> <pre><code>def has_frame(self, frame_idx: int) -&gt; bool:\n    \"\"\"Check if a frame index is contained in the video.\n\n    Args:\n        frame_idx: Index of frame to check.\n\n    Returns:\n        `True` if the index is contained in the video, otherwise `False`.\n    \"\"\"\n    if self.frame_map:\n        return frame_idx in self.frame_map\n    else:\n        return frame_idx &lt; len(self)\n</code></pre>"},{"location":"reference/sleap_io/io/video_reading/#sleap_io.io.video_reading.HDF5Video.read_test_frame","title":"<code>read_test_frame()</code>","text":"<p>Read a single frame from the video to test for grayscale.</p> Source code in <code>sleap_io/io/video_reading.py</code> <pre><code>def read_test_frame(self) -&gt; np.ndarray:\n    \"\"\"Read a single frame from the video to test for grayscale.\"\"\"\n    if self.frame_map:\n        frame_idx = list(self.frame_map.keys())[0]\n    else:\n        frame_idx = 0\n    return self._read_frame(frame_idx)\n</code></pre>"},{"location":"reference/sleap_io/io/video_reading/#sleap_io.io.video_reading.ImageVideo","title":"<code>ImageVideo</code>","text":"<p>               Bases: <code>VideoBackend</code></p> <p>Video backend for reading videos stored as image files.</p> <p>This backend supports reading videos stored as a list of images.</p> <p>Attributes:</p> Name Type Description <code>filename</code> <code>str | Path | list[str] | list[Path]</code> <p>Path to image files.</p> <code>grayscale</code> <code>Optional[bool]</code> <p>Whether to force grayscale. If None, autodetect on first frame load.</p> <p>Methods:</p> Name Description <code>find_images</code> <p>Find images in a folder and return a list of filenames.</p> Source code in <code>sleap_io/io/video_reading.py</code> <pre><code>@attrs.define\nclass ImageVideo(VideoBackend):\n    \"\"\"Video backend for reading videos stored as image files.\n\n    This backend supports reading videos stored as a list of images.\n\n    Attributes:\n        filename: Path to image files.\n        grayscale: Whether to force grayscale. If None, autodetect on first frame load.\n    \"\"\"\n\n    EXTS = (\"png\", \"jpg\", \"jpeg\", \"tif\", \"tiff\", \"bmp\")\n\n    @staticmethod\n    def find_images(folder: str) -&gt; list[str]:\n        \"\"\"Find images in a folder and return a list of filenames.\"\"\"\n        folder = Path(folder)\n        return sorted(\n            [f.as_posix() for f in folder.glob(\"*\") if f.suffix[1:] in ImageVideo.EXTS]\n        )\n\n    @property\n    def num_frames(self) -&gt; int:\n        \"\"\"Number of frames in the video.\"\"\"\n        return len(self.filename)\n\n    def _read_frame(self, frame_idx: int) -&gt; np.ndarray:\n        \"\"\"Read a single frame from the video.\n\n        Args:\n            frame_idx: Index of frame to read.\n\n        Returns:\n            The frame as a numpy array of shape `(height, width, channels)`.\n\n        Notes:\n            This does not apply grayscale conversion. It is recommended to use the\n            `get_frame` method of the `VideoBackend` class instead.\n        \"\"\"\n        img = iio.imread(self.filename[frame_idx])\n        if img.ndim == 2:\n            img = np.expand_dims(img, axis=-1)\n        return img\n</code></pre>"},{"location":"reference/sleap_io/io/video_reading/#sleap_io.io.video_reading.ImageVideo.num_frames","title":"<code>num_frames</code>  <code>property</code>","text":"<p>Number of frames in the video.</p>"},{"location":"reference/sleap_io/io/video_reading/#sleap_io.io.video_reading.ImageVideo.find_images","title":"<code>find_images(folder)</code>  <code>staticmethod</code>","text":"<p>Find images in a folder and return a list of filenames.</p> Source code in <code>sleap_io/io/video_reading.py</code> <pre><code>@staticmethod\ndef find_images(folder: str) -&gt; list[str]:\n    \"\"\"Find images in a folder and return a list of filenames.\"\"\"\n    folder = Path(folder)\n    return sorted(\n        [f.as_posix() for f in folder.glob(\"*\") if f.suffix[1:] in ImageVideo.EXTS]\n    )\n</code></pre>"},{"location":"reference/sleap_io/io/video_reading/#sleap_io.io.video_reading.MediaVideo","title":"<code>MediaVideo</code>","text":"<p>               Bases: <code>VideoBackend</code></p> <p>Video backend for reading videos stored as common media files.</p> <p>This backend supports reading through FFMPEG (the default), pyav, or OpenCV. Here are their trade-offs:</p> <pre><code>- \"opencv\": Fastest video reader, but only supports a limited number of codecs\n    and may not be able to read some videos. It requires `opencv-python` to be\n    installed. It is the fastest because it uses the OpenCV C++ library to read\n    videos, but is limited by the version of FFMPEG that was linked into it at\n    build time as well as the OpenCV version used.\n- \"FFMPEG\": Slowest, but most reliable. This is the default backend. It requires\n    `imageio-ffmpeg` and a `ffmpeg` executable on the system path (which can be\n    installed via conda). The `imageio` plugin for FFMPEG reads frames into raw\n    bytes which are communicated to Python through STDOUT on a subprocess pipe,\n    which can be slow. However, it is the most reliable and feature-complete. If\n    you install the conda-forge version of ffmpeg, it will be compiled with\n    support for many codecs, including GPU-accelerated codecs like NVDEC for\n    H264 and others.\n- \"pyav\": Supports most codecs that FFMPEG does, but not as complete or reliable\n    of an implementation in `imageio` as FFMPEG for some video types. It is\n    faster than FFMPEG because it uses the `av` package to read frames directly\n    into numpy arrays in memory without the need for a subprocess pipe. These\n    are Python bindings for the C library libav, which is the same library that\n    FFMPEG uses under the hood.\n</code></pre> <p>Attributes:</p> Name Type Description <code>filename</code> <code>str | Path | list[str] | list[Path]</code> <p>Path to video file.</p> <code>grayscale</code> <code>Optional[bool]</code> <p>Whether to force grayscale. If None, autodetect on first frame load.</p> <code>keep_open</code> <code>bool</code> <p>Whether to keep the video reader open between calls to read frames. If False, will close the reader after each call. If True (the default), it will keep the reader open and cache it for subsequent calls which may enhance the performance of reading multiple frames.</p> <code>plugin</code> <code>str</code> <p>Video plugin to use. One of \"opencv\", \"FFMPEG\", or \"pyav\". If <code>None</code>, will use the first available plugin in the order listed above.</p> Source code in <code>sleap_io/io/video_reading.py</code> <pre><code>@attrs.define\nclass MediaVideo(VideoBackend):\n    \"\"\"Video backend for reading videos stored as common media files.\n\n    This backend supports reading through FFMPEG (the default), pyav, or OpenCV. Here\n    are their trade-offs:\n\n        - \"opencv\": Fastest video reader, but only supports a limited number of codecs\n            and may not be able to read some videos. It requires `opencv-python` to be\n            installed. It is the fastest because it uses the OpenCV C++ library to read\n            videos, but is limited by the version of FFMPEG that was linked into it at\n            build time as well as the OpenCV version used.\n        - \"FFMPEG\": Slowest, but most reliable. This is the default backend. It requires\n            `imageio-ffmpeg` and a `ffmpeg` executable on the system path (which can be\n            installed via conda). The `imageio` plugin for FFMPEG reads frames into raw\n            bytes which are communicated to Python through STDOUT on a subprocess pipe,\n            which can be slow. However, it is the most reliable and feature-complete. If\n            you install the conda-forge version of ffmpeg, it will be compiled with\n            support for many codecs, including GPU-accelerated codecs like NVDEC for\n            H264 and others.\n        - \"pyav\": Supports most codecs that FFMPEG does, but not as complete or reliable\n            of an implementation in `imageio` as FFMPEG for some video types. It is\n            faster than FFMPEG because it uses the `av` package to read frames directly\n            into numpy arrays in memory without the need for a subprocess pipe. These\n            are Python bindings for the C library libav, which is the same library that\n            FFMPEG uses under the hood.\n\n    Attributes:\n        filename: Path to video file.\n        grayscale: Whether to force grayscale. If None, autodetect on first frame load.\n        keep_open: Whether to keep the video reader open between calls to read frames.\n            If False, will close the reader after each call. If True (the default), it\n            will keep the reader open and cache it for subsequent calls which may\n            enhance the performance of reading multiple frames.\n        plugin: Video plugin to use. One of \"opencv\", \"FFMPEG\", or \"pyav\". If `None`,\n            will use the first available plugin in the order listed above.\n    \"\"\"\n\n    plugin: str = attrs.field()\n\n    @plugin.validator\n    def _validate_plugin(self, attribute, value):\n        # Normalize the plugin name\n        normalized = normalize_plugin_name(value)\n        # Update the actual value to the normalized version\n        object.__setattr__(self, attribute.name, normalized)\n\n    EXTS = (\"mp4\", \"avi\", \"mov\", \"mj2\", \"mkv\")\n\n    @plugin.default\n    def _default_plugin(self) -&gt; str:\n        # Check global default first\n        if _default_video_plugin is not None:\n            return _default_video_plugin\n\n        # Otherwise auto-detect\n        if \"cv2\" in sys.modules:\n            return \"opencv\"\n        elif \"imageio_ffmpeg\" in sys.modules:\n            return \"FFMPEG\"\n        elif \"av\" in sys.modules:\n            return \"pyav\"\n        else:\n            raise ImportError(\n                \"No video plugins found. Install opencv-python, imageio-ffmpeg, or av.\"\n            )\n\n    @property\n    def reader(self) -&gt; object:\n        \"\"\"Return the reader object for the video, caching if necessary.\"\"\"\n        if self.keep_open:\n            if self._open_reader is None:\n                if self.plugin == \"opencv\":\n                    self._open_reader = cv2.VideoCapture(self.filename)\n                elif self.plugin == \"pyav\" or self.plugin == \"FFMPEG\":\n                    self._open_reader = iio.imopen(\n                        self.filename, \"r\", plugin=self.plugin\n                    )\n            return self._open_reader\n        else:\n            if self.plugin == \"opencv\":\n                return cv2.VideoCapture(self.filename)\n            elif self.plugin == \"pyav\" or self.plugin == \"FFMPEG\":\n                return iio.imopen(self.filename, \"r\", plugin=self.plugin)\n\n    @property\n    def num_frames(self) -&gt; int:\n        \"\"\"Number of frames in the video.\"\"\"\n        if self.plugin == \"opencv\":\n            return int(self.reader.get(cv2.CAP_PROP_FRAME_COUNT))\n        else:\n            props = iio.improps(self.filename, plugin=self.plugin)\n            n_frames = props.n_images\n            if np.isinf(n_frames):\n                legacy_reader = self.reader.legacy_get_reader()\n                # Note: This might be super slow for some videos, so maybe we should\n                # defer evaluation of this or give the user control over it.\n                n_frames = legacy_reader.count_frames()\n            return n_frames\n\n    def _read_frame(self, frame_idx: int) -&gt; np.ndarray:\n        \"\"\"Read a single frame from the video.\n\n        Args:\n            frame_idx: Index of frame to read.\n\n        Returns:\n            The frame as a numpy array of shape `(height, width, channels)`.\n\n        Notes:\n            This does not apply grayscale conversion. It is recommended to use the\n            `get_frame` method of the `VideoBackend` class instead.\n        \"\"\"\n        if self.plugin == \"opencv\":\n            if self.keep_open:\n                if self._open_reader is None:\n                    self._open_reader = cv2.VideoCapture(self.filename)\n                reader = self._open_reader\n            else:\n                reader = cv2.VideoCapture(self.filename)\n\n            if reader.get(cv2.CAP_PROP_POS_FRAMES) != frame_idx:\n                reader.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n            success, img = reader.read()\n\n            if success:\n                img = img[..., ::-1]  # BGR -&gt; RGB\n\n        elif self.plugin == \"pyav\" or self.plugin == \"FFMPEG\":\n            if self.keep_open:\n                img = self.reader.read(index=frame_idx)\n            else:\n                with iio.imopen(self.filename, \"r\", plugin=self.plugin) as reader:\n                    img = reader.read(index=frame_idx)\n            success = img is not None\n\n        if not success:\n            raise IndexError(f\"Failed to read frame index {frame_idx}.\")\n\n        return img\n\n    def _read_frames(self, frame_inds: list) -&gt; np.ndarray:\n        \"\"\"Read a list of frames from the video.\n\n        Args:\n            frame_inds: List of indices of frames to read.\n\n        Returns:\n            The frame as a numpy array of shape `(frames, height, width, channels)`.\n\n        Notes:\n            This does not apply grayscale conversion. It is recommended to use the\n            `get_frames` method of the `VideoBackend` class instead.\n        \"\"\"\n        if self.plugin == \"opencv\":\n            if self.keep_open:\n                if self._open_reader is None:\n                    self._open_reader = cv2.VideoCapture(self.filename)\n                reader = self._open_reader\n            else:\n                reader = cv2.VideoCapture(self.filename)\n\n            reader.set(cv2.CAP_PROP_POS_FRAMES, frame_inds[0])\n            imgs = []\n            for idx in frame_inds:\n                if reader.get(cv2.CAP_PROP_POS_FRAMES) != idx:\n                    reader.set(cv2.CAP_PROP_POS_FRAMES, idx)\n                _, img = reader.read()\n                imgs.append(img)\n            imgs = np.stack(imgs, axis=0)\n\n            imgs = imgs[..., ::-1]  # BGR -&gt; RGB\n\n        elif self.plugin == \"pyav\" or self.plugin == \"FFMPEG\":\n            if self.keep_open:\n                if self._open_reader is None:\n                    self._open_reader = iio.imopen(\n                        self.filename, \"r\", plugin=self.plugin\n                    )\n                reader = self._open_reader\n                imgs = np.stack([reader.read(index=idx) for idx in frame_inds], axis=0)\n            else:\n                with iio.imopen(self.filename, \"r\", plugin=self.plugin) as reader:\n                    imgs = np.stack(\n                        [reader.read(index=idx) for idx in frame_inds], axis=0\n                    )\n        return imgs\n</code></pre>"},{"location":"reference/sleap_io/io/video_reading/#sleap_io.io.video_reading.MediaVideo.num_frames","title":"<code>num_frames</code>  <code>property</code>","text":"<p>Number of frames in the video.</p>"},{"location":"reference/sleap_io/io/video_reading/#sleap_io.io.video_reading.MediaVideo.reader","title":"<code>reader</code>  <code>property</code>","text":"<p>Return the reader object for the video, caching if necessary.</p>"},{"location":"reference/sleap_io/io/video_reading/#sleap_io.io.video_reading.TiffVideo","title":"<code>TiffVideo</code>","text":"<p>               Bases: <code>VideoBackend</code></p> <p>Video backend for reading multi-page TIFF stacks.</p> <p>This backend supports reading multi-page TIFF files as video sequences. Each page in the TIFF is treated as a frame.</p> <p>Attributes:</p> Name Type Description <code>filename</code> <code>str | Path | list[str] | list[Path]</code> <p>Path to the multi-page TIFF file.</p> <code>grayscale</code> <code>Optional[bool]</code> <p>Whether to force grayscale. If None, autodetect on first frame load.</p> <code>keep_open</code> <code>bool</code> <p>Whether to keep the reader open between calls to read frames.</p> <code>format</code> <code>Optional[str]</code> <p>Format of the TIFF file (\"multi_page\", \"THW\", \"HWT\", \"THWC\", \"CHWT\").</p> <p>Methods:</p> Name Description <code>__attrs_post_init__</code> <p>Initialize format if not provided.</p> <code>detect_format</code> <p>Detect TIFF format and shape for single files.</p> <code>is_multipage</code> <p>Check if a TIFF file contains multiple pages.</p> Source code in <code>sleap_io/io/video_reading.py</code> <pre><code>@attrs.define\nclass TiffVideo(VideoBackend):\n    \"\"\"Video backend for reading multi-page TIFF stacks.\n\n    This backend supports reading multi-page TIFF files as video sequences.\n    Each page in the TIFF is treated as a frame.\n\n    Attributes:\n        filename: Path to the multi-page TIFF file.\n        grayscale: Whether to force grayscale. If None, autodetect on first frame load.\n        keep_open: Whether to keep the reader open between calls to read frames.\n        format: Format of the TIFF file (\"multi_page\", \"THW\", \"HWT\", \"THWC\", \"CHWT\").\n    \"\"\"\n\n    EXTS = (\"tif\", \"tiff\")\n    format: Optional[str] = None\n\n    @staticmethod\n    def is_multipage(filename: str) -&gt; bool:\n        \"\"\"Check if a TIFF file contains multiple pages.\n\n        Args:\n            filename: Path to the TIFF file.\n\n        Returns:\n            True if the TIFF contains multiple pages, False otherwise.\n        \"\"\"\n        try:\n            # Try to read the second frame\n            iio.imread(filename, index=1)\n            return True\n        except (IndexError, ValueError):\n            return False\n        except Exception:\n            # For any other error, assume it's not multi-page\n            return False\n\n    @staticmethod\n    def detect_format(filename: str) -&gt; tuple[str, dict]:\n        \"\"\"Detect TIFF format and shape for single files.\n\n        Args:\n            filename: Path to the TIFF file.\n\n        Returns:\n            Tuple of (format_type, metadata) where:\n            - format_type: \"single_frame\", \"multi_page\", \"rank3_video\", or \"rank4_video\"\n            - metadata: dict with shape info and inferred format\n        \"\"\"\n        try:\n            # Read first frame to check shape\n            img = iio.imread(filename, index=0)\n            shape = img.shape\n\n            # Check if multi-page first\n            is_multi = TiffVideo.is_multipage(filename)\n\n            if is_multi:\n                return \"multi_page\", {\"shape\": shape}\n\n            # Single page cases\n            if img.ndim == 2:\n                # Rank-2: single channel image\n                return \"single_frame\", {\"shape\": shape}\n            elif img.ndim == 3:\n                # Rank-3: could be HWC (single frame) or THW/HWT (video)\n                return TiffVideo._detect_rank3_format(shape)\n            elif img.ndim == 4:\n                # Rank-4: video with channels\n                return TiffVideo._detect_rank4_format(shape)\n            else:\n                return \"single_frame\", {\"shape\": shape}\n\n        except Exception:\n            return \"single_frame\", {\"shape\": None}\n\n    @staticmethod\n    def _detect_rank3_format(shape: tuple) -&gt; tuple[str, dict]:\n        \"\"\"Detect format for rank-3 TIFF files.\n\n        Args:\n            shape: Shape tuple (dim1, dim2, dim3)\n\n        Returns:\n            Tuple of (format_type, metadata)\n        \"\"\"\n        dim1, dim2, dim3 = shape\n\n        # If last dimension is 1 or 3, likely HWC (single frame)\n        if dim3 in (1, 3):\n            return \"single_frame\", {\"shape\": shape, \"format\": \"HWC\"}\n\n        # If first two dims are equal, it's likely HWT format\n        # (most common case for square frames stored as H x W x T)\n        if dim1 == dim2:\n            # Default to HWT format for square frames\n            return \"rank3_video\", {\n                \"shape\": shape,\n                \"format\": \"HWT\",\n                \"height\": dim1,\n                \"width\": dim2,\n                \"n_frames\": dim3,\n            }\n        else:\n            # For non-square frames, check if it could be THW\n            # This is less common but possible\n            if dim2 == dim3:\n                # Could be THW format\n                return \"rank3_video\", {\n                    \"shape\": shape,\n                    \"format\": \"THW\",\n                    \"n_frames\": dim1,\n                    \"height\": dim2,\n                    \"width\": dim3,\n                }\n            else:\n                # Default to HWT format\n                return \"rank3_video\", {\n                    \"shape\": shape,\n                    \"format\": \"HWT\",\n                    \"height\": dim1,\n                    \"width\": dim2,\n                    \"n_frames\": dim3,\n                }\n\n    @staticmethod\n    def _detect_rank4_format(shape: tuple) -&gt; tuple[str, dict]:\n        \"\"\"Detect format for rank-4 TIFF files.\n\n        Args:\n            shape: Shape tuple (dim1, dim2, dim3, dim4)\n\n        Returns:\n            Tuple of (format_type, metadata)\n        \"\"\"\n        dim1, dim2, dim3, dim4 = shape\n\n        # Check if first or last dimension is 1 or 3 (channels)\n        if dim1 in (1, 3):\n            # CHWT format\n            return \"rank4_video\", {\n                \"shape\": shape,\n                \"format\": \"CHWT\",\n                \"channels\": dim1,\n                \"height\": dim2,\n                \"width\": dim3,\n                \"n_frames\": dim4,\n            }\n        elif dim4 in (1, 3):\n            # THWC format\n            return \"rank4_video\", {\n                \"shape\": shape,\n                \"format\": \"THWC\",\n                \"n_frames\": dim1,\n                \"height\": dim2,\n                \"width\": dim3,\n                \"channels\": dim4,\n            }\n        else:\n            # Default to THWC\n            return \"rank4_video\", {\n                \"shape\": shape,\n                \"format\": \"THWC\",\n                \"n_frames\": dim1,\n                \"height\": dim2,\n                \"width\": dim3,\n                \"channels\": dim4,\n            }\n\n    def __attrs_post_init__(self):\n        \"\"\"Initialize format if not provided.\"\"\"\n        if self.format is None:\n            # Auto-detect format\n            format_type, metadata = TiffVideo.detect_format(self.filename)\n            if format_type == \"multi_page\":\n                self.format = \"multi_page\"\n            elif format_type in (\"rank3_video\", \"rank4_video\"):\n                self.format = metadata.get(\"format\", \"multi_page\")\n            else:\n                self.format = \"multi_page\"\n\n    @property\n    def num_frames(self) -&gt; int:\n        \"\"\"Number of frames in the TIFF stack.\"\"\"\n        if self.format == \"multi_page\":\n            # Count frames by trying to read each one until we get an error\n            frame_count = 0\n            while True:\n                try:\n                    iio.imread(self.filename, index=frame_count)\n                    frame_count += 1\n                except (IndexError, ValueError):\n                    break\n            return frame_count\n        else:\n            # For rank3/rank4 formats, detect from shape\n            format_type, metadata = TiffVideo.detect_format(self.filename)\n            return metadata.get(\"n_frames\", 1)\n\n    def _read_frame(self, frame_idx: int) -&gt; np.ndarray:\n        \"\"\"Read a single frame from the TIFF stack.\n\n        Args:\n            frame_idx: Index of frame to read.\n\n        Returns:\n            The frame as a numpy array of shape `(height, width, channels)`.\n\n        Notes:\n            This does not apply grayscale conversion. It is recommended to use the\n            `get_frame` method of the `VideoBackend` class instead.\n        \"\"\"\n        if self.format == \"multi_page\":\n            img = iio.imread(self.filename, index=frame_idx)\n            if img.ndim == 2:\n                img = np.expand_dims(img, axis=-1)\n            return img\n        else:\n            # Read entire array for rank3/rank4 formats\n            img = iio.imread(self.filename)\n\n            if self.format == \"THW\":\n                # Extract frame from THW format\n                frame = img[frame_idx, :, :]\n                return np.expand_dims(frame, axis=-1)\n            elif self.format == \"HWT\":\n                # Extract frame from HWT format\n                frame = img[:, :, frame_idx]\n                return np.expand_dims(frame, axis=-1)\n            elif self.format == \"THWC\":\n                # Extract frame from THWC format\n                return img[frame_idx, :, :, :]\n            elif self.format == \"CHWT\":\n                # Extract frame from CHWT format\n                frame = img[:, :, :, frame_idx]\n                return np.moveaxis(frame, 0, -1)  # CHW -&gt; HWC\n            else:\n                raise ValueError(f\"Unknown format: {self.format}\")\n\n    def _read_frames(self, frame_inds: list) -&gt; np.ndarray:\n        \"\"\"Read multiple frames from the TIFF stack.\n\n        Args:\n            frame_inds: List of frame indices to read.\n\n        Returns:\n            Frames as a numpy array of shape `(frames, height, width, channels)`.\n        \"\"\"\n        if self.format == \"multi_page\":\n            imgs = []\n            for idx in frame_inds:\n                imgs.append(self._read_frame(idx))\n            return np.stack(imgs, axis=0)\n        else:\n            # For rank3/rank4, read all at once and extract\n            img = iio.imread(self.filename)\n\n            if self.format == \"THW\":\n                frames = img[frame_inds, :, :]\n                return np.expand_dims(frames, axis=-1)\n            elif self.format == \"HWT\":\n                frames = img[:, :, frame_inds]\n                frames = np.moveaxis(frames, -1, 0)  # HWT -&gt; THW\n                return np.expand_dims(frames, axis=-1)\n            elif self.format == \"THWC\":\n                return img[frame_inds, :, :, :]\n            elif self.format == \"CHWT\":\n                frames = img[:, :, :, frame_inds]\n                frames = np.moveaxis(frames, -1, 0)  # CHWT -&gt; TCHW\n                frames = np.moveaxis(frames, 1, -1)  # TCHW -&gt; THWC\n                return frames\n            else:\n                raise ValueError(f\"Unknown format: {self.format}\")\n</code></pre>"},{"location":"reference/sleap_io/io/video_reading/#sleap_io.io.video_reading.TiffVideo.num_frames","title":"<code>num_frames</code>  <code>property</code>","text":"<p>Number of frames in the TIFF stack.</p>"},{"location":"reference/sleap_io/io/video_reading/#sleap_io.io.video_reading.TiffVideo.__attrs_post_init__","title":"<code>__attrs_post_init__()</code>","text":"<p>Initialize format if not provided.</p> Source code in <code>sleap_io/io/video_reading.py</code> <pre><code>def __attrs_post_init__(self):\n    \"\"\"Initialize format if not provided.\"\"\"\n    if self.format is None:\n        # Auto-detect format\n        format_type, metadata = TiffVideo.detect_format(self.filename)\n        if format_type == \"multi_page\":\n            self.format = \"multi_page\"\n        elif format_type in (\"rank3_video\", \"rank4_video\"):\n            self.format = metadata.get(\"format\", \"multi_page\")\n        else:\n            self.format = \"multi_page\"\n</code></pre>"},{"location":"reference/sleap_io/io/video_reading/#sleap_io.io.video_reading.TiffVideo.detect_format","title":"<code>detect_format(filename)</code>  <code>staticmethod</code>","text":"<p>Detect TIFF format and shape for single files.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>Path to the TIFF file.</p> required <p>Returns:</p> Type Description <code>tuple[str, dict]</code> <p>Tuple of (format_type, metadata) where: - format_type: \"single_frame\", \"multi_page\", \"rank3_video\", or \"rank4_video\" - metadata: dict with shape info and inferred format</p> Source code in <code>sleap_io/io/video_reading.py</code> <pre><code>@staticmethod\ndef detect_format(filename: str) -&gt; tuple[str, dict]:\n    \"\"\"Detect TIFF format and shape for single files.\n\n    Args:\n        filename: Path to the TIFF file.\n\n    Returns:\n        Tuple of (format_type, metadata) where:\n        - format_type: \"single_frame\", \"multi_page\", \"rank3_video\", or \"rank4_video\"\n        - metadata: dict with shape info and inferred format\n    \"\"\"\n    try:\n        # Read first frame to check shape\n        img = iio.imread(filename, index=0)\n        shape = img.shape\n\n        # Check if multi-page first\n        is_multi = TiffVideo.is_multipage(filename)\n\n        if is_multi:\n            return \"multi_page\", {\"shape\": shape}\n\n        # Single page cases\n        if img.ndim == 2:\n            # Rank-2: single channel image\n            return \"single_frame\", {\"shape\": shape}\n        elif img.ndim == 3:\n            # Rank-3: could be HWC (single frame) or THW/HWT (video)\n            return TiffVideo._detect_rank3_format(shape)\n        elif img.ndim == 4:\n            # Rank-4: video with channels\n            return TiffVideo._detect_rank4_format(shape)\n        else:\n            return \"single_frame\", {\"shape\": shape}\n\n    except Exception:\n        return \"single_frame\", {\"shape\": None}\n</code></pre>"},{"location":"reference/sleap_io/io/video_reading/#sleap_io.io.video_reading.TiffVideo.is_multipage","title":"<code>is_multipage(filename)</code>  <code>staticmethod</code>","text":"<p>Check if a TIFF file contains multiple pages.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>Path to the TIFF file.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the TIFF contains multiple pages, False otherwise.</p> Source code in <code>sleap_io/io/video_reading.py</code> <pre><code>@staticmethod\ndef is_multipage(filename: str) -&gt; bool:\n    \"\"\"Check if a TIFF file contains multiple pages.\n\n    Args:\n        filename: Path to the TIFF file.\n\n    Returns:\n        True if the TIFF contains multiple pages, False otherwise.\n    \"\"\"\n    try:\n        # Try to read the second frame\n        iio.imread(filename, index=1)\n        return True\n    except (IndexError, ValueError):\n        return False\n    except Exception:\n        # For any other error, assume it's not multi-page\n        return False\n</code></pre>"},{"location":"reference/sleap_io/io/video_reading/#sleap_io.io.video_reading.VideoBackend","title":"<code>VideoBackend</code>","text":"<p>Base class for video backends.</p> <p>This class is not meant to be used directly. Instead, use the <code>from_filename</code> constructor to create a backend instance.</p> <p>Attributes:</p> Name Type Description <code>filename</code> <code>str | Path | list[str] | list[Path]</code> <p>Path to video file(s).</p> <code>grayscale</code> <code>Optional[bool]</code> <p>Whether to force grayscale. If None, autodetect on first frame load.</p> <code>keep_open</code> <code>bool</code> <p>Whether to keep the video reader open between calls to read frames. If False, will close the reader after each call. If True (the default), it will keep the reader open and cache it for subsequent calls which may enhance the performance of reading multiple frames.</p> <p>Methods:</p> Name Description <code>__getitem__</code> <p>Return a single frame or a list of frames from the video.</p> <code>__len__</code> <p>Return number of frames in the video.</p> <code>detect_grayscale</code> <p>Detect whether the video is grayscale.</p> <code>from_filename</code> <p>Create a VideoBackend from a filename.</p> <code>get_frame</code> <p>Read a single frame from the video.</p> <code>get_frames</code> <p>Read a list of frames from the video.</p> <code>has_frame</code> <p>Check if a frame index is contained in the video.</p> <code>read_test_frame</code> <p>Read a single frame from the video to test for grayscale.</p> Source code in <code>sleap_io/io/video_reading.py</code> <pre><code>@attrs.define\nclass VideoBackend:\n    \"\"\"Base class for video backends.\n\n    This class is not meant to be used directly. Instead, use the `from_filename`\n    constructor to create a backend instance.\n\n    Attributes:\n        filename: Path to video file(s).\n        grayscale: Whether to force grayscale. If None, autodetect on first frame load.\n        keep_open: Whether to keep the video reader open between calls to read frames.\n            If False, will close the reader after each call. If True (the default), it\n            will keep the reader open and cache it for subsequent calls which may\n            enhance the performance of reading multiple frames.\n    \"\"\"\n\n    filename: str | Path | list[str] | list[Path]\n    grayscale: Optional[bool] = None\n    keep_open: bool = True\n    _cached_shape: Optional[Tuple[int, int, int, int]] = None\n    _open_reader: Optional[object] = None\n\n    @classmethod\n    def from_filename(\n        cls,\n        filename: str | list[str],\n        dataset: Optional[str] = None,\n        grayscale: Optional[bool] = None,\n        keep_open: bool = True,\n        **kwargs,\n    ) -&gt; VideoBackend:\n        \"\"\"Create a VideoBackend from a filename.\n\n        Args:\n            filename: Path to video file(s).\n            dataset: Name of dataset in HDF5 file.\n            grayscale: Whether to force grayscale. If None, autodetect on first frame\n                load.\n            keep_open: Whether to keep the video reader open between calls to read\n                frames. If False, will close the reader after each call. If True (the\n                default), it will keep the reader open and cache it for subsequent calls\n                which may enhance the performance of reading multiple frames.\n            **kwargs: Additional backend-specific arguments. These are filtered to only\n                include parameters that are valid for the specific backend being\n                created:\n                - For ImageVideo: No additional arguments.\n                - For MediaVideo: plugin (str): Video plugin to use. One of \"opencv\",\n                  \"FFMPEG\", or \"pyav\". Also accepts aliases (case-insensitive).\n                  If None, uses global default if set, otherwise auto-detects.\n                - For HDF5Video: input_format (str), frame_map (dict),\n                  source_filename (str),\n                  source_inds (np.ndarray), image_format (str). See HDF5Video for\n                  details.\n\n        Returns:\n            VideoBackend subclass instance.\n        \"\"\"\n        if isinstance(filename, Path):\n            filename = filename.as_posix()\n\n        if type(filename) is str and Path(filename).is_dir():\n            filename = ImageVideo.find_images(filename)\n\n        if type(filename) is list:\n            filename = [Path(f).as_posix() for f in filename]\n            return ImageVideo(\n                filename, grayscale=grayscale, **_get_valid_kwargs(ImageVideo, kwargs)\n            )\n        elif filename.endswith((\"tif\", \"tiff\")):\n            # Detect TIFF format\n            format_type, metadata = TiffVideo.detect_format(filename)\n\n            if format_type in (\"multi_page\", \"rank3_video\", \"rank4_video\"):\n                # Use TiffVideo for multi-page or multi-dimensional TIFFs\n                tiff_kwargs = _get_valid_kwargs(TiffVideo, kwargs)\n                # Add format if detected\n                if format_type in (\"rank3_video\", \"rank4_video\"):\n                    tiff_kwargs[\"format\"] = metadata.get(\"format\")\n                return TiffVideo(\n                    filename,\n                    grayscale=grayscale,\n                    keep_open=keep_open,\n                    **tiff_kwargs,\n                )\n            else:\n                # Single-page TIFF, treat as regular image\n                return ImageVideo(\n                    [filename],\n                    grayscale=grayscale,\n                    **_get_valid_kwargs(ImageVideo, kwargs),\n                )\n        elif filename.endswith(ImageVideo.EXTS):\n            return ImageVideo(\n                [filename], grayscale=grayscale, **_get_valid_kwargs(ImageVideo, kwargs)\n            )\n        elif filename.endswith(MediaVideo.EXTS):\n            return MediaVideo(\n                filename,\n                grayscale=grayscale,\n                keep_open=keep_open,\n                **_get_valid_kwargs(MediaVideo, kwargs),\n            )\n        elif filename.endswith(HDF5Video.EXTS):\n            return HDF5Video(\n                filename,\n                dataset=dataset,\n                grayscale=grayscale,\n                keep_open=keep_open,\n                **_get_valid_kwargs(HDF5Video, kwargs),\n            )\n        else:\n            raise ValueError(f\"Unknown video file type: {filename}\")\n\n    def _read_frame(self, frame_idx: int) -&gt; np.ndarray:\n        \"\"\"Read a single frame from the video. Must be implemented in subclasses.\"\"\"\n        raise NotImplementedError\n\n    def _read_frames(self, frame_inds: list) -&gt; np.ndarray:\n        \"\"\"Read a list of frames from the video.\"\"\"\n        return np.stack([self.get_frame(i) for i in frame_inds], axis=0)\n\n    def read_test_frame(self) -&gt; np.ndarray:\n        \"\"\"Read a single frame from the video to test for grayscale.\n\n        Note:\n            This reads the frame at index 0. This may not be appropriate if the first\n            frame is not available in a given backend.\n        \"\"\"\n        return self._read_frame(0)\n\n    def detect_grayscale(self, test_img: np.ndarray | None = None) -&gt; bool:\n        \"\"\"Detect whether the video is grayscale.\n\n        This works by reading in a test frame and comparing the first and last channel\n        for equality. It may fail in cases where, due to compression, the first and\n        last channels are not exactly the same.\n\n        Args:\n            test_img: Optional test image to use. If not provided, a test image will be\n                loaded via the `read_test_frame` method.\n\n        Returns:\n            Whether the video is grayscale. This value is also cached in the `grayscale`\n            attribute of the class.\n        \"\"\"\n        if test_img is None:\n            test_img = self.read_test_frame()\n        is_grayscale = np.array_equal(test_img[..., 0], test_img[..., -1])\n        self.grayscale = is_grayscale\n        return is_grayscale\n\n    @property\n    def num_frames(self) -&gt; int:\n        \"\"\"Number of frames in the video. Must be implemented in subclasses.\"\"\"\n        raise NotImplementedError\n\n    @property\n    def img_shape(self) -&gt; Tuple[int, int, int]:\n        \"\"\"Shape of a single frame in the video.\"\"\"\n        height, width, channels = self.read_test_frame().shape\n        if self.grayscale is None:\n            self.detect_grayscale()\n        if self.grayscale is False:\n            channels = 3\n        elif self.grayscale is True:\n            channels = 1\n        return int(height), int(width), int(channels)\n\n    @property\n    def shape(self) -&gt; Tuple[int, int, int, int]:\n        \"\"\"Shape of the video as a tuple of `(frames, height, width, channels)`.\n\n        On first call, this will defer to `num_frames` and `img_shape` to determine the\n        full shape. This call may be expensive for some subclasses, so the result is\n        cached and returned on subsequent calls.\n        \"\"\"\n        if self._cached_shape is not None:\n            return self._cached_shape\n        else:\n            shape = (self.num_frames,) + self.img_shape\n            self._cached_shape = shape\n            return shape\n\n    @property\n    def frames(self) -&gt; int:\n        \"\"\"Number of frames in the video.\"\"\"\n        return self.shape[0]\n\n    def __len__(self) -&gt; int:\n        \"\"\"Return number of frames in the video.\"\"\"\n        return self.shape[0]\n\n    def has_frame(self, frame_idx: int) -&gt; bool:\n        \"\"\"Check if a frame index is contained in the video.\n\n        Args:\n            frame_idx: Index of frame to check.\n\n        Returns:\n            `True` if the index is contained in the video, otherwise `False`.\n        \"\"\"\n        return frame_idx &lt; len(self)\n\n    def get_frame(self, frame_idx: int) -&gt; np.ndarray:\n        \"\"\"Read a single frame from the video.\n\n        Args:\n            frame_idx: Index of frame to read.\n\n        Returns:\n            Frame as a numpy array of shape `(height, width, channels)` where the\n            `channels` dimension is 1 for grayscale videos and 3 for color videos.\n\n        Notes:\n            If the `grayscale` attribute is set to `True`, the `channels` dimension will\n            be reduced to 1 if an RGB frame is loaded from the backend.\n\n            If the `grayscale` attribute is set to `None`, the `grayscale` attribute\n            will be automatically set based on the first frame read.\n\n        See also: `get_frames`\n        \"\"\"\n        if not self.has_frame(frame_idx):\n            raise IndexError(f\"Frame index {frame_idx} out of range.\")\n\n        img = self._read_frame(frame_idx)\n\n        if self.grayscale is None:\n            self.detect_grayscale(img)\n\n        if self.grayscale:\n            img = img[..., [0]]\n\n        return img\n\n    def get_frames(self, frame_inds: list[int]) -&gt; np.ndarray:\n        \"\"\"Read a list of frames from the video.\n\n        Depending on the backend implementation, this may be faster than reading frames\n        individually using `get_frame`.\n\n        Args:\n            frame_inds: List of frame indices to read.\n\n        Returns:\n            Frames as a numpy array of shape `(frames, height, width, channels)` where\n            `channels` dimension is 1 for grayscale videos and 3 for color videos.\n\n        Notes:\n            If the `grayscale` attribute is set to `True`, the `channels` dimension will\n            be reduced to 1 if an RGB frame is loaded from the backend.\n\n            If the `grayscale` attribute is set to `None`, the `grayscale` attribute\n            will be automatically set based on the first frame read.\n\n        See also: `get_frame`\n        \"\"\"\n        imgs = self._read_frames(frame_inds)\n\n        if self.grayscale is None:\n            self.detect_grayscale(imgs[0])\n\n        if self.grayscale:\n            imgs = imgs[..., [0]]\n\n        return imgs\n\n    def __getitem__(self, ind: int | list[int] | slice) -&gt; np.ndarray:\n        \"\"\"Return a single frame or a list of frames from the video.\n\n        Args:\n            ind: Index or list of indices of frames to read.\n\n        Returns:\n            Frame or frames as a numpy array of shape `(height, width, channels)` if a\n            scalar index is provided, or `(frames, height, width, channels)` if a list\n            of indices is provided.\n\n        See also: get_frame, get_frames\n        \"\"\"\n        if np.isscalar(ind):\n            return self.get_frame(ind)\n        else:\n            if type(ind) is slice:\n                start = (ind.start or 0) % len(self)\n                stop = ind.stop or len(self)\n                if stop &lt; 0:\n                    stop = len(self) + stop\n                step = ind.step or 1\n                ind = range(start, stop, step)\n            return self.get_frames(ind)\n</code></pre>"},{"location":"reference/sleap_io/io/video_reading/#sleap_io.io.video_reading.VideoBackend.frames","title":"<code>frames</code>  <code>property</code>","text":"<p>Number of frames in the video.</p>"},{"location":"reference/sleap_io/io/video_reading/#sleap_io.io.video_reading.VideoBackend.img_shape","title":"<code>img_shape</code>  <code>property</code>","text":"<p>Shape of a single frame in the video.</p>"},{"location":"reference/sleap_io/io/video_reading/#sleap_io.io.video_reading.VideoBackend.num_frames","title":"<code>num_frames</code>  <code>property</code>","text":"<p>Number of frames in the video. Must be implemented in subclasses.</p>"},{"location":"reference/sleap_io/io/video_reading/#sleap_io.io.video_reading.VideoBackend.shape","title":"<code>shape</code>  <code>property</code>","text":"<p>Shape of the video as a tuple of <code>(frames, height, width, channels)</code>.</p> <p>On first call, this will defer to <code>num_frames</code> and <code>img_shape</code> to determine the full shape. This call may be expensive for some subclasses, so the result is cached and returned on subsequent calls.</p>"},{"location":"reference/sleap_io/io/video_reading/#sleap_io.io.video_reading.VideoBackend.__getitem__","title":"<code>__getitem__(ind)</code>","text":"<p>Return a single frame or a list of frames from the video.</p> <p>Parameters:</p> Name Type Description Default <code>ind</code> <code>int | list[int] | slice</code> <p>Index or list of indices of frames to read.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Frame or frames as a numpy array of shape <code>(height, width, channels)</code> if a scalar index is provided, or <code>(frames, height, width, channels)</code> if a list of indices is provided.</p> <p>See also: get_frame, get_frames</p> Source code in <code>sleap_io/io/video_reading.py</code> <pre><code>def __getitem__(self, ind: int | list[int] | slice) -&gt; np.ndarray:\n    \"\"\"Return a single frame or a list of frames from the video.\n\n    Args:\n        ind: Index or list of indices of frames to read.\n\n    Returns:\n        Frame or frames as a numpy array of shape `(height, width, channels)` if a\n        scalar index is provided, or `(frames, height, width, channels)` if a list\n        of indices is provided.\n\n    See also: get_frame, get_frames\n    \"\"\"\n    if np.isscalar(ind):\n        return self.get_frame(ind)\n    else:\n        if type(ind) is slice:\n            start = (ind.start or 0) % len(self)\n            stop = ind.stop or len(self)\n            if stop &lt; 0:\n                stop = len(self) + stop\n            step = ind.step or 1\n            ind = range(start, stop, step)\n        return self.get_frames(ind)\n</code></pre>"},{"location":"reference/sleap_io/io/video_reading/#sleap_io.io.video_reading.VideoBackend.__len__","title":"<code>__len__()</code>","text":"<p>Return number of frames in the video.</p> Source code in <code>sleap_io/io/video_reading.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"Return number of frames in the video.\"\"\"\n    return self.shape[0]\n</code></pre>"},{"location":"reference/sleap_io/io/video_reading/#sleap_io.io.video_reading.VideoBackend.detect_grayscale","title":"<code>detect_grayscale(test_img=None)</code>","text":"<p>Detect whether the video is grayscale.</p> <p>This works by reading in a test frame and comparing the first and last channel for equality. It may fail in cases where, due to compression, the first and last channels are not exactly the same.</p> <p>Parameters:</p> Name Type Description Default <code>test_img</code> <code>ndarray | None</code> <p>Optional test image to use. If not provided, a test image will be loaded via the <code>read_test_frame</code> method.</p> <code>None</code> <p>Returns:</p> Type Description <code>bool</code> <p>Whether the video is grayscale. This value is also cached in the <code>grayscale</code> attribute of the class.</p> Source code in <code>sleap_io/io/video_reading.py</code> <pre><code>def detect_grayscale(self, test_img: np.ndarray | None = None) -&gt; bool:\n    \"\"\"Detect whether the video is grayscale.\n\n    This works by reading in a test frame and comparing the first and last channel\n    for equality. It may fail in cases where, due to compression, the first and\n    last channels are not exactly the same.\n\n    Args:\n        test_img: Optional test image to use. If not provided, a test image will be\n            loaded via the `read_test_frame` method.\n\n    Returns:\n        Whether the video is grayscale. This value is also cached in the `grayscale`\n        attribute of the class.\n    \"\"\"\n    if test_img is None:\n        test_img = self.read_test_frame()\n    is_grayscale = np.array_equal(test_img[..., 0], test_img[..., -1])\n    self.grayscale = is_grayscale\n    return is_grayscale\n</code></pre>"},{"location":"reference/sleap_io/io/video_reading/#sleap_io.io.video_reading.VideoBackend.from_filename","title":"<code>from_filename(filename, dataset=None, grayscale=None, keep_open=True, **kwargs)</code>  <code>classmethod</code>","text":"<p>Create a VideoBackend from a filename.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str | list[str]</code> <p>Path to video file(s).</p> required <code>dataset</code> <code>Optional[str]</code> <p>Name of dataset in HDF5 file.</p> <code>None</code> <code>grayscale</code> <code>Optional[bool]</code> <p>Whether to force grayscale. If None, autodetect on first frame load.</p> <code>None</code> <code>keep_open</code> <code>bool</code> <p>Whether to keep the video reader open between calls to read frames. If False, will close the reader after each call. If True (the default), it will keep the reader open and cache it for subsequent calls which may enhance the performance of reading multiple frames.</p> <code>True</code> <code>**kwargs</code> <p>Additional backend-specific arguments. These are filtered to only include parameters that are valid for the specific backend being created: - For ImageVideo: No additional arguments. - For MediaVideo: plugin (str): Video plugin to use. One of \"opencv\",   \"FFMPEG\", or \"pyav\". Also accepts aliases (case-insensitive).   If None, uses global default if set, otherwise auto-detects. - For HDF5Video: input_format (str), frame_map (dict),   source_filename (str),   source_inds (np.ndarray), image_format (str). See HDF5Video for   details.</p> <code>{}</code> <p>Returns:</p> Type Description <code>VideoBackend</code> <p>VideoBackend subclass instance.</p> Source code in <code>sleap_io/io/video_reading.py</code> <pre><code>@classmethod\ndef from_filename(\n    cls,\n    filename: str | list[str],\n    dataset: Optional[str] = None,\n    grayscale: Optional[bool] = None,\n    keep_open: bool = True,\n    **kwargs,\n) -&gt; VideoBackend:\n    \"\"\"Create a VideoBackend from a filename.\n\n    Args:\n        filename: Path to video file(s).\n        dataset: Name of dataset in HDF5 file.\n        grayscale: Whether to force grayscale. If None, autodetect on first frame\n            load.\n        keep_open: Whether to keep the video reader open between calls to read\n            frames. If False, will close the reader after each call. If True (the\n            default), it will keep the reader open and cache it for subsequent calls\n            which may enhance the performance of reading multiple frames.\n        **kwargs: Additional backend-specific arguments. These are filtered to only\n            include parameters that are valid for the specific backend being\n            created:\n            - For ImageVideo: No additional arguments.\n            - For MediaVideo: plugin (str): Video plugin to use. One of \"opencv\",\n              \"FFMPEG\", or \"pyav\". Also accepts aliases (case-insensitive).\n              If None, uses global default if set, otherwise auto-detects.\n            - For HDF5Video: input_format (str), frame_map (dict),\n              source_filename (str),\n              source_inds (np.ndarray), image_format (str). See HDF5Video for\n              details.\n\n    Returns:\n        VideoBackend subclass instance.\n    \"\"\"\n    if isinstance(filename, Path):\n        filename = filename.as_posix()\n\n    if type(filename) is str and Path(filename).is_dir():\n        filename = ImageVideo.find_images(filename)\n\n    if type(filename) is list:\n        filename = [Path(f).as_posix() for f in filename]\n        return ImageVideo(\n            filename, grayscale=grayscale, **_get_valid_kwargs(ImageVideo, kwargs)\n        )\n    elif filename.endswith((\"tif\", \"tiff\")):\n        # Detect TIFF format\n        format_type, metadata = TiffVideo.detect_format(filename)\n\n        if format_type in (\"multi_page\", \"rank3_video\", \"rank4_video\"):\n            # Use TiffVideo for multi-page or multi-dimensional TIFFs\n            tiff_kwargs = _get_valid_kwargs(TiffVideo, kwargs)\n            # Add format if detected\n            if format_type in (\"rank3_video\", \"rank4_video\"):\n                tiff_kwargs[\"format\"] = metadata.get(\"format\")\n            return TiffVideo(\n                filename,\n                grayscale=grayscale,\n                keep_open=keep_open,\n                **tiff_kwargs,\n            )\n        else:\n            # Single-page TIFF, treat as regular image\n            return ImageVideo(\n                [filename],\n                grayscale=grayscale,\n                **_get_valid_kwargs(ImageVideo, kwargs),\n            )\n    elif filename.endswith(ImageVideo.EXTS):\n        return ImageVideo(\n            [filename], grayscale=grayscale, **_get_valid_kwargs(ImageVideo, kwargs)\n        )\n    elif filename.endswith(MediaVideo.EXTS):\n        return MediaVideo(\n            filename,\n            grayscale=grayscale,\n            keep_open=keep_open,\n            **_get_valid_kwargs(MediaVideo, kwargs),\n        )\n    elif filename.endswith(HDF5Video.EXTS):\n        return HDF5Video(\n            filename,\n            dataset=dataset,\n            grayscale=grayscale,\n            keep_open=keep_open,\n            **_get_valid_kwargs(HDF5Video, kwargs),\n        )\n    else:\n        raise ValueError(f\"Unknown video file type: {filename}\")\n</code></pre>"},{"location":"reference/sleap_io/io/video_reading/#sleap_io.io.video_reading.VideoBackend.get_frame","title":"<code>get_frame(frame_idx)</code>","text":"<p>Read a single frame from the video.</p> <p>Parameters:</p> Name Type Description Default <code>frame_idx</code> <code>int</code> <p>Index of frame to read.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Frame as a numpy array of shape <code>(height, width, channels)</code> where the <code>channels</code> dimension is 1 for grayscale videos and 3 for color videos.</p> Notes <p>If the <code>grayscale</code> attribute is set to <code>True</code>, the <code>channels</code> dimension will be reduced to 1 if an RGB frame is loaded from the backend.</p> <p>If the <code>grayscale</code> attribute is set to <code>None</code>, the <code>grayscale</code> attribute will be automatically set based on the first frame read.</p> <p>See also: <code>get_frames</code></p> Source code in <code>sleap_io/io/video_reading.py</code> <pre><code>def get_frame(self, frame_idx: int) -&gt; np.ndarray:\n    \"\"\"Read a single frame from the video.\n\n    Args:\n        frame_idx: Index of frame to read.\n\n    Returns:\n        Frame as a numpy array of shape `(height, width, channels)` where the\n        `channels` dimension is 1 for grayscale videos and 3 for color videos.\n\n    Notes:\n        If the `grayscale` attribute is set to `True`, the `channels` dimension will\n        be reduced to 1 if an RGB frame is loaded from the backend.\n\n        If the `grayscale` attribute is set to `None`, the `grayscale` attribute\n        will be automatically set based on the first frame read.\n\n    See also: `get_frames`\n    \"\"\"\n    if not self.has_frame(frame_idx):\n        raise IndexError(f\"Frame index {frame_idx} out of range.\")\n\n    img = self._read_frame(frame_idx)\n\n    if self.grayscale is None:\n        self.detect_grayscale(img)\n\n    if self.grayscale:\n        img = img[..., [0]]\n\n    return img\n</code></pre>"},{"location":"reference/sleap_io/io/video_reading/#sleap_io.io.video_reading.VideoBackend.get_frames","title":"<code>get_frames(frame_inds)</code>","text":"<p>Read a list of frames from the video.</p> <p>Depending on the backend implementation, this may be faster than reading frames individually using <code>get_frame</code>.</p> <p>Parameters:</p> Name Type Description Default <code>frame_inds</code> <code>list[int]</code> <p>List of frame indices to read.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Frames as a numpy array of shape <code>(frames, height, width, channels)</code> where <code>channels</code> dimension is 1 for grayscale videos and 3 for color videos.</p> Notes <p>If the <code>grayscale</code> attribute is set to <code>True</code>, the <code>channels</code> dimension will be reduced to 1 if an RGB frame is loaded from the backend.</p> <p>If the <code>grayscale</code> attribute is set to <code>None</code>, the <code>grayscale</code> attribute will be automatically set based on the first frame read.</p> <p>See also: <code>get_frame</code></p> Source code in <code>sleap_io/io/video_reading.py</code> <pre><code>def get_frames(self, frame_inds: list[int]) -&gt; np.ndarray:\n    \"\"\"Read a list of frames from the video.\n\n    Depending on the backend implementation, this may be faster than reading frames\n    individually using `get_frame`.\n\n    Args:\n        frame_inds: List of frame indices to read.\n\n    Returns:\n        Frames as a numpy array of shape `(frames, height, width, channels)` where\n        `channels` dimension is 1 for grayscale videos and 3 for color videos.\n\n    Notes:\n        If the `grayscale` attribute is set to `True`, the `channels` dimension will\n        be reduced to 1 if an RGB frame is loaded from the backend.\n\n        If the `grayscale` attribute is set to `None`, the `grayscale` attribute\n        will be automatically set based on the first frame read.\n\n    See also: `get_frame`\n    \"\"\"\n    imgs = self._read_frames(frame_inds)\n\n    if self.grayscale is None:\n        self.detect_grayscale(imgs[0])\n\n    if self.grayscale:\n        imgs = imgs[..., [0]]\n\n    return imgs\n</code></pre>"},{"location":"reference/sleap_io/io/video_reading/#sleap_io.io.video_reading.VideoBackend.has_frame","title":"<code>has_frame(frame_idx)</code>","text":"<p>Check if a frame index is contained in the video.</p> <p>Parameters:</p> Name Type Description Default <code>frame_idx</code> <code>int</code> <p>Index of frame to check.</p> required <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if the index is contained in the video, otherwise <code>False</code>.</p> Source code in <code>sleap_io/io/video_reading.py</code> <pre><code>def has_frame(self, frame_idx: int) -&gt; bool:\n    \"\"\"Check if a frame index is contained in the video.\n\n    Args:\n        frame_idx: Index of frame to check.\n\n    Returns:\n        `True` if the index is contained in the video, otherwise `False`.\n    \"\"\"\n    return frame_idx &lt; len(self)\n</code></pre>"},{"location":"reference/sleap_io/io/video_reading/#sleap_io.io.video_reading.VideoBackend.read_test_frame","title":"<code>read_test_frame()</code>","text":"<p>Read a single frame from the video to test for grayscale.</p> Note <p>This reads the frame at index 0. This may not be appropriate if the first frame is not available in a given backend.</p> Source code in <code>sleap_io/io/video_reading.py</code> <pre><code>def read_test_frame(self) -&gt; np.ndarray:\n    \"\"\"Read a single frame from the video to test for grayscale.\n\n    Note:\n        This reads the frame at index 0. This may not be appropriate if the first\n        frame is not available in a given backend.\n    \"\"\"\n    return self._read_frame(0)\n</code></pre>"},{"location":"reference/sleap_io/io/video_reading/#sleap_io.io.video_reading.get_default_video_plugin","title":"<code>get_default_video_plugin()</code>","text":"<p>Get the current default video plugin.</p> <p>Returns:</p> Type Description <code>Optional[str]</code> <p>The current default video plugin name, or None if not set.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import sleap_io as sio\n&gt;&gt;&gt; sio.get_default_video_plugin()\nNone\n&gt;&gt;&gt; sio.set_default_video_plugin(\"opencv\")\n&gt;&gt;&gt; sio.get_default_video_plugin()\n'opencv'\n</code></pre> Source code in <code>sleap_io/io/video_reading.py</code> <pre><code>def get_default_video_plugin() -&gt; Optional[str]:\n    \"\"\"Get the current default video plugin.\n\n    Returns:\n        The current default video plugin name, or None if not set.\n\n    Examples:\n        &gt;&gt;&gt; import sleap_io as sio\n        &gt;&gt;&gt; sio.get_default_video_plugin()\n        None\n        &gt;&gt;&gt; sio.set_default_video_plugin(\"opencv\")\n        &gt;&gt;&gt; sio.get_default_video_plugin()\n        'opencv'\n    \"\"\"\n    return _default_video_plugin\n</code></pre>"},{"location":"reference/sleap_io/io/video_reading/#sleap_io.io.video_reading.normalize_plugin_name","title":"<code>normalize_plugin_name(plugin)</code>","text":"<p>Normalize plugin names to standard format.</p> <p>Parameters:</p> Name Type Description Default <code>plugin</code> <code>str</code> <p>Plugin name or alias (case-insensitive).</p> required <p>Returns:</p> Type Description <code>str</code> <p>Normalized plugin name (\"opencv\", \"FFMPEG\", or \"pyav\").</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If plugin name is not recognized.</p> Source code in <code>sleap_io/io/video_reading.py</code> <pre><code>def normalize_plugin_name(plugin: str) -&gt; str:\n    \"\"\"Normalize plugin names to standard format.\n\n    Args:\n        plugin: Plugin name or alias (case-insensitive).\n\n    Returns:\n        Normalized plugin name (\"opencv\", \"FFMPEG\", or \"pyav\").\n\n    Raises:\n        ValueError: If plugin name is not recognized.\n    \"\"\"\n    plugin_lower = plugin.lower()\n\n    # Map aliases to standard names\n    aliases = {\n        \"cv\": \"opencv\",\n        \"cv2\": \"opencv\",\n        \"opencv\": \"opencv\",\n        \"ocv\": \"opencv\",\n        \"ffmpeg\": \"FFMPEG\",\n        \"imageio-ffmpeg\": \"FFMPEG\",\n        \"imageio_ffmpeg\": \"FFMPEG\",\n        \"pyav\": \"pyav\",\n        \"av\": \"pyav\",\n    }\n\n    if plugin_lower not in aliases:\n        raise ValueError(\n            f\"Unknown plugin: {plugin}. Valid options: opencv, FFMPEG, pyav\"\n        )\n\n    return aliases[plugin_lower]\n</code></pre>"},{"location":"reference/sleap_io/io/video_reading/#sleap_io.io.video_reading.set_default_video_plugin","title":"<code>set_default_video_plugin(plugin)</code>","text":"<p>Set the default video plugin for all subsequently loaded videos.</p> <p>Parameters:</p> Name Type Description Default <code>plugin</code> <code>Optional[str]</code> <p>Video plugin name. One of \"opencv\", \"FFMPEG\", or \"pyav\". Also accepts aliases: \"cv\", \"cv2\", \"ocv\" for opencv; \"imageio-ffmpeg\", \"imageio_ffmpeg\" for FFMPEG; \"av\" for pyav. Case-insensitive. If None, clears the default preference.</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; import sleap_io as sio\n&gt;&gt;&gt; sio.set_default_video_plugin(\"opencv\")\n&gt;&gt;&gt; sio.set_default_video_plugin(\"cv2\")  # Same as \"opencv\"\n&gt;&gt;&gt; sio.set_default_video_plugin(None)  # Clear preference\n</code></pre> Source code in <code>sleap_io/io/video_reading.py</code> <pre><code>def set_default_video_plugin(plugin: Optional[str]) -&gt; None:\n    \"\"\"Set the default video plugin for all subsequently loaded videos.\n\n    Args:\n        plugin: Video plugin name. One of \"opencv\", \"FFMPEG\", or \"pyav\".\n            Also accepts aliases: \"cv\", \"cv2\", \"ocv\" for opencv;\n            \"imageio-ffmpeg\", \"imageio_ffmpeg\" for FFMPEG; \"av\" for pyav.\n            Case-insensitive. If None, clears the default preference.\n\n    Examples:\n        &gt;&gt;&gt; import sleap_io as sio\n        &gt;&gt;&gt; sio.set_default_video_plugin(\"opencv\")\n        &gt;&gt;&gt; sio.set_default_video_plugin(\"cv2\")  # Same as \"opencv\"\n        &gt;&gt;&gt; sio.set_default_video_plugin(None)  # Clear preference\n    \"\"\"\n    global _default_video_plugin\n    if plugin is not None:\n        plugin = normalize_plugin_name(plugin)\n    _default_video_plugin = plugin\n</code></pre>"},{"location":"reference/sleap_io/io/video_writing/","title":"video_writing","text":""},{"location":"reference/sleap_io/io/video_writing/#sleap_io.io.video_writing","title":"<code>sleap_io.io.video_writing</code>","text":"<p>Utilities for writing videos.</p> <p>Classes:</p> Name Description <code>MJPEGFrameWriter</code> <p>Video writer for MJPEG format optimized for seekable frame containers.</p> <code>VideoWriter</code> <p>Simple video writer using imageio and FFMPEG.</p>"},{"location":"reference/sleap_io/io/video_writing/#sleap_io.io.video_writing.MJPEGFrameWriter","title":"<code>MJPEGFrameWriter</code>","text":"<p>Video writer for MJPEG format optimized for seekable frame containers.</p> <p>This writer is designed for scientific/archival use where frames from arbitrary indices need to be independently seekable. Each frame is intra-coded (I-frame only) to ensure reliable random access.</p> <p>Attributes:</p> Name Type Description <code>filename</code> <code>Path</code> <p>Path to output MJPEG video file.</p> <code>fps</code> <code>float</code> <p>Nominal frames per second. Defaults to 30.</p> <code>quality</code> <code>int</code> <p>MJPEG quality level (2-31, lower is better). Defaults to 2.</p> <code>output_params</code> <code>list[str]</code> <p>Additional output parameters for FFMPEG.</p> Notes <p>This class can be used as a context manager:</p> <pre><code>with MJPEGFrameWriter(\"output.avi\") as writer:\n    for frame in frames:\n        writer.write_frame(frame)\n</code></pre> <p>Methods:</p> Name Description <code>__enter__</code> <p>Context manager entry.</p> <code>__exit__</code> <p>Context manager exit.</p> <code>build_output_params</code> <p>Build the output parameters for FFMPEG MJPEG encoding.</p> <code>close</code> <p>Close the MJPEG writer.</p> <code>open</code> <p>Open the MJPEG writer.</p> <code>write_frame</code> <p>Write a frame to the MJPEG video.</p> <code>write_frames</code> <p>Write multiple frames to the MJPEG video.</p> Source code in <code>sleap_io/io/video_writing.py</code> <pre><code>@attrs.define\nclass MJPEGFrameWriter:\n    \"\"\"Video writer for MJPEG format optimized for seekable frame containers.\n\n    This writer is designed for scientific/archival use where frames from arbitrary\n    indices need to be independently seekable. Each frame is intra-coded (I-frame only)\n    to ensure reliable random access.\n\n    Attributes:\n        filename: Path to output MJPEG video file.\n        fps: Nominal frames per second. Defaults to 30.\n        quality: MJPEG quality level (2-31, lower is better). Defaults to 2.\n\n        output_params: Additional output parameters for FFMPEG.\n\n    Notes:\n        This class can be used as a context manager:\n\n        ```python\n        with MJPEGFrameWriter(\"output.avi\") as writer:\n            for frame in frames:\n                writer.write_frame(frame)\n        ```\n    \"\"\"\n\n    filename: Path = attrs.field(converter=Path)\n    fps: float = 30\n    quality: int = 2\n\n    output_params: list[str] = attrs.field(factory=list)\n    _writer: \"imageio.plugins.ffmpeg.FfmpegFormat.Writer\" | None = None\n    _frame_index: int = 0\n\n    def build_output_params(self) -&gt; list[str]:\n        \"\"\"Build the output parameters for FFMPEG MJPEG encoding.\"\"\"\n        params = [\n            # MJPEG quality (2-32)\n            \"-q:v\",\n            str(self.quality),\n            # All frames are keyframes (I-frames)\n            \"-g\",\n            \"1\",\n            # Use full range (JPEG) color\n            \"-vf\",\n            \"scale=in_range=pc:out_range=pc,format=yuv420p\",\n            \"-color_range\",\n            \"pc\",\n        ]\n\n        return params + self.output_params\n\n    def open(self):\n        \"\"\"Open the MJPEG writer.\"\"\"\n        self.close()\n        self._frame_index = 0\n\n        self.filename.parent.mkdir(parents=True, exist_ok=True)\n        self._writer = iio_v2.get_writer(\n            self.filename.as_posix(),\n            format=\"FFMPEG\",\n            fps=self.fps,\n            codec=\"mjpeg\",\n            pixelformat=\"yuv420p\",  # Use full range YUV for MJPEG\n            output_params=self.build_output_params(),\n        )\n\n    def close(self):\n        \"\"\"Close the MJPEG writer.\"\"\"\n        if self._writer is not None:\n            self._writer.close()\n            self._writer = None\n            self._frame_index = 0\n\n    def write_frame(self, frame: np.ndarray):\n        \"\"\"Write a frame to the MJPEG video.\n\n        Args:\n            frame: Frame to write. Should be a 2D or 3D numpy array with\n                dimensions (height, width) or (height, width, channels).\n        \"\"\"\n        if self._writer is None:\n            self.open()\n\n        self._writer.append_data(frame)\n        self._frame_index += 1\n\n    def write_frames(self, frames: List[np.ndarray]):\n        \"\"\"Write multiple frames to the MJPEG video.\n\n        Args:\n            frames: List of frames to write.\n        \"\"\"\n        for frame in frames:\n            self.write_frame(frame)\n\n    def __enter__(self):\n        \"\"\"Context manager entry.\"\"\"\n        return self\n\n    def __exit__(\n        self,\n        exc_type: Optional[Type[BaseException]],\n        exc_value: Optional[BaseException],\n        traceback: Optional[TracebackType],\n    ) -&gt; Optional[bool]:\n        \"\"\"Context manager exit.\"\"\"\n        self.close()\n        return False\n</code></pre>"},{"location":"reference/sleap_io/io/video_writing/#sleap_io.io.video_writing.MJPEGFrameWriter.__enter__","title":"<code>__enter__()</code>","text":"<p>Context manager entry.</p> Source code in <code>sleap_io/io/video_writing.py</code> <pre><code>def __enter__(self):\n    \"\"\"Context manager entry.\"\"\"\n    return self\n</code></pre>"},{"location":"reference/sleap_io/io/video_writing/#sleap_io.io.video_writing.MJPEGFrameWriter.__exit__","title":"<code>__exit__(exc_type, exc_value, traceback)</code>","text":"<p>Context manager exit.</p> Source code in <code>sleap_io/io/video_writing.py</code> <pre><code>def __exit__(\n    self,\n    exc_type: Optional[Type[BaseException]],\n    exc_value: Optional[BaseException],\n    traceback: Optional[TracebackType],\n) -&gt; Optional[bool]:\n    \"\"\"Context manager exit.\"\"\"\n    self.close()\n    return False\n</code></pre>"},{"location":"reference/sleap_io/io/video_writing/#sleap_io.io.video_writing.MJPEGFrameWriter.build_output_params","title":"<code>build_output_params()</code>","text":"<p>Build the output parameters for FFMPEG MJPEG encoding.</p> Source code in <code>sleap_io/io/video_writing.py</code> <pre><code>def build_output_params(self) -&gt; list[str]:\n    \"\"\"Build the output parameters for FFMPEG MJPEG encoding.\"\"\"\n    params = [\n        # MJPEG quality (2-32)\n        \"-q:v\",\n        str(self.quality),\n        # All frames are keyframes (I-frames)\n        \"-g\",\n        \"1\",\n        # Use full range (JPEG) color\n        \"-vf\",\n        \"scale=in_range=pc:out_range=pc,format=yuv420p\",\n        \"-color_range\",\n        \"pc\",\n    ]\n\n    return params + self.output_params\n</code></pre>"},{"location":"reference/sleap_io/io/video_writing/#sleap_io.io.video_writing.MJPEGFrameWriter.close","title":"<code>close()</code>","text":"<p>Close the MJPEG writer.</p> Source code in <code>sleap_io/io/video_writing.py</code> <pre><code>def close(self):\n    \"\"\"Close the MJPEG writer.\"\"\"\n    if self._writer is not None:\n        self._writer.close()\n        self._writer = None\n        self._frame_index = 0\n</code></pre>"},{"location":"reference/sleap_io/io/video_writing/#sleap_io.io.video_writing.MJPEGFrameWriter.open","title":"<code>open()</code>","text":"<p>Open the MJPEG writer.</p> Source code in <code>sleap_io/io/video_writing.py</code> <pre><code>def open(self):\n    \"\"\"Open the MJPEG writer.\"\"\"\n    self.close()\n    self._frame_index = 0\n\n    self.filename.parent.mkdir(parents=True, exist_ok=True)\n    self._writer = iio_v2.get_writer(\n        self.filename.as_posix(),\n        format=\"FFMPEG\",\n        fps=self.fps,\n        codec=\"mjpeg\",\n        pixelformat=\"yuv420p\",  # Use full range YUV for MJPEG\n        output_params=self.build_output_params(),\n    )\n</code></pre>"},{"location":"reference/sleap_io/io/video_writing/#sleap_io.io.video_writing.MJPEGFrameWriter.write_frame","title":"<code>write_frame(frame)</code>","text":"<p>Write a frame to the MJPEG video.</p> <p>Parameters:</p> Name Type Description Default <code>frame</code> <code>ndarray</code> <p>Frame to write. Should be a 2D or 3D numpy array with dimensions (height, width) or (height, width, channels).</p> required Source code in <code>sleap_io/io/video_writing.py</code> <pre><code>def write_frame(self, frame: np.ndarray):\n    \"\"\"Write a frame to the MJPEG video.\n\n    Args:\n        frame: Frame to write. Should be a 2D or 3D numpy array with\n            dimensions (height, width) or (height, width, channels).\n    \"\"\"\n    if self._writer is None:\n        self.open()\n\n    self._writer.append_data(frame)\n    self._frame_index += 1\n</code></pre>"},{"location":"reference/sleap_io/io/video_writing/#sleap_io.io.video_writing.MJPEGFrameWriter.write_frames","title":"<code>write_frames(frames)</code>","text":"<p>Write multiple frames to the MJPEG video.</p> <p>Parameters:</p> Name Type Description Default <code>frames</code> <code>List[ndarray]</code> <p>List of frames to write.</p> required Source code in <code>sleap_io/io/video_writing.py</code> <pre><code>def write_frames(self, frames: List[np.ndarray]):\n    \"\"\"Write multiple frames to the MJPEG video.\n\n    Args:\n        frames: List of frames to write.\n    \"\"\"\n    for frame in frames:\n        self.write_frame(frame)\n</code></pre>"},{"location":"reference/sleap_io/io/video_writing/#sleap_io.io.video_writing.VideoWriter","title":"<code>VideoWriter</code>","text":"<p>Simple video writer using imageio and FFMPEG.</p> <p>Attributes:</p> Name Type Description <code>filename</code> <code>Path</code> <p>Path to output video file.</p> <code>fps</code> <code>float</code> <p>Frames per second. Defaults to 30.</p> <code>pixelformat</code> <code>str</code> <p>Pixel format for video. Defaults to \"yuv420p\".</p> <code>codec</code> <code>str</code> <p>Codec to use for encoding. Defaults to \"libx264\".</p> <code>crf</code> <code>int</code> <p>Constant rate factor to control lossiness of video. Values go from 2 to 32, with numbers in the 18 to 30 range being most common. Lower values mean less compressed/higher quality. Defaults to 25. No effect if codec is not \"libx264\".</p> <code>preset</code> <code>str</code> <p>H264 encoding preset. Defaults to \"superfast\". No effect if codec is not \"libx264\".</p> <code>output_params</code> <code>list[str]</code> <p>Additional output parameters for FFMPEG. This should be a list of strings corresponding to command line arguments for FFMPEG and libx264. Use <code>ffmpeg -h encoder=libx264</code> to see all options for libx264 output_params.</p> Notes <p>This class can be used as a context manager to ensure the video is properly closed after writing. For example:</p> <pre><code>with VideoWriter(\"output.mp4\") as writer:\n    for frame in frames:\n        writer(frame)\n</code></pre> <p>Methods:</p> Name Description <code>__call__</code> <p>Write a frame to the video.</p> <code>__enter__</code> <p>Context manager entry.</p> <code>__exit__</code> <p>Context manager exit.</p> <code>build_output_params</code> <p>Build the output parameters for FFMPEG.</p> <code>close</code> <p>Close the video writer.</p> <code>open</code> <p>Open the video writer.</p> <code>write_frame</code> <p>Write a frame to the video.</p> Source code in <code>sleap_io/io/video_writing.py</code> <pre><code>@attrs.define\nclass VideoWriter:\n    \"\"\"Simple video writer using imageio and FFMPEG.\n\n    Attributes:\n        filename: Path to output video file.\n        fps: Frames per second. Defaults to 30.\n        pixelformat: Pixel format for video. Defaults to \"yuv420p\".\n        codec: Codec to use for encoding. Defaults to \"libx264\".\n        crf: Constant rate factor to control lossiness of video. Values go from 2 to 32,\n            with numbers in the 18 to 30 range being most common. Lower values mean less\n            compressed/higher quality. Defaults to 25. No effect if codec is not\n            \"libx264\".\n        preset: H264 encoding preset. Defaults to \"superfast\". No effect if codec is not\n            \"libx264\".\n        output_params: Additional output parameters for FFMPEG. This should be a list of\n            strings corresponding to command line arguments for FFMPEG and libx264. Use\n            `ffmpeg -h encoder=libx264` to see all options for libx264 output_params.\n\n    Notes:\n        This class can be used as a context manager to ensure the video is properly\n        closed after writing. For example:\n\n        ```python\n        with VideoWriter(\"output.mp4\") as writer:\n            for frame in frames:\n                writer(frame)\n        ```\n    \"\"\"\n\n    filename: Path = attrs.field(converter=Path)\n    fps: float = 30\n    pixelformat: str = \"yuv420p\"\n    codec: str = \"libx264\"\n    crf: int = 25\n    preset: str = \"superfast\"\n    output_params: list[str] = attrs.field(factory=list)\n    _writer: \"imageio.plugins.ffmpeg.FfmpegFormat.Writer\" | None = None\n\n    def build_output_params(self) -&gt; list[str]:\n        \"\"\"Build the output parameters for FFMPEG.\"\"\"\n        output_params = []\n        if self.codec == \"libx264\":\n            output_params.extend(\n                [\n                    \"-crf\",\n                    str(self.crf),\n                    \"-preset\",\n                    self.preset,\n                ]\n            )\n        return output_params + self.output_params\n\n    def open(self):\n        \"\"\"Open the video writer.\"\"\"\n        self.close()\n\n        self.filename.parent.mkdir(parents=True, exist_ok=True)\n        self._writer = iio_v2.get_writer(\n            self.filename.as_posix(),\n            format=\"FFMPEG\",\n            fps=self.fps,\n            codec=self.codec,\n            pixelformat=self.pixelformat,\n            output_params=self.build_output_params(),\n        )\n\n    def close(self):\n        \"\"\"Close the video writer.\"\"\"\n        if self._writer is not None:\n            self._writer.close()\n            self._writer = None\n\n    def write_frame(self, frame: np.ndarray):\n        \"\"\"Write a frame to the video.\n\n        Args:\n            frame: Frame to write to video. Should be a 2D or 3D numpy array with\n                dimensions (height, width) or (height, width, channels).\n        \"\"\"\n        if self._writer is None:\n            self.open()\n\n        self._writer.append_data(frame)\n\n    def __enter__(self):\n        \"\"\"Context manager entry.\"\"\"\n        return self\n\n    def __exit__(\n        self,\n        exc_type: Optional[Type[BaseException]],\n        exc_value: Optional[BaseException],\n        traceback: Optional[TracebackType],\n    ) -&gt; Optional[bool]:\n        \"\"\"Context manager exit.\"\"\"\n        self.close()\n        return False\n\n    def __call__(self, frame: np.ndarray):\n        \"\"\"Write a frame to the video.\n\n        Args:\n            frame: Frame to write to video. Should be a 2D or 3D numpy array with\n                dimensions (height, width) or (height, width, channels).\n        \"\"\"\n        self.write_frame(frame)\n</code></pre>"},{"location":"reference/sleap_io/io/video_writing/#sleap_io.io.video_writing.VideoWriter.__call__","title":"<code>__call__(frame)</code>","text":"<p>Write a frame to the video.</p> <p>Parameters:</p> Name Type Description Default <code>frame</code> <code>ndarray</code> <p>Frame to write to video. Should be a 2D or 3D numpy array with dimensions (height, width) or (height, width, channels).</p> required Source code in <code>sleap_io/io/video_writing.py</code> <pre><code>def __call__(self, frame: np.ndarray):\n    \"\"\"Write a frame to the video.\n\n    Args:\n        frame: Frame to write to video. Should be a 2D or 3D numpy array with\n            dimensions (height, width) or (height, width, channels).\n    \"\"\"\n    self.write_frame(frame)\n</code></pre>"},{"location":"reference/sleap_io/io/video_writing/#sleap_io.io.video_writing.VideoWriter.__enter__","title":"<code>__enter__()</code>","text":"<p>Context manager entry.</p> Source code in <code>sleap_io/io/video_writing.py</code> <pre><code>def __enter__(self):\n    \"\"\"Context manager entry.\"\"\"\n    return self\n</code></pre>"},{"location":"reference/sleap_io/io/video_writing/#sleap_io.io.video_writing.VideoWriter.__exit__","title":"<code>__exit__(exc_type, exc_value, traceback)</code>","text":"<p>Context manager exit.</p> Source code in <code>sleap_io/io/video_writing.py</code> <pre><code>def __exit__(\n    self,\n    exc_type: Optional[Type[BaseException]],\n    exc_value: Optional[BaseException],\n    traceback: Optional[TracebackType],\n) -&gt; Optional[bool]:\n    \"\"\"Context manager exit.\"\"\"\n    self.close()\n    return False\n</code></pre>"},{"location":"reference/sleap_io/io/video_writing/#sleap_io.io.video_writing.VideoWriter.build_output_params","title":"<code>build_output_params()</code>","text":"<p>Build the output parameters for FFMPEG.</p> Source code in <code>sleap_io/io/video_writing.py</code> <pre><code>def build_output_params(self) -&gt; list[str]:\n    \"\"\"Build the output parameters for FFMPEG.\"\"\"\n    output_params = []\n    if self.codec == \"libx264\":\n        output_params.extend(\n            [\n                \"-crf\",\n                str(self.crf),\n                \"-preset\",\n                self.preset,\n            ]\n        )\n    return output_params + self.output_params\n</code></pre>"},{"location":"reference/sleap_io/io/video_writing/#sleap_io.io.video_writing.VideoWriter.close","title":"<code>close()</code>","text":"<p>Close the video writer.</p> Source code in <code>sleap_io/io/video_writing.py</code> <pre><code>def close(self):\n    \"\"\"Close the video writer.\"\"\"\n    if self._writer is not None:\n        self._writer.close()\n        self._writer = None\n</code></pre>"},{"location":"reference/sleap_io/io/video_writing/#sleap_io.io.video_writing.VideoWriter.open","title":"<code>open()</code>","text":"<p>Open the video writer.</p> Source code in <code>sleap_io/io/video_writing.py</code> <pre><code>def open(self):\n    \"\"\"Open the video writer.\"\"\"\n    self.close()\n\n    self.filename.parent.mkdir(parents=True, exist_ok=True)\n    self._writer = iio_v2.get_writer(\n        self.filename.as_posix(),\n        format=\"FFMPEG\",\n        fps=self.fps,\n        codec=self.codec,\n        pixelformat=self.pixelformat,\n        output_params=self.build_output_params(),\n    )\n</code></pre>"},{"location":"reference/sleap_io/io/video_writing/#sleap_io.io.video_writing.VideoWriter.write_frame","title":"<code>write_frame(frame)</code>","text":"<p>Write a frame to the video.</p> <p>Parameters:</p> Name Type Description Default <code>frame</code> <code>ndarray</code> <p>Frame to write to video. Should be a 2D or 3D numpy array with dimensions (height, width) or (height, width, channels).</p> required Source code in <code>sleap_io/io/video_writing.py</code> <pre><code>def write_frame(self, frame: np.ndarray):\n    \"\"\"Write a frame to the video.\n\n    Args:\n        frame: Frame to write to video. Should be a 2D or 3D numpy array with\n            dimensions (height, width) or (height, width, channels).\n    \"\"\"\n    if self._writer is None:\n        self.open()\n\n    self._writer.append_data(frame)\n</code></pre>"},{"location":"reference/sleap_io/model/","title":"model","text":""},{"location":"reference/sleap_io/model/#sleap_io.model","title":"<code>sleap_io.model</code>","text":"<p>This subpackage contains data model interfaces.</p> <p>Modules:</p> Name Description <code>camera</code> <p>Data structure for a single camera view in a multi-camera setup.</p> <code>instance</code> <p>Data structures for data associated with a single instance such as an animal.</p> <code>labeled_frame</code> <p>Data structures for data contained within a single video frame.</p> <code>labels</code> <p>Data structure for the labels, a top-level container for pose data.</p> <code>labels_set</code> <p>Data model for collections of Labels objects.</p> <code>matching</code> <p>Unified matcher system for comparing and matching data structures during merging.</p> <code>skeleton</code> <p>Data model for skeletons.</p> <code>suggestions</code> <p>Data module for suggestions.</p> <code>video</code> <p>Data model for videos.</p>"},{"location":"reference/sleap_io/model/camera/","title":"camera","text":""},{"location":"reference/sleap_io/model/camera/#sleap_io.model.camera","title":"<code>sleap_io.model.camera</code>","text":"<p>Data structure for a single camera view in a multi-camera setup.</p> <p>Classes:</p> Name Description <code>Camera</code> <p>A camera used to record in a multi-view <code>RecordingSession</code>.</p> <code>CameraGroup</code> <p>A group of cameras used to record a multi-view <code>RecordingSession</code>.</p> <code>FrameGroup</code> <p>Defines a group of <code>InstanceGroups</code> across views at the same frame index.</p> <code>InstanceGroup</code> <p>Defines a group of instances across the same frame index.</p> <code>RecordingSession</code> <p>A recording session with multiple cameras.</p> <p>Functions:</p> Name Description <code>rodrigues_transformation</code> <p>Convert between rotation vector and rotation matrix using Rodrigues' formula.</p>"},{"location":"reference/sleap_io/model/camera/#sleap_io.model.camera.Camera","title":"<code>Camera</code>","text":"<p>A camera used to record in a multi-view <code>RecordingSession</code>.</p> <p>Attributes:</p> Name Type Description <code>matrix</code> <code>ndarray</code> <p>Intrinsic camera matrix of size (3, 3) and type float64.</p> <code>dist</code> <code>ndarray</code> <p>Radial-tangential distortion coefficients [k_1, k_2, p_1, p_2, k_3] of size (5,) and type float64.</p> <code>size</code> <code>tuple[int, int]</code> <p>Image size (width, height) of camera in pixels of size (2,) and type int.</p> <code>rvec</code> <code>ndarray</code> <p>Rotation vector in unnormalized axis-angle representation of size (3,) and type float64.</p> <code>tvec</code> <code>ndarray</code> <p>Translation vector of size (3,) and type float64.</p> <code>extrinsic_matrix</code> <code>ndarray</code> <p>Extrinsic matrix of camera of size (4, 4) and type float64.</p> <code>name</code> <code>str</code> <p>Camera name.</p> <code>metadata</code> <code>dict</code> <p>Dictionary of metadata.</p> <p>Methods:</p> Name Description <code>__attrs_post_init__</code> <p>Initialize extrinsic matrix from rotation and translation vectors.</p> <code>__repr__</code> <p>Return a readable representation of the camera.</p> <code>get_video</code> <p>Get video associated with recording session.</p> Source code in <code>sleap_io/model/camera.py</code> <pre><code>@define(eq=False)  # Set eq to false to make class hashable\nclass Camera:\n    \"\"\"A camera used to record in a multi-view `RecordingSession`.\n\n    Attributes:\n        matrix: Intrinsic camera matrix of size (3, 3) and type float64.\n        dist: Radial-tangential distortion coefficients [k_1, k_2, p_1, p_2, k_3] of\n            size (5,) and type float64.\n        size: Image size (width, height) of camera in pixels of size (2,) and type int.\n        rvec: Rotation vector in unnormalized axis-angle representation of size (3,) and\n            type float64.\n        tvec: Translation vector of size (3,) and type float64.\n        extrinsic_matrix: Extrinsic matrix of camera of size (4, 4) and type float64.\n        name: Camera name.\n        metadata: Dictionary of metadata.\n    \"\"\"\n\n    matrix: np.ndarray = field(\n        default=np.eye(3),\n        converter=lambda x: np.array(x, dtype=\"float64\"),\n    )\n    dist: np.ndarray = field(\n        default=np.zeros(5), converter=lambda x: np.array(x, dtype=\"float64\").ravel()\n    )\n    size: tuple[int, int] = field(\n        default=None, converter=attrs.converters.optional(tuple)\n    )\n    _rvec: np.ndarray = field(\n        default=np.zeros(3), converter=lambda x: np.array(x, dtype=\"float64\").ravel()\n    )\n    _tvec: np.ndarray = field(\n        default=np.zeros(3), converter=lambda x: np.array(x, dtype=\"float64\").ravel()\n    )\n    name: str = field(default=None, converter=attrs.converters.optional(str))\n    _extrinsic_matrix: np.ndarray = field(init=False)\n    metadata: dict = field(factory=dict, validator=instance_of(dict))\n\n    @matrix.validator\n    @dist.validator\n    @size.validator\n    @_rvec.validator\n    @_tvec.validator\n    @_extrinsic_matrix.validator\n    def _validate_shape(self, attribute: attrs.Attribute, value):\n        \"\"\"Validate shape of attribute based on metadata.\n\n        Args:\n            attribute: Attribute to validate.\n            value: Value of attribute to validate.\n\n        Raises:\n            ValueError: If attribute shape is not as expected.\n        \"\"\"\n        # Define metadata for each attribute\n        attr_metadata = {\n            \"matrix\": {\"shape\": (3, 3), \"type\": np.ndarray},\n            \"dist\": {\"shape\": (5,), \"type\": np.ndarray},\n            \"size\": {\"shape\": (2,), \"type\": tuple},\n            \"_rvec\": {\"shape\": (3,), \"type\": np.ndarray},\n            \"_tvec\": {\"shape\": (3,), \"type\": np.ndarray},\n            \"_extrinsic_matrix\": {\"shape\": (4, 4), \"type\": np.ndarray},\n        }\n        optional_attrs = [\"size\"]\n\n        # Skip validation if optional attribute is None\n        if attribute.name in optional_attrs and value is None:\n            return\n\n        # Validate shape of attribute\n        expected_shape = attr_metadata[attribute.name][\"shape\"]\n        expected_type = attr_metadata[attribute.name][\"type\"]\n        if np.shape(value) != expected_shape:\n            raise ValueError(\n                f\"{attribute.name} must be a {expected_type} of size {expected_shape}, \"\n                f\"but received shape: {np.shape(value)} and type: {type(value)} for \"\n                f\"value: {value}\"\n            )\n\n    def __attrs_post_init__(self):\n        \"\"\"Initialize extrinsic matrix from rotation and translation vectors.\"\"\"\n        self._extrinsic_matrix = np.eye(4, dtype=\"float64\")\n        self._extrinsic_matrix[:3, :3] = rodrigues_transformation(self._rvec)[0]\n        self._extrinsic_matrix[:3, 3] = self._tvec\n\n    @property\n    def rvec(self) -&gt; np.ndarray:\n        \"\"\"Get rotation vector of camera.\n\n        Returns:\n            Rotation vector of camera of size 3.\n        \"\"\"\n        return self._rvec\n\n    @rvec.setter\n    def rvec(self, value: np.ndarray):\n        \"\"\"Set rotation vector and update extrinsic matrix.\n\n        Args:\n            value: Rotation vector of size 3.\n        \"\"\"\n        self._rvec = value\n        self._extrinsic_matrix[:3, :3] = rodrigues_transformation(self._rvec)[0]\n\n    @property\n    def tvec(self) -&gt; np.ndarray:\n        \"\"\"Get translation vector of camera.\n\n        Returns:\n            Translation vector of camera of size 3.\n        \"\"\"\n        return self._tvec\n\n    @tvec.setter\n    def tvec(self, value: np.ndarray):\n        \"\"\"Set translation vector and update extrinsic matrix.\n\n        Args:\n            value: Translation vector of size 3.\n        \"\"\"\n        self._tvec = value\n\n        # Update extrinsic matrix\n        self._extrinsic_matrix[:3, 3] = self._tvec\n\n    @property\n    def extrinsic_matrix(self) -&gt; np.ndarray:\n        \"\"\"Get extrinsic matrix of camera.\n\n        Returns:\n            Extrinsic matrix of camera of size 4 x 4.\n        \"\"\"\n        return self._extrinsic_matrix\n\n    @extrinsic_matrix.setter\n    def extrinsic_matrix(self, value: np.ndarray):\n        \"\"\"Set extrinsic matrix and update rotation and translation vectors.\n\n        Args:\n            value: Extrinsic matrix of size 4 x 4.\n        \"\"\"\n        self._extrinsic_matrix = value\n\n        # Update rotation and translation vectors\n        self._rvec = rodrigues_transformation(self._extrinsic_matrix[:3, :3])[0].ravel()\n        self._tvec = self._extrinsic_matrix[:3, 3]\n\n    def get_video(self, session: RecordingSession) -&gt; Video | None:\n        \"\"\"Get video associated with recording session.\n\n        Args:\n            session: Recording session to get video for.\n\n        Returns:\n            Video associated with recording session or None if not found.\n        \"\"\"\n        return session.get_video(camera=self)\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return a readable representation of the camera.\"\"\"\n        matrix_str = (\n            \"identity\" if np.array_equal(self.matrix, np.eye(3)) else \"non-identity\"\n        )\n        dist_str = \"zero\" if np.array_equal(self.dist, np.zeros(5)) else \"non-zero\"\n        size_str = \"None\" if self.size is None else self.size\n        rvec_str = (\n            \"zero\"\n            if np.array_equal(self.rvec, np.zeros(3))\n            else np.array2string(self.rvec, precision=2, suppress_small=True)\n        )\n        tvec_str = (\n            \"zero\"\n            if np.array_equal(self.tvec, np.zeros(3))\n            else np.array2string(self.tvec, precision=2, suppress_small=True)\n        )\n        name_str = self.name if self.name is not None else \"None\"\n        return (\n            \"Camera(\"\n            f\"matrix={matrix_str}, \"\n            f\"dist={dist_str}, \"\n            f\"size={size_str}, \"\n            f\"rvec={rvec_str}, \"\n            f\"tvec={tvec_str}, \"\n            f\"name={name_str}\"\n            \")\"\n        )\n</code></pre>"},{"location":"reference/sleap_io/model/camera/#sleap_io.model.camera.Camera.extrinsic_matrix","title":"<code>extrinsic_matrix</code>  <code>property</code> <code>writable</code>","text":"<p>Get extrinsic matrix of camera.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>Extrinsic matrix of camera of size 4 x 4.</p>"},{"location":"reference/sleap_io/model/camera/#sleap_io.model.camera.Camera.rvec","title":"<code>rvec</code>  <code>property</code> <code>writable</code>","text":"<p>Get rotation vector of camera.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>Rotation vector of camera of size 3.</p>"},{"location":"reference/sleap_io/model/camera/#sleap_io.model.camera.Camera.tvec","title":"<code>tvec</code>  <code>property</code> <code>writable</code>","text":"<p>Get translation vector of camera.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>Translation vector of camera of size 3.</p>"},{"location":"reference/sleap_io/model/camera/#sleap_io.model.camera.Camera.__attrs_post_init__","title":"<code>__attrs_post_init__()</code>","text":"<p>Initialize extrinsic matrix from rotation and translation vectors.</p> Source code in <code>sleap_io/model/camera.py</code> <pre><code>def __attrs_post_init__(self):\n    \"\"\"Initialize extrinsic matrix from rotation and translation vectors.\"\"\"\n    self._extrinsic_matrix = np.eye(4, dtype=\"float64\")\n    self._extrinsic_matrix[:3, :3] = rodrigues_transformation(self._rvec)[0]\n    self._extrinsic_matrix[:3, 3] = self._tvec\n</code></pre>"},{"location":"reference/sleap_io/model/camera/#sleap_io.model.camera.Camera.__repr__","title":"<code>__repr__()</code>","text":"<p>Return a readable representation of the camera.</p> Source code in <code>sleap_io/model/camera.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return a readable representation of the camera.\"\"\"\n    matrix_str = (\n        \"identity\" if np.array_equal(self.matrix, np.eye(3)) else \"non-identity\"\n    )\n    dist_str = \"zero\" if np.array_equal(self.dist, np.zeros(5)) else \"non-zero\"\n    size_str = \"None\" if self.size is None else self.size\n    rvec_str = (\n        \"zero\"\n        if np.array_equal(self.rvec, np.zeros(3))\n        else np.array2string(self.rvec, precision=2, suppress_small=True)\n    )\n    tvec_str = (\n        \"zero\"\n        if np.array_equal(self.tvec, np.zeros(3))\n        else np.array2string(self.tvec, precision=2, suppress_small=True)\n    )\n    name_str = self.name if self.name is not None else \"None\"\n    return (\n        \"Camera(\"\n        f\"matrix={matrix_str}, \"\n        f\"dist={dist_str}, \"\n        f\"size={size_str}, \"\n        f\"rvec={rvec_str}, \"\n        f\"tvec={tvec_str}, \"\n        f\"name={name_str}\"\n        \")\"\n    )\n</code></pre>"},{"location":"reference/sleap_io/model/camera/#sleap_io.model.camera.Camera.get_video","title":"<code>get_video(session)</code>","text":"<p>Get video associated with recording session.</p> <p>Parameters:</p> Name Type Description Default <code>session</code> <code>RecordingSession</code> <p>Recording session to get video for.</p> required <p>Returns:</p> Type Description <code>Video | None</code> <p>Video associated with recording session or None if not found.</p> Source code in <code>sleap_io/model/camera.py</code> <pre><code>def get_video(self, session: RecordingSession) -&gt; Video | None:\n    \"\"\"Get video associated with recording session.\n\n    Args:\n        session: Recording session to get video for.\n\n    Returns:\n        Video associated with recording session or None if not found.\n    \"\"\"\n    return session.get_video(camera=self)\n</code></pre>"},{"location":"reference/sleap_io/model/camera/#sleap_io.model.camera.CameraGroup","title":"<code>CameraGroup</code>","text":"<p>A group of cameras used to record a multi-view <code>RecordingSession</code>.</p> <p>Attributes:</p> Name Type Description <code>cameras</code> <code>list[Camera]</code> <p>List of <code>Camera</code> objects in the group.</p> <code>metadata</code> <code>dict</code> <p>Dictionary of metadata.</p> <p>Methods:</p> Name Description <code>__repr__</code> <p>Return a readable representation of the camera group.</p> Source code in <code>sleap_io/model/camera.py</code> <pre><code>@define\nclass CameraGroup:\n    \"\"\"A group of cameras used to record a multi-view `RecordingSession`.\n\n    Attributes:\n        cameras: List of `Camera` objects in the group.\n        metadata: Dictionary of metadata.\n    \"\"\"\n\n    cameras: list[Camera] = field(factory=list, validator=instance_of(list))\n    metadata: dict = field(factory=dict, validator=instance_of(dict))\n\n    def __repr__(self):\n        \"\"\"Return a readable representation of the camera group.\"\"\"\n        camera_names = \", \".join([c.name or \"None\" for c in self.cameras])\n        return f\"CameraGroup(cameras={len(self.cameras)}:[{camera_names}])\"\n</code></pre>"},{"location":"reference/sleap_io/model/camera/#sleap_io.model.camera.CameraGroup.__repr__","title":"<code>__repr__()</code>","text":"<p>Return a readable representation of the camera group.</p> Source code in <code>sleap_io/model/camera.py</code> <pre><code>def __repr__(self):\n    \"\"\"Return a readable representation of the camera group.\"\"\"\n    camera_names = \", \".join([c.name or \"None\" for c in self.cameras])\n    return f\"CameraGroup(cameras={len(self.cameras)}:[{camera_names}])\"\n</code></pre>"},{"location":"reference/sleap_io/model/camera/#sleap_io.model.camera.FrameGroup","title":"<code>FrameGroup</code>","text":"<p>Defines a group of <code>InstanceGroups</code> across views at the same frame index.</p> <p>Attributes:</p> Name Type Description <code>frame_idx</code> <code>int</code> <p>Frame index for the <code>FrameGroup</code>.</p> <code>instance_groups</code> <code>list[InstanceGroup]</code> <p>List of <code>InstanceGroup</code>s in the <code>FrameGroup</code>.</p> <code>cameras</code> <code>list[Camera]</code> <p>List of <code>Camera</code> objects linked to <code>LabeledFrame</code>s in the <code>FrameGroup</code>.</p> <code>labeled_frames</code> <code>list[LabeledFrame]</code> <p>List of <code>LabeledFrame</code>s in the <code>FrameGroup</code>.</p> <code>metadata</code> <code>dict</code> <p>Metadata for the <code>FrameGroup</code> that is provided but not deserialized.</p> <p>Methods:</p> Name Description <code>__repr__</code> <p>Return a readable representation of the frame group.</p> <code>get_frame</code> <p>Get <code>LabeledFrame</code> associated with <code>camera</code>.</p> Source code in <code>sleap_io/model/camera.py</code> <pre><code>@define(eq=False)  # Set eq to false to make class hashable\nclass FrameGroup:\n    \"\"\"Defines a group of `InstanceGroups` across views at the same frame index.\n\n    Attributes:\n        frame_idx: Frame index for the `FrameGroup`.\n        instance_groups: List of `InstanceGroup`s in the `FrameGroup`.\n        cameras: List of `Camera` objects linked to `LabeledFrame`s in the `FrameGroup`.\n        labeled_frames: List of `LabeledFrame`s in the `FrameGroup`.\n        metadata: Metadata for the `FrameGroup` that is provided but not deserialized.\n    \"\"\"\n\n    frame_idx: int = field(converter=int)\n    _instance_groups: list[InstanceGroup] = field(\n        factory=list, validator=instance_of(list)\n    )\n    _labeled_frame_by_camera: dict[Camera, LabeledFrame] = field(\n        factory=dict, validator=instance_of(dict)\n    )\n    metadata: dict = field(factory=dict, validator=instance_of(dict))\n\n    @property\n    def instance_groups(self) -&gt; list[InstanceGroup]:\n        \"\"\"List of `InstanceGroup`s.\"\"\"\n        return self._instance_groups\n\n    @property\n    def cameras(self) -&gt; list[Camera]:\n        \"\"\"List of `Camera` objects.\"\"\"\n        return list(self._labeled_frame_by_camera.keys())\n\n    @property\n    def labeled_frames(self) -&gt; list[LabeledFrame]:\n        \"\"\"List of `LabeledFrame`s.\"\"\"\n        return list(self._labeled_frame_by_camera.values())\n\n    def get_frame(self, camera: Camera) -&gt; LabeledFrame | None:\n        \"\"\"Get `LabeledFrame` associated with `camera`.\n\n        Args:\n            camera: `Camera` to get `LabeledFrame`.\n\n        Returns:\n            `LabeledFrame` associated with `camera` or None if not found.\n        \"\"\"\n        return self._labeled_frame_by_camera.get(camera, None)\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return a readable representation of the frame group.\"\"\"\n        cameras_str = \", \".join([c.name or \"None\" for c in self.cameras])\n        return (\n            f\"FrameGroup(\"\n            f\"frame_idx={self.frame_idx},\"\n            f\"instance_groups={len(self.instance_groups)},\"\n            f\"cameras={len(self.cameras)}:[{cameras_str}]\"\n            f\")\"\n        )\n</code></pre>"},{"location":"reference/sleap_io/model/camera/#sleap_io.model.camera.FrameGroup.cameras","title":"<code>cameras</code>  <code>property</code>","text":"<p>List of <code>Camera</code> objects.</p>"},{"location":"reference/sleap_io/model/camera/#sleap_io.model.camera.FrameGroup.instance_groups","title":"<code>instance_groups</code>  <code>property</code>","text":"<p>List of <code>InstanceGroup</code>s.</p>"},{"location":"reference/sleap_io/model/camera/#sleap_io.model.camera.FrameGroup.labeled_frames","title":"<code>labeled_frames</code>  <code>property</code>","text":"<p>List of <code>LabeledFrame</code>s.</p>"},{"location":"reference/sleap_io/model/camera/#sleap_io.model.camera.FrameGroup.__repr__","title":"<code>__repr__()</code>","text":"<p>Return a readable representation of the frame group.</p> Source code in <code>sleap_io/model/camera.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return a readable representation of the frame group.\"\"\"\n    cameras_str = \", \".join([c.name or \"None\" for c in self.cameras])\n    return (\n        f\"FrameGroup(\"\n        f\"frame_idx={self.frame_idx},\"\n        f\"instance_groups={len(self.instance_groups)},\"\n        f\"cameras={len(self.cameras)}:[{cameras_str}]\"\n        f\")\"\n    )\n</code></pre>"},{"location":"reference/sleap_io/model/camera/#sleap_io.model.camera.FrameGroup.get_frame","title":"<code>get_frame(camera)</code>","text":"<p>Get <code>LabeledFrame</code> associated with <code>camera</code>.</p> <p>Parameters:</p> Name Type Description Default <code>camera</code> <code>Camera</code> <p><code>Camera</code> to get <code>LabeledFrame</code>.</p> required <p>Returns:</p> Type Description <code>LabeledFrame | None</code> <p><code>LabeledFrame</code> associated with <code>camera</code> or None if not found.</p> Source code in <code>sleap_io/model/camera.py</code> <pre><code>def get_frame(self, camera: Camera) -&gt; LabeledFrame | None:\n    \"\"\"Get `LabeledFrame` associated with `camera`.\n\n    Args:\n        camera: `Camera` to get `LabeledFrame`.\n\n    Returns:\n        `LabeledFrame` associated with `camera` or None if not found.\n    \"\"\"\n    return self._labeled_frame_by_camera.get(camera, None)\n</code></pre>"},{"location":"reference/sleap_io/model/camera/#sleap_io.model.camera.InstanceGroup","title":"<code>InstanceGroup</code>","text":"<p>Defines a group of instances across the same frame index.</p> <p>Attributes:</p> Name Type Description <code>instances_by_camera</code> <p>Dictionary of <code>Instance</code> objects by <code>Camera</code>.</p> <code>instances</code> <code>list[Instance]</code> <p>List of <code>Instance</code> objects in the group.</p> <code>cameras</code> <code>list[Camera]</code> <p>List of <code>Camera</code> objects that have an <code>Instance</code> associated.</p> <code>score</code> <code>float | None</code> <p>Optional score for the <code>InstanceGroup</code>. Setting the score will also update the score for all <code>instances</code> already in the <code>InstanceGroup</code>. The score for <code>instances</code> will not be updated upon initialization.</p> <code>points</code> <code>ndarray | None</code> <p>Optional 3D points for the <code>InstanceGroup</code>.</p> <code>metadata</code> <code>dict</code> <p>Dictionary of metadata.</p> <p>Methods:</p> Name Description <code>__repr__</code> <p>Return a readable representation of the instance group.</p> <code>get_instance</code> <p>Get <code>Instance</code> associated with <code>camera</code>.</p> Source code in <code>sleap_io/model/camera.py</code> <pre><code>@define(eq=False)  # Set eq to false to make class hashable\nclass InstanceGroup:\n    \"\"\"Defines a group of instances across the same frame index.\n\n    Attributes:\n        instances_by_camera: Dictionary of `Instance` objects by `Camera`.\n        instances: List of `Instance` objects in the group.\n        cameras: List of `Camera` objects that have an `Instance` associated.\n        score: Optional score for the `InstanceGroup`. Setting the score will also\n            update the score for all `instances` already in the `InstanceGroup`. The\n            score for `instances` will not be updated upon initialization.\n        points: Optional 3D points for the `InstanceGroup`.\n        metadata: Dictionary of metadata.\n    \"\"\"\n\n    _instance_by_camera: dict[Camera, Instance] = field(\n        factory=dict, validator=instance_of(dict)\n    )\n    _score: float | None = field(\n        default=None, converter=attrs.converters.optional(float)\n    )\n    _points: np.ndarray | None = field(\n        default=None,\n        converter=attrs.converters.optional(lambda x: np.array(x, dtype=\"float64\")),\n    )\n    metadata: dict = field(factory=dict, validator=instance_of(dict))\n\n    @property\n    def instance_by_camera(self) -&gt; dict[Camera, Instance]:\n        \"\"\"Get dictionary of `Instance` objects by `Camera`.\"\"\"\n        return self._instance_by_camera\n\n    @property\n    def instances(self) -&gt; list[Instance]:\n        \"\"\"List of `Instance` objects.\"\"\"\n        return list(self._instance_by_camera.values())\n\n    @property\n    def cameras(self) -&gt; list[Camera]:\n        \"\"\"List of `Camera` objects.\"\"\"\n        return list(self._instance_by_camera.keys())\n\n    @property\n    def score(self) -&gt; float | None:\n        \"\"\"Get score for `InstanceGroup`.\"\"\"\n        return self._score\n\n    @property\n    def points(self) -&gt; np.ndarray | None:\n        \"\"\"Get 3D points for `InstanceGroup`.\"\"\"\n        return self._points\n\n    def get_instance(self, camera: Camera) -&gt; Instance | None:\n        \"\"\"Get `Instance` associated with `camera`.\n\n        Args:\n            camera: `Camera` to get `Instance`.\n\n        Returns:\n            `Instance` associated with `camera` or None if not found.\n        \"\"\"\n        return self._instance_by_camera.get(camera, None)\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return a readable representation of the instance group.\"\"\"\n        cameras_str = \", \".join([c.name or \"None\" for c in self.cameras])\n        return f\"InstanceGroup(cameras={len(self.cameras)}:[{cameras_str}])\"\n</code></pre>"},{"location":"reference/sleap_io/model/camera/#sleap_io.model.camera.InstanceGroup.cameras","title":"<code>cameras</code>  <code>property</code>","text":"<p>List of <code>Camera</code> objects.</p>"},{"location":"reference/sleap_io/model/camera/#sleap_io.model.camera.InstanceGroup.instance_by_camera","title":"<code>instance_by_camera</code>  <code>property</code>","text":"<p>Get dictionary of <code>Instance</code> objects by <code>Camera</code>.</p>"},{"location":"reference/sleap_io/model/camera/#sleap_io.model.camera.InstanceGroup.instances","title":"<code>instances</code>  <code>property</code>","text":"<p>List of <code>Instance</code> objects.</p>"},{"location":"reference/sleap_io/model/camera/#sleap_io.model.camera.InstanceGroup.points","title":"<code>points</code>  <code>property</code>","text":"<p>Get 3D points for <code>InstanceGroup</code>.</p>"},{"location":"reference/sleap_io/model/camera/#sleap_io.model.camera.InstanceGroup.score","title":"<code>score</code>  <code>property</code>","text":"<p>Get score for <code>InstanceGroup</code>.</p>"},{"location":"reference/sleap_io/model/camera/#sleap_io.model.camera.InstanceGroup.__repr__","title":"<code>__repr__()</code>","text":"<p>Return a readable representation of the instance group.</p> Source code in <code>sleap_io/model/camera.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return a readable representation of the instance group.\"\"\"\n    cameras_str = \", \".join([c.name or \"None\" for c in self.cameras])\n    return f\"InstanceGroup(cameras={len(self.cameras)}:[{cameras_str}])\"\n</code></pre>"},{"location":"reference/sleap_io/model/camera/#sleap_io.model.camera.InstanceGroup.get_instance","title":"<code>get_instance(camera)</code>","text":"<p>Get <code>Instance</code> associated with <code>camera</code>.</p> <p>Parameters:</p> Name Type Description Default <code>camera</code> <code>Camera</code> <p><code>Camera</code> to get <code>Instance</code>.</p> required <p>Returns:</p> Type Description <code>Instance | None</code> <p><code>Instance</code> associated with <code>camera</code> or None if not found.</p> Source code in <code>sleap_io/model/camera.py</code> <pre><code>def get_instance(self, camera: Camera) -&gt; Instance | None:\n    \"\"\"Get `Instance` associated with `camera`.\n\n    Args:\n        camera: `Camera` to get `Instance`.\n\n    Returns:\n        `Instance` associated with `camera` or None if not found.\n    \"\"\"\n    return self._instance_by_camera.get(camera, None)\n</code></pre>"},{"location":"reference/sleap_io/model/camera/#sleap_io.model.camera.RecordingSession","title":"<code>RecordingSession</code>","text":"<p>A recording session with multiple cameras.</p> <p>Attributes:</p> Name Type Description <code>camera_group</code> <code>CameraGroup</code> <p><code>CameraGroup</code> object containing cameras in the session.</p> <code>frame_groups</code> <code>dict[int, FrameGroup]</code> <p>Dictionary mapping frame index to <code>FrameGroup</code>.</p> <code>videos</code> <code>list[Video]</code> <p>List of <code>Video</code> objects linked to <code>Camera</code>s in the session.</p> <code>cameras</code> <code>list[Camera]</code> <p>List of <code>Camera</code> objects linked to <code>Video</code>s in the session.</p> <code>metadata</code> <code>dict</code> <p>Dictionary of metadata.</p> <p>Methods:</p> Name Description <code>__repr__</code> <p>Return a readable representation of the session.</p> <code>add_video</code> <p>Add <code>video</code> to <code>RecordingSession</code> and mapping to <code>camera</code>.</p> <code>get_camera</code> <p>Get <code>Camera</code> associated with <code>video</code>.</p> <code>get_video</code> <p>Get <code>Video</code> associated with <code>camera</code>.</p> <code>remove_video</code> <p>Remove <code>video</code> from <code>RecordingSession</code> and mapping to <code>Camera</code>.</p> Source code in <code>sleap_io/model/camera.py</code> <pre><code>@define(eq=False)  # Set eq to false to make class hashable\nclass RecordingSession:\n    \"\"\"A recording session with multiple cameras.\n\n    Attributes:\n        camera_group: `CameraGroup` object containing cameras in the session.\n        frame_groups: Dictionary mapping frame index to `FrameGroup`.\n        videos: List of `Video` objects linked to `Camera`s in the session.\n        cameras: List of `Camera` objects linked to `Video`s in the session.\n        metadata: Dictionary of metadata.\n    \"\"\"\n\n    camera_group: CameraGroup = field(\n        factory=CameraGroup, validator=instance_of(CameraGroup)\n    )\n    _video_by_camera: dict[Camera, Video] = field(\n        factory=dict, validator=instance_of(dict)\n    )\n    _camera_by_video: dict[Video, Camera] = field(\n        factory=dict, validator=instance_of(dict)\n    )\n    _frame_group_by_frame_idx: dict[int, FrameGroup] = field(\n        factory=dict, validator=instance_of(dict)\n    )\n    metadata: dict = field(factory=dict, validator=instance_of(dict))\n\n    @property\n    def frame_groups(self) -&gt; dict[int, FrameGroup]:\n        \"\"\"Get dictionary of `FrameGroup` objects by frame index.\n\n        Returns:\n            Dictionary of `FrameGroup` objects by frame index.\n        \"\"\"\n        return self._frame_group_by_frame_idx\n\n    @property\n    def videos(self) -&gt; list[Video]:\n        \"\"\"Get list of `Video` objects in the `RecordingSession`.\n\n        Returns:\n            List of `Video` objects in `RecordingSession`.\n        \"\"\"\n        return list(self._video_by_camera.values())\n\n    @property\n    def cameras(self) -&gt; list[Camera]:\n        \"\"\"Get list of `Camera` objects linked to `Video`s in the `RecordingSession`.\n\n        Returns:\n            List of `Camera` objects in `RecordingSession`.\n        \"\"\"\n        return list(self._video_by_camera.keys())\n\n    def get_camera(self, video: Video) -&gt; Camera | None:\n        \"\"\"Get `Camera` associated with `video`.\n\n        Args:\n            video: `Video` to get `Camera`\n\n        Returns:\n            `Camera` associated with `video` or None if not found\n        \"\"\"\n        return self._camera_by_video.get(video, None)\n\n    def get_video(self, camera: Camera) -&gt; Video | None:\n        \"\"\"Get `Video` associated with `camera`.\n\n        Args:\n            camera: `Camera` to get `Video`\n\n        Returns:\n            `Video` associated with `camera` or None if not found\n        \"\"\"\n        return self._video_by_camera.get(camera, None)\n\n    def add_video(self, video: Video, camera: Camera):\n        \"\"\"Add `video` to `RecordingSession` and mapping to `camera`.\n\n        Args:\n            video: `Video` object to add to `RecordingSession`.\n            camera: `Camera` object to associate with `video`.\n\n        Raises:\n            ValueError: If `camera` is not in associated `CameraGroup`.\n            ValueError: If `video` is not a `Video` object.\n        \"\"\"\n        # Raise ValueError if camera is not in associated camera group\n        self.camera_group.cameras.index(camera)\n\n        # Raise ValueError if `Video` is not a `Video` object\n        if not isinstance(video, Video):\n            raise ValueError(\n                f\"Expected `Video` object, but received {type(video)} object.\"\n            )\n\n        # Add camera to video mapping\n        self._video_by_camera[camera] = video\n\n        # Add video to camera mapping\n        self._camera_by_video[video] = camera\n\n    def remove_video(self, video: Video):\n        \"\"\"Remove `video` from `RecordingSession` and mapping to `Camera`.\n\n        Args:\n            video: `Video` object to remove from `RecordingSession`.\n\n        Raises:\n            ValueError: If `video` is not in associated `RecordingSession`.\n        \"\"\"\n        # Remove video from camera mapping\n        camera = self._camera_by_video.pop(video)\n\n        # Remove camera from video mapping\n        self._video_by_camera.pop(camera)\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return a readable representation of the session.\"\"\"\n        return (\n            \"RecordingSession(\"\n            f\"camera_group={len(self.camera_group.cameras)}cameras, \"\n            f\"videos={len(self.videos)}, \"\n            f\"frame_groups={len(self.frame_groups)}\"\n            \")\"\n        )\n</code></pre>"},{"location":"reference/sleap_io/model/camera/#sleap_io.model.camera.RecordingSession.cameras","title":"<code>cameras</code>  <code>property</code>","text":"<p>Get list of <code>Camera</code> objects linked to <code>Video</code>s in the <code>RecordingSession</code>.</p> <p>Returns:</p> Type Description <code>list[Camera]</code> <p>List of <code>Camera</code> objects in <code>RecordingSession</code>.</p>"},{"location":"reference/sleap_io/model/camera/#sleap_io.model.camera.RecordingSession.frame_groups","title":"<code>frame_groups</code>  <code>property</code>","text":"<p>Get dictionary of <code>FrameGroup</code> objects by frame index.</p> <p>Returns:</p> Type Description <code>dict[int, FrameGroup]</code> <p>Dictionary of <code>FrameGroup</code> objects by frame index.</p>"},{"location":"reference/sleap_io/model/camera/#sleap_io.model.camera.RecordingSession.videos","title":"<code>videos</code>  <code>property</code>","text":"<p>Get list of <code>Video</code> objects in the <code>RecordingSession</code>.</p> <p>Returns:</p> Type Description <code>list[Video]</code> <p>List of <code>Video</code> objects in <code>RecordingSession</code>.</p>"},{"location":"reference/sleap_io/model/camera/#sleap_io.model.camera.RecordingSession.__repr__","title":"<code>__repr__()</code>","text":"<p>Return a readable representation of the session.</p> Source code in <code>sleap_io/model/camera.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return a readable representation of the session.\"\"\"\n    return (\n        \"RecordingSession(\"\n        f\"camera_group={len(self.camera_group.cameras)}cameras, \"\n        f\"videos={len(self.videos)}, \"\n        f\"frame_groups={len(self.frame_groups)}\"\n        \")\"\n    )\n</code></pre>"},{"location":"reference/sleap_io/model/camera/#sleap_io.model.camera.RecordingSession.add_video","title":"<code>add_video(video, camera)</code>","text":"<p>Add <code>video</code> to <code>RecordingSession</code> and mapping to <code>camera</code>.</p> <p>Parameters:</p> Name Type Description Default <code>video</code> <code>Video</code> <p><code>Video</code> object to add to <code>RecordingSession</code>.</p> required <code>camera</code> <code>Camera</code> <p><code>Camera</code> object to associate with <code>video</code>.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If <code>camera</code> is not in associated <code>CameraGroup</code>.</p> <code>ValueError</code> <p>If <code>video</code> is not a <code>Video</code> object.</p> Source code in <code>sleap_io/model/camera.py</code> <pre><code>def add_video(self, video: Video, camera: Camera):\n    \"\"\"Add `video` to `RecordingSession` and mapping to `camera`.\n\n    Args:\n        video: `Video` object to add to `RecordingSession`.\n        camera: `Camera` object to associate with `video`.\n\n    Raises:\n        ValueError: If `camera` is not in associated `CameraGroup`.\n        ValueError: If `video` is not a `Video` object.\n    \"\"\"\n    # Raise ValueError if camera is not in associated camera group\n    self.camera_group.cameras.index(camera)\n\n    # Raise ValueError if `Video` is not a `Video` object\n    if not isinstance(video, Video):\n        raise ValueError(\n            f\"Expected `Video` object, but received {type(video)} object.\"\n        )\n\n    # Add camera to video mapping\n    self._video_by_camera[camera] = video\n\n    # Add video to camera mapping\n    self._camera_by_video[video] = camera\n</code></pre>"},{"location":"reference/sleap_io/model/camera/#sleap_io.model.camera.RecordingSession.get_camera","title":"<code>get_camera(video)</code>","text":"<p>Get <code>Camera</code> associated with <code>video</code>.</p> <p>Parameters:</p> Name Type Description Default <code>video</code> <code>Video</code> <p><code>Video</code> to get <code>Camera</code></p> required <p>Returns:</p> Type Description <code>Camera | None</code> <p><code>Camera</code> associated with <code>video</code> or None if not found</p> Source code in <code>sleap_io/model/camera.py</code> <pre><code>def get_camera(self, video: Video) -&gt; Camera | None:\n    \"\"\"Get `Camera` associated with `video`.\n\n    Args:\n        video: `Video` to get `Camera`\n\n    Returns:\n        `Camera` associated with `video` or None if not found\n    \"\"\"\n    return self._camera_by_video.get(video, None)\n</code></pre>"},{"location":"reference/sleap_io/model/camera/#sleap_io.model.camera.RecordingSession.get_video","title":"<code>get_video(camera)</code>","text":"<p>Get <code>Video</code> associated with <code>camera</code>.</p> <p>Parameters:</p> Name Type Description Default <code>camera</code> <code>Camera</code> <p><code>Camera</code> to get <code>Video</code></p> required <p>Returns:</p> Type Description <code>Video | None</code> <p><code>Video</code> associated with <code>camera</code> or None if not found</p> Source code in <code>sleap_io/model/camera.py</code> <pre><code>def get_video(self, camera: Camera) -&gt; Video | None:\n    \"\"\"Get `Video` associated with `camera`.\n\n    Args:\n        camera: `Camera` to get `Video`\n\n    Returns:\n        `Video` associated with `camera` or None if not found\n    \"\"\"\n    return self._video_by_camera.get(camera, None)\n</code></pre>"},{"location":"reference/sleap_io/model/camera/#sleap_io.model.camera.RecordingSession.remove_video","title":"<code>remove_video(video)</code>","text":"<p>Remove <code>video</code> from <code>RecordingSession</code> and mapping to <code>Camera</code>.</p> <p>Parameters:</p> Name Type Description Default <code>video</code> <code>Video</code> <p><code>Video</code> object to remove from <code>RecordingSession</code>.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If <code>video</code> is not in associated <code>RecordingSession</code>.</p> Source code in <code>sleap_io/model/camera.py</code> <pre><code>def remove_video(self, video: Video):\n    \"\"\"Remove `video` from `RecordingSession` and mapping to `Camera`.\n\n    Args:\n        video: `Video` object to remove from `RecordingSession`.\n\n    Raises:\n        ValueError: If `video` is not in associated `RecordingSession`.\n    \"\"\"\n    # Remove video from camera mapping\n    camera = self._camera_by_video.pop(video)\n\n    # Remove camera from video mapping\n    self._video_by_camera.pop(camera)\n</code></pre>"},{"location":"reference/sleap_io/model/camera/#sleap_io.model.camera.rodrigues_transformation","title":"<code>rodrigues_transformation(input_matrix)</code>","text":"<p>Convert between rotation vector and rotation matrix using Rodrigues' formula.</p> <p>This function implements the Rodrigues' rotation formula to convert between: 1. A 3D rotation vector (axis-angle representation) to a 3x3 rotation matrix 2. A 3x3 rotation matrix to a 3D rotation vector</p> <p>Parameters:</p> Name Type Description Default <code>input_matrix</code> <code>ndarray</code> <p>A 3x3 rotation matrix or a 3x1 rotation vector.</p> required <p>Returns:</p> Type Description <code>tuple[ndarray, ndarray]</code> <p>A tuple containing the converted matrix/vector and the Jacobian (None for now).</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the input is not a valid rotation matrix or vector.</p> Source code in <code>sleap_io/model/camera.py</code> <pre><code>def rodrigues_transformation(input_matrix: np.ndarray) -&gt; tuple[np.ndarray, np.ndarray]:\n    \"\"\"Convert between rotation vector and rotation matrix using Rodrigues' formula.\n\n    This function implements the Rodrigues' rotation formula to convert between:\n    1. A 3D rotation vector (axis-angle representation) to a 3x3 rotation matrix\n    2. A 3x3 rotation matrix to a 3D rotation vector\n\n    Args:\n        input_matrix: A 3x3 rotation matrix or a 3x1 rotation vector.\n\n    Returns:\n        A tuple containing the converted matrix/vector and the Jacobian (None for now).\n\n    Raises:\n        ValueError: If the input is not a valid rotation matrix or vector.\n    \"\"\"\n    # Matrix to vector conversion\n    if input_matrix.shape == (3, 3):\n        # Get the rotation angle (trace(R) = 1 + 2*cos(theta))\n        cos_theta = (np.trace(input_matrix) - 1) / 2.0\n        cos_theta = np.clip(cos_theta, -1.0, 1.0)  # Ensure numerical stability\n        theta = np.arccos(cos_theta)\n\n        # Handle small angles or identity rotation\n        if np.isclose(theta, 0.0, atol=1e-8):\n            # For small angles or identity, return zero vector\n            return np.zeros(3), None\n\n        # Compute the rotation axis\n        sin_theta = np.sin(theta)\n        if np.isclose(sin_theta, 0.0, atol=1e-8):\n            # Handle 180-degree rotation (sin_theta = 0)\n            # Find the largest diagonal element\n            diag = np.diag(input_matrix)\n            k = np.argmax(diag)\n            axis = np.zeros(3)\n            if diag[k] &gt; -1.0:\n                # Extract the column with largest diagonal\n                axis[k] = 1.0\n                v = input_matrix[:, k] + axis\n                axis = v / np.linalg.norm(v)\n            rvec = theta * axis\n        else:\n            # Normal case: extract the skew-symmetric part\n            axis = np.array(\n                [\n                    input_matrix[2, 1] - input_matrix[1, 2],\n                    input_matrix[0, 2] - input_matrix[2, 0],\n                    input_matrix[1, 0] - input_matrix[0, 1],\n                ]\n            ) / (2.0 * sin_theta)\n\n            # Ensure the axis is a unit vector\n            axis_norm = np.linalg.norm(axis)\n            if axis_norm &gt; 0:\n                axis = axis / axis_norm\n\n            rvec = theta * axis\n\n        return rvec, None\n\n    # Vector to matrix conversion\n    elif input_matrix.shape == (3,) or input_matrix.shape == (3, 1):\n        # Handle both flat and column vectors\n        rvec = input_matrix.ravel()\n        theta = np.linalg.norm(rvec)\n\n        # Handle small angles\n        if np.isclose(theta, 0.0, atol=1e-8):\n            return np.eye(3), None\n\n        # Normalize the rotation axis\n        axis = rvec / theta\n\n        # Create the cross-product matrix\n        K = np.array(\n            [[0, -axis[2], axis[1]], [axis[2], 0, -axis[0]], [-axis[1], axis[0], 0]]\n        )\n\n        # Rodrigues' formula: R = I + sin(\u03b8)K + (1-cos(\u03b8))K\u00b2\n        sin_theta = np.sin(theta)\n        cos_theta = np.cos(theta)\n        K_squared = np.dot(K, K)\n\n        rotation_matrix = np.eye(3) + sin_theta * K + (1.0 - cos_theta) * K_squared\n\n        return rotation_matrix, None\n\n    else:\n        raise ValueError(\n            f\"Input must be a 3x3 matrix or a 3-element vector, got shape \"\n            f\"{input_matrix.shape}\"\n        )\n</code></pre>"},{"location":"reference/sleap_io/model/instance/","title":"instance","text":""},{"location":"reference/sleap_io/model/instance/#sleap_io.model.instance","title":"<code>sleap_io.model.instance</code>","text":"<p>Data structures for data associated with a single instance such as an animal.</p> <p>The <code>Instance</code> class is a SLEAP data structure that contains a collection of points that correspond to landmarks within a <code>Skeleton</code>.</p> <p><code>PredictedInstance</code> additionally contains metadata associated with how the instance was estimated, such as confidence scores.</p> <p>Classes:</p> Name Description <code>Instance</code> <p>This class represents a ground truth instance such as an animal.</p> <code>PointsArray</code> <p>A specialized array for storing instance points data.</p> <code>PredictedInstance</code> <p>A <code>PredictedInstance</code> is an <code>Instance</code> that was predicted using a model.</p> <code>PredictedPointsArray</code> <p>A specialized array for storing predicted instance points data with scores.</p> <code>Track</code> <p>An object that represents the same animal/object across multiple detections.</p>"},{"location":"reference/sleap_io/model/instance/#sleap_io.model.instance.Instance","title":"<code>Instance</code>","text":"<p>This class represents a ground truth instance such as an animal.</p> <p>An <code>Instance</code> has a set of landmarks (points) that correspond to a <code>Skeleton</code>. Each point is associated with a <code>Node</code> in the skeleton. The points are stored in a structured numpy array with columns for x, y, visible, complete and name.</p> <p>The <code>Instance</code> may also be associated with a <code>Track</code> which links multiple instances together across frames or videos.</p> <p>Attributes:</p> Name Type Description <code>points</code> <code>PointsArray</code> <p>A numpy structured array with columns for xy, visible and complete. The array should have shape <code>(n_nodes,)</code>. This representation is useful for performance efficiency when working with large datasets.</p> <code>skeleton</code> <code>Skeleton</code> <p>The <code>Skeleton</code> that describes the <code>Node</code>s and <code>Edge</code>s associated with this instance.</p> <code>track</code> <code>Optional[Track]</code> <p>An optional <code>Track</code> associated with a unique animal/object across frames or videos.</p> <code>tracking_score</code> <code>Optional[float]</code> <p>The score associated with the <code>Track</code> assignment. This is typically the value from the score matrix used in an identity assignment. This is <code>None</code> if the instance is not associated with a track or if the track was assigned manually.</p> <code>from_predicted</code> <code>Optional[PredictedInstance]</code> <p>The <code>PredictedInstance</code> (if any) that this instance was initialized from. This is used with human-in-the-loop workflows.</p> <p>Methods:</p> Name Description <code>__attrs_post_init__</code> <p>Convert the points array after initialization.</p> <code>__getitem__</code> <p>Return the point associated with a node.</p> <code>__len__</code> <p>Return the number of points in the instance.</p> <code>__repr__</code> <p>Return a readable representation of the instance.</p> <code>__setitem__</code> <p>Set the point associated with a node.</p> <code>bounding_box</code> <p>Get the bounding box of visible points.</p> <code>empty</code> <p>Create an empty instance with no points.</p> <code>from_numpy</code> <p>Create an instance object from a numpy array.</p> <code>numpy</code> <p>Return the instance points as a <code>(n_nodes, 2)</code> numpy array.</p> <code>overlaps_with</code> <p>Check if this instance overlaps with another based on bounding box IoU.</p> <code>replace_skeleton</code> <p>Replace the skeleton associated with the instance.</p> <code>same_identity_as</code> <p>Check if this instance has the same identity (track) as another instance.</p> <code>same_pose_as</code> <p>Check if this instance has the same pose as another instance.</p> <code>update_skeleton</code> <p>Update or replace the skeleton associated with the instance.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>@attrs.define(auto_attribs=True, slots=True, eq=False)\nclass Instance:\n    \"\"\"This class represents a ground truth instance such as an animal.\n\n    An `Instance` has a set of landmarks (points) that correspond to a `Skeleton`. Each\n    point is associated with a `Node` in the skeleton. The points are stored in a\n    structured numpy array with columns for x, y, visible, complete and name.\n\n    The `Instance` may also be associated with a `Track` which links multiple instances\n    together across frames or videos.\n\n    Attributes:\n        points: A numpy structured array with columns for xy, visible and complete. The\n            array should have shape `(n_nodes,)`. This representation is useful for\n            performance efficiency when working with large datasets.\n        skeleton: The `Skeleton` that describes the `Node`s and `Edge`s associated with\n            this instance.\n        track: An optional `Track` associated with a unique animal/object across frames\n            or videos.\n        tracking_score: The score associated with the `Track` assignment. This is\n            typically the value from the score matrix used in an identity assignment.\n            This is `None` if the instance is not associated with a track or if the\n            track was assigned manually.\n        from_predicted: The `PredictedInstance` (if any) that this instance was\n            initialized from. This is used with human-in-the-loop workflows.\n    \"\"\"\n\n    points: PointsArray = attrs.field(eq=attrs.cmp_using(eq=np.array_equal))\n    skeleton: Skeleton\n    track: Optional[Track] = None\n    tracking_score: Optional[float] = None\n    from_predicted: Optional[PredictedInstance] = None\n\n    @classmethod\n    def empty(\n        cls,\n        skeleton: Skeleton,\n        track: Optional[Track] = None,\n        tracking_score: Optional[float] = None,\n        from_predicted: Optional[PredictedInstance] = None,\n    ) -&gt; \"Instance\":\n        \"\"\"Create an empty instance with no points.\n\n        Args:\n            skeleton: The `Skeleton` that this `Instance` is associated with.\n            track: An optional `Track` associated with a unique animal/object across\n                frames or videos.\n            tracking_score: The score associated with the `Track` assignment. This is\n                typically the value from the score matrix used in an identity\n                assignment. This is `None` if the instance is not associated with a\n                track or if the track was assigned manually.\n            from_predicted: The `PredictedInstance` (if any) that this instance was\n                initialized from. This is used with human-in-the-loop workflows.\n\n        Returns:\n            An `Instance` with an empty numpy array of shape `(n_nodes,)`.\n        \"\"\"\n        points = PointsArray.empty(len(skeleton))\n        points[\"name\"] = skeleton.node_names\n\n        return cls(\n            points=points,\n            skeleton=skeleton,\n            track=track,\n            tracking_score=tracking_score,\n            from_predicted=from_predicted,\n        )\n\n    @classmethod\n    def _convert_points(\n        cls, points_data: np.ndarray | dict | list, skeleton: Skeleton\n    ) -&gt; PointsArray:\n        \"\"\"Convert points to a structured numpy array if needed.\"\"\"\n        if isinstance(points_data, dict):\n            return PointsArray.from_dict(points_data, skeleton)\n        elif isinstance(points_data, (list, np.ndarray)):\n            if isinstance(points_data, list):\n                points_data = np.array(points_data)\n\n            points = PointsArray.from_array(points_data)\n            points[\"name\"] = skeleton.node_names\n            return points\n        else:\n            raise ValueError(\"points must be a numpy array or dictionary.\")\n\n    @classmethod\n    def from_numpy(\n        cls,\n        points_data: np.ndarray,\n        skeleton: Skeleton,\n        track: Optional[Track] = None,\n        tracking_score: Optional[float] = None,\n        from_predicted: Optional[PredictedInstance] = None,\n    ) -&gt; \"Instance\":\n        \"\"\"Create an instance object from a numpy array.\n\n        Args:\n            points_data: A numpy array of shape `(n_nodes, D)` corresponding to the\n                points of the skeleton. Values of `np.nan` indicate \"missing\" nodes and\n                will be reflected in the \"visible\" field.\n\n                If `D == 2`, the array should have columns for x and y.\n                If `D == 3`, the array should have columns for x, y and visible.\n                If `D == 4`, the array should have columns for x, y, visible and\n                complete.\n\n                If this is provided as a structured array, it will be used without copy\n                if it has the correct dtype. Otherwise, a new structured array will be\n                created reusing the provided data.\n            skeleton: The `Skeleton` that this `Instance` is associated with. It should\n                have `n_nodes` nodes.\n            track: An optional `Track` associated with a unique animal/object across\n                frames or videos.\n            tracking_score: The score associated with the `Track` assignment. This is\n                typically the value from the score matrix used in an identity\n                assignment. This is `None` if the instance is not associated with a\n                track or if the track was assigned manually.\n            from_predicted: The `PredictedInstance` (if any) that this instance was\n                initialized from. This is used with human-in-the-loop workflows.\n\n        Returns:\n            An `Instance` object with the specified points.\n        \"\"\"\n        return cls(\n            points=points_data,\n            skeleton=skeleton,\n            track=track,\n            tracking_score=tracking_score,\n            from_predicted=from_predicted,\n        )\n\n    def __attrs_post_init__(self):\n        \"\"\"Convert the points array after initialization.\"\"\"\n        if not isinstance(self.points, PointsArray):\n            self.points = self._convert_points(self.points, self.skeleton)\n\n        # Ensure points have node names\n        if \"name\" in self.points.dtype.names and not all(self.points[\"name\"]):\n            self.points[\"name\"] = self.skeleton.node_names\n\n    def numpy(\n        self,\n        invisible_as_nan: bool = True,\n    ) -&gt; np.ndarray:\n        \"\"\"Return the instance points as a `(n_nodes, 2)` numpy array.\n\n        Args:\n            invisible_as_nan: If `True` (the default), points that are not visible will\n                be set to `np.nan`. If `False`, they will be whatever the stored value\n                of `Instance.points[\"xy\"]` is.\n\n        Returns:\n            A numpy array of shape `(n_nodes, 2)` corresponding to the points of the\n            skeleton. Values of `np.nan` indicate \"missing\" nodes.\n\n        Notes:\n            This will always return a copy of the array.\n\n            If you need to avoid making a copy, just access the `Instance.points[\"xy\"]`\n            attribute directly. This will not replace invisible points with `np.nan`.\n        \"\"\"\n        if invisible_as_nan:\n            return np.where(\n                self.points[\"visible\"].reshape(-1, 1), self.points[\"xy\"], np.nan\n            )\n        else:\n            return self.points[\"xy\"].copy()\n\n    def __getitem__(self, node: Union[int, str, Node]) -&gt; np.ndarray:\n        \"\"\"Return the point associated with a node.\"\"\"\n        if type(node) is not int:\n            node = self.skeleton.index(node)\n\n        return self.points[node]\n\n    def __setitem__(self, node: Union[int, str, Node], value):\n        \"\"\"Set the point associated with a node.\n\n        Args:\n            node: The node to set the point for. Can be an integer index, string name,\n                or Node object.\n            value: A tuple or array-like of length 2 containing (x, y) coordinates.\n\n        Notes:\n            This sets the point coordinates and marks the point as visible.\n        \"\"\"\n        if type(node) is not int:\n            node = self.skeleton.index(node)\n\n        if len(value) &lt; 2:\n            raise ValueError(\"Value must have at least 2 elements (x, y)\")\n\n        self.points[node][\"xy\"] = value[:2]\n        self.points[node][\"visible\"] = True\n\n    def __len__(self) -&gt; int:\n        \"\"\"Return the number of points in the instance.\"\"\"\n        return len(self.points)\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return a readable representation of the instance.\"\"\"\n        pts = self.numpy().tolist()\n        track = f'\"{self.track.name}\"' if self.track is not None else self.track\n\n        return f\"Instance(points={pts}, track={track})\"\n\n    @property\n    def n_visible(self) -&gt; int:\n        \"\"\"Return the number of visible points in the instance.\"\"\"\n        return sum(self.points[\"visible\"])\n\n    @property\n    def is_empty(self) -&gt; bool:\n        \"\"\"Return `True` if no points are visible on the instance.\"\"\"\n        return ~(self.points[\"visible\"].any())\n\n    def update_skeleton(self, names_only: bool = False):\n        \"\"\"Update or replace the skeleton associated with the instance.\n\n        Args:\n            names_only: If `True`, only update the node names in the points array. If\n                `False`, the points array will be updated to match the new skeleton.\n        \"\"\"\n        if names_only:\n            # Update the node names.\n            self.points[\"name\"] = self.skeleton.node_names\n            return\n\n        # Find correspondences.\n        new_node_inds, old_node_inds = self.skeleton.match_nodes(self.points[\"name\"])\n\n        # Update the points.\n        new_points = PointsArray.empty(len(self.skeleton))\n        new_points[new_node_inds] = self.points[old_node_inds]\n        new_points[\"name\"] = self.skeleton.node_names\n        self.points = new_points\n\n    def replace_skeleton(\n        self,\n        new_skeleton: Skeleton,\n        node_names_map: dict[str, str] | None = None,\n    ):\n        \"\"\"Replace the skeleton associated with the instance.\n\n        Args:\n            new_skeleton: The new `Skeleton` to associate with the instance.\n            node_names_map: Dictionary mapping nodes in the old skeleton to nodes in the\n                new skeleton. Keys and values should be specified as lists of strings.\n                If not provided, only nodes with identical names will be mapped. Points\n                associated with unmapped nodes will be removed.\n\n        Notes:\n            This method will update the `Instance.skeleton` attribute and the\n            `Instance.points` attribute in place (a copy is made of the points array).\n\n            It is recommended to use `Labels.replace_skeleton` instead of this method if\n            more flexible node mapping is required.\n        \"\"\"\n        # Update skeleton object.\n        # old_skeleton = self.skeleton\n        self.skeleton = new_skeleton\n\n        # Get node names with replacements from node map if possible.\n        # old_node_names = old_skeleton.node_names\n        old_node_names = self.points[\"name\"].tolist()\n        if node_names_map is not None:\n            old_node_names = [node_names_map.get(node, node) for node in old_node_names]\n\n        # Find correspondences.\n        new_node_inds, old_node_inds = self.skeleton.match_nodes(old_node_names)\n        # old_node_inds = np.array(old_node_inds).reshape(-1, 1)\n        # new_node_inds = np.array(new_node_inds).reshape(-1, 1)\n\n        # Update the points.\n        new_points = PointsArray.empty(len(self.skeleton))\n        new_points[new_node_inds] = self.points[old_node_inds]\n        self.points = new_points\n        self.points[\"name\"] = self.skeleton.node_names\n\n    def same_pose_as(self, other: \"Instance\", tolerance: float = 5.0) -&gt; bool:\n        \"\"\"Check if this instance has the same pose as another instance.\n\n        Args:\n            other: Another instance to compare with.\n            tolerance: Maximum distance (in pixels) between corresponding points\n                for them to be considered the same.\n\n        Returns:\n            True if the instances have the same pose within tolerance, False otherwise.\n\n        Notes:\n            Two instances are considered to have the same pose if:\n            - They have the same skeleton structure\n            - All visible points are within the tolerance distance\n            - They have the same visibility pattern\n        \"\"\"\n        # Check skeleton compatibility\n        if not self.skeleton.matches(other.skeleton):\n            return False\n\n        # Get visible points for both instances\n        self_visible = self.points[\"visible\"]\n        other_visible = other.points[\"visible\"]\n\n        # Check if visibility patterns match\n        if not np.array_equal(self_visible, other_visible):\n            return False\n\n        # Compare visible points\n        if not self_visible.any():\n            # Both instances have no visible points\n            return True\n\n        # Calculate distances between corresponding visible points\n        self_pts = self.points[\"xy\"][self_visible]\n        other_pts = other.points[\"xy\"][other_visible]\n\n        distances = np.linalg.norm(self_pts - other_pts, axis=1)\n\n        return np.all(distances &lt;= tolerance)\n\n    def same_identity_as(self, other: \"Instance\") -&gt; bool:\n        \"\"\"Check if this instance has the same identity (track) as another instance.\n\n        Args:\n            other: Another instance to compare with.\n\n        Returns:\n            True if both instances have the same track identity, False otherwise.\n\n        Notes:\n            Instances have the same identity if they share the same Track object\n            (by identity, not just by name).\n        \"\"\"\n        if self.track is None or other.track is None:\n            return False\n        return self.track is other.track\n\n    def overlaps_with(self, other: \"Instance\", iou_threshold: float = 0.5) -&gt; bool:\n        \"\"\"Check if this instance overlaps with another based on bounding box IoU.\n\n        Args:\n            other: Another instance to compare with.\n            iou_threshold: Minimum IoU (Intersection over Union) value to consider\n                the instances as overlapping.\n\n        Returns:\n            True if the instances overlap above the threshold, False otherwise.\n\n        Notes:\n            Overlap is computed using the bounding boxes of visible points.\n            If either instance has no visible points, they don't overlap.\n        \"\"\"\n        # Get visible points for both instances\n        self_visible = self.points[\"visible\"]\n        other_visible = other.points[\"visible\"]\n\n        if not self_visible.any() or not other_visible.any():\n            return False\n\n        # Calculate bounding boxes\n        self_pts = self.points[\"xy\"][self_visible]\n        other_pts = other.points[\"xy\"][other_visible]\n\n        self_bbox = np.array(\n            [\n                [np.min(self_pts[:, 0]), np.min(self_pts[:, 1])],  # min x, y\n                [np.max(self_pts[:, 0]), np.max(self_pts[:, 1])],  # max x, y\n            ]\n        )\n\n        other_bbox = np.array(\n            [\n                [np.min(other_pts[:, 0]), np.min(other_pts[:, 1])],\n                [np.max(other_pts[:, 0]), np.max(other_pts[:, 1])],\n            ]\n        )\n\n        # Calculate intersection\n        intersection_min = np.maximum(self_bbox[0], other_bbox[0])\n        intersection_max = np.minimum(self_bbox[1], other_bbox[1])\n\n        if np.any(intersection_min &gt;= intersection_max):\n            # No intersection\n            return False\n\n        intersection_area = np.prod(intersection_max - intersection_min)\n\n        # Calculate union\n        self_area = np.prod(self_bbox[1] - self_bbox[0])\n        other_area = np.prod(other_bbox[1] - other_bbox[0])\n        union_area = self_area + other_area - intersection_area\n\n        # Calculate IoU\n        iou = intersection_area / union_area if union_area &gt; 0 else 0\n\n        return iou &gt;= iou_threshold\n\n    def bounding_box(self) -&gt; Optional[np.ndarray]:\n        \"\"\"Get the bounding box of visible points.\n\n        Returns:\n            A numpy array of shape (2, 2) with [[min_x, min_y], [max_x, max_y]],\n            or None if there are no visible points.\n        \"\"\"\n        visible = self.points[\"visible\"]\n        if not visible.any():\n            return None\n\n        pts = self.points[\"xy\"][visible]\n        return np.array(\n            [\n                [np.min(pts[:, 0]), np.min(pts[:, 1])],\n                [np.max(pts[:, 0]), np.max(pts[:, 1])],\n            ]\n        )\n</code></pre>"},{"location":"reference/sleap_io/model/instance/#sleap_io.model.instance.Instance.is_empty","title":"<code>is_empty</code>  <code>property</code>","text":"<p>Return <code>True</code> if no points are visible on the instance.</p>"},{"location":"reference/sleap_io/model/instance/#sleap_io.model.instance.Instance.n_visible","title":"<code>n_visible</code>  <code>property</code>","text":"<p>Return the number of visible points in the instance.</p>"},{"location":"reference/sleap_io/model/instance/#sleap_io.model.instance.Instance.__attrs_post_init__","title":"<code>__attrs_post_init__()</code>","text":"<p>Convert the points array after initialization.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>def __attrs_post_init__(self):\n    \"\"\"Convert the points array after initialization.\"\"\"\n    if not isinstance(self.points, PointsArray):\n        self.points = self._convert_points(self.points, self.skeleton)\n\n    # Ensure points have node names\n    if \"name\" in self.points.dtype.names and not all(self.points[\"name\"]):\n        self.points[\"name\"] = self.skeleton.node_names\n</code></pre>"},{"location":"reference/sleap_io/model/instance/#sleap_io.model.instance.Instance.__getitem__","title":"<code>__getitem__(node)</code>","text":"<p>Return the point associated with a node.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>def __getitem__(self, node: Union[int, str, Node]) -&gt; np.ndarray:\n    \"\"\"Return the point associated with a node.\"\"\"\n    if type(node) is not int:\n        node = self.skeleton.index(node)\n\n    return self.points[node]\n</code></pre>"},{"location":"reference/sleap_io/model/instance/#sleap_io.model.instance.Instance.__len__","title":"<code>__len__()</code>","text":"<p>Return the number of points in the instance.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"Return the number of points in the instance.\"\"\"\n    return len(self.points)\n</code></pre>"},{"location":"reference/sleap_io/model/instance/#sleap_io.model.instance.Instance.__repr__","title":"<code>__repr__()</code>","text":"<p>Return a readable representation of the instance.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return a readable representation of the instance.\"\"\"\n    pts = self.numpy().tolist()\n    track = f'\"{self.track.name}\"' if self.track is not None else self.track\n\n    return f\"Instance(points={pts}, track={track})\"\n</code></pre>"},{"location":"reference/sleap_io/model/instance/#sleap_io.model.instance.Instance.__setitem__","title":"<code>__setitem__(node, value)</code>","text":"<p>Set the point associated with a node.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>Union[int, str, Node]</code> <p>The node to set the point for. Can be an integer index, string name, or Node object.</p> required <code>value</code> <p>A tuple or array-like of length 2 containing (x, y) coordinates.</p> required Notes <p>This sets the point coordinates and marks the point as visible.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>def __setitem__(self, node: Union[int, str, Node], value):\n    \"\"\"Set the point associated with a node.\n\n    Args:\n        node: The node to set the point for. Can be an integer index, string name,\n            or Node object.\n        value: A tuple or array-like of length 2 containing (x, y) coordinates.\n\n    Notes:\n        This sets the point coordinates and marks the point as visible.\n    \"\"\"\n    if type(node) is not int:\n        node = self.skeleton.index(node)\n\n    if len(value) &lt; 2:\n        raise ValueError(\"Value must have at least 2 elements (x, y)\")\n\n    self.points[node][\"xy\"] = value[:2]\n    self.points[node][\"visible\"] = True\n</code></pre>"},{"location":"reference/sleap_io/model/instance/#sleap_io.model.instance.Instance.bounding_box","title":"<code>bounding_box()</code>","text":"<p>Get the bounding box of visible points.</p> <p>Returns:</p> Type Description <code>Optional[ndarray]</code> <p>A numpy array of shape (2, 2) with [[min_x, min_y], [max_x, max_y]], or None if there are no visible points.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>def bounding_box(self) -&gt; Optional[np.ndarray]:\n    \"\"\"Get the bounding box of visible points.\n\n    Returns:\n        A numpy array of shape (2, 2) with [[min_x, min_y], [max_x, max_y]],\n        or None if there are no visible points.\n    \"\"\"\n    visible = self.points[\"visible\"]\n    if not visible.any():\n        return None\n\n    pts = self.points[\"xy\"][visible]\n    return np.array(\n        [\n            [np.min(pts[:, 0]), np.min(pts[:, 1])],\n            [np.max(pts[:, 0]), np.max(pts[:, 1])],\n        ]\n    )\n</code></pre>"},{"location":"reference/sleap_io/model/instance/#sleap_io.model.instance.Instance.empty","title":"<code>empty(skeleton, track=None, tracking_score=None, from_predicted=None)</code>  <code>classmethod</code>","text":"<p>Create an empty instance with no points.</p> <p>Parameters:</p> Name Type Description Default <code>skeleton</code> <code>Skeleton</code> <p>The <code>Skeleton</code> that this <code>Instance</code> is associated with.</p> required <code>track</code> <code>Optional[Track]</code> <p>An optional <code>Track</code> associated with a unique animal/object across frames or videos.</p> <code>None</code> <code>tracking_score</code> <code>Optional[float]</code> <p>The score associated with the <code>Track</code> assignment. This is typically the value from the score matrix used in an identity assignment. This is <code>None</code> if the instance is not associated with a track or if the track was assigned manually.</p> <code>None</code> <code>from_predicted</code> <code>Optional[PredictedInstance]</code> <p>The <code>PredictedInstance</code> (if any) that this instance was initialized from. This is used with human-in-the-loop workflows.</p> <code>None</code> <p>Returns:</p> Type Description <code>'Instance'</code> <p>An <code>Instance</code> with an empty numpy array of shape <code>(n_nodes,)</code>.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>@classmethod\ndef empty(\n    cls,\n    skeleton: Skeleton,\n    track: Optional[Track] = None,\n    tracking_score: Optional[float] = None,\n    from_predicted: Optional[PredictedInstance] = None,\n) -&gt; \"Instance\":\n    \"\"\"Create an empty instance with no points.\n\n    Args:\n        skeleton: The `Skeleton` that this `Instance` is associated with.\n        track: An optional `Track` associated with a unique animal/object across\n            frames or videos.\n        tracking_score: The score associated with the `Track` assignment. This is\n            typically the value from the score matrix used in an identity\n            assignment. This is `None` if the instance is not associated with a\n            track or if the track was assigned manually.\n        from_predicted: The `PredictedInstance` (if any) that this instance was\n            initialized from. This is used with human-in-the-loop workflows.\n\n    Returns:\n        An `Instance` with an empty numpy array of shape `(n_nodes,)`.\n    \"\"\"\n    points = PointsArray.empty(len(skeleton))\n    points[\"name\"] = skeleton.node_names\n\n    return cls(\n        points=points,\n        skeleton=skeleton,\n        track=track,\n        tracking_score=tracking_score,\n        from_predicted=from_predicted,\n    )\n</code></pre>"},{"location":"reference/sleap_io/model/instance/#sleap_io.model.instance.Instance.from_numpy","title":"<code>from_numpy(points_data, skeleton, track=None, tracking_score=None, from_predicted=None)</code>  <code>classmethod</code>","text":"<p>Create an instance object from a numpy array.</p> <p>Parameters:</p> Name Type Description Default <code>points_data</code> <code>ndarray</code> <p>A numpy array of shape <code>(n_nodes, D)</code> corresponding to the points of the skeleton. Values of <code>np.nan</code> indicate \"missing\" nodes and will be reflected in the \"visible\" field.</p> <p>If <code>D == 2</code>, the array should have columns for x and y. If <code>D == 3</code>, the array should have columns for x, y and visible. If <code>D == 4</code>, the array should have columns for x, y, visible and complete.</p> <p>If this is provided as a structured array, it will be used without copy if it has the correct dtype. Otherwise, a new structured array will be created reusing the provided data.</p> required <code>skeleton</code> <code>Skeleton</code> <p>The <code>Skeleton</code> that this <code>Instance</code> is associated with. It should have <code>n_nodes</code> nodes.</p> required <code>track</code> <code>Optional[Track]</code> <p>An optional <code>Track</code> associated with a unique animal/object across frames or videos.</p> <code>None</code> <code>tracking_score</code> <code>Optional[float]</code> <p>The score associated with the <code>Track</code> assignment. This is typically the value from the score matrix used in an identity assignment. This is <code>None</code> if the instance is not associated with a track or if the track was assigned manually.</p> <code>None</code> <code>from_predicted</code> <code>Optional[PredictedInstance]</code> <p>The <code>PredictedInstance</code> (if any) that this instance was initialized from. This is used with human-in-the-loop workflows.</p> <code>None</code> <p>Returns:</p> Type Description <code>'Instance'</code> <p>An <code>Instance</code> object with the specified points.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>@classmethod\ndef from_numpy(\n    cls,\n    points_data: np.ndarray,\n    skeleton: Skeleton,\n    track: Optional[Track] = None,\n    tracking_score: Optional[float] = None,\n    from_predicted: Optional[PredictedInstance] = None,\n) -&gt; \"Instance\":\n    \"\"\"Create an instance object from a numpy array.\n\n    Args:\n        points_data: A numpy array of shape `(n_nodes, D)` corresponding to the\n            points of the skeleton. Values of `np.nan` indicate \"missing\" nodes and\n            will be reflected in the \"visible\" field.\n\n            If `D == 2`, the array should have columns for x and y.\n            If `D == 3`, the array should have columns for x, y and visible.\n            If `D == 4`, the array should have columns for x, y, visible and\n            complete.\n\n            If this is provided as a structured array, it will be used without copy\n            if it has the correct dtype. Otherwise, a new structured array will be\n            created reusing the provided data.\n        skeleton: The `Skeleton` that this `Instance` is associated with. It should\n            have `n_nodes` nodes.\n        track: An optional `Track` associated with a unique animal/object across\n            frames or videos.\n        tracking_score: The score associated with the `Track` assignment. This is\n            typically the value from the score matrix used in an identity\n            assignment. This is `None` if the instance is not associated with a\n            track or if the track was assigned manually.\n        from_predicted: The `PredictedInstance` (if any) that this instance was\n            initialized from. This is used with human-in-the-loop workflows.\n\n    Returns:\n        An `Instance` object with the specified points.\n    \"\"\"\n    return cls(\n        points=points_data,\n        skeleton=skeleton,\n        track=track,\n        tracking_score=tracking_score,\n        from_predicted=from_predicted,\n    )\n</code></pre>"},{"location":"reference/sleap_io/model/instance/#sleap_io.model.instance.Instance.numpy","title":"<code>numpy(invisible_as_nan=True)</code>","text":"<p>Return the instance points as a <code>(n_nodes, 2)</code> numpy array.</p> <p>Parameters:</p> Name Type Description Default <code>invisible_as_nan</code> <code>bool</code> <p>If <code>True</code> (the default), points that are not visible will be set to <code>np.nan</code>. If <code>False</code>, they will be whatever the stored value of <code>Instance.points[\"xy\"]</code> is.</p> <code>True</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>A numpy array of shape <code>(n_nodes, 2)</code> corresponding to the points of the skeleton. Values of <code>np.nan</code> indicate \"missing\" nodes.</p> Notes <p>This will always return a copy of the array.</p> <p>If you need to avoid making a copy, just access the <code>Instance.points[\"xy\"]</code> attribute directly. This will not replace invisible points with <code>np.nan</code>.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>def numpy(\n    self,\n    invisible_as_nan: bool = True,\n) -&gt; np.ndarray:\n    \"\"\"Return the instance points as a `(n_nodes, 2)` numpy array.\n\n    Args:\n        invisible_as_nan: If `True` (the default), points that are not visible will\n            be set to `np.nan`. If `False`, they will be whatever the stored value\n            of `Instance.points[\"xy\"]` is.\n\n    Returns:\n        A numpy array of shape `(n_nodes, 2)` corresponding to the points of the\n        skeleton. Values of `np.nan` indicate \"missing\" nodes.\n\n    Notes:\n        This will always return a copy of the array.\n\n        If you need to avoid making a copy, just access the `Instance.points[\"xy\"]`\n        attribute directly. This will not replace invisible points with `np.nan`.\n    \"\"\"\n    if invisible_as_nan:\n        return np.where(\n            self.points[\"visible\"].reshape(-1, 1), self.points[\"xy\"], np.nan\n        )\n    else:\n        return self.points[\"xy\"].copy()\n</code></pre>"},{"location":"reference/sleap_io/model/instance/#sleap_io.model.instance.Instance.overlaps_with","title":"<code>overlaps_with(other, iou_threshold=0.5)</code>","text":"<p>Check if this instance overlaps with another based on bounding box IoU.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>'Instance'</code> <p>Another instance to compare with.</p> required <code>iou_threshold</code> <code>float</code> <p>Minimum IoU (Intersection over Union) value to consider the instances as overlapping.</p> <code>0.5</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if the instances overlap above the threshold, False otherwise.</p> Notes <p>Overlap is computed using the bounding boxes of visible points. If either instance has no visible points, they don't overlap.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>def overlaps_with(self, other: \"Instance\", iou_threshold: float = 0.5) -&gt; bool:\n    \"\"\"Check if this instance overlaps with another based on bounding box IoU.\n\n    Args:\n        other: Another instance to compare with.\n        iou_threshold: Minimum IoU (Intersection over Union) value to consider\n            the instances as overlapping.\n\n    Returns:\n        True if the instances overlap above the threshold, False otherwise.\n\n    Notes:\n        Overlap is computed using the bounding boxes of visible points.\n        If either instance has no visible points, they don't overlap.\n    \"\"\"\n    # Get visible points for both instances\n    self_visible = self.points[\"visible\"]\n    other_visible = other.points[\"visible\"]\n\n    if not self_visible.any() or not other_visible.any():\n        return False\n\n    # Calculate bounding boxes\n    self_pts = self.points[\"xy\"][self_visible]\n    other_pts = other.points[\"xy\"][other_visible]\n\n    self_bbox = np.array(\n        [\n            [np.min(self_pts[:, 0]), np.min(self_pts[:, 1])],  # min x, y\n            [np.max(self_pts[:, 0]), np.max(self_pts[:, 1])],  # max x, y\n        ]\n    )\n\n    other_bbox = np.array(\n        [\n            [np.min(other_pts[:, 0]), np.min(other_pts[:, 1])],\n            [np.max(other_pts[:, 0]), np.max(other_pts[:, 1])],\n        ]\n    )\n\n    # Calculate intersection\n    intersection_min = np.maximum(self_bbox[0], other_bbox[0])\n    intersection_max = np.minimum(self_bbox[1], other_bbox[1])\n\n    if np.any(intersection_min &gt;= intersection_max):\n        # No intersection\n        return False\n\n    intersection_area = np.prod(intersection_max - intersection_min)\n\n    # Calculate union\n    self_area = np.prod(self_bbox[1] - self_bbox[0])\n    other_area = np.prod(other_bbox[1] - other_bbox[0])\n    union_area = self_area + other_area - intersection_area\n\n    # Calculate IoU\n    iou = intersection_area / union_area if union_area &gt; 0 else 0\n\n    return iou &gt;= iou_threshold\n</code></pre>"},{"location":"reference/sleap_io/model/instance/#sleap_io.model.instance.Instance.replace_skeleton","title":"<code>replace_skeleton(new_skeleton, node_names_map=None)</code>","text":"<p>Replace the skeleton associated with the instance.</p> <p>Parameters:</p> Name Type Description Default <code>new_skeleton</code> <code>Skeleton</code> <p>The new <code>Skeleton</code> to associate with the instance.</p> required <code>node_names_map</code> <code>dict[str, str] | None</code> <p>Dictionary mapping nodes in the old skeleton to nodes in the new skeleton. Keys and values should be specified as lists of strings. If not provided, only nodes with identical names will be mapped. Points associated with unmapped nodes will be removed.</p> <code>None</code> Notes <p>This method will update the <code>Instance.skeleton</code> attribute and the <code>Instance.points</code> attribute in place (a copy is made of the points array).</p> <p>It is recommended to use <code>Labels.replace_skeleton</code> instead of this method if more flexible node mapping is required.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>def replace_skeleton(\n    self,\n    new_skeleton: Skeleton,\n    node_names_map: dict[str, str] | None = None,\n):\n    \"\"\"Replace the skeleton associated with the instance.\n\n    Args:\n        new_skeleton: The new `Skeleton` to associate with the instance.\n        node_names_map: Dictionary mapping nodes in the old skeleton to nodes in the\n            new skeleton. Keys and values should be specified as lists of strings.\n            If not provided, only nodes with identical names will be mapped. Points\n            associated with unmapped nodes will be removed.\n\n    Notes:\n        This method will update the `Instance.skeleton` attribute and the\n        `Instance.points` attribute in place (a copy is made of the points array).\n\n        It is recommended to use `Labels.replace_skeleton` instead of this method if\n        more flexible node mapping is required.\n    \"\"\"\n    # Update skeleton object.\n    # old_skeleton = self.skeleton\n    self.skeleton = new_skeleton\n\n    # Get node names with replacements from node map if possible.\n    # old_node_names = old_skeleton.node_names\n    old_node_names = self.points[\"name\"].tolist()\n    if node_names_map is not None:\n        old_node_names = [node_names_map.get(node, node) for node in old_node_names]\n\n    # Find correspondences.\n    new_node_inds, old_node_inds = self.skeleton.match_nodes(old_node_names)\n    # old_node_inds = np.array(old_node_inds).reshape(-1, 1)\n    # new_node_inds = np.array(new_node_inds).reshape(-1, 1)\n\n    # Update the points.\n    new_points = PointsArray.empty(len(self.skeleton))\n    new_points[new_node_inds] = self.points[old_node_inds]\n    self.points = new_points\n    self.points[\"name\"] = self.skeleton.node_names\n</code></pre>"},{"location":"reference/sleap_io/model/instance/#sleap_io.model.instance.Instance.same_identity_as","title":"<code>same_identity_as(other)</code>","text":"<p>Check if this instance has the same identity (track) as another instance.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>'Instance'</code> <p>Another instance to compare with.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if both instances have the same track identity, False otherwise.</p> Notes <p>Instances have the same identity if they share the same Track object (by identity, not just by name).</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>def same_identity_as(self, other: \"Instance\") -&gt; bool:\n    \"\"\"Check if this instance has the same identity (track) as another instance.\n\n    Args:\n        other: Another instance to compare with.\n\n    Returns:\n        True if both instances have the same track identity, False otherwise.\n\n    Notes:\n        Instances have the same identity if they share the same Track object\n        (by identity, not just by name).\n    \"\"\"\n    if self.track is None or other.track is None:\n        return False\n    return self.track is other.track\n</code></pre>"},{"location":"reference/sleap_io/model/instance/#sleap_io.model.instance.Instance.same_pose_as","title":"<code>same_pose_as(other, tolerance=5.0)</code>","text":"<p>Check if this instance has the same pose as another instance.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>'Instance'</code> <p>Another instance to compare with.</p> required <code>tolerance</code> <code>float</code> <p>Maximum distance (in pixels) between corresponding points for them to be considered the same.</p> <code>5.0</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if the instances have the same pose within tolerance, False otherwise.</p> Notes <p>Two instances are considered to have the same pose if: - They have the same skeleton structure - All visible points are within the tolerance distance - They have the same visibility pattern</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>def same_pose_as(self, other: \"Instance\", tolerance: float = 5.0) -&gt; bool:\n    \"\"\"Check if this instance has the same pose as another instance.\n\n    Args:\n        other: Another instance to compare with.\n        tolerance: Maximum distance (in pixels) between corresponding points\n            for them to be considered the same.\n\n    Returns:\n        True if the instances have the same pose within tolerance, False otherwise.\n\n    Notes:\n        Two instances are considered to have the same pose if:\n        - They have the same skeleton structure\n        - All visible points are within the tolerance distance\n        - They have the same visibility pattern\n    \"\"\"\n    # Check skeleton compatibility\n    if not self.skeleton.matches(other.skeleton):\n        return False\n\n    # Get visible points for both instances\n    self_visible = self.points[\"visible\"]\n    other_visible = other.points[\"visible\"]\n\n    # Check if visibility patterns match\n    if not np.array_equal(self_visible, other_visible):\n        return False\n\n    # Compare visible points\n    if not self_visible.any():\n        # Both instances have no visible points\n        return True\n\n    # Calculate distances between corresponding visible points\n    self_pts = self.points[\"xy\"][self_visible]\n    other_pts = other.points[\"xy\"][other_visible]\n\n    distances = np.linalg.norm(self_pts - other_pts, axis=1)\n\n    return np.all(distances &lt;= tolerance)\n</code></pre>"},{"location":"reference/sleap_io/model/instance/#sleap_io.model.instance.Instance.update_skeleton","title":"<code>update_skeleton(names_only=False)</code>","text":"<p>Update or replace the skeleton associated with the instance.</p> <p>Parameters:</p> Name Type Description Default <code>names_only</code> <code>bool</code> <p>If <code>True</code>, only update the node names in the points array. If <code>False</code>, the points array will be updated to match the new skeleton.</p> <code>False</code> Source code in <code>sleap_io/model/instance.py</code> <pre><code>def update_skeleton(self, names_only: bool = False):\n    \"\"\"Update or replace the skeleton associated with the instance.\n\n    Args:\n        names_only: If `True`, only update the node names in the points array. If\n            `False`, the points array will be updated to match the new skeleton.\n    \"\"\"\n    if names_only:\n        # Update the node names.\n        self.points[\"name\"] = self.skeleton.node_names\n        return\n\n    # Find correspondences.\n    new_node_inds, old_node_inds = self.skeleton.match_nodes(self.points[\"name\"])\n\n    # Update the points.\n    new_points = PointsArray.empty(len(self.skeleton))\n    new_points[new_node_inds] = self.points[old_node_inds]\n    new_points[\"name\"] = self.skeleton.node_names\n    self.points = new_points\n</code></pre>"},{"location":"reference/sleap_io/model/instance/#sleap_io.model.instance.PointsArray","title":"<code>PointsArray</code>","text":"<p>               Bases: <code>ndarray</code></p> <p>A specialized array for storing instance points data.</p> <p>This class ensures that the array always uses the correct dtype and provides convenience methods for working with point data.</p> The structured dtype includes the following fields <ul> <li>xy: A float64 array of shape (2,) containing the x, y coordinates</li> <li>visible: A boolean indicating if the point is visible</li> <li>complete: A boolean indicating if the point is complete</li> <li>name: An object dtype containing the name of the node</li> </ul> <p>Methods:</p> Name Description <code>empty</code> <p>Create an empty points array with the appropriate dtype.</p> <code>from_array</code> <p>Convert an existing array to a PointsArray with the appropriate dtype.</p> <code>from_dict</code> <p>Create a PointsArray from a dictionary of node points.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>class PointsArray(np.ndarray):\n    \"\"\"A specialized array for storing instance points data.\n\n    This class ensures that the array always uses the correct dtype and provides\n    convenience methods for working with point data.\n\n    The structured dtype includes the following fields:\n        - xy: A float64 array of shape (2,) containing the x, y coordinates\n        - visible: A boolean indicating if the point is visible\n        - complete: A boolean indicating if the point is complete\n        - name: An object dtype containing the name of the node\n    \"\"\"\n\n    @classmethod\n    def _get_dtype(cls):\n        \"\"\"Get the dtype for points array.\n\n        Returns:\n            np.dtype: A structured numpy dtype with fields for xy coordinates,\n                visible flag, complete flag, and node names.\n        \"\"\"\n        return np.dtype(\n            [\n                (\"xy\", \"&lt;f8\", (2,)),  # 64-bit (8-byte) little-endian double, ndim=2\n                (\"visible\", \"bool\"),\n                (\"complete\", \"bool\"),\n                (\n                    \"name\",\n                    \"O\",\n                ),  # object dtype to store pointers to python string objects\n            ]\n        )\n\n    @classmethod\n    def empty(cls, length: int) -&gt; \"PointsArray\":\n        \"\"\"Create an empty points array with the appropriate dtype.\n\n        Args:\n            length: The number of points (nodes) to allocate in the array.\n\n        Returns:\n            PointsArray: An empty array of the specified length with the appropriate\n                dtype.\n        \"\"\"\n        dtype = cls._get_dtype()\n        arr = np.empty(length, dtype=dtype).view(cls)\n        return arr\n\n    @classmethod\n    def from_array(cls, array: np.ndarray) -&gt; \"PointsArray\":\n        \"\"\"Convert an existing array to a PointsArray with the appropriate dtype.\n\n        Args:\n            array: A numpy array to convert. Can be a structured array or a regular\n                array. If a regular array, it is assumed to have columns for x, y\n                coordinates and optionally visible and complete flags.\n\n        Returns:\n            PointsArray: A structured array view of the input data with the appropriate\n                dtype.\n\n        Notes:\n            If the input is a structured array with fields matching the target dtype,\n            those fields will be copied. Otherwise, a best-effort conversion is made:\n\n            - First two columns (or first 2D element) are interpreted as x, y coords\n            - Third column (if present) is interpreted as visible flag\n            - Fourth column (if present) is interpreted as complete flag\n\n            If visibility is not provided, it is inferred from NaN values in the x\n            coordinate.\n        \"\"\"\n        dtype = cls._get_dtype()\n\n        # If already the right type, just view as PointsArray\n        if isinstance(array, np.ndarray) and array.dtype == dtype:\n            return array.view(cls)\n\n        # Otherwise, create a new array with the right dtype\n        new_array = np.empty(len(array), dtype=dtype).view(cls)\n\n        # Copy available fields\n        if isinstance(array, np.ndarray) and array.dtype.fields is not None:\n            # Structured array, copy matching fields\n            for field_name in dtype.names:\n                if field_name in array.dtype.names:\n                    new_array[field_name] = array[field_name]\n        elif isinstance(array, np.ndarray):\n            # Regular array, assume x, y coordinates\n            new_array[\"xy\"] = array[:, 0:2]\n\n            # Default visibility based on NaN\n            new_array[\"visible\"] = ~np.isnan(array[:, 0])\n\n            # If there are more columns, assume they are visible and complete\n            if array.shape[1] &gt;= 3:\n                new_array[\"visible\"] = array[:, 2].astype(bool)\n\n            if array.shape[1] &gt;= 4:\n                new_array[\"complete\"] = array[:, 3].astype(bool)\n\n        return new_array\n\n    @classmethod\n    def from_dict(cls, points_dict: dict, skeleton: Skeleton) -&gt; \"PointsArray\":\n        \"\"\"Create a PointsArray from a dictionary of node points.\n\n        Args:\n            points_dict: A dictionary mapping nodes (as Node objects, indices, or\n                strings) to point data. Each point should be an array-like with at least\n                2 elements for x, y coordinates, and optionally visible and complete\n                flags.\n            skeleton: The Skeleton object that defines the nodes.\n\n        Returns:\n            PointsArray: A structured array with the appropriate dtype containing the\n                point data from the dictionary.\n\n        Notes:\n            For each entry in the points_dict:\n            - First two values are treated as x, y coordinates\n            - Third value (if present) is treated as visible flag\n            - Fourth value (if present) is treated as complete flag\n\n            If visibility is not provided, it is inferred from NaN values in the x\n            coordinate.\n        \"\"\"\n        points = cls.empty(len(skeleton))\n\n        for node, data in points_dict.items():\n            if isinstance(node, (Node, str)):\n                node = skeleton.index(node)\n\n            points[node][\"xy\"] = data[:2]\n\n            idx = 2\n            if len(data) &gt; idx:\n                points[node][\"visible\"] = data[idx]\n            else:\n                points[node][\"visible\"] = ~np.isnan(data[0])\n\n            idx += 1\n            if len(data) &gt; idx:\n                points[node][\"complete\"] = data[idx]\n\n        return points\n</code></pre>"},{"location":"reference/sleap_io/model/instance/#sleap_io.model.instance.PointsArray.empty","title":"<code>empty(length)</code>  <code>classmethod</code>","text":"<p>Create an empty points array with the appropriate dtype.</p> <p>Parameters:</p> Name Type Description Default <code>length</code> <code>int</code> <p>The number of points (nodes) to allocate in the array.</p> required <p>Returns:</p> Name Type Description <code>PointsArray</code> <code>'PointsArray'</code> <p>An empty array of the specified length with the appropriate     dtype.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>@classmethod\ndef empty(cls, length: int) -&gt; \"PointsArray\":\n    \"\"\"Create an empty points array with the appropriate dtype.\n\n    Args:\n        length: The number of points (nodes) to allocate in the array.\n\n    Returns:\n        PointsArray: An empty array of the specified length with the appropriate\n            dtype.\n    \"\"\"\n    dtype = cls._get_dtype()\n    arr = np.empty(length, dtype=dtype).view(cls)\n    return arr\n</code></pre>"},{"location":"reference/sleap_io/model/instance/#sleap_io.model.instance.PointsArray.from_array","title":"<code>from_array(array)</code>  <code>classmethod</code>","text":"<p>Convert an existing array to a PointsArray with the appropriate dtype.</p> <p>Parameters:</p> Name Type Description Default <code>array</code> <code>ndarray</code> <p>A numpy array to convert. Can be a structured array or a regular array. If a regular array, it is assumed to have columns for x, y coordinates and optionally visible and complete flags.</p> required <p>Returns:</p> Name Type Description <code>PointsArray</code> <code>'PointsArray'</code> <p>A structured array view of the input data with the appropriate     dtype.</p> Notes <p>If the input is a structured array with fields matching the target dtype, those fields will be copied. Otherwise, a best-effort conversion is made:</p> <ul> <li>First two columns (or first 2D element) are interpreted as x, y coords</li> <li>Third column (if present) is interpreted as visible flag</li> <li>Fourth column (if present) is interpreted as complete flag</li> </ul> <p>If visibility is not provided, it is inferred from NaN values in the x coordinate.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>@classmethod\ndef from_array(cls, array: np.ndarray) -&gt; \"PointsArray\":\n    \"\"\"Convert an existing array to a PointsArray with the appropriate dtype.\n\n    Args:\n        array: A numpy array to convert. Can be a structured array or a regular\n            array. If a regular array, it is assumed to have columns for x, y\n            coordinates and optionally visible and complete flags.\n\n    Returns:\n        PointsArray: A structured array view of the input data with the appropriate\n            dtype.\n\n    Notes:\n        If the input is a structured array with fields matching the target dtype,\n        those fields will be copied. Otherwise, a best-effort conversion is made:\n\n        - First two columns (or first 2D element) are interpreted as x, y coords\n        - Third column (if present) is interpreted as visible flag\n        - Fourth column (if present) is interpreted as complete flag\n\n        If visibility is not provided, it is inferred from NaN values in the x\n        coordinate.\n    \"\"\"\n    dtype = cls._get_dtype()\n\n    # If already the right type, just view as PointsArray\n    if isinstance(array, np.ndarray) and array.dtype == dtype:\n        return array.view(cls)\n\n    # Otherwise, create a new array with the right dtype\n    new_array = np.empty(len(array), dtype=dtype).view(cls)\n\n    # Copy available fields\n    if isinstance(array, np.ndarray) and array.dtype.fields is not None:\n        # Structured array, copy matching fields\n        for field_name in dtype.names:\n            if field_name in array.dtype.names:\n                new_array[field_name] = array[field_name]\n    elif isinstance(array, np.ndarray):\n        # Regular array, assume x, y coordinates\n        new_array[\"xy\"] = array[:, 0:2]\n\n        # Default visibility based on NaN\n        new_array[\"visible\"] = ~np.isnan(array[:, 0])\n\n        # If there are more columns, assume they are visible and complete\n        if array.shape[1] &gt;= 3:\n            new_array[\"visible\"] = array[:, 2].astype(bool)\n\n        if array.shape[1] &gt;= 4:\n            new_array[\"complete\"] = array[:, 3].astype(bool)\n\n    return new_array\n</code></pre>"},{"location":"reference/sleap_io/model/instance/#sleap_io.model.instance.PointsArray.from_dict","title":"<code>from_dict(points_dict, skeleton)</code>  <code>classmethod</code>","text":"<p>Create a PointsArray from a dictionary of node points.</p> <p>Parameters:</p> Name Type Description Default <code>points_dict</code> <code>dict</code> <p>A dictionary mapping nodes (as Node objects, indices, or strings) to point data. Each point should be an array-like with at least 2 elements for x, y coordinates, and optionally visible and complete flags.</p> required <code>skeleton</code> <code>Skeleton</code> <p>The Skeleton object that defines the nodes.</p> required <p>Returns:</p> Name Type Description <code>PointsArray</code> <code>'PointsArray'</code> <p>A structured array with the appropriate dtype containing the     point data from the dictionary.</p> Notes <p>For each entry in the points_dict: - First two values are treated as x, y coordinates - Third value (if present) is treated as visible flag - Fourth value (if present) is treated as complete flag</p> <p>If visibility is not provided, it is inferred from NaN values in the x coordinate.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>@classmethod\ndef from_dict(cls, points_dict: dict, skeleton: Skeleton) -&gt; \"PointsArray\":\n    \"\"\"Create a PointsArray from a dictionary of node points.\n\n    Args:\n        points_dict: A dictionary mapping nodes (as Node objects, indices, or\n            strings) to point data. Each point should be an array-like with at least\n            2 elements for x, y coordinates, and optionally visible and complete\n            flags.\n        skeleton: The Skeleton object that defines the nodes.\n\n    Returns:\n        PointsArray: A structured array with the appropriate dtype containing the\n            point data from the dictionary.\n\n    Notes:\n        For each entry in the points_dict:\n        - First two values are treated as x, y coordinates\n        - Third value (if present) is treated as visible flag\n        - Fourth value (if present) is treated as complete flag\n\n        If visibility is not provided, it is inferred from NaN values in the x\n        coordinate.\n    \"\"\"\n    points = cls.empty(len(skeleton))\n\n    for node, data in points_dict.items():\n        if isinstance(node, (Node, str)):\n            node = skeleton.index(node)\n\n        points[node][\"xy\"] = data[:2]\n\n        idx = 2\n        if len(data) &gt; idx:\n            points[node][\"visible\"] = data[idx]\n        else:\n            points[node][\"visible\"] = ~np.isnan(data[0])\n\n        idx += 1\n        if len(data) &gt; idx:\n            points[node][\"complete\"] = data[idx]\n\n    return points\n</code></pre>"},{"location":"reference/sleap_io/model/instance/#sleap_io.model.instance.PredictedInstance","title":"<code>PredictedInstance</code>","text":"<p>               Bases: <code>Instance</code></p> <p>A <code>PredictedInstance</code> is an <code>Instance</code> that was predicted using a model.</p> <p>Attributes:</p> Name Type Description <code>skeleton</code> <code>Skeleton</code> <p>The <code>Skeleton</code> that this <code>Instance</code> is associated with.</p> <code>points</code> <code>PredictedPointsArray</code> <p>A dictionary where keys are <code>Skeleton</code> nodes and values are <code>Point</code>s.</p> <code>track</code> <code>Optional[Track]</code> <p>An optional <code>Track</code> associated with a unique animal/object across frames or videos.</p> <code>from_predicted</code> <code>Optional[PredictedInstance]</code> <p>Not applicable in <code>PredictedInstance</code>s (must be set to <code>None</code>).</p> <code>score</code> <code>float</code> <p>The instance detection or part grouping prediction score. This is a scalar that represents the confidence with which this entire instance was predicted. This may not always be applicable depending on the model type.</p> <code>tracking_score</code> <code>Optional[float]</code> <p>The score associated with the <code>Track</code> assignment. This is typically the value from the score matrix used in an identity assignment.</p> <p>Methods:</p> Name Description <code>__getitem__</code> <p>Return the point associated with a node.</p> <code>__repr__</code> <p>Return a readable representation of the instance.</p> <code>__setitem__</code> <p>Set the point associated with a node.</p> <code>empty</code> <p>Create an empty instance with no points.</p> <code>from_numpy</code> <p>Create a predicted instance object from a numpy array.</p> <code>numpy</code> <p>Return the instance points as a <code>(n_nodes, 2)</code> numpy array.</p> <code>replace_skeleton</code> <p>Replace the skeleton associated with the instance.</p> <code>update_skeleton</code> <p>Update or replace the skeleton associated with the instance.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>@attrs.define(eq=False)\nclass PredictedInstance(Instance):\n    \"\"\"A `PredictedInstance` is an `Instance` that was predicted using a model.\n\n    Attributes:\n        skeleton: The `Skeleton` that this `Instance` is associated with.\n        points: A dictionary where keys are `Skeleton` nodes and values are `Point`s.\n        track: An optional `Track` associated with a unique animal/object across frames\n            or videos.\n        from_predicted: Not applicable in `PredictedInstance`s (must be set to `None`).\n        score: The instance detection or part grouping prediction score. This is a\n            scalar that represents the confidence with which this entire instance was\n            predicted. This may not always be applicable depending on the model type.\n        tracking_score: The score associated with the `Track` assignment. This is\n            typically the value from the score matrix used in an identity assignment.\n    \"\"\"\n\n    points: PredictedPointsArray = attrs.field(eq=attrs.cmp_using(eq=np.array_equal))\n    skeleton: Skeleton\n    score: float = 0.0\n    track: Optional[Track] = None\n    tracking_score: Optional[float] = 0\n    from_predicted: Optional[PredictedInstance] = None\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return a readable representation of the instance.\"\"\"\n        pts = self.numpy().tolist()\n        track = f'\"{self.track.name}\"' if self.track is not None else self.track\n\n        score = str(self.score) if self.score is None else f\"{self.score:.2f}\"\n        tracking_score = (\n            str(self.tracking_score)\n            if self.tracking_score is None\n            else f\"{self.tracking_score:.2f}\"\n        )\n        return (\n            f\"PredictedInstance(points={pts}, track={track}, \"\n            f\"score={score}, tracking_score={tracking_score})\"\n        )\n\n    @classmethod\n    def empty(\n        cls,\n        skeleton: Skeleton,\n        score: float = 0.0,\n        track: Optional[Track] = None,\n        tracking_score: Optional[float] = None,\n        from_predicted: Optional[PredictedInstance] = None,\n    ) -&gt; \"PredictedInstance\":\n        \"\"\"Create an empty instance with no points.\"\"\"\n        points = PredictedPointsArray.empty(len(skeleton))\n        points[\"name\"] = skeleton.node_names\n\n        return cls(\n            points=points,\n            skeleton=skeleton,\n            score=score,\n            track=track,\n            tracking_score=tracking_score,\n            from_predicted=from_predicted,\n        )\n\n    @classmethod\n    def _convert_points(\n        cls, points_data: np.ndarray | dict | list, skeleton: Skeleton\n    ) -&gt; PredictedPointsArray:\n        \"\"\"Convert points to a structured numpy array if needed.\"\"\"\n        if isinstance(points_data, dict):\n            return PredictedPointsArray.from_dict(points_data, skeleton)\n        elif isinstance(points_data, (list, np.ndarray)):\n            if isinstance(points_data, list):\n                points_data = np.array(points_data)\n\n            points = PredictedPointsArray.from_array(points_data)\n            points[\"name\"] = skeleton.node_names\n            return points\n        else:\n            raise ValueError(\"points must be a numpy array or dictionary.\")\n\n    @classmethod\n    def from_numpy(\n        cls,\n        points_data: np.ndarray,\n        skeleton: Skeleton,\n        point_scores: Optional[np.ndarray] = None,\n        score: float = 0.0,\n        track: Optional[Track] = None,\n        tracking_score: Optional[float] = None,\n        from_predicted: Optional[PredictedInstance] = None,\n    ) -&gt; \"PredictedInstance\":\n        \"\"\"Create a predicted instance object from a numpy array.\"\"\"\n        points = cls._convert_points(points_data, skeleton)\n        if point_scores is not None:\n            points[\"score\"] = point_scores\n\n        return cls(\n            points=points,\n            skeleton=skeleton,\n            score=score,\n            track=track,\n            tracking_score=tracking_score,\n            from_predicted=from_predicted,\n        )\n\n    def numpy(\n        self,\n        invisible_as_nan: bool = True,\n        scores: bool = False,\n    ) -&gt; np.ndarray:\n        \"\"\"Return the instance points as a `(n_nodes, 2)` numpy array.\n\n        Args:\n            invisible_as_nan: If `True` (the default), points that are not visible will\n                be set to `np.nan`. If `False`, they will be whatever the stored value\n                of `PredictedInstance.points[\"xy\"]` is.\n            scores: If `True`, the score associated with each point will be\n                included in the output.\n\n        Returns:\n            A numpy array of shape `(n_nodes, 2)` corresponding to the points of the\n            skeleton. Values of `np.nan` indicate \"missing\" nodes.\n\n            If `scores` is `True`, the array will have shape `(n_nodes, 3)` with the\n            third column containing the score associated with each point.\n\n        Notes:\n            This will always return a copy of the array.\n\n            If you need to avoid making a copy, just access the\n            `PredictedInstance.points[\"xy\"]` attribute directly. This will not replace\n            invisible points with `np.nan`.\n        \"\"\"\n        if invisible_as_nan:\n            pts = np.where(\n                self.points[\"visible\"].reshape(-1, 1), self.points[\"xy\"], np.nan\n            )\n        else:\n            pts = self.points[\"xy\"].copy()\n\n        if scores:\n            return np.column_stack((pts, self.points[\"score\"]))\n        else:\n            return pts\n\n    def update_skeleton(self, names_only: bool = False):\n        \"\"\"Update or replace the skeleton associated with the instance.\n\n        Args:\n            names_only: If `True`, only update the node names in the points array. If\n                `False`, the points array will be updated to match the new skeleton.\n        \"\"\"\n        if names_only:\n            # Update the node names.\n            self.points[\"name\"] = self.skeleton.node_names\n            return\n\n        # Find correspondences.\n        new_node_inds, old_node_inds = self.skeleton.match_nodes(self.points[\"name\"])\n\n        # Update the points.\n        new_points = PredictedPointsArray.empty(len(self.skeleton))\n        new_points[new_node_inds] = self.points[old_node_inds]\n        new_points[\"name\"] = self.skeleton.node_names\n        self.points = new_points\n\n    def replace_skeleton(\n        self,\n        new_skeleton: Skeleton,\n        node_names_map: dict[str, str] | None = None,\n    ):\n        \"\"\"Replace the skeleton associated with the instance.\n\n        Args:\n            new_skeleton: The new `Skeleton` to associate with the instance.\n            node_names_map: Dictionary mapping nodes in the old skeleton to nodes in the\n                new skeleton. Keys and values should be specified as lists of strings.\n                If not provided, only nodes with identical names will be mapped. Points\n                associated with unmapped nodes will be removed.\n\n        Notes:\n            This method will update the `PredictedInstance.skeleton` attribute and the\n            `PredictedInstance.points` attribute in place (a copy is made of the points\n            array).\n\n            It is recommended to use `Labels.replace_skeleton` instead of this method if\n            more flexible node mapping is required.\n        \"\"\"\n        # Update skeleton object.\n        self.skeleton = new_skeleton\n\n        # Get node names with replacements from node map if possible.\n        old_node_names = self.points[\"name\"].tolist()\n        if node_names_map is not None:\n            old_node_names = [node_names_map.get(node, node) for node in old_node_names]\n\n        # Find correspondences.\n        new_node_inds, old_node_inds = self.skeleton.match_nodes(old_node_names)\n\n        # Update the points.\n        new_points = PredictedPointsArray.empty(len(self.skeleton))\n        new_points[new_node_inds] = self.points[old_node_inds]\n        self.points = new_points\n        self.points[\"name\"] = self.skeleton.node_names\n\n    def __getitem__(self, node: Union[int, str, Node]) -&gt; np.ndarray:\n        \"\"\"Return the point associated with a node.\"\"\"\n        # Inherit from Instance.__getitem__\n        return super().__getitem__(node)\n\n    def __setitem__(self, node: Union[int, str, Node], value):\n        \"\"\"Set the point associated with a node.\n\n        Args:\n            node: The node to set the point for. Can be an integer index, string name,\n                or Node object.\n            value: A tuple or array-like of length 2 or 3 containing (x, y) coordinates\n                and optionally a confidence score. If the score is not provided, it\n                defaults to 1.0.\n\n        Notes:\n            This sets the point coordinates, score, and marks the point as visible.\n        \"\"\"\n        if type(node) is not int:\n            node = self.skeleton.index(node)\n\n        if len(value) &lt; 2:\n            raise ValueError(\"Value must have at least 2 elements (x, y)\")\n\n        self.points[node][\"xy\"] = value[:2]\n\n        # Set score if provided, otherwise default to 1.0\n        if len(value) &gt;= 3:\n            self.points[node][\"score\"] = value[2]\n        else:\n            self.points[node][\"score\"] = 1.0\n\n        self.points[node][\"visible\"] = True\n</code></pre>"},{"location":"reference/sleap_io/model/instance/#sleap_io.model.instance.PredictedInstance.__getitem__","title":"<code>__getitem__(node)</code>","text":"<p>Return the point associated with a node.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>def __getitem__(self, node: Union[int, str, Node]) -&gt; np.ndarray:\n    \"\"\"Return the point associated with a node.\"\"\"\n    # Inherit from Instance.__getitem__\n    return super().__getitem__(node)\n</code></pre>"},{"location":"reference/sleap_io/model/instance/#sleap_io.model.instance.PredictedInstance.__repr__","title":"<code>__repr__()</code>","text":"<p>Return a readable representation of the instance.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return a readable representation of the instance.\"\"\"\n    pts = self.numpy().tolist()\n    track = f'\"{self.track.name}\"' if self.track is not None else self.track\n\n    score = str(self.score) if self.score is None else f\"{self.score:.2f}\"\n    tracking_score = (\n        str(self.tracking_score)\n        if self.tracking_score is None\n        else f\"{self.tracking_score:.2f}\"\n    )\n    return (\n        f\"PredictedInstance(points={pts}, track={track}, \"\n        f\"score={score}, tracking_score={tracking_score})\"\n    )\n</code></pre>"},{"location":"reference/sleap_io/model/instance/#sleap_io.model.instance.PredictedInstance.__setitem__","title":"<code>__setitem__(node, value)</code>","text":"<p>Set the point associated with a node.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>Union[int, str, Node]</code> <p>The node to set the point for. Can be an integer index, string name, or Node object.</p> required <code>value</code> <p>A tuple or array-like of length 2 or 3 containing (x, y) coordinates and optionally a confidence score. If the score is not provided, it defaults to 1.0.</p> required Notes <p>This sets the point coordinates, score, and marks the point as visible.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>def __setitem__(self, node: Union[int, str, Node], value):\n    \"\"\"Set the point associated with a node.\n\n    Args:\n        node: The node to set the point for. Can be an integer index, string name,\n            or Node object.\n        value: A tuple or array-like of length 2 or 3 containing (x, y) coordinates\n            and optionally a confidence score. If the score is not provided, it\n            defaults to 1.0.\n\n    Notes:\n        This sets the point coordinates, score, and marks the point as visible.\n    \"\"\"\n    if type(node) is not int:\n        node = self.skeleton.index(node)\n\n    if len(value) &lt; 2:\n        raise ValueError(\"Value must have at least 2 elements (x, y)\")\n\n    self.points[node][\"xy\"] = value[:2]\n\n    # Set score if provided, otherwise default to 1.0\n    if len(value) &gt;= 3:\n        self.points[node][\"score\"] = value[2]\n    else:\n        self.points[node][\"score\"] = 1.0\n\n    self.points[node][\"visible\"] = True\n</code></pre>"},{"location":"reference/sleap_io/model/instance/#sleap_io.model.instance.PredictedInstance.empty","title":"<code>empty(skeleton, score=0.0, track=None, tracking_score=None, from_predicted=None)</code>  <code>classmethod</code>","text":"<p>Create an empty instance with no points.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>@classmethod\ndef empty(\n    cls,\n    skeleton: Skeleton,\n    score: float = 0.0,\n    track: Optional[Track] = None,\n    tracking_score: Optional[float] = None,\n    from_predicted: Optional[PredictedInstance] = None,\n) -&gt; \"PredictedInstance\":\n    \"\"\"Create an empty instance with no points.\"\"\"\n    points = PredictedPointsArray.empty(len(skeleton))\n    points[\"name\"] = skeleton.node_names\n\n    return cls(\n        points=points,\n        skeleton=skeleton,\n        score=score,\n        track=track,\n        tracking_score=tracking_score,\n        from_predicted=from_predicted,\n    )\n</code></pre>"},{"location":"reference/sleap_io/model/instance/#sleap_io.model.instance.PredictedInstance.from_numpy","title":"<code>from_numpy(points_data, skeleton, point_scores=None, score=0.0, track=None, tracking_score=None, from_predicted=None)</code>  <code>classmethod</code>","text":"<p>Create a predicted instance object from a numpy array.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>@classmethod\ndef from_numpy(\n    cls,\n    points_data: np.ndarray,\n    skeleton: Skeleton,\n    point_scores: Optional[np.ndarray] = None,\n    score: float = 0.0,\n    track: Optional[Track] = None,\n    tracking_score: Optional[float] = None,\n    from_predicted: Optional[PredictedInstance] = None,\n) -&gt; \"PredictedInstance\":\n    \"\"\"Create a predicted instance object from a numpy array.\"\"\"\n    points = cls._convert_points(points_data, skeleton)\n    if point_scores is not None:\n        points[\"score\"] = point_scores\n\n    return cls(\n        points=points,\n        skeleton=skeleton,\n        score=score,\n        track=track,\n        tracking_score=tracking_score,\n        from_predicted=from_predicted,\n    )\n</code></pre>"},{"location":"reference/sleap_io/model/instance/#sleap_io.model.instance.PredictedInstance.numpy","title":"<code>numpy(invisible_as_nan=True, scores=False)</code>","text":"<p>Return the instance points as a <code>(n_nodes, 2)</code> numpy array.</p> <p>Parameters:</p> Name Type Description Default <code>invisible_as_nan</code> <code>bool</code> <p>If <code>True</code> (the default), points that are not visible will be set to <code>np.nan</code>. If <code>False</code>, they will be whatever the stored value of <code>PredictedInstance.points[\"xy\"]</code> is.</p> <code>True</code> <code>scores</code> <code>bool</code> <p>If <code>True</code>, the score associated with each point will be included in the output.</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>A numpy array of shape <code>(n_nodes, 2)</code> corresponding to the points of the skeleton. Values of <code>np.nan</code> indicate \"missing\" nodes.</p> <p>If <code>scores</code> is <code>True</code>, the array will have shape <code>(n_nodes, 3)</code> with the third column containing the score associated with each point.</p> Notes <p>This will always return a copy of the array.</p> <p>If you need to avoid making a copy, just access the <code>PredictedInstance.points[\"xy\"]</code> attribute directly. This will not replace invisible points with <code>np.nan</code>.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>def numpy(\n    self,\n    invisible_as_nan: bool = True,\n    scores: bool = False,\n) -&gt; np.ndarray:\n    \"\"\"Return the instance points as a `(n_nodes, 2)` numpy array.\n\n    Args:\n        invisible_as_nan: If `True` (the default), points that are not visible will\n            be set to `np.nan`. If `False`, they will be whatever the stored value\n            of `PredictedInstance.points[\"xy\"]` is.\n        scores: If `True`, the score associated with each point will be\n            included in the output.\n\n    Returns:\n        A numpy array of shape `(n_nodes, 2)` corresponding to the points of the\n        skeleton. Values of `np.nan` indicate \"missing\" nodes.\n\n        If `scores` is `True`, the array will have shape `(n_nodes, 3)` with the\n        third column containing the score associated with each point.\n\n    Notes:\n        This will always return a copy of the array.\n\n        If you need to avoid making a copy, just access the\n        `PredictedInstance.points[\"xy\"]` attribute directly. This will not replace\n        invisible points with `np.nan`.\n    \"\"\"\n    if invisible_as_nan:\n        pts = np.where(\n            self.points[\"visible\"].reshape(-1, 1), self.points[\"xy\"], np.nan\n        )\n    else:\n        pts = self.points[\"xy\"].copy()\n\n    if scores:\n        return np.column_stack((pts, self.points[\"score\"]))\n    else:\n        return pts\n</code></pre>"},{"location":"reference/sleap_io/model/instance/#sleap_io.model.instance.PredictedInstance.replace_skeleton","title":"<code>replace_skeleton(new_skeleton, node_names_map=None)</code>","text":"<p>Replace the skeleton associated with the instance.</p> <p>Parameters:</p> Name Type Description Default <code>new_skeleton</code> <code>Skeleton</code> <p>The new <code>Skeleton</code> to associate with the instance.</p> required <code>node_names_map</code> <code>dict[str, str] | None</code> <p>Dictionary mapping nodes in the old skeleton to nodes in the new skeleton. Keys and values should be specified as lists of strings. If not provided, only nodes with identical names will be mapped. Points associated with unmapped nodes will be removed.</p> <code>None</code> Notes <p>This method will update the <code>PredictedInstance.skeleton</code> attribute and the <code>PredictedInstance.points</code> attribute in place (a copy is made of the points array).</p> <p>It is recommended to use <code>Labels.replace_skeleton</code> instead of this method if more flexible node mapping is required.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>def replace_skeleton(\n    self,\n    new_skeleton: Skeleton,\n    node_names_map: dict[str, str] | None = None,\n):\n    \"\"\"Replace the skeleton associated with the instance.\n\n    Args:\n        new_skeleton: The new `Skeleton` to associate with the instance.\n        node_names_map: Dictionary mapping nodes in the old skeleton to nodes in the\n            new skeleton. Keys and values should be specified as lists of strings.\n            If not provided, only nodes with identical names will be mapped. Points\n            associated with unmapped nodes will be removed.\n\n    Notes:\n        This method will update the `PredictedInstance.skeleton` attribute and the\n        `PredictedInstance.points` attribute in place (a copy is made of the points\n        array).\n\n        It is recommended to use `Labels.replace_skeleton` instead of this method if\n        more flexible node mapping is required.\n    \"\"\"\n    # Update skeleton object.\n    self.skeleton = new_skeleton\n\n    # Get node names with replacements from node map if possible.\n    old_node_names = self.points[\"name\"].tolist()\n    if node_names_map is not None:\n        old_node_names = [node_names_map.get(node, node) for node in old_node_names]\n\n    # Find correspondences.\n    new_node_inds, old_node_inds = self.skeleton.match_nodes(old_node_names)\n\n    # Update the points.\n    new_points = PredictedPointsArray.empty(len(self.skeleton))\n    new_points[new_node_inds] = self.points[old_node_inds]\n    self.points = new_points\n    self.points[\"name\"] = self.skeleton.node_names\n</code></pre>"},{"location":"reference/sleap_io/model/instance/#sleap_io.model.instance.PredictedInstance.update_skeleton","title":"<code>update_skeleton(names_only=False)</code>","text":"<p>Update or replace the skeleton associated with the instance.</p> <p>Parameters:</p> Name Type Description Default <code>names_only</code> <code>bool</code> <p>If <code>True</code>, only update the node names in the points array. If <code>False</code>, the points array will be updated to match the new skeleton.</p> <code>False</code> Source code in <code>sleap_io/model/instance.py</code> <pre><code>def update_skeleton(self, names_only: bool = False):\n    \"\"\"Update or replace the skeleton associated with the instance.\n\n    Args:\n        names_only: If `True`, only update the node names in the points array. If\n            `False`, the points array will be updated to match the new skeleton.\n    \"\"\"\n    if names_only:\n        # Update the node names.\n        self.points[\"name\"] = self.skeleton.node_names\n        return\n\n    # Find correspondences.\n    new_node_inds, old_node_inds = self.skeleton.match_nodes(self.points[\"name\"])\n\n    # Update the points.\n    new_points = PredictedPointsArray.empty(len(self.skeleton))\n    new_points[new_node_inds] = self.points[old_node_inds]\n    new_points[\"name\"] = self.skeleton.node_names\n    self.points = new_points\n</code></pre>"},{"location":"reference/sleap_io/model/instance/#sleap_io.model.instance.PredictedPointsArray","title":"<code>PredictedPointsArray</code>","text":"<p>               Bases: <code>PointsArray</code></p> <p>A specialized array for storing predicted instance points data with scores.</p> <p>This extends the PointsArray class to include score information for each point.</p> The structured dtype includes the following fields <ul> <li>xy: A float64 array of shape (2,) containing the x, y coordinates</li> <li>score: A float64 containing the confidence score for the point</li> <li>visible: A boolean indicating if the point is visible</li> <li>complete: A boolean indicating if the point is complete</li> <li>name: An object dtype containing the name of the node</li> </ul> <p>Methods:</p> Name Description <code>from_array</code> <p>Convert an existing array to a PredictedPointsArray with appropriate dtype.</p> <code>from_dict</code> <p>Create a PredictedPointsArray from a dictionary of node points.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>class PredictedPointsArray(PointsArray):\n    \"\"\"A specialized array for storing predicted instance points data with scores.\n\n    This extends the PointsArray class to include score information for each point.\n\n    The structured dtype includes the following fields:\n        - xy: A float64 array of shape (2,) containing the x, y coordinates\n        - score: A float64 containing the confidence score for the point\n        - visible: A boolean indicating if the point is visible\n        - complete: A boolean indicating if the point is complete\n        - name: An object dtype containing the name of the node\n    \"\"\"\n\n    @classmethod\n    def _get_dtype(cls):\n        \"\"\"Get the dtype for predicted points array with scores.\n\n        Returns:\n            np.dtype: A structured numpy dtype with fields for xy coordinates,\n                score, visible flag, complete flag, and node names.\n        \"\"\"\n        return np.dtype(\n            [\n                (\"xy\", \"&lt;f8\", (2,)),  # 64-bit (8-byte) little-endian double, ndim=2\n                (\"score\", \"&lt;f8\"),  # 64-bit (8-byte) little-endian double\n                (\"visible\", \"bool\"),\n                (\"complete\", \"bool\"),\n                (\n                    \"name\",\n                    \"O\",\n                ),  # object dtype to store pointers to python string objects\n            ]\n        )\n\n    @classmethod\n    def from_array(cls, array: np.ndarray) -&gt; \"PredictedPointsArray\":\n        \"\"\"Convert an existing array to a PredictedPointsArray with appropriate dtype.\n\n        Args:\n            array: A numpy array to convert. Can be a structured array or a regular\n                array. If a regular array, it is assumed to have columns for x, y\n                coordinates, scores, and optionally visible and complete flags.\n\n        Returns:\n            PredictedPointsArray: A structured array view of the input data with the\n                appropriate dtype.\n\n        Notes:\n            If the input is a structured array with fields matching the target dtype,\n            those fields will be copied. Otherwise, a best-effort conversion is made:\n\n            - First two columns (or first 2D element) are interpreted as x, y coords\n            - Third column (if present) is interpreted as the score\n            - Fourth column (if present) is interpreted as visible flag\n            - Fifth column (if present) is interpreted as complete flag\n\n            If visibility is not provided, it is inferred from NaN values in the x\n            coordinate.\n        \"\"\"\n        dtype = cls._get_dtype()\n\n        # If already the right type, just view as PredictedPointsArray\n        if isinstance(array, np.ndarray) and array.dtype == dtype:\n            return array.view(cls)\n\n        # Otherwise, create a new array with the right dtype\n        new_array = np.empty(len(array), dtype=dtype).view(cls)\n\n        # Copy available fields\n        if isinstance(array, np.ndarray) and array.dtype.fields is not None:\n            # Structured array, copy matching fields\n            for field_name in dtype.names:\n                if field_name in array.dtype.names:\n                    new_array[field_name] = array[field_name]\n        elif isinstance(array, np.ndarray):\n            # Regular array, assume x, y coordinates\n            new_array[\"xy\"] = array[:, 0:2]\n\n            # Default visibility based on NaN\n            new_array[\"visible\"] = ~np.isnan(array[:, 0])\n\n            # If there's a third column, assume it's the score\n            if array.shape[1] &gt;= 3:\n                new_array[\"score\"] = array[:, 2]\n\n            # If there are more columns, assume they are visible and complete\n            if array.shape[1] &gt;= 4:\n                new_array[\"visible\"] = array[:, 3].astype(bool)\n\n            if array.shape[1] &gt;= 5:\n                new_array[\"complete\"] = array[:, 4].astype(bool)\n\n        return new_array\n\n    @classmethod\n    def from_dict(cls, points_dict: dict, skeleton: Skeleton) -&gt; \"PredictedPointsArray\":\n        \"\"\"Create a PredictedPointsArray from a dictionary of node points.\n\n        Args:\n            points_dict: A dictionary mapping nodes (as Node objects, indices, or\n                strings) to point data. Each point should be an array-like with at least\n                2 elements for x, y coordinates, and optionally score, visible, and\n                complete flags.\n            skeleton: The Skeleton object that defines the nodes.\n\n        Returns:\n            PredictedPointsArray: A structured array with the appropriate dtype\n                containing the point data from the dictionary.\n\n        Notes:\n            For each entry in the points_dict:\n            - First two values are treated as x, y coordinates\n            - Third value (if present) is treated as score\n            - Fourth value (if present) is treated as visible flag\n            - Fifth value (if present) is treated as complete flag\n\n            If visibility is not provided, it is inferred from NaN values in the x\n            coordinate.\n        \"\"\"\n        points = cls.empty(len(skeleton))\n\n        for node, data in points_dict.items():\n            if isinstance(node, (Node, str)):\n                node = skeleton.index(node)\n\n            points[node][\"xy\"] = data[:2]\n\n            # Score is the third element\n            idx = 2\n            if len(data) &gt; idx:\n                points[node][\"score\"] = data[idx]\n                idx += 1\n\n            # Visibility is the fourth element (or third if no score)\n            if len(data) &gt; idx:\n                points[node][\"visible\"] = data[idx]\n            else:\n                points[node][\"visible\"] = ~np.isnan(data[0])\n\n            idx += 1\n            # Completeness is the fifth element (or fourth if no score)\n            if len(data) &gt; idx:\n                points[node][\"complete\"] = data[idx]\n\n        return points\n</code></pre>"},{"location":"reference/sleap_io/model/instance/#sleap_io.model.instance.PredictedPointsArray.from_array","title":"<code>from_array(array)</code>  <code>classmethod</code>","text":"<p>Convert an existing array to a PredictedPointsArray with appropriate dtype.</p> <p>Parameters:</p> Name Type Description Default <code>array</code> <code>ndarray</code> <p>A numpy array to convert. Can be a structured array or a regular array. If a regular array, it is assumed to have columns for x, y coordinates, scores, and optionally visible and complete flags.</p> required <p>Returns:</p> Name Type Description <code>PredictedPointsArray</code> <code>'PredictedPointsArray'</code> <p>A structured array view of the input data with the     appropriate dtype.</p> Notes <p>If the input is a structured array with fields matching the target dtype, those fields will be copied. Otherwise, a best-effort conversion is made:</p> <ul> <li>First two columns (or first 2D element) are interpreted as x, y coords</li> <li>Third column (if present) is interpreted as the score</li> <li>Fourth column (if present) is interpreted as visible flag</li> <li>Fifth column (if present) is interpreted as complete flag</li> </ul> <p>If visibility is not provided, it is inferred from NaN values in the x coordinate.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>@classmethod\ndef from_array(cls, array: np.ndarray) -&gt; \"PredictedPointsArray\":\n    \"\"\"Convert an existing array to a PredictedPointsArray with appropriate dtype.\n\n    Args:\n        array: A numpy array to convert. Can be a structured array or a regular\n            array. If a regular array, it is assumed to have columns for x, y\n            coordinates, scores, and optionally visible and complete flags.\n\n    Returns:\n        PredictedPointsArray: A structured array view of the input data with the\n            appropriate dtype.\n\n    Notes:\n        If the input is a structured array with fields matching the target dtype,\n        those fields will be copied. Otherwise, a best-effort conversion is made:\n\n        - First two columns (or first 2D element) are interpreted as x, y coords\n        - Third column (if present) is interpreted as the score\n        - Fourth column (if present) is interpreted as visible flag\n        - Fifth column (if present) is interpreted as complete flag\n\n        If visibility is not provided, it is inferred from NaN values in the x\n        coordinate.\n    \"\"\"\n    dtype = cls._get_dtype()\n\n    # If already the right type, just view as PredictedPointsArray\n    if isinstance(array, np.ndarray) and array.dtype == dtype:\n        return array.view(cls)\n\n    # Otherwise, create a new array with the right dtype\n    new_array = np.empty(len(array), dtype=dtype).view(cls)\n\n    # Copy available fields\n    if isinstance(array, np.ndarray) and array.dtype.fields is not None:\n        # Structured array, copy matching fields\n        for field_name in dtype.names:\n            if field_name in array.dtype.names:\n                new_array[field_name] = array[field_name]\n    elif isinstance(array, np.ndarray):\n        # Regular array, assume x, y coordinates\n        new_array[\"xy\"] = array[:, 0:2]\n\n        # Default visibility based on NaN\n        new_array[\"visible\"] = ~np.isnan(array[:, 0])\n\n        # If there's a third column, assume it's the score\n        if array.shape[1] &gt;= 3:\n            new_array[\"score\"] = array[:, 2]\n\n        # If there are more columns, assume they are visible and complete\n        if array.shape[1] &gt;= 4:\n            new_array[\"visible\"] = array[:, 3].astype(bool)\n\n        if array.shape[1] &gt;= 5:\n            new_array[\"complete\"] = array[:, 4].astype(bool)\n\n    return new_array\n</code></pre>"},{"location":"reference/sleap_io/model/instance/#sleap_io.model.instance.PredictedPointsArray.from_dict","title":"<code>from_dict(points_dict, skeleton)</code>  <code>classmethod</code>","text":"<p>Create a PredictedPointsArray from a dictionary of node points.</p> <p>Parameters:</p> Name Type Description Default <code>points_dict</code> <code>dict</code> <p>A dictionary mapping nodes (as Node objects, indices, or strings) to point data. Each point should be an array-like with at least 2 elements for x, y coordinates, and optionally score, visible, and complete flags.</p> required <code>skeleton</code> <code>Skeleton</code> <p>The Skeleton object that defines the nodes.</p> required <p>Returns:</p> Name Type Description <code>PredictedPointsArray</code> <code>'PredictedPointsArray'</code> <p>A structured array with the appropriate dtype     containing the point data from the dictionary.</p> Notes <p>For each entry in the points_dict: - First two values are treated as x, y coordinates - Third value (if present) is treated as score - Fourth value (if present) is treated as visible flag - Fifth value (if present) is treated as complete flag</p> <p>If visibility is not provided, it is inferred from NaN values in the x coordinate.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>@classmethod\ndef from_dict(cls, points_dict: dict, skeleton: Skeleton) -&gt; \"PredictedPointsArray\":\n    \"\"\"Create a PredictedPointsArray from a dictionary of node points.\n\n    Args:\n        points_dict: A dictionary mapping nodes (as Node objects, indices, or\n            strings) to point data. Each point should be an array-like with at least\n            2 elements for x, y coordinates, and optionally score, visible, and\n            complete flags.\n        skeleton: The Skeleton object that defines the nodes.\n\n    Returns:\n        PredictedPointsArray: A structured array with the appropriate dtype\n            containing the point data from the dictionary.\n\n    Notes:\n        For each entry in the points_dict:\n        - First two values are treated as x, y coordinates\n        - Third value (if present) is treated as score\n        - Fourth value (if present) is treated as visible flag\n        - Fifth value (if present) is treated as complete flag\n\n        If visibility is not provided, it is inferred from NaN values in the x\n        coordinate.\n    \"\"\"\n    points = cls.empty(len(skeleton))\n\n    for node, data in points_dict.items():\n        if isinstance(node, (Node, str)):\n            node = skeleton.index(node)\n\n        points[node][\"xy\"] = data[:2]\n\n        # Score is the third element\n        idx = 2\n        if len(data) &gt; idx:\n            points[node][\"score\"] = data[idx]\n            idx += 1\n\n        # Visibility is the fourth element (or third if no score)\n        if len(data) &gt; idx:\n            points[node][\"visible\"] = data[idx]\n        else:\n            points[node][\"visible\"] = ~np.isnan(data[0])\n\n        idx += 1\n        # Completeness is the fifth element (or fourth if no score)\n        if len(data) &gt; idx:\n            points[node][\"complete\"] = data[idx]\n\n    return points\n</code></pre>"},{"location":"reference/sleap_io/model/instance/#sleap_io.model.instance.Track","title":"<code>Track</code>","text":"<p>An object that represents the same animal/object across multiple detections.</p> <p>This allows tracking of unique entities in the video over time and space.</p> <p>A <code>Track</code> may also be used to refer to unique identity classes that span multiple videos, such as <code>\"female mouse\"</code>.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>A name given to this track for identification purposes.</p> Notes <p><code>Track</code>s are compared by identity. This means that unique track objects with the same name are considered to be different.</p> <p>Methods:</p> Name Description <code>matches</code> <p>Check if this track matches another track.</p> <code>similarity_to</code> <p>Calculate similarity metrics with another track.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>@attrs.define(eq=False)\nclass Track:\n    \"\"\"An object that represents the same animal/object across multiple detections.\n\n    This allows tracking of unique entities in the video over time and space.\n\n    A `Track` may also be used to refer to unique identity classes that span multiple\n    videos, such as `\"female mouse\"`.\n\n    Attributes:\n        name: A name given to this track for identification purposes.\n\n    Notes:\n        `Track`s are compared by identity. This means that unique track objects with the\n        same name are considered to be different.\n    \"\"\"\n\n    name: str = \"\"\n\n    def matches(self, other: \"Track\", method: str = \"name\") -&gt; bool:\n        \"\"\"Check if this track matches another track.\n\n        Args:\n            other: Another track to compare with.\n            method: Matching method - \"name\" (match by name) or \"identity\"\n                (match by object identity).\n\n        Returns:\n            True if the tracks match according to the specified method.\n        \"\"\"\n        if method == \"name\":\n            return self.name == other.name\n        elif method == \"identity\":\n            return self is other\n        else:\n            raise ValueError(f\"Unknown matching method: {method}\")\n\n    def similarity_to(self, other: \"Track\") -&gt; dict[str, any]:\n        \"\"\"Calculate similarity metrics with another track.\n\n        Args:\n            other: Another track to compare with.\n\n        Returns:\n            A dictionary with similarity metrics:\n            - 'same_name': Whether the tracks have the same name\n            - 'same_identity': Whether the tracks are the same object\n            - 'name_similarity': Simple string similarity score (0-1)\n        \"\"\"\n        # Calculate simple string similarity\n        if self.name and other.name:\n            # Simple character overlap similarity\n            common_chars = set(self.name.lower()) &amp; set(other.name.lower())\n            all_chars = set(self.name.lower()) | set(other.name.lower())\n            name_similarity = len(common_chars) / len(all_chars) if all_chars else 0\n        else:\n            name_similarity = 1.0 if self.name == other.name else 0.0\n\n        return {\n            \"same_name\": self.name == other.name,\n            \"same_identity\": self is other,\n            \"name_similarity\": name_similarity,\n        }\n</code></pre>"},{"location":"reference/sleap_io/model/instance/#sleap_io.model.instance.Track.matches","title":"<code>matches(other, method='name')</code>","text":"<p>Check if this track matches another track.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>'Track'</code> <p>Another track to compare with.</p> required <code>method</code> <code>str</code> <p>Matching method - \"name\" (match by name) or \"identity\" (match by object identity).</p> <code>'name'</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if the tracks match according to the specified method.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>def matches(self, other: \"Track\", method: str = \"name\") -&gt; bool:\n    \"\"\"Check if this track matches another track.\n\n    Args:\n        other: Another track to compare with.\n        method: Matching method - \"name\" (match by name) or \"identity\"\n            (match by object identity).\n\n    Returns:\n        True if the tracks match according to the specified method.\n    \"\"\"\n    if method == \"name\":\n        return self.name == other.name\n    elif method == \"identity\":\n        return self is other\n    else:\n        raise ValueError(f\"Unknown matching method: {method}\")\n</code></pre>"},{"location":"reference/sleap_io/model/instance/#sleap_io.model.instance.Track.similarity_to","title":"<code>similarity_to(other)</code>","text":"<p>Calculate similarity metrics with another track.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>'Track'</code> <p>Another track to compare with.</p> required <p>Returns:</p> Type Description <code>dict[str, any]</code> <p>A dictionary with similarity metrics: - 'same_name': Whether the tracks have the same name - 'same_identity': Whether the tracks are the same object - 'name_similarity': Simple string similarity score (0-1)</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>def similarity_to(self, other: \"Track\") -&gt; dict[str, any]:\n    \"\"\"Calculate similarity metrics with another track.\n\n    Args:\n        other: Another track to compare with.\n\n    Returns:\n        A dictionary with similarity metrics:\n        - 'same_name': Whether the tracks have the same name\n        - 'same_identity': Whether the tracks are the same object\n        - 'name_similarity': Simple string similarity score (0-1)\n    \"\"\"\n    # Calculate simple string similarity\n    if self.name and other.name:\n        # Simple character overlap similarity\n        common_chars = set(self.name.lower()) &amp; set(other.name.lower())\n        all_chars = set(self.name.lower()) | set(other.name.lower())\n        name_similarity = len(common_chars) / len(all_chars) if all_chars else 0\n    else:\n        name_similarity = 1.0 if self.name == other.name else 0.0\n\n    return {\n        \"same_name\": self.name == other.name,\n        \"same_identity\": self is other,\n        \"name_similarity\": name_similarity,\n    }\n</code></pre>"},{"location":"reference/sleap_io/model/labeled_frame/","title":"labeled_frame","text":""},{"location":"reference/sleap_io/model/labeled_frame/#sleap_io.model.labeled_frame","title":"<code>sleap_io.model.labeled_frame</code>","text":"<p>Data structures for data contained within a single video frame.</p> <p>The <code>LabeledFrame</code> class is a data structure that contains <code>Instance</code>s and <code>PredictedInstance</code>s that are associated with a single frame within a video.</p> <p>Classes:</p> Name Description <code>LabeledFrame</code> <p>Labeled data for a single frame of a video.</p>"},{"location":"reference/sleap_io/model/labeled_frame/#sleap_io.model.labeled_frame.LabeledFrame","title":"<code>LabeledFrame</code>","text":"<p>Labeled data for a single frame of a video.</p> <p>Attributes:</p> Name Type Description <code>video</code> <code>Video</code> <p>The <code>Video</code> associated with this <code>LabeledFrame</code>.</p> <code>frame_idx</code> <code>int</code> <p>The index of the <code>LabeledFrame</code> in the <code>Video</code>.</p> <code>instances</code> <code>list[Union[Instance, PredictedInstance]]</code> <p>List of <code>Instance</code> objects associated with this <code>LabeledFrame</code>.</p> Notes <p>Instances of this class are hashed by identity, not by value. This means that two <code>LabeledFrame</code> instances with the same attributes will NOT be considered equal in a set or dict.</p> <p>Methods:</p> Name Description <code>__getitem__</code> <p>Return the <code>Instance</code> at <code>key</code> index in the <code>instances</code> list.</p> <code>__iter__</code> <p>Iterate over <code>Instance</code>s in <code>instances</code> list.</p> <code>__len__</code> <p>Return the number of instances in the frame.</p> <code>matches</code> <p>Check if this frame matches another frame's identity.</p> <code>merge</code> <p>Merge instances from another frame into this frame.</p> <code>numpy</code> <p>Return all instances in the frame as a numpy array.</p> <code>remove_empty_instances</code> <p>Remove all instances with no visible points.</p> <code>remove_predictions</code> <p>Remove all <code>PredictedInstance</code> objects from the frame.</p> <code>similarity_to</code> <p>Calculate instance overlap metrics with another frame.</p> Source code in <code>sleap_io/model/labeled_frame.py</code> <pre><code>@define(eq=False)\nclass LabeledFrame:\n    \"\"\"Labeled data for a single frame of a video.\n\n    Attributes:\n        video: The `Video` associated with this `LabeledFrame`.\n        frame_idx: The index of the `LabeledFrame` in the `Video`.\n        instances: List of `Instance` objects associated with this `LabeledFrame`.\n\n    Notes:\n        Instances of this class are hashed by identity, not by value. This means that\n        two `LabeledFrame` instances with the same attributes will NOT be considered\n        equal in a set or dict.\n    \"\"\"\n\n    video: Video\n    frame_idx: int = field(converter=int)\n    instances: list[Union[Instance, PredictedInstance]] = field(factory=list)\n\n    def __len__(self) -&gt; int:\n        \"\"\"Return the number of instances in the frame.\"\"\"\n        return len(self.instances)\n\n    def __getitem__(self, key: int) -&gt; Union[Instance, PredictedInstance]:\n        \"\"\"Return the `Instance` at `key` index in the `instances` list.\"\"\"\n        return self.instances[key]\n\n    def __iter__(self):\n        \"\"\"Iterate over `Instance`s in `instances` list.\"\"\"\n        return iter(self.instances)\n\n    @property\n    def user_instances(self) -&gt; list[Instance]:\n        \"\"\"Frame instances that are user-labeled (`Instance` objects).\"\"\"\n        return [inst for inst in self.instances if type(inst) is Instance]\n\n    @property\n    def has_user_instances(self) -&gt; bool:\n        \"\"\"Return True if the frame has any user-labeled instances.\"\"\"\n        for inst in self.instances:\n            if type(inst) is Instance:\n                return True\n        return False\n\n    @property\n    def predicted_instances(self) -&gt; list[Instance]:\n        \"\"\"Frame instances that are predicted by a model (`PredictedInstance`).\"\"\"\n        return [inst for inst in self.instances if type(inst) is PredictedInstance]\n\n    @property\n    def has_predicted_instances(self) -&gt; bool:\n        \"\"\"Return True if the frame has any predicted instances.\"\"\"\n        for inst in self.instances:\n            if type(inst) is PredictedInstance:\n                return True\n        return False\n\n    def numpy(self) -&gt; np.ndarray:\n        \"\"\"Return all instances in the frame as a numpy array.\n\n        Returns:\n            Points as a numpy array of shape `(n_instances, n_nodes, 2)`.\n\n            Note that the order of the instances is arbitrary.\n        \"\"\"\n        n_instances = len(self.instances)\n        n_nodes = len(self.instances[0]) if n_instances &gt; 0 else 0\n        pts = np.full((n_instances, n_nodes, 2), np.nan)\n        for i, inst in enumerate(self.instances):\n            pts[i] = inst.numpy()[:, 0:2]\n        return pts\n\n    @property\n    def image(self) -&gt; np.ndarray:\n        \"\"\"Return the image of the frame as a numpy array.\"\"\"\n        return self.video[self.frame_idx]\n\n    @property\n    def unused_predictions(self) -&gt; list[Instance]:\n        \"\"\"Return a list of \"unused\" `PredictedInstance` objects in frame.\n\n        This is all of the `PredictedInstance` objects which do not have a corresponding\n        `Instance` in the same track in the same frame.\n        \"\"\"\n        unused_predictions = []\n        any_tracks = [inst.track for inst in self.instances if inst.track is not None]\n        if len(any_tracks):\n            # Use tracks to determine which predicted instances have been used\n            used_tracks = [\n                inst.track\n                for inst in self.instances\n                if type(inst) is Instance and inst.track is not None\n            ]\n            unused_predictions = [\n                inst\n                for inst in self.instances\n                if inst.track not in used_tracks and type(inst) is PredictedInstance\n            ]\n\n        else:\n            # Use from_predicted to determine which predicted instances have been used\n            # TODO: should we always do this instead of using tracks?\n            used_instances = [\n                inst.from_predicted\n                for inst in self.instances\n                if inst.from_predicted is not None\n            ]\n            unused_predictions = [\n                inst\n                for inst in self.instances\n                if type(inst) is PredictedInstance and inst not in used_instances\n            ]\n\n        return unused_predictions\n\n    def remove_predictions(self):\n        \"\"\"Remove all `PredictedInstance` objects from the frame.\"\"\"\n        self.instances = [inst for inst in self.instances if type(inst) is Instance]\n\n    def remove_empty_instances(self):\n        \"\"\"Remove all instances with no visible points.\"\"\"\n        self.instances = [inst for inst in self.instances if not inst.is_empty]\n\n    def matches(self, other: \"LabeledFrame\", video_must_match: bool = True) -&gt; bool:\n        \"\"\"Check if this frame matches another frame's identity.\n\n        Args:\n            other: Another LabeledFrame to compare with.\n            video_must_match: If True, frames must be from the same video.\n                If False, only frame index needs to match.\n\n        Returns:\n            True if the frames have the same identity, False otherwise.\n\n        Notes:\n            Frame identity is determined by video and frame index.\n            This does not compare the instances within the frame.\n        \"\"\"\n        if self.frame_idx != other.frame_idx:\n            return False\n\n        if video_must_match:\n            # Check if videos are the same object\n            if self.video is other.video:\n                return True\n            # Check if videos have matching paths\n            return self.video.matches_path(other.video, strict=False)\n\n        return True\n\n    def similarity_to(self, other: \"LabeledFrame\") -&gt; dict[str, any]:\n        \"\"\"Calculate instance overlap metrics with another frame.\n\n        Args:\n            other: Another LabeledFrame to compare with.\n\n        Returns:\n            A dictionary with similarity metrics:\n            - 'n_user_self': Number of user instances in this frame\n            - 'n_user_other': Number of user instances in the other frame\n            - 'n_pred_self': Number of predicted instances in this frame\n            - 'n_pred_other': Number of predicted instances in the other frame\n            - 'n_overlapping': Number of instances that overlap (by IoU)\n            - 'mean_pose_distance': Mean distance between matching poses\n        \"\"\"\n        metrics = {\n            \"n_user_self\": len(self.user_instances),\n            \"n_user_other\": len(other.user_instances),\n            \"n_pred_self\": len(self.predicted_instances),\n            \"n_pred_other\": len(other.predicted_instances),\n            \"n_overlapping\": 0,\n            \"mean_pose_distance\": None,\n        }\n\n        # Count overlapping instances and compute pose distances\n        pose_distances = []\n        for inst1 in self.instances:\n            for inst2 in other.instances:\n                # Check if instances overlap\n                if inst1.overlaps_with(inst2, iou_threshold=0.1):\n                    metrics[\"n_overlapping\"] += 1\n\n                    # If they have the same skeleton, compute pose distance\n                    if inst1.skeleton.matches(inst2.skeleton):\n                        # Get visible points for both\n                        pts1 = inst1.numpy()\n                        pts2 = inst2.numpy()\n\n                        # Compute distances for visible points in both\n                        valid = ~(np.isnan(pts1[:, 0]) | np.isnan(pts2[:, 0]))\n                        if valid.any():\n                            distances = np.linalg.norm(\n                                pts1[valid] - pts2[valid], axis=1\n                            )\n                            pose_distances.extend(distances.tolist())\n\n        if pose_distances:\n            metrics[\"mean_pose_distance\"] = np.mean(pose_distances)\n\n        return metrics\n\n    def merge(\n        self,\n        other: \"LabeledFrame\",\n        instance_matcher: Optional[\"InstanceMatcher\"] = None,\n        strategy: str = \"smart\",\n    ) -&gt; tuple[list[Instance], list[tuple[Instance, Instance, str]]]:\n        \"\"\"Merge instances from another frame into this frame.\n\n        Args:\n            other: Another LabeledFrame to merge instances from.\n            instance_matcher: Matcher to use for finding duplicate instances.\n                If None, uses default spatial matching with 5px tolerance.\n            strategy: Merge strategy:\n                - \"smart\": Keep user labels, update predictions only if no user label\n                - \"keep_original\": Keep all original instances, ignore new ones\n                - \"keep_new\": Replace with new instances\n                - \"keep_both\": Keep all instances from both frames\n\n        Returns:\n            A tuple of (merged_instances, conflicts) where:\n            - merged_instances: List of instances after merging\n            - conflicts: List of (original, new, resolution) tuples for conflicts\n\n        Notes:\n            This method doesn't modify the frame in place. It returns the merged\n            instance list which can be assigned back if desired.\n        \"\"\"\n        from sleap_io.model.matching import InstanceMatcher, InstanceMatchMethod\n\n        if instance_matcher is None:\n            instance_matcher = InstanceMatcher(\n                method=InstanceMatchMethod.SPATIAL, threshold=5.0\n            )\n\n        conflicts = []\n\n        if strategy == \"keep_original\":\n            return self.instances.copy(), conflicts\n        elif strategy == \"keep_new\":\n            return other.instances.copy(), conflicts\n        elif strategy == \"keep_both\":\n            return self.instances + other.instances, conflicts\n\n        # Smart merging strategy\n        merged_instances = []\n        used_indices = set()\n\n        # First, keep all user instances from self\n        for inst in self.instances:\n            if type(inst) is Instance:\n                merged_instances.append(inst)\n\n        # Find matches between instances\n        matches = instance_matcher.find_matches(self.instances, other.instances)\n\n        # Group matches by instance in other frame\n        other_to_self = {}\n        for self_idx, other_idx, score in matches:\n            if other_idx not in other_to_self or score &gt; other_to_self[other_idx][1]:\n                other_to_self[other_idx] = (self_idx, score)\n\n        # Process instances from other frame\n        for other_idx, other_inst in enumerate(other.instances):\n            if other_idx in other_to_self:\n                self_idx, score = other_to_self[other_idx]\n                self_inst = self.instances[self_idx]\n\n                # Check for conflicts\n                if type(self_inst) is Instance and type(other_inst) is Instance:\n                    # Both are user instances - conflict\n                    conflicts.append((self_inst, other_inst, \"kept_original\"))\n                    used_indices.add(self_idx)\n                elif (\n                    type(self_inst) is PredictedInstance\n                    and type(other_inst) is Instance\n                ):\n                    # Replace prediction with user instance\n                    if self_idx not in used_indices:\n                        merged_instances.append(other_inst)\n                        used_indices.add(self_idx)\n                elif (\n                    type(self_inst) is Instance\n                    and type(other_inst) is PredictedInstance\n                ):\n                    # Keep user instance, ignore prediction\n                    conflicts.append((self_inst, other_inst, \"kept_user\"))\n                    used_indices.add(self_idx)\n                else:\n                    # Both are predictions - keep the one with higher score\n                    if self_idx not in used_indices:\n                        if hasattr(other_inst, \"score\") and hasattr(self_inst, \"score\"):\n                            if other_inst.score &gt; self_inst.score:\n                                merged_instances.append(other_inst)\n                            else:\n                                merged_instances.append(self_inst)\n                        else:\n                            merged_instances.append(other_inst)\n                        used_indices.add(self_idx)\n            else:\n                # No match found, add new instance\n                merged_instances.append(other_inst)\n\n        # Add remaining instances from self that weren't matched\n        for self_idx, self_inst in enumerate(self.instances):\n            if type(self_inst) is PredictedInstance and self_idx not in used_indices:\n                # Check if this prediction should be kept\n                # NOTE: This defensive logic should be unreachable under normal\n                # circumstances since all matched instances should have been added to\n                # used_indices above. However, we keep this as a safety net for edge\n                # cases or future changes.\n                keep = True\n                for other_idx, (matched_self_idx, _) in other_to_self.items():\n                    if matched_self_idx == self_idx:\n                        keep = False\n                        break\n                if keep:\n                    merged_instances.append(self_inst)\n\n        return merged_instances, conflicts\n</code></pre>"},{"location":"reference/sleap_io/model/labeled_frame/#sleap_io.model.labeled_frame.LabeledFrame.has_predicted_instances","title":"<code>has_predicted_instances</code>  <code>property</code>","text":"<p>Return True if the frame has any predicted instances.</p>"},{"location":"reference/sleap_io/model/labeled_frame/#sleap_io.model.labeled_frame.LabeledFrame.has_user_instances","title":"<code>has_user_instances</code>  <code>property</code>","text":"<p>Return True if the frame has any user-labeled instances.</p>"},{"location":"reference/sleap_io/model/labeled_frame/#sleap_io.model.labeled_frame.LabeledFrame.image","title":"<code>image</code>  <code>property</code>","text":"<p>Return the image of the frame as a numpy array.</p>"},{"location":"reference/sleap_io/model/labeled_frame/#sleap_io.model.labeled_frame.LabeledFrame.predicted_instances","title":"<code>predicted_instances</code>  <code>property</code>","text":"<p>Frame instances that are predicted by a model (<code>PredictedInstance</code>).</p>"},{"location":"reference/sleap_io/model/labeled_frame/#sleap_io.model.labeled_frame.LabeledFrame.unused_predictions","title":"<code>unused_predictions</code>  <code>property</code>","text":"<p>Return a list of \"unused\" <code>PredictedInstance</code> objects in frame.</p> <p>This is all of the <code>PredictedInstance</code> objects which do not have a corresponding <code>Instance</code> in the same track in the same frame.</p>"},{"location":"reference/sleap_io/model/labeled_frame/#sleap_io.model.labeled_frame.LabeledFrame.user_instances","title":"<code>user_instances</code>  <code>property</code>","text":"<p>Frame instances that are user-labeled (<code>Instance</code> objects).</p>"},{"location":"reference/sleap_io/model/labeled_frame/#sleap_io.model.labeled_frame.LabeledFrame.__getitem__","title":"<code>__getitem__(key)</code>","text":"<p>Return the <code>Instance</code> at <code>key</code> index in the <code>instances</code> list.</p> Source code in <code>sleap_io/model/labeled_frame.py</code> <pre><code>def __getitem__(self, key: int) -&gt; Union[Instance, PredictedInstance]:\n    \"\"\"Return the `Instance` at `key` index in the `instances` list.\"\"\"\n    return self.instances[key]\n</code></pre>"},{"location":"reference/sleap_io/model/labeled_frame/#sleap_io.model.labeled_frame.LabeledFrame.__iter__","title":"<code>__iter__()</code>","text":"<p>Iterate over <code>Instance</code>s in <code>instances</code> list.</p> Source code in <code>sleap_io/model/labeled_frame.py</code> <pre><code>def __iter__(self):\n    \"\"\"Iterate over `Instance`s in `instances` list.\"\"\"\n    return iter(self.instances)\n</code></pre>"},{"location":"reference/sleap_io/model/labeled_frame/#sleap_io.model.labeled_frame.LabeledFrame.__len__","title":"<code>__len__()</code>","text":"<p>Return the number of instances in the frame.</p> Source code in <code>sleap_io/model/labeled_frame.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"Return the number of instances in the frame.\"\"\"\n    return len(self.instances)\n</code></pre>"},{"location":"reference/sleap_io/model/labeled_frame/#sleap_io.model.labeled_frame.LabeledFrame.matches","title":"<code>matches(other, video_must_match=True)</code>","text":"<p>Check if this frame matches another frame's identity.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>'LabeledFrame'</code> <p>Another LabeledFrame to compare with.</p> required <code>video_must_match</code> <code>bool</code> <p>If True, frames must be from the same video. If False, only frame index needs to match.</p> <code>True</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if the frames have the same identity, False otherwise.</p> Notes <p>Frame identity is determined by video and frame index. This does not compare the instances within the frame.</p> Source code in <code>sleap_io/model/labeled_frame.py</code> <pre><code>def matches(self, other: \"LabeledFrame\", video_must_match: bool = True) -&gt; bool:\n    \"\"\"Check if this frame matches another frame's identity.\n\n    Args:\n        other: Another LabeledFrame to compare with.\n        video_must_match: If True, frames must be from the same video.\n            If False, only frame index needs to match.\n\n    Returns:\n        True if the frames have the same identity, False otherwise.\n\n    Notes:\n        Frame identity is determined by video and frame index.\n        This does not compare the instances within the frame.\n    \"\"\"\n    if self.frame_idx != other.frame_idx:\n        return False\n\n    if video_must_match:\n        # Check if videos are the same object\n        if self.video is other.video:\n            return True\n        # Check if videos have matching paths\n        return self.video.matches_path(other.video, strict=False)\n\n    return True\n</code></pre>"},{"location":"reference/sleap_io/model/labeled_frame/#sleap_io.model.labeled_frame.LabeledFrame.merge","title":"<code>merge(other, instance_matcher=None, strategy='smart')</code>","text":"<p>Merge instances from another frame into this frame.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>'LabeledFrame'</code> <p>Another LabeledFrame to merge instances from.</p> required <code>instance_matcher</code> <code>Optional['InstanceMatcher']</code> <p>Matcher to use for finding duplicate instances. If None, uses default spatial matching with 5px tolerance.</p> <code>None</code> <code>strategy</code> <code>str</code> <p>Merge strategy: - \"smart\": Keep user labels, update predictions only if no user label - \"keep_original\": Keep all original instances, ignore new ones - \"keep_new\": Replace with new instances - \"keep_both\": Keep all instances from both frames</p> <code>'smart'</code> <p>Returns:</p> Type Description <code>tuple[list[Instance], list[tuple[Instance, Instance, str]]]</code> <p>A tuple of (merged_instances, conflicts) where: - merged_instances: List of instances after merging - conflicts: List of (original, new, resolution) tuples for conflicts</p> Notes <p>This method doesn't modify the frame in place. It returns the merged instance list which can be assigned back if desired.</p> Source code in <code>sleap_io/model/labeled_frame.py</code> <pre><code>def merge(\n    self,\n    other: \"LabeledFrame\",\n    instance_matcher: Optional[\"InstanceMatcher\"] = None,\n    strategy: str = \"smart\",\n) -&gt; tuple[list[Instance], list[tuple[Instance, Instance, str]]]:\n    \"\"\"Merge instances from another frame into this frame.\n\n    Args:\n        other: Another LabeledFrame to merge instances from.\n        instance_matcher: Matcher to use for finding duplicate instances.\n            If None, uses default spatial matching with 5px tolerance.\n        strategy: Merge strategy:\n            - \"smart\": Keep user labels, update predictions only if no user label\n            - \"keep_original\": Keep all original instances, ignore new ones\n            - \"keep_new\": Replace with new instances\n            - \"keep_both\": Keep all instances from both frames\n\n    Returns:\n        A tuple of (merged_instances, conflicts) where:\n        - merged_instances: List of instances after merging\n        - conflicts: List of (original, new, resolution) tuples for conflicts\n\n    Notes:\n        This method doesn't modify the frame in place. It returns the merged\n        instance list which can be assigned back if desired.\n    \"\"\"\n    from sleap_io.model.matching import InstanceMatcher, InstanceMatchMethod\n\n    if instance_matcher is None:\n        instance_matcher = InstanceMatcher(\n            method=InstanceMatchMethod.SPATIAL, threshold=5.0\n        )\n\n    conflicts = []\n\n    if strategy == \"keep_original\":\n        return self.instances.copy(), conflicts\n    elif strategy == \"keep_new\":\n        return other.instances.copy(), conflicts\n    elif strategy == \"keep_both\":\n        return self.instances + other.instances, conflicts\n\n    # Smart merging strategy\n    merged_instances = []\n    used_indices = set()\n\n    # First, keep all user instances from self\n    for inst in self.instances:\n        if type(inst) is Instance:\n            merged_instances.append(inst)\n\n    # Find matches between instances\n    matches = instance_matcher.find_matches(self.instances, other.instances)\n\n    # Group matches by instance in other frame\n    other_to_self = {}\n    for self_idx, other_idx, score in matches:\n        if other_idx not in other_to_self or score &gt; other_to_self[other_idx][1]:\n            other_to_self[other_idx] = (self_idx, score)\n\n    # Process instances from other frame\n    for other_idx, other_inst in enumerate(other.instances):\n        if other_idx in other_to_self:\n            self_idx, score = other_to_self[other_idx]\n            self_inst = self.instances[self_idx]\n\n            # Check for conflicts\n            if type(self_inst) is Instance and type(other_inst) is Instance:\n                # Both are user instances - conflict\n                conflicts.append((self_inst, other_inst, \"kept_original\"))\n                used_indices.add(self_idx)\n            elif (\n                type(self_inst) is PredictedInstance\n                and type(other_inst) is Instance\n            ):\n                # Replace prediction with user instance\n                if self_idx not in used_indices:\n                    merged_instances.append(other_inst)\n                    used_indices.add(self_idx)\n            elif (\n                type(self_inst) is Instance\n                and type(other_inst) is PredictedInstance\n            ):\n                # Keep user instance, ignore prediction\n                conflicts.append((self_inst, other_inst, \"kept_user\"))\n                used_indices.add(self_idx)\n            else:\n                # Both are predictions - keep the one with higher score\n                if self_idx not in used_indices:\n                    if hasattr(other_inst, \"score\") and hasattr(self_inst, \"score\"):\n                        if other_inst.score &gt; self_inst.score:\n                            merged_instances.append(other_inst)\n                        else:\n                            merged_instances.append(self_inst)\n                    else:\n                        merged_instances.append(other_inst)\n                    used_indices.add(self_idx)\n        else:\n            # No match found, add new instance\n            merged_instances.append(other_inst)\n\n    # Add remaining instances from self that weren't matched\n    for self_idx, self_inst in enumerate(self.instances):\n        if type(self_inst) is PredictedInstance and self_idx not in used_indices:\n            # Check if this prediction should be kept\n            # NOTE: This defensive logic should be unreachable under normal\n            # circumstances since all matched instances should have been added to\n            # used_indices above. However, we keep this as a safety net for edge\n            # cases or future changes.\n            keep = True\n            for other_idx, (matched_self_idx, _) in other_to_self.items():\n                if matched_self_idx == self_idx:\n                    keep = False\n                    break\n            if keep:\n                merged_instances.append(self_inst)\n\n    return merged_instances, conflicts\n</code></pre>"},{"location":"reference/sleap_io/model/labeled_frame/#sleap_io.model.labeled_frame.LabeledFrame.numpy","title":"<code>numpy()</code>","text":"<p>Return all instances in the frame as a numpy array.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>Points as a numpy array of shape <code>(n_instances, n_nodes, 2)</code>.</p> <p>Note that the order of the instances is arbitrary.</p> Source code in <code>sleap_io/model/labeled_frame.py</code> <pre><code>def numpy(self) -&gt; np.ndarray:\n    \"\"\"Return all instances in the frame as a numpy array.\n\n    Returns:\n        Points as a numpy array of shape `(n_instances, n_nodes, 2)`.\n\n        Note that the order of the instances is arbitrary.\n    \"\"\"\n    n_instances = len(self.instances)\n    n_nodes = len(self.instances[0]) if n_instances &gt; 0 else 0\n    pts = np.full((n_instances, n_nodes, 2), np.nan)\n    for i, inst in enumerate(self.instances):\n        pts[i] = inst.numpy()[:, 0:2]\n    return pts\n</code></pre>"},{"location":"reference/sleap_io/model/labeled_frame/#sleap_io.model.labeled_frame.LabeledFrame.remove_empty_instances","title":"<code>remove_empty_instances()</code>","text":"<p>Remove all instances with no visible points.</p> Source code in <code>sleap_io/model/labeled_frame.py</code> <pre><code>def remove_empty_instances(self):\n    \"\"\"Remove all instances with no visible points.\"\"\"\n    self.instances = [inst for inst in self.instances if not inst.is_empty]\n</code></pre>"},{"location":"reference/sleap_io/model/labeled_frame/#sleap_io.model.labeled_frame.LabeledFrame.remove_predictions","title":"<code>remove_predictions()</code>","text":"<p>Remove all <code>PredictedInstance</code> objects from the frame.</p> Source code in <code>sleap_io/model/labeled_frame.py</code> <pre><code>def remove_predictions(self):\n    \"\"\"Remove all `PredictedInstance` objects from the frame.\"\"\"\n    self.instances = [inst for inst in self.instances if type(inst) is Instance]\n</code></pre>"},{"location":"reference/sleap_io/model/labeled_frame/#sleap_io.model.labeled_frame.LabeledFrame.similarity_to","title":"<code>similarity_to(other)</code>","text":"<p>Calculate instance overlap metrics with another frame.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>'LabeledFrame'</code> <p>Another LabeledFrame to compare with.</p> required <p>Returns:</p> Type Description <code>dict[str, any]</code> <p>A dictionary with similarity metrics: - 'n_user_self': Number of user instances in this frame - 'n_user_other': Number of user instances in the other frame - 'n_pred_self': Number of predicted instances in this frame - 'n_pred_other': Number of predicted instances in the other frame - 'n_overlapping': Number of instances that overlap (by IoU) - 'mean_pose_distance': Mean distance between matching poses</p> Source code in <code>sleap_io/model/labeled_frame.py</code> <pre><code>def similarity_to(self, other: \"LabeledFrame\") -&gt; dict[str, any]:\n    \"\"\"Calculate instance overlap metrics with another frame.\n\n    Args:\n        other: Another LabeledFrame to compare with.\n\n    Returns:\n        A dictionary with similarity metrics:\n        - 'n_user_self': Number of user instances in this frame\n        - 'n_user_other': Number of user instances in the other frame\n        - 'n_pred_self': Number of predicted instances in this frame\n        - 'n_pred_other': Number of predicted instances in the other frame\n        - 'n_overlapping': Number of instances that overlap (by IoU)\n        - 'mean_pose_distance': Mean distance between matching poses\n    \"\"\"\n    metrics = {\n        \"n_user_self\": len(self.user_instances),\n        \"n_user_other\": len(other.user_instances),\n        \"n_pred_self\": len(self.predicted_instances),\n        \"n_pred_other\": len(other.predicted_instances),\n        \"n_overlapping\": 0,\n        \"mean_pose_distance\": None,\n    }\n\n    # Count overlapping instances and compute pose distances\n    pose_distances = []\n    for inst1 in self.instances:\n        for inst2 in other.instances:\n            # Check if instances overlap\n            if inst1.overlaps_with(inst2, iou_threshold=0.1):\n                metrics[\"n_overlapping\"] += 1\n\n                # If they have the same skeleton, compute pose distance\n                if inst1.skeleton.matches(inst2.skeleton):\n                    # Get visible points for both\n                    pts1 = inst1.numpy()\n                    pts2 = inst2.numpy()\n\n                    # Compute distances for visible points in both\n                    valid = ~(np.isnan(pts1[:, 0]) | np.isnan(pts2[:, 0]))\n                    if valid.any():\n                        distances = np.linalg.norm(\n                            pts1[valid] - pts2[valid], axis=1\n                        )\n                        pose_distances.extend(distances.tolist())\n\n    if pose_distances:\n        metrics[\"mean_pose_distance\"] = np.mean(pose_distances)\n\n    return metrics\n</code></pre>"},{"location":"reference/sleap_io/model/labels/","title":"labels","text":""},{"location":"reference/sleap_io/model/labels/#sleap_io.model.labels","title":"<code>sleap_io.model.labels</code>","text":"<p>Data structure for the labels, a top-level container for pose data.</p> <p><code>Label</code>s contain <code>LabeledFrame</code>s, which in turn contain <code>Instance</code>s, which contain points.</p> <p>This structure also maintains metadata that is common across all child objects such as <code>Track</code>s, <code>Video</code>s, <code>Skeleton</code>s and others.</p> <p>It is intended to be the entrypoint for deserialization and main container that should be used for serialization. It is designed to support both labeled data (used for training models) and predictions (inference results).</p> <p>Classes:</p> Name Description <code>Labels</code> <p>Pose data for a set of videos that have user labels and/or predictions.</p>"},{"location":"reference/sleap_io/model/labels/#sleap_io.model.labels.Labels","title":"<code>Labels</code>","text":"<p>Pose data for a set of videos that have user labels and/or predictions.</p> <p>Attributes:</p> Name Type Description <code>labeled_frames</code> <code>list[LabeledFrame]</code> <p>A list of <code>LabeledFrame</code>s that are associated with this dataset.</p> <code>videos</code> <code>list[Video]</code> <p>A list of <code>Video</code>s that are associated with this dataset. Videos do not need to have corresponding <code>LabeledFrame</code>s if they do not have any labels or predictions yet.</p> <code>skeletons</code> <code>list[Skeleton]</code> <p>A list of <code>Skeleton</code>s that are associated with this dataset. This should generally only contain a single skeleton.</p> <code>tracks</code> <code>list[Track]</code> <p>A list of <code>Track</code>s that are associated with this dataset.</p> <code>suggestions</code> <code>list[SuggestionFrame]</code> <p>A list of <code>SuggestionFrame</code>s that are associated with this dataset.</p> <code>sessions</code> <code>list[RecordingSession]</code> <p>A list of <code>RecordingSession</code>s that are associated with this dataset.</p> <code>provenance</code> <code>dict[str, Any]</code> <p>Dictionary of arbitrary metadata providing additional information about where the dataset came from.</p> Notes <p><code>Video</code>s in contain <code>LabeledFrame</code>s, and <code>Skeleton</code>s and <code>Track</code>s in contained <code>Instance</code>s are added to the respective lists automatically.</p> <p>Methods:</p> Name Description <code>__attrs_post_init__</code> <p>Append videos, skeletons, and tracks seen in <code>labeled_frames</code> to <code>Labels</code>.</p> <code>__getitem__</code> <p>Return one or more labeled frames based on indexing criteria.</p> <code>__iter__</code> <p>Iterate over <code>labeled_frames</code> list when calling iter method on <code>Labels</code>.</p> <code>__len__</code> <p>Return number of labeled frames.</p> <code>__repr__</code> <p>Return a readable representation of the labels.</p> <code>__str__</code> <p>Return a readable representation of the labels.</p> <code>append</code> <p>Append a labeled frame to the labels.</p> <code>clean</code> <p>Remove empty frames, unused skeletons, tracks and videos.</p> <code>extend</code> <p>Append a labeled frame to the labels.</p> <code>extract</code> <p>Extract a set of frames into a new Labels object.</p> <code>find</code> <p>Search for labeled frames given video and/or frame index.</p> <code>from_numpy</code> <p>Create a new Labels object from a numpy array of tracks.</p> <code>make_training_splits</code> <p>Make splits for training with embedded images.</p> <code>merge</code> <p>Merge another Labels object into this one.</p> <code>numpy</code> <p>Construct a numpy array from instance points.</p> <code>remove_nodes</code> <p>Remove nodes from the skeleton.</p> <code>remove_predictions</code> <p>Remove all predicted instances from the labels.</p> <code>rename_nodes</code> <p>Rename nodes in the skeleton.</p> <code>reorder_nodes</code> <p>Reorder nodes in the skeleton.</p> <code>replace_filenames</code> <p>Replace video filenames.</p> <code>replace_skeleton</code> <p>Replace the skeleton in the labels.</p> <code>replace_videos</code> <p>Replace videos and update all references.</p> <code>save</code> <p>Save labels to file in specified format.</p> <code>set_video_plugin</code> <p>Reopen all media videos with the specified plugin.</p> <code>split</code> <p>Separate the labels into random splits.</p> <code>trim</code> <p>Trim the labels to a subset of frames and videos accordingly.</p> <code>update</code> <p>Update data structures based on contents.</p> <code>update_from_numpy</code> <p>Update instances from a numpy array of tracks.</p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>@define\nclass Labels:\n    \"\"\"Pose data for a set of videos that have user labels and/or predictions.\n\n    Attributes:\n        labeled_frames: A list of `LabeledFrame`s that are associated with this dataset.\n        videos: A list of `Video`s that are associated with this dataset. Videos do not\n            need to have corresponding `LabeledFrame`s if they do not have any\n            labels or predictions yet.\n        skeletons: A list of `Skeleton`s that are associated with this dataset. This\n            should generally only contain a single skeleton.\n        tracks: A list of `Track`s that are associated with this dataset.\n        suggestions: A list of `SuggestionFrame`s that are associated with this dataset.\n        sessions: A list of `RecordingSession`s that are associated with this dataset.\n        provenance: Dictionary of arbitrary metadata providing additional information\n            about where the dataset came from.\n\n    Notes:\n        `Video`s in contain `LabeledFrame`s, and `Skeleton`s and `Track`s in contained\n        `Instance`s are added to the respective lists automatically.\n    \"\"\"\n\n    labeled_frames: list[LabeledFrame] = field(factory=list)\n    videos: list[Video] = field(factory=list)\n    skeletons: list[Skeleton] = field(factory=list)\n    tracks: list[Track] = field(factory=list)\n    suggestions: list[SuggestionFrame] = field(factory=list)\n    sessions: list[RecordingSession] = field(factory=list)\n    provenance: dict[str, Any] = field(factory=dict)\n\n    def __attrs_post_init__(self):\n        \"\"\"Append videos, skeletons, and tracks seen in `labeled_frames` to `Labels`.\"\"\"\n        self.update()\n\n    def update(self):\n        \"\"\"Update data structures based on contents.\n\n        This function will update the list of skeletons, videos and tracks from the\n        labeled frames, instances and suggestions.\n        \"\"\"\n        for lf in self.labeled_frames:\n            if lf.video not in self.videos:\n                self.videos.append(lf.video)\n\n            for inst in lf:\n                if inst.skeleton not in self.skeletons:\n                    self.skeletons.append(inst.skeleton)\n\n                if inst.track is not None and inst.track not in self.tracks:\n                    self.tracks.append(inst.track)\n\n        for sf in self.suggestions:\n            if sf.video not in self.videos:\n                self.videos.append(sf.video)\n\n    def __getitem__(\n        self, key: int | slice | list[int] | np.ndarray | tuple[Video, int]\n    ) -&gt; list[LabeledFrame] | LabeledFrame:\n        \"\"\"Return one or more labeled frames based on indexing criteria.\"\"\"\n        if type(key) is int:\n            return self.labeled_frames[key]\n        elif type(key) is slice:\n            return [self.labeled_frames[i] for i in range(*key.indices(len(self)))]\n        elif type(key) is list:\n            return [self.labeled_frames[i] for i in key]\n        elif isinstance(key, np.ndarray):\n            return [self.labeled_frames[i] for i in key.tolist()]\n        elif type(key) is tuple and len(key) == 2:\n            video, frame_idx = key\n            res = self.find(video, frame_idx)\n            if len(res) == 1:\n                return res[0]\n            elif len(res) == 0:\n                raise IndexError(\n                    f\"No labeled frames found for video {video} and \"\n                    f\"frame index {frame_idx}.\"\n                )\n        elif type(key) is Video:\n            res = self.find(key)\n            if len(res) == 0:\n                raise IndexError(f\"No labeled frames found for video {key}.\")\n            return res\n        else:\n            raise IndexError(f\"Invalid indexing argument for labels: {key}\")\n\n    def __iter__(self):\n        \"\"\"Iterate over `labeled_frames` list when calling iter method on `Labels`.\"\"\"\n        return iter(self.labeled_frames)\n\n    def __len__(self) -&gt; int:\n        \"\"\"Return number of labeled frames.\"\"\"\n        return len(self.labeled_frames)\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return a readable representation of the labels.\"\"\"\n        return (\n            \"Labels(\"\n            f\"labeled_frames={len(self.labeled_frames)}, \"\n            f\"videos={len(self.videos)}, \"\n            f\"skeletons={len(self.skeletons)}, \"\n            f\"tracks={len(self.tracks)}, \"\n            f\"suggestions={len(self.suggestions)}, \"\n            f\"sessions={len(self.sessions)}\"\n            \")\"\n        )\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return a readable representation of the labels.\"\"\"\n        return self.__repr__()\n\n    def append(self, lf: LabeledFrame, update: bool = True):\n        \"\"\"Append a labeled frame to the labels.\n\n        Args:\n            lf: A labeled frame to add to the labels.\n            update: If `True` (the default), update list of videos, tracks and\n                skeletons from the contents.\n        \"\"\"\n        self.labeled_frames.append(lf)\n\n        if update:\n            if lf.video not in self.videos:\n                self.videos.append(lf.video)\n\n            for inst in lf:\n                if inst.skeleton not in self.skeletons:\n                    self.skeletons.append(inst.skeleton)\n\n                if inst.track is not None and inst.track not in self.tracks:\n                    self.tracks.append(inst.track)\n\n    def extend(self, lfs: list[LabeledFrame], update: bool = True):\n        \"\"\"Append a labeled frame to the labels.\n\n        Args:\n            lfs: A list of labeled frames to add to the labels.\n            update: If `True` (the default), update list of videos, tracks and\n                skeletons from the contents.\n        \"\"\"\n        self.labeled_frames.extend(lfs)\n\n        if update:\n            for lf in lfs:\n                if lf.video not in self.videos:\n                    self.videos.append(lf.video)\n\n                for inst in lf:\n                    if inst.skeleton not in self.skeletons:\n                        self.skeletons.append(inst.skeleton)\n\n                    if inst.track is not None and inst.track not in self.tracks:\n                        self.tracks.append(inst.track)\n\n    def numpy(\n        self,\n        video: Optional[Union[Video, int]] = None,\n        untracked: bool = False,\n        return_confidence: bool = False,\n        user_instances: bool = True,\n    ) -&gt; np.ndarray:\n        \"\"\"Construct a numpy array from instance points.\n\n        Args:\n            video: Video or video index to convert to numpy arrays. If `None` (the\n                default), uses the first video.\n            untracked: If `False` (the default), include only instances that have a\n                track assignment. If `True`, includes all instances in each frame in\n                arbitrary order.\n            return_confidence: If `False` (the default), only return points of nodes. If\n                `True`, return the points and scores of nodes.\n            user_instances: If `True` (the default), include user instances when\n                available, preferring them over predicted instances with the same track.\n                If `False`,\n                only include predicted instances.\n\n        Returns:\n            An array of tracks of shape `(n_frames, n_tracks, n_nodes, 2)` if\n            `return_confidence` is `False`. Otherwise returned shape is\n            `(n_frames, n_tracks, n_nodes, 3)` if `return_confidence` is `True`.\n\n            Missing data will be replaced with `np.nan`.\n\n            If this is a single instance project, a track does not need to be assigned.\n\n            When `user_instances=False`, only predicted instances will be returned.\n            When `user_instances=True`, user instances will be preferred over predicted\n            instances with the same track or if linked via `from_predicted`.\n\n        Notes:\n            This method assumes that instances have tracks assigned and is intended to\n            function primarily for single-video prediction results.\n        \"\"\"\n        # Get labeled frames for specified video.\n        if video is None:\n            video = 0\n        if type(video) is int:\n            video = self.videos[video]\n        lfs = [lf for lf in self.labeled_frames if lf.video == video]\n\n        # Figure out frame index range.\n        first_frame, last_frame = 0, 0\n        for lf in lfs:\n            first_frame = min(first_frame, lf.frame_idx)\n            last_frame = max(last_frame, lf.frame_idx)\n\n        # Figure out the number of tracks based on number of instances in each frame.\n        # Check the max number of instances (predicted or user, depending on settings)\n        n_instances = 0\n        for lf in lfs:\n            if user_instances:\n                # Count max of either user or predicted instances per frame (not sum)\n                n_frame_instances = max(\n                    len(lf.user_instances), len(lf.predicted_instances)\n                )\n            else:\n                n_frame_instances = len(lf.predicted_instances)\n            n_instances = max(n_instances, n_frame_instances)\n\n        # Case 1: We don't care about order because there's only 1 instance per frame,\n        # or we're considering untracked instances.\n        is_single_instance = n_instances == 1\n        untracked = untracked or is_single_instance\n        if untracked:\n            n_tracks = n_instances\n        else:\n            # Case 2: We're considering only tracked instances.\n            n_tracks = len(self.tracks)\n\n        n_frames = int(last_frame - first_frame + 1)\n        skeleton = self.skeletons[-1]  # Assume project only uses last skeleton\n        n_nodes = len(skeleton.nodes)\n\n        if return_confidence:\n            tracks = np.full((n_frames, n_tracks, n_nodes, 3), np.nan, dtype=\"float32\")\n        else:\n            tracks = np.full((n_frames, n_tracks, n_nodes, 2), np.nan, dtype=\"float32\")\n\n        for lf in lfs:\n            i = int(lf.frame_idx - first_frame)\n\n            if untracked:\n                # For untracked instances, fill them in arbitrary order\n                j = 0\n                instances_to_include = []\n\n                # If user instances are preferred, add them first\n                if user_instances and lf.has_user_instances:\n                    # First collect all user instances\n                    for inst in lf.user_instances:\n                        instances_to_include.append(inst)\n\n                    # For the trivial case (single instance per frame), if we found\n                    # user instances, we shouldn't include any predicted instances\n                    if is_single_instance and len(instances_to_include) &gt; 0:\n                        pass  # Skip adding predicted instances\n                    else:\n                        # Add predicted instances that don't have a corresponding\n                        # user instance\n                        for inst in lf.predicted_instances:\n                            skip = False\n                            for user_inst in lf.user_instances:\n                                # Skip if this predicted instance is linked to a user\n                                # instance via from_predicted\n                                if (\n                                    hasattr(user_inst, \"from_predicted\")\n                                    and user_inst.from_predicted == inst\n                                ):\n                                    skip = True\n                                    break\n                                # Skip if user and predicted instances share same track\n                                if (\n                                    user_inst.track is not None\n                                    and inst.track is not None\n                                    and user_inst.track == inst.track\n                                ):\n                                    skip = True\n                                    break\n                            if not skip:\n                                instances_to_include.append(inst)\n                else:\n                    # If user_instances=False, only include predicted instances\n                    instances_to_include = lf.predicted_instances\n\n                # Now process all the instances we want to include\n                for inst in instances_to_include:\n                    if j &lt; n_tracks:\n                        if return_confidence:\n                            if isinstance(inst, PredictedInstance):\n                                tracks[i, j] = inst.numpy(scores=True)\n                            else:\n                                # For user instances, set confidence to 1.0\n                                points_data = inst.numpy()\n                                confidence = np.ones(\n                                    (points_data.shape[0], 1), dtype=\"float32\"\n                                )\n                                tracks[i, j] = np.hstack((points_data, confidence))\n                        else:\n                            tracks[i, j] = inst.numpy()\n                        j += 1\n            else:  # untracked is False\n                # For tracked instances, organize by track ID\n\n                # Create mapping from track to best instance for this frame\n                track_to_instance = {}\n\n                # First, add predicted instances to the mapping\n                for inst in lf.predicted_instances:\n                    if inst.track is not None:\n                        track_to_instance[inst.track] = inst\n\n                # Then, add user instances to the mapping (if user_instances=True)\n                if user_instances:\n                    for inst in lf.user_instances:\n                        if inst.track is not None:\n                            track_to_instance[inst.track] = inst\n\n                # Process the preferred instances for each track\n                for track in track_to_instance:\n                    inst = track_to_instance[track]\n                    j = self.tracks.index(track)\n\n                    if type(inst) is PredictedInstance:\n                        tracks[i, j] = inst.numpy(scores=return_confidence)\n                    elif type(inst) is Instance:\n                        tracks[i, j, :, :2] = inst.numpy()\n\n                        # If return_confidence is True, add dummy confidence scores\n                        if return_confidence:\n                            tracks[i, j, :, 2] = 1.0\n\n        return tracks\n\n    @classmethod\n    def from_numpy(\n        cls,\n        tracks_arr: np.ndarray,\n        videos: list[Video],\n        skeletons: list[Skeleton] | Skeleton | None = None,\n        tracks: list[Track] | None = None,\n        first_frame: int = 0,\n        return_confidence: bool = False,\n    ) -&gt; \"Labels\":\n        \"\"\"Create a new Labels object from a numpy array of tracks.\n\n        This factory method creates a new Labels object with instances constructed from\n        the provided numpy array. It is the inverse operation of `Labels.numpy()`.\n\n        Args:\n            tracks_arr: A numpy array of tracks, with shape\n                `(n_frames, n_tracks, n_nodes, 2)` or\n                `(n_frames, n_tracks, n_nodes, 3)`,\n                where the last dimension contains the x,y coordinates (and optionally\n                confidence scores).\n            videos: List of Video objects to associate with the labels. At least one\n                video\n                is required.\n            skeletons: Skeleton or list of Skeleton objects to use for the instances.\n                At least one skeleton is required.\n            tracks: List of Track objects corresponding to the second dimension of the\n                array. If not specified, new tracks will be created automatically.\n            first_frame: Frame index to start the labeled frames from. Default is 0.\n            return_confidence: Whether the tracks_arr contains confidence scores in the\n                last dimension. If True, tracks_arr.shape[-1] should be 3.\n\n        Returns:\n            A new Labels object with instances constructed from the numpy array.\n\n        Raises:\n            ValueError: If the array dimensions are invalid, or if no videos or\n                skeletons are provided.\n\n        Examples:\n            &gt;&gt;&gt; import numpy as np\n            &gt;&gt;&gt; from sleap_io import Labels, Video, Skeleton\n            &gt;&gt;&gt; # Create a simple tracking array for 2 frames, 1 track, 2 nodes\n            &gt;&gt;&gt; arr = np.zeros((2, 1, 2, 2))\n            &gt;&gt;&gt; arr[0, 0] = [[10, 20], [30, 40]]  # Frame 0\n            &gt;&gt;&gt; arr[1, 0] = [[15, 25], [35, 45]]  # Frame 1\n            &gt;&gt;&gt; # Create a video and skeleton\n            &gt;&gt;&gt; video = Video(filename=\"example.mp4\")\n            &gt;&gt;&gt; skeleton = Skeleton([\"head\", \"tail\"])\n            &gt;&gt;&gt; # Create labels from the array\n            &gt;&gt;&gt; labels = Labels.from_numpy(arr, videos=[video], skeletons=[skeleton])\n        \"\"\"\n        # Check dimensions\n        if len(tracks_arr.shape) != 4:\n            raise ValueError(\n                f\"Array must have 4 dimensions (n_frames, n_tracks, n_nodes, 2 or 3), \"\n                f\"but got {tracks_arr.shape}\"\n            )\n\n        # Validate videos\n        if not videos:\n            raise ValueError(\"At least one video must be provided\")\n        video = videos[0]  # Use the first video for creating labeled frames\n\n        # Process skeletons input\n        if skeletons is None:\n            raise ValueError(\"At least one skeleton must be provided\")\n        elif isinstance(skeletons, Skeleton):\n            skeletons = [skeletons]\n        elif not skeletons:  # Check for empty list\n            raise ValueError(\"At least one skeleton must be provided\")\n\n        skeleton = skeletons[0]  # Use the first skeleton for creating instances\n        n_nodes = len(skeleton.nodes)\n\n        # Check if tracks_arr contains confidence scores\n        has_confidence = tracks_arr.shape[-1] == 3 or return_confidence\n\n        # Get dimensions\n        n_frames, n_tracks_arr, _ = tracks_arr.shape[:3]\n\n        # Create or validate tracks\n        if tracks is None:\n            # Auto-create tracks if not provided\n            tracks = [Track(f\"track_{i}\") for i in range(n_tracks_arr)]\n        elif len(tracks) &lt; n_tracks_arr:\n            # Add missing tracks if needed\n            original_len = len(tracks)\n            for i in range(n_tracks_arr - original_len):\n                tracks.append(Track(f\"track_{i}\"))\n\n        # Create a new empty Labels object\n        labels = cls()\n        labels.videos = list(videos)\n        labels.skeletons = list(skeletons)\n        labels.tracks = list(tracks)\n\n        # Create labeled frames and instances from the array data\n        for i in range(n_frames):\n            frame_idx = i + first_frame\n\n            # Check if this frame has any valid data across all tracks\n            frame_has_valid_data = False\n            for j in range(n_tracks_arr):\n                track_data = tracks_arr[i, j]\n                # Check if at least one node in this track has valid xy coordinates\n                if np.any(~np.isnan(track_data[:, 0])):\n                    frame_has_valid_data = True\n                    break\n\n            # Skip creating a frame if there's no valid data\n            if not frame_has_valid_data:\n                continue\n\n            # Create a new labeled frame\n            labeled_frame = LabeledFrame(video=video, frame_idx=frame_idx)\n            frame_has_valid_instances = False\n\n            # Process each track in this frame\n            for j in range(n_tracks_arr):\n                track = tracks[j]\n                track_data = tracks_arr[i, j]\n\n                # Check if there's any valid data for this track at this frame\n                valid_points = ~np.isnan(track_data[:, 0])\n                if not np.any(valid_points):\n                    continue\n\n                # Create points from numpy data\n                points = track_data[:, :2].copy()\n\n                # Create new instance\n                if has_confidence:\n                    # Get confidence scores\n                    if tracks_arr.shape[-1] == 3:\n                        scores = track_data[:, 2].copy()\n                    else:\n                        scores = np.ones(n_nodes)\n\n                    # Fix NaN scores\n                    scores = np.where(np.isnan(scores), 1.0, scores)\n\n                    # Create instance with confidence scores\n                    new_instance = PredictedInstance.from_numpy(\n                        points_data=points,\n                        skeleton=skeleton,\n                        point_scores=scores,\n                        score=1.0,\n                        track=track,\n                    )\n                else:\n                    # Create instance with default scores\n                    new_instance = PredictedInstance.from_numpy(\n                        points_data=points,\n                        skeleton=skeleton,\n                        point_scores=np.ones(n_nodes),\n                        score=1.0,\n                        track=track,\n                    )\n\n                # Add to frame\n                labeled_frame.instances.append(new_instance)\n                frame_has_valid_instances = True\n\n            # Only add frames that have instances\n            if frame_has_valid_instances:\n                labels.append(labeled_frame, update=False)\n\n        # Update internal references\n        labels.update()\n\n        return labels\n\n    @property\n    def video(self) -&gt; Video:\n        \"\"\"Return the video if there is only a single video in the labels.\"\"\"\n        if len(self.videos) == 0:\n            raise ValueError(\"There are no videos in the labels.\")\n        elif len(self.videos) == 1:\n            return self.videos[0]\n        else:\n            raise ValueError(\n                \"Labels.video can only be used when there is only a single video saved \"\n                \"in the labels. Use Labels.videos instead.\"\n            )\n\n    @property\n    def skeleton(self) -&gt; Skeleton:\n        \"\"\"Return the skeleton if there is only a single skeleton in the labels.\"\"\"\n        if len(self.skeletons) == 0:\n            raise ValueError(\"There are no skeletons in the labels.\")\n        elif len(self.skeletons) == 1:\n            return self.skeletons[0]\n        else:\n            raise ValueError(\n                \"Labels.skeleton can only be used when there is only a single skeleton \"\n                \"saved in the labels. Use Labels.skeletons instead.\"\n            )\n\n    def find(\n        self,\n        video: Video,\n        frame_idx: int | list[int] | None = None,\n        return_new: bool = False,\n    ) -&gt; list[LabeledFrame]:\n        \"\"\"Search for labeled frames given video and/or frame index.\n\n        Args:\n            video: A `Video` that is associated with the project.\n            frame_idx: The frame index (or indices) which we want to find in the video.\n                If a range is specified, we'll return all frames with indices in that\n                range. If not specific, then we'll return all labeled frames for video.\n            return_new: Whether to return singleton of new and empty `LabeledFrame` if\n                none are found in project.\n\n        Returns:\n            List of `LabeledFrame` objects that match the criteria.\n\n            The list will be empty if no matches found, unless return_new is True, in\n            which case it contains new (empty) `LabeledFrame` objects with `video` and\n            `frame_index` set.\n        \"\"\"\n        results = []\n\n        if frame_idx is None:\n            for lf in self.labeled_frames:\n                if lf.video == video:\n                    results.append(lf)\n            return results\n\n        if np.isscalar(frame_idx):\n            frame_idx = np.array(frame_idx).reshape(-1)\n\n        for frame_ind in frame_idx:\n            result = None\n            for lf in self.labeled_frames:\n                if lf.video == video and lf.frame_idx == frame_ind:\n                    result = lf\n                    results.append(result)\n                    break\n            if result is None and return_new:\n                results.append(LabeledFrame(video=video, frame_idx=frame_ind))\n\n        return results\n\n    def save(\n        self,\n        filename: str,\n        format: Optional[str] = None,\n        embed: bool | str | list[tuple[Video, int]] | None = False,\n        restore_original_videos: bool = True,\n        verbose: bool = True,\n        **kwargs,\n    ):\n        \"\"\"Save labels to file in specified format.\n\n        Args:\n            filename: Path to save labels to.\n            format: The format to save the labels in. If `None`, the format will be\n                inferred from the file extension. Available formats are `\"slp\"`,\n                `\"nwb\"`, `\"labelstudio\"`, and `\"jabs\"`.\n            embed: Frames to embed in the saved labels file. One of `None`, `True`,\n                `\"all\"`, `\"user\"`, `\"suggestions\"`, `\"user+suggestions\"`, `\"source\"` or\n                list of tuples of `(video, frame_idx)`.\n\n                If `False` is specified (the default), the source video will be\n                restored if available, otherwise the embedded frames will be re-saved.\n\n                If `True` or `\"all\"`, all labeled frames and suggested frames will be\n                embedded.\n\n                If `\"source\"` is specified, no images will be embedded and the source\n                video will be restored if available.\n\n                This argument is only valid for the SLP backend.\n            restore_original_videos: If `True` (default) and `embed=False`, use original\n                video files. If `False` and `embed=False`, keep references to source\n                `.pkg.slp` files. Only applies when `embed=False`.\n            verbose: If `True` (the default), display a progress bar when embedding\n                frames.\n            **kwargs: Additional format-specific arguments passed to the save function.\n                See `save_file` for format-specific options.\n        \"\"\"\n        from pathlib import Path\n\n        from sleap_io import save_file\n        from sleap_io.io.slp import sanitize_filename\n\n        # Check for self-referential save when embed=False\n        if embed is False and (format == \"slp\" or str(filename).endswith(\".slp\")):\n            # Check if any videos have embedded images and would be self-referential\n            sanitized_save_path = Path(sanitize_filename(filename)).resolve()\n            for video in self.videos:\n                if (\n                    hasattr(video.backend, \"has_embedded_images\")\n                    and video.backend.has_embedded_images\n                    and video.source_video is None\n                ):\n                    sanitized_video_path = Path(\n                        sanitize_filename(video.filename)\n                    ).resolve()\n                    if sanitized_video_path == sanitized_save_path:\n                        raise ValueError(\n                            f\"Cannot save with embed=False when overwriting a file \"\n                            f\"that contains embedded videos. Use \"\n                            f\"labels.save('{filename}', embed=True) to re-embed the \"\n                            f\"frames, or save to a different filename.\"\n                        )\n\n        save_file(\n            self,\n            filename,\n            format=format,\n            embed=embed,\n            restore_original_videos=restore_original_videos,\n            verbose=verbose,\n            **kwargs,\n        )\n\n    def clean(\n        self,\n        frames: bool = True,\n        empty_instances: bool = False,\n        skeletons: bool = True,\n        tracks: bool = True,\n        videos: bool = False,\n    ):\n        \"\"\"Remove empty frames, unused skeletons, tracks and videos.\n\n        Args:\n            frames: If `True` (the default), remove empty frames.\n            empty_instances: If `True` (NOT default), remove instances that have no\n                visible points.\n            skeletons: If `True` (the default), remove unused skeletons.\n            tracks: If `True` (the default), remove unused tracks.\n            videos: If `True` (NOT default), remove videos that have no labeled frames.\n        \"\"\"\n        used_skeletons = []\n        used_tracks = []\n        used_videos = []\n        kept_frames = []\n        for lf in self.labeled_frames:\n            if empty_instances:\n                lf.remove_empty_instances()\n\n            if frames and len(lf) == 0:\n                continue\n\n            if videos and lf.video not in used_videos:\n                used_videos.append(lf.video)\n\n            if skeletons or tracks:\n                for inst in lf:\n                    if skeletons and inst.skeleton not in used_skeletons:\n                        used_skeletons.append(inst.skeleton)\n                    if (\n                        tracks\n                        and inst.track is not None\n                        and inst.track not in used_tracks\n                    ):\n                        used_tracks.append(inst.track)\n\n            if frames:\n                kept_frames.append(lf)\n\n        if videos:\n            self.videos = [video for video in self.videos if video in used_videos]\n\n        if skeletons:\n            self.skeletons = [\n                skeleton for skeleton in self.skeletons if skeleton in used_skeletons\n            ]\n\n        if tracks:\n            self.tracks = [track for track in self.tracks if track in used_tracks]\n\n        if frames:\n            self.labeled_frames = kept_frames\n\n    def remove_predictions(self, clean: bool = True):\n        \"\"\"Remove all predicted instances from the labels.\n\n        Args:\n            clean: If `True` (the default), also remove any empty frames and unused\n                tracks and skeletons. It does NOT remove videos that have no labeled\n                frames or instances with no visible points.\n\n        See also: `Labels.clean`\n        \"\"\"\n        for lf in self.labeled_frames:\n            lf.remove_predictions()\n\n        if clean:\n            self.clean(\n                frames=True,\n                empty_instances=False,\n                skeletons=True,\n                tracks=True,\n                videos=False,\n            )\n\n    @property\n    def user_labeled_frames(self) -&gt; list[LabeledFrame]:\n        \"\"\"Return all labeled frames with user (non-predicted) instances.\"\"\"\n        return [lf for lf in self.labeled_frames if lf.has_user_instances]\n\n    @property\n    def instances(self) -&gt; Iterator[Instance]:\n        \"\"\"Return an iterator over all instances within all labeled frames.\"\"\"\n        return (instance for lf in self.labeled_frames for instance in lf.instances)\n\n    def rename_nodes(\n        self,\n        name_map: dict[NodeOrIndex, str] | list[str],\n        skeleton: Skeleton | None = None,\n    ):\n        \"\"\"Rename nodes in the skeleton.\n\n        Args:\n            name_map: A dictionary mapping old node names to new node names. Keys can be\n                specified as `Node` objects, integer indices, or string names. Values\n                must be specified as string names.\n\n                If a list of strings is provided of the same length as the current\n                nodes, the nodes will be renamed to the names in the list in order.\n            skeleton: `Skeleton` to update. If `None` (the default), assumes there is\n                only one skeleton in the labels and raises `ValueError` otherwise.\n\n        Raises:\n            ValueError: If the new node names exist in the skeleton, if the old node\n                names are not found in the skeleton, or if there is more than one\n                skeleton in the `Labels` but it is not specified.\n\n        Notes:\n            This method is recommended over `Skeleton.rename_nodes` as it will update\n            all instances in the labels to reflect the new node names.\n\n        Example:\n            &gt;&gt;&gt; labels = Labels(skeletons=[Skeleton([\"A\", \"B\", \"C\"])])\n            &gt;&gt;&gt; labels.rename_nodes({\"A\": \"X\", \"B\": \"Y\", \"C\": \"Z\"})\n            &gt;&gt;&gt; labels.skeleton.node_names\n            [\"X\", \"Y\", \"Z\"]\n            &gt;&gt;&gt; labels.rename_nodes([\"a\", \"b\", \"c\"])\n            &gt;&gt;&gt; labels.skeleton.node_names\n            [\"a\", \"b\", \"c\"]\n        \"\"\"\n        if skeleton is None:\n            if len(self.skeletons) != 1:\n                raise ValueError(\n                    \"Skeleton must be specified when there is more than one skeleton \"\n                    \"in the labels.\"\n                )\n            skeleton = self.skeleton\n\n        skeleton.rename_nodes(name_map)\n\n        # Update instances.\n        for inst in self.instances:\n            if inst.skeleton == skeleton:\n                inst.points[\"name\"] = inst.skeleton.node_names\n\n    def remove_nodes(self, nodes: list[NodeOrIndex], skeleton: Skeleton | None = None):\n        \"\"\"Remove nodes from the skeleton.\n\n        Args:\n            nodes: A list of node names, indices, or `Node` objects to remove.\n            skeleton: `Skeleton` to update. If `None` (the default), assumes there is\n                only one skeleton in the labels and raises `ValueError` otherwise.\n\n        Raises:\n            ValueError: If the nodes are not found in the skeleton, or if there is more\n                than one skeleton in the labels and it is not specified.\n\n        Notes:\n            This method should always be used when removing nodes from the skeleton as\n            it handles updating the lookup caches necessary for indexing nodes by name,\n            and updating instances to reflect the changes made to the skeleton.\n\n            Any edges and symmetries that are connected to the removed nodes will also\n            be removed.\n        \"\"\"\n        if skeleton is None:\n            if len(self.skeletons) != 1:\n                raise ValueError(\n                    \"Skeleton must be specified when there is more than one skeleton \"\n                    \"in the labels.\"\n                )\n            skeleton = self.skeleton\n\n        skeleton.remove_nodes(nodes)\n\n        for inst in self.instances:\n            if inst.skeleton == skeleton:\n                inst.update_skeleton()\n\n    def reorder_nodes(\n        self, new_order: list[NodeOrIndex], skeleton: Skeleton | None = None\n    ):\n        \"\"\"Reorder nodes in the skeleton.\n\n        Args:\n            new_order: A list of node names, indices, or `Node` objects specifying the\n                new order of the nodes.\n            skeleton: `Skeleton` to update. If `None` (the default), assumes there is\n                only one skeleton in the labels and raises `ValueError` otherwise.\n\n        Raises:\n            ValueError: If the new order of nodes is not the same length as the current\n                nodes, or if there is more than one skeleton in the `Labels` but it is\n                not specified.\n\n        Notes:\n            This method handles updating the lookup caches necessary for indexing nodes\n            by name, as well as updating instances to reflect the changes made to the\n            skeleton.\n        \"\"\"\n        if skeleton is None:\n            if len(self.skeletons) != 1:\n                raise ValueError(\n                    \"Skeleton must be specified when there is more than one skeleton \"\n                    \"in the labels.\"\n                )\n            skeleton = self.skeleton\n\n        skeleton.reorder_nodes(new_order)\n\n        for inst in self.instances:\n            if inst.skeleton == skeleton:\n                inst.update_skeleton()\n\n    def replace_skeleton(\n        self,\n        new_skeleton: Skeleton,\n        old_skeleton: Skeleton | None = None,\n        node_map: dict[NodeOrIndex, NodeOrIndex] | None = None,\n    ):\n        \"\"\"Replace the skeleton in the labels.\n\n        Args:\n            new_skeleton: The new `Skeleton` to replace the old skeleton with.\n            old_skeleton: The old `Skeleton` to replace. If `None` (the default),\n                assumes there is only one skeleton in the labels and raises `ValueError`\n                otherwise.\n            node_map: Dictionary mapping nodes in the old skeleton to nodes in the new\n                skeleton. Keys and values can be specified as `Node` objects, integer\n                indices, or string names. If not provided, only nodes with identical\n                names will be mapped. Points associated with unmapped nodes will be\n                removed.\n\n        Raises:\n            ValueError: If there is more than one skeleton in the `Labels` but it is not\n                specified.\n\n        Warning:\n            This method will replace the skeleton in all instances in the labels that\n            have the old skeleton. **All point data associated with nodes not in the\n            `node_map` will be lost.**\n        \"\"\"\n        if old_skeleton is None:\n            if len(self.skeletons) != 1:\n                raise ValueError(\n                    \"Old skeleton must be specified when there is more than one \"\n                    \"skeleton in the labels.\"\n                )\n            old_skeleton = self.skeleton\n\n        if node_map is None:\n            node_map = {}\n            for old_node in old_skeleton.nodes:\n                for new_node in new_skeleton.nodes:\n                    if old_node.name == new_node.name:\n                        node_map[old_node] = new_node\n                        break\n        else:\n            node_map = {\n                old_skeleton.require_node(\n                    old, add_missing=False\n                ): new_skeleton.require_node(new, add_missing=False)\n                for old, new in node_map.items()\n            }\n\n        # Create node name map.\n        node_names_map = {old.name: new.name for old, new in node_map.items()}\n\n        # Replace the skeleton in the instances.\n        for inst in self.instances:\n            if inst.skeleton == old_skeleton:\n                inst.replace_skeleton(\n                    new_skeleton=new_skeleton, node_names_map=node_names_map\n                )\n\n        # Replace the skeleton in the labels.\n        self.skeletons[self.skeletons.index(old_skeleton)] = new_skeleton\n\n    def replace_videos(\n        self,\n        old_videos: list[Video] | None = None,\n        new_videos: list[Video] | None = None,\n        video_map: dict[Video, Video] | None = None,\n    ):\n        \"\"\"Replace videos and update all references.\n\n        Args:\n            old_videos: List of videos to be replaced.\n            new_videos: List of videos to replace with.\n            video_map: Alternative input of dictionary where keys are the old videos and\n                values are the new videos.\n        \"\"\"\n        if (\n            old_videos is None\n            and new_videos is not None\n            and len(new_videos) == len(self.videos)\n        ):\n            old_videos = self.videos\n\n        if video_map is None:\n            video_map = {o: n for o, n in zip(old_videos, new_videos)}\n\n        # Update the labeled frames with the new videos.\n        for lf in self.labeled_frames:\n            if lf.video in video_map:\n                lf.video = video_map[lf.video]\n\n        # Update suggestions with the new videos.\n        for sf in self.suggestions:\n            if sf.video in video_map:\n                sf.video = video_map[sf.video]\n\n        # Update the list of videos.\n        self.videos = [video_map.get(video, video) for video in self.videos]\n\n    def replace_filenames(\n        self,\n        new_filenames: list[str | Path] | None = None,\n        filename_map: dict[str | Path, str | Path] | None = None,\n        prefix_map: dict[str | Path, str | Path] | None = None,\n        open_videos: bool = True,\n    ):\n        \"\"\"Replace video filenames.\n\n        Args:\n            new_filenames: List of new filenames. Must have the same length as the\n                number of videos in the labels.\n            filename_map: Dictionary mapping old filenames (keys) to new filenames\n                (values).\n            prefix_map: Dictionary mapping old prefixes (keys) to new prefixes (values).\n            open_videos: If `True` (the default), attempt to open the video backend for\n                I/O after replacing the filename. If `False`, the backend will not be\n                opened (useful for operations with costly file existence checks).\n\n        Notes:\n            Only one of the argument types can be provided.\n        \"\"\"\n        n = 0\n        if new_filenames is not None:\n            n += 1\n        if filename_map is not None:\n            n += 1\n        if prefix_map is not None:\n            n += 1\n        if n != 1:\n            raise ValueError(\n                \"Exactly one input method must be provided to replace filenames.\"\n            )\n\n        if new_filenames is not None:\n            if len(self.videos) != len(new_filenames):\n                raise ValueError(\n                    f\"Number of new filenames ({len(new_filenames)}) does not match \"\n                    f\"the number of videos ({len(self.videos)}).\"\n                )\n\n            for video, new_filename in zip(self.videos, new_filenames):\n                video.replace_filename(new_filename, open=open_videos)\n\n        elif filename_map is not None:\n            for video in self.videos:\n                for old_fn, new_fn in filename_map.items():\n                    if type(video.filename) is list:\n                        new_fns = []\n                        for fn in video.filename:\n                            if Path(fn) == Path(old_fn):\n                                new_fns.append(new_fn)\n                            else:\n                                new_fns.append(fn)\n                        video.replace_filename(new_fns, open=open_videos)\n                    else:\n                        if Path(video.filename) == Path(old_fn):\n                            video.replace_filename(new_fn, open=open_videos)\n\n        elif prefix_map is not None:\n            for video in self.videos:\n                for old_prefix, new_prefix in prefix_map.items():\n                    # Sanitize old_prefix for cross-platform matching\n                    old_prefix_sanitized = sanitize_filename(old_prefix)\n\n                    # Check if old prefix ends with a separator\n                    old_ends_with_sep = old_prefix_sanitized.endswith(\"/\")\n\n                    if type(video.filename) is list:\n                        new_fns = []\n                        for fn in video.filename:\n                            # Sanitize filename for matching\n                            fn_sanitized = sanitize_filename(fn)\n\n                            if fn_sanitized.startswith(old_prefix_sanitized):\n                                # Calculate the remainder after removing the prefix\n                                remainder = fn_sanitized[len(old_prefix_sanitized) :]\n\n                                # Build the new filename\n                                if remainder.startswith(\"/\"):\n                                    # Remainder has separator, remove it to avoid double\n                                    # slash\n                                    remainder = remainder[1:]\n                                    # Always add separator between prefix and remainder\n                                    if new_prefix and not new_prefix.endswith(\n                                        (\"/\", \"\\\\\")\n                                    ):\n                                        new_fn = new_prefix + \"/\" + remainder\n                                    else:\n                                        new_fn = new_prefix + remainder\n                                elif old_ends_with_sep:\n                                    # Old prefix had separator, preserve it in the new\n                                    # one\n                                    if new_prefix and not new_prefix.endswith(\n                                        (\"/\", \"\\\\\")\n                                    ):\n                                        new_fn = new_prefix + \"/\" + remainder\n                                    else:\n                                        new_fn = new_prefix + remainder\n                                else:\n                                    # No separator in old prefix, don't add one\n                                    new_fn = new_prefix + remainder\n\n                                new_fns.append(new_fn)\n                            else:\n                                new_fns.append(fn)\n                        video.replace_filename(new_fns, open=open_videos)\n                    else:\n                        # Sanitize filename for matching\n                        fn_sanitized = sanitize_filename(video.filename)\n\n                        if fn_sanitized.startswith(old_prefix_sanitized):\n                            # Calculate the remainder after removing the prefix\n                            remainder = fn_sanitized[len(old_prefix_sanitized) :]\n\n                            # Build the new filename\n                            if remainder.startswith(\"/\"):\n                                # Remainder has separator, remove it to avoid double\n                                # slash\n                                remainder = remainder[1:]\n                                # Always add separator between prefix and remainder\n                                if new_prefix and not new_prefix.endswith((\"/\", \"\\\\\")):\n                                    new_fn = new_prefix + \"/\" + remainder\n                                else:\n                                    new_fn = new_prefix + remainder\n                            elif old_ends_with_sep:\n                                # Old prefix had separator, preserve it in the new one\n                                if new_prefix and not new_prefix.endswith((\"/\", \"\\\\\")):\n                                    new_fn = new_prefix + \"/\" + remainder\n                                else:\n                                    new_fn = new_prefix + remainder\n                            else:\n                                # No separator in old prefix, don't add one\n                                new_fn = new_prefix + remainder\n\n                            video.replace_filename(new_fn, open=open_videos)\n\n    def extract(\n        self, inds: list[int] | list[tuple[Video, int]] | np.ndarray, copy: bool = True\n    ) -&gt; Labels:\n        \"\"\"Extract a set of frames into a new Labels object.\n\n        Args:\n            inds: Indices of labeled frames. Can be specified as a list of array of\n                integer indices of labeled frames or tuples of Video and frame indices.\n            copy: If `True` (the default), return a copy of the frames and containing\n                objects. Otherwise, return a reference to the data.\n\n        Returns:\n            A new `Labels` object containing the selected labels.\n\n        Notes:\n            This copies the labeled frames and their associated data, including\n            skeletons and tracks, and tries to maintain the relative ordering.\n\n            This also copies the provenance and inserts an extra key: `\"source_labels\"`\n            with the path to the current labels, if available.\n\n            It does NOT copy suggested frames.\n        \"\"\"\n        lfs = self[inds]\n\n        if copy:\n            lfs = deepcopy(lfs)\n        labels = Labels(lfs)\n\n        # Try to keep the lists in the same order.\n        track_to_ind = {track.name: ind for ind, track in enumerate(self.tracks)}\n        labels.tracks = sorted(labels.tracks, key=lambda x: track_to_ind[x.name])\n\n        skel_to_ind = {skel.name: ind for ind, skel in enumerate(self.skeletons)}\n        labels.skeletons = sorted(labels.skeletons, key=lambda x: skel_to_ind[x.name])\n\n        labels.provenance = deepcopy(labels.provenance)\n        labels.provenance[\"source_labels\"] = self.provenance.get(\"filename\", None)\n\n        return labels\n\n    def split(self, n: int | float, seed: int | None = None):\n        \"\"\"Separate the labels into random splits.\n\n        Args:\n            n: Size of the first split. If integer &gt;= 1, assumes that this is the number\n                of labeled frames in the first split. If &lt; 1.0, this will be treated as\n                a fraction of the total labeled frames.\n            seed: Optional integer seed to use for reproducibility.\n\n        Returns:\n            A LabelsSet with keys \"split1\" and \"split2\".\n\n            If an integer was specified, `len(split1) == n`.\n\n            If a fraction was specified, `len(split1) == int(n * len(labels))`.\n\n            The second split contains the remainder, i.e.,\n            `len(split2) == len(labels) - len(split1)`.\n\n            If there are too few frames, a minimum of 1 frame will be kept in the second\n            split.\n\n            If there is exactly 1 labeled frame in the labels, the same frame will be\n            assigned to both splits.\n\n        Notes:\n            This method now returns a LabelsSet for easier management of splits.\n            For backward compatibility, the returned LabelsSet can be unpacked like\n            a tuple:\n            `split1, split2 = labels.split(0.8)`\n        \"\"\"\n        # Import here to avoid circular imports\n        from sleap_io.model.labels_set import LabelsSet\n\n        n0 = len(self)\n        if n0 == 0:\n            return LabelsSet({\"split1\": self, \"split2\": self})\n        n1 = n\n        if n &lt; 1.0:\n            n1 = max(int(n0 * float(n)), 1)\n        n2 = max(n0 - n1, 1)\n        n1, n2 = int(n1), int(n2)\n\n        rng = np.random.default_rng(seed=seed)\n        inds1 = rng.choice(n0, size=(n1,), replace=False)\n\n        if n0 == 1:\n            inds2 = np.array([0])\n        else:\n            inds2 = np.setdiff1d(np.arange(n0), inds1)\n\n        split1 = self.extract(inds1, copy=True)\n        split2 = self.extract(inds2, copy=True)\n\n        return LabelsSet({\"split1\": split1, \"split2\": split2})\n\n    def make_training_splits(\n        self,\n        n_train: int | float,\n        n_val: int | float | None = None,\n        n_test: int | float | None = None,\n        save_dir: str | Path | None = None,\n        seed: int | None = None,\n        embed: bool = True,\n    ) -&gt; LabelsSet:\n        \"\"\"Make splits for training with embedded images.\n\n        Args:\n            n_train: Size of the training split as integer or fraction.\n            n_val: Size of the validation split as integer or fraction. If `None`,\n                this will be inferred based on the values of `n_train` and `n_test`. If\n                `n_test` is `None`, this will be the remainder of the data after the\n                training split.\n            n_test: Size of the testing split as integer or fraction. If `None`, the\n                test split will not be saved.\n            save_dir: If specified, save splits to SLP files with embedded images.\n            seed: Optional integer seed to use for reproducibility.\n            embed: If `True` (the default), embed user labeled frame images in the saved\n                files, which is useful for portability but can be slow for large\n                projects. If `False`, labels are saved with references to the source\n                videos files.\n\n        Returns:\n            A `LabelsSet` containing \"train\", \"val\", and optionally \"test\" keys.\n            The `LabelsSet` can be unpacked for backward compatibility:\n            `train, val = labels.make_training_splits(0.8)`\n            `train, val, test = labels.make_training_splits(0.8, n_test=0.1)`\n\n        Notes:\n            Predictions and suggestions will be removed before saving, leaving only\n            frames with user labeled data (the source labels are not affected).\n\n            Frames with user labeled data will be embedded in the resulting files.\n\n            If `save_dir` is specified, this will save the randomly sampled splits to:\n\n            - `{save_dir}/train.pkg.slp`\n            - `{save_dir}/val.pkg.slp`\n            - `{save_dir}/test.pkg.slp` (if `n_test` is specified)\n\n            If `embed` is `False`, the files will be saved without embedded images to:\n\n            - `{save_dir}/train.slp`\n            - `{save_dir}/val.slp`\n            - `{save_dir}/test.slp` (if `n_test` is specified)\n\n        See also: `Labels.split`\n        \"\"\"\n        # Import here to avoid circular imports\n        from sleap_io.model.labels_set import LabelsSet\n\n        # Clean up labels.\n        labels = deepcopy(self)\n        labels.remove_predictions()\n        labels.suggestions = []\n        labels.clean()\n\n        # Make train split.\n        labels_train, labels_rest = labels.split(n_train, seed=seed)\n\n        # Make test split.\n        if n_test is not None:\n            if n_test &lt; 1:\n                n_test = (n_test * len(labels)) / len(labels_rest)\n            labels_test, labels_rest = labels_rest.split(n=n_test, seed=seed)\n\n        # Make val split.\n        if n_val is not None:\n            if n_val &lt; 1:\n                n_val = (n_val * len(labels)) / len(labels_rest)\n            if isinstance(n_val, float) and n_val == 1.0:\n                labels_val = labels_rest\n            else:\n                labels_val, _ = labels_rest.split(n=n_val, seed=seed)\n        else:\n            labels_val = labels_rest\n\n        # Update provenance.\n        source_labels = self.provenance.get(\"filename\", None)\n        labels_train.provenance[\"source_labels\"] = source_labels\n        if n_val is not None:\n            labels_val.provenance[\"source_labels\"] = source_labels\n        if n_test is not None:\n            labels_test.provenance[\"source_labels\"] = source_labels\n\n        # Create LabelsSet\n        if n_test is None:\n            labels_set = LabelsSet({\"train\": labels_train, \"val\": labels_val})\n        else:\n            labels_set = LabelsSet(\n                {\"train\": labels_train, \"val\": labels_val, \"test\": labels_test}\n            )\n\n        # Save.\n        if save_dir is not None:\n            labels_set.save(save_dir, embed=embed)\n\n        return labels_set\n\n    def trim(\n        self,\n        save_path: str | Path,\n        frame_inds: list[int] | np.ndarray,\n        video: Video | int | None = None,\n        video_kwargs: dict[str, Any] | None = None,\n    ) -&gt; Labels:\n        \"\"\"Trim the labels to a subset of frames and videos accordingly.\n\n        Args:\n            save_path: Path to the trimmed labels SLP file. Video will be saved with the\n                same base name but with .mp4 extension.\n            frame_inds: Frame indices to save. Can be specified as a list or array of\n                frame integers.\n            video: Video or integer index of the video to trim. Does not need to be\n                specified for single-video projects.\n            video_kwargs: A dictionary of keyword arguments to provide to\n                `sio.save_video` for video compression.\n\n        Returns:\n            The resulting labels object referencing the trimmed data.\n\n        Notes:\n            This will remove any data outside of the trimmed frames, save new videos,\n            and adjust the frame indices to match the newly trimmed videos.\n        \"\"\"\n        if video is None:\n            if len(self.videos) == 1:\n                video = self.video\n            else:\n                raise ValueError(\n                    \"Video needs to be specified when trimming multi-video projects.\"\n                )\n        if type(video) is int:\n            video = self.videos[video]\n\n        # Write trimmed clip.\n        save_path = Path(save_path)\n        video_path = save_path.with_suffix(\".mp4\")\n        fidx0, fidx1 = np.min(frame_inds), np.max(frame_inds)\n        new_video = video.save(\n            video_path,\n            frame_inds=np.arange(fidx0, fidx1 + 1),\n            video_kwargs=video_kwargs,\n        )\n\n        # Get frames in range.\n        # TODO: Create an optimized search function for this access pattern.\n        inds = []\n        for ind, lf in enumerate(self):\n            if lf.video == video and lf.frame_idx &gt;= fidx0 and lf.frame_idx &lt;= fidx1:\n                inds.append(ind)\n        trimmed_labels = self.extract(inds, copy=True)\n\n        # Adjust video and frame indices.\n        trimmed_labels.videos = [new_video]\n        for lf in trimmed_labels:\n            lf.video = new_video\n            lf.frame_idx = lf.frame_idx - fidx0\n\n        # Save.\n        trimmed_labels.save(save_path)\n\n        return trimmed_labels\n\n    def update_from_numpy(\n        self,\n        tracks_arr: np.ndarray,\n        video: Optional[Union[Video, int]] = None,\n        tracks: Optional[list[Track]] = None,\n        create_missing: bool = True,\n    ):\n        \"\"\"Update instances from a numpy array of tracks.\n\n        This function updates the points in existing instances, and creates new\n        instances for tracks that don't have a corresponding instance in a frame.\n\n        Args:\n            tracks_arr: A numpy array of tracks, with shape\n                `(n_frames, n_tracks, n_nodes, 2)` or\n                `(n_frames, n_tracks, n_nodes, 3)`,\n                where the last dimension contains the x,y coordinates (and optionally\n                confidence scores).\n            video: The video to update instances for. If not specified, the first video\n                in the labels will be used if there is only one video.\n            tracks: List of `Track` objects corresponding to the second dimension of the\n                array. If not specified, `self.tracks` will be used, and must have the\n                same length as the second dimension of the array.\n            create_missing: If `True` (the default), creates new `PredictedInstance`s\n                for tracks that don't have corresponding instances in a frame. If\n                `False`, only updates existing instances.\n\n        Raises:\n            ValueError: If the video cannot be determined, or if tracks are not\n                specified and the number of tracks in the array doesn't match the number\n                of tracks in the labels.\n\n        Notes:\n            This method is the inverse of `Labels.numpy()`, and can be used to update\n            instance points after modifying the numpy array.\n\n            If the array has a third dimension with shape 3 (tracks_arr.shape[-1] == 3),\n            the last channel is assumed to be confidence scores.\n        \"\"\"\n        # Check dimensions\n        if len(tracks_arr.shape) != 4:\n            raise ValueError(\n                f\"Array must have 4 dimensions (n_frames, n_tracks, n_nodes, 2 or 3), \"\n                f\"but got {tracks_arr.shape}\"\n            )\n\n        # Determine if confidence scores are included\n        has_confidence = tracks_arr.shape[3] == 3\n\n        # Determine the video to update\n        if video is None:\n            if len(self.videos) == 1:\n                video = self.videos[0]\n            else:\n                raise ValueError(\n                    \"Video must be specified when there is more than one video in the \"\n                    \"Labels.\"\n                )\n        elif isinstance(video, int):\n            video = self.videos[video]\n\n        # Get dimensions\n        n_frames, n_tracks_arr, n_nodes = tracks_arr.shape[:3]\n\n        # Get tracks to update\n        if tracks is None:\n            if len(self.tracks) != n_tracks_arr:\n                raise ValueError(\n                    f\"Number of tracks in array ({n_tracks_arr}) doesn't match \"\n                    f\"number of tracks in labels ({len(self.tracks)}). Please specify \"\n                    f\"the tracks corresponding to the second dimension of the array.\"\n                )\n            tracks = self.tracks\n\n        # Special case: Check if the array has more tracks than the provided tracks list\n        # This is for test_update_from_numpy where a new track is added\n        special_case = n_tracks_arr &gt; len(tracks)\n\n        # Get all labeled frames for the specified video\n        lfs = [lf for lf in self.labeled_frames if lf.video == video]\n\n        # Figure out frame index range from existing labeled frames\n        # Default to 0 if no labeled frames exist\n        first_frame = 0\n        if lfs:\n            first_frame = min(lf.frame_idx for lf in lfs)\n\n        # Ensure we have a skeleton\n        if not self.skeletons:\n            raise ValueError(\"No skeletons available in the labels.\")\n        skeleton = self.skeletons[-1]  # Use the same assumption as in numpy()\n\n        # Create a frame lookup dict for fast access\n        frame_lookup = {lf.frame_idx: lf for lf in lfs}\n\n        # Update or create instances for each frame in the array\n        for i in range(n_frames):\n            frame_idx = i + first_frame\n\n            # Find or create labeled frame\n            labeled_frame = None\n            if frame_idx in frame_lookup:\n                labeled_frame = frame_lookup[frame_idx]\n            else:\n                if create_missing:\n                    labeled_frame = LabeledFrame(video=video, frame_idx=frame_idx)\n                    self.append(labeled_frame, update=False)\n                    frame_lookup[frame_idx] = labeled_frame\n                else:\n                    continue\n\n            # First, handle regular tracks (up to len(tracks))\n            for j in range(min(n_tracks_arr, len(tracks))):\n                track = tracks[j]\n                track_data = tracks_arr[i, j]\n\n                # Check if there's any valid data for this track at this frame\n                valid_points = ~np.isnan(track_data[:, 0])\n                if not np.any(valid_points):\n                    continue\n\n                # Look for existing instance with this track\n                found_instance = None\n\n                # First check predicted instances\n                for inst in labeled_frame.predicted_instances:\n                    if inst.track and inst.track.name == track.name:\n                        found_instance = inst\n                        break\n\n                # Then check user instances if none found\n                if found_instance is None:\n                    for inst in labeled_frame.user_instances:\n                        if inst.track and inst.track.name == track.name:\n                            found_instance = inst\n                            break\n\n                # Create new instance if not found and create_missing is True\n                if found_instance is None and create_missing:\n                    # Create points from numpy data\n                    points = track_data[:, :2].copy()\n\n                    if has_confidence:\n                        # Get confidence scores\n                        scores = track_data[:, 2].copy()\n                        # Fix NaN scores\n                        scores = np.where(np.isnan(scores), 1.0, scores)\n\n                        # Create new instance\n                        new_instance = PredictedInstance.from_numpy(\n                            points_data=points,\n                            skeleton=skeleton,\n                            point_scores=scores,\n                            score=1.0,\n                            track=track,\n                        )\n                    else:\n                        # Create with default scores\n                        new_instance = PredictedInstance.from_numpy(\n                            points_data=points,\n                            skeleton=skeleton,\n                            point_scores=np.ones(n_nodes),\n                            score=1.0,\n                            track=track,\n                        )\n\n                    # Add to frame\n                    labeled_frame.instances.append(new_instance)\n                    found_instance = new_instance\n\n                # Update existing instance points\n                if found_instance is not None:\n                    points = track_data[:, :2]\n                    mask = ~np.isnan(points[:, 0])\n                    for node_idx in np.where(mask)[0]:\n                        found_instance.points[node_idx][\"xy\"] = points[node_idx]\n\n                    # Update confidence scores if available\n                    if has_confidence and isinstance(found_instance, PredictedInstance):\n                        scores = track_data[:, 2]\n                        score_mask = ~np.isnan(scores)\n                        for node_idx in np.where(score_mask)[0]:\n                            found_instance.points[node_idx][\"score\"] = float(\n                                scores[node_idx]\n                            )\n\n            # Special case: Handle any additional tracks in the array\n            # This is the fix for test_update_from_numpy where a new track is added\n            if special_case and create_missing and len(tracks) &gt; 0:\n                # In the test case, the last track in the tracks list is the new one\n                new_track = tracks[-1]\n\n                # Check if there's data for the new track in the current frame\n                # Use the last column in the array (new track)\n                new_track_data = tracks_arr[i, -1]\n\n                # Check if there's any valid data for this track at this frame\n                valid_points = ~np.isnan(new_track_data[:, 0])\n                if np.any(valid_points):\n                    # Create points from numpy data for the new track\n                    points = new_track_data[:, :2].copy()\n\n                    if has_confidence:\n                        # Get confidence scores\n                        scores = new_track_data[:, 2].copy()\n                        # Fix NaN scores\n                        scores = np.where(np.isnan(scores), 1.0, scores)\n\n                        # Create new instance for the new track\n                        new_instance = PredictedInstance.from_numpy(\n                            points_data=points,\n                            skeleton=skeleton,\n                            point_scores=scores,\n                            score=1.0,\n                            track=new_track,\n                        )\n                    else:\n                        # Create with default scores\n                        new_instance = PredictedInstance.from_numpy(\n                            points_data=points,\n                            skeleton=skeleton,\n                            point_scores=np.ones(n_nodes),\n                            score=1.0,\n                            track=new_track,\n                        )\n\n                    # Add the new instance directly to the frame's instances list\n                    labeled_frame.instances.append(new_instance)\n\n        # Make sure everything is properly linked\n        self.update()\n\n    def merge(\n        self,\n        other: \"Labels\",\n        instance_matcher: Optional[\"InstanceMatcher\"] = None,\n        skeleton_matcher: Optional[\"SkeletonMatcher\"] = None,\n        video_matcher: Optional[\"VideoMatcher\"] = None,\n        track_matcher: Optional[\"TrackMatcher\"] = None,\n        frame_strategy: str = \"smart\",\n        validate: bool = True,\n        progress_callback: Optional[Callable] = None,\n        error_mode: str = \"continue\",\n    ) -&gt; \"MergeResult\":\n        \"\"\"Merge another Labels object into this one.\n\n        Args:\n            other: Another Labels object to merge into this one.\n            instance_matcher: Matcher for comparing instances. If None, uses default\n                spatial matching with 5px tolerance.\n            skeleton_matcher: Matcher for comparing skeletons. If None, uses structure\n                matching.\n            video_matcher: Matcher for comparing videos. If None, uses auto matching.\n            track_matcher: Matcher for comparing tracks. If None, uses name matching.\n            frame_strategy: Strategy for merging frames:\n                - \"smart\": Keep user labels, update predictions\n                - \"keep_original\": Keep original frames\n                - \"keep_new\": Replace with new frames\n                - \"keep_both\": Keep all frames\n            validate: If True, validate for conflicts before merging.\n            progress_callback: Optional callback for progress updates.\n                Should accept (current, total, message) arguments.\n            error_mode: How to handle errors:\n                - \"continue\": Log errors but continue\n                - \"strict\": Raise exception on first error\n                - \"warn\": Print warnings but continue\n\n        Returns:\n            MergeResult object with statistics and any errors/conflicts.\n\n        Notes:\n            This method modifies the Labels object in place. The merge is designed to\n            handle common workflows like merging predictions back into a project.\n        \"\"\"\n        from datetime import datetime\n        from pathlib import Path\n\n        from sleap_io.model.matching import (\n            ConflictResolution,\n            ErrorMode,\n            InstanceMatcher,\n            MergeError,\n            MergeResult,\n            SkeletonMatcher,\n            SkeletonMatchMethod,\n            SkeletonMismatchError,\n            TrackMatcher,\n            VideoMatcher,\n            VideoMatchMethod,\n        )\n\n        # Initialize matchers with defaults if not provided\n        if instance_matcher is None:\n            instance_matcher = InstanceMatcher()\n        if skeleton_matcher is None:\n            skeleton_matcher = SkeletonMatcher(method=SkeletonMatchMethod.STRUCTURE)\n        if video_matcher is None:\n            video_matcher = VideoMatcher()\n        if track_matcher is None:\n            track_matcher = TrackMatcher()\n\n        # Parse error mode\n        error_mode_enum = ErrorMode(error_mode)\n\n        # Initialize result\n        result = MergeResult(successful=True)\n\n        # Track merge history in provenance\n        if \"merge_history\" not in self.provenance:\n            self.provenance[\"merge_history\"] = []\n\n        merge_record = {\n            \"timestamp\": datetime.now().isoformat(),\n            \"source_labels\": {\n                \"n_frames\": len(other.labeled_frames),\n                \"n_videos\": len(other.videos),\n                \"n_skeletons\": len(other.skeletons),\n                \"n_tracks\": len(other.tracks),\n            },\n            \"strategy\": frame_strategy,\n        }\n\n        try:\n            # Step 1: Match and merge skeletons\n            skeleton_map = {}\n            for other_skel in other.skeletons:\n                matched = False\n                for self_skel in self.skeletons:\n                    if skeleton_matcher.match(self_skel, other_skel):\n                        skeleton_map[other_skel] = self_skel\n                        matched = True\n                        break\n\n                if not matched:\n                    if validate and error_mode_enum == ErrorMode.STRICT:\n                        raise SkeletonMismatchError(\n                            message=f\"No matching skeleton found for {other_skel.name}\",\n                            details={\"skeleton\": other_skel},\n                        )\n                    elif error_mode_enum == ErrorMode.WARN:\n                        print(f\"Warning: No matching skeleton for {other_skel.name}\")\n\n                    # Add new skeleton if no match\n                    self.skeletons.append(other_skel)\n                    skeleton_map[other_skel] = other_skel\n\n            # Step 2: Match and merge videos\n            video_map = {}\n            frame_idx_map = {}  # Maps (old_video, old_idx) -&gt; (new_video, new_idx)\n\n            for other_video in other.videos:\n                matched = False\n                for self_video in self.videos:\n                    if video_matcher.match(self_video, other_video):\n                        # Special handling for different match methods\n                        if video_matcher.method == VideoMatchMethod.IMAGE_DEDUP:\n                            # Deduplicate images from other_video\n                            deduped_video = other_video.deduplicate_with(self_video)\n                            if deduped_video is None:\n                                # All images were duplicates, map to existing video\n                                video_map[other_video] = self_video\n                                # Build frame index mapping for deduplicated frames\n                                if isinstance(\n                                    other_video.filename, list\n                                ) and isinstance(self_video.filename, list):\n                                    other_basenames = [\n                                        Path(f).name for f in other_video.filename\n                                    ]\n                                    self_basenames = [\n                                        Path(f).name for f in self_video.filename\n                                    ]\n                                    for old_idx, basename in enumerate(other_basenames):\n                                        if basename in self_basenames:\n                                            new_idx = self_basenames.index(basename)\n                                            frame_idx_map[(other_video, old_idx)] = (\n                                                self_video,\n                                                new_idx,\n                                            )\n                            else:\n                                # Add deduplicated video as new\n                                self.videos.append(deduped_video)\n                                video_map[other_video] = deduped_video\n                                # Build frame index mapping for remaining frames\n                                if isinstance(\n                                    other_video.filename, list\n                                ) and isinstance(deduped_video.filename, list):\n                                    other_basenames = [\n                                        Path(f).name for f in other_video.filename\n                                    ]\n                                    deduped_basenames = [\n                                        Path(f).name for f in deduped_video.filename\n                                    ]\n                                    for old_idx, basename in enumerate(other_basenames):\n                                        if basename in deduped_basenames:\n                                            new_idx = deduped_basenames.index(basename)\n                                            frame_idx_map[(other_video, old_idx)] = (\n                                                deduped_video,\n                                                new_idx,\n                                            )\n                        elif video_matcher.method == VideoMatchMethod.SHAPE:\n                            # Merge videos with same shape\n                            merged_video = self_video.merge_with(other_video)\n                            # Replace self_video with merged version\n                            self_video_idx = self.videos.index(self_video)\n                            self.videos[self_video_idx] = merged_video\n                            video_map[other_video] = merged_video\n                            video_map[self_video] = (\n                                merged_video  # Update mapping for self too\n                            )\n                            # Build frame index mapping\n                            if isinstance(other_video.filename, list) and isinstance(\n                                merged_video.filename, list\n                            ):\n                                other_basenames = [\n                                    Path(f).name for f in other_video.filename\n                                ]\n                                merged_basenames = [\n                                    Path(f).name for f in merged_video.filename\n                                ]\n                                for old_idx, basename in enumerate(other_basenames):\n                                    if basename in merged_basenames:\n                                        new_idx = merged_basenames.index(basename)\n                                        frame_idx_map[(other_video, old_idx)] = (\n                                            merged_video,\n                                            new_idx,\n                                        )\n                        else:\n                            # Regular matching, no special handling\n                            video_map[other_video] = self_video\n                        matched = True\n                        break\n\n                if not matched:\n                    # Add new video if no match\n                    self.videos.append(other_video)\n                    video_map[other_video] = other_video\n\n            # Step 3: Match and merge tracks\n            track_map = {}\n            for other_track in other.tracks:\n                matched = False\n                for self_track in self.tracks:\n                    if track_matcher.match(self_track, other_track):\n                        track_map[other_track] = self_track\n                        matched = True\n                        break\n\n                if not matched:\n                    # Add new track if no match\n                    self.tracks.append(other_track)\n                    track_map[other_track] = other_track\n\n            # Step 4: Merge frames\n            total_frames = len(other.labeled_frames)\n\n            for frame_idx, other_frame in enumerate(other.labeled_frames):\n                if progress_callback:\n                    progress_callback(\n                        frame_idx,\n                        total_frames,\n                        f\"Merging frame {frame_idx + 1}/{total_frames}\",\n                    )\n\n                # Check if frame index needs remapping (for deduplicated/merged videos)\n                if (other_frame.video, other_frame.frame_idx) in frame_idx_map:\n                    mapped_video, mapped_frame_idx = frame_idx_map[\n                        (other_frame.video, other_frame.frame_idx)\n                    ]\n                else:\n                    # Map video to self\n                    mapped_video = video_map.get(other_frame.video, other_frame.video)\n                    mapped_frame_idx = other_frame.frame_idx\n\n                # Find matching frame in self\n                matching_frames = self.find(mapped_video, mapped_frame_idx)\n\n                if len(matching_frames) == 0:\n                    # No matching frame, create new one\n                    new_frame = LabeledFrame(\n                        video=mapped_video,\n                        frame_idx=mapped_frame_idx,\n                        instances=[],\n                    )\n\n                    # Map instances to new skeleton/track\n                    for inst in other_frame.instances:\n                        new_inst = self._map_instance(inst, skeleton_map, track_map)\n                        new_frame.instances.append(new_inst)\n                        result.instances_added += 1\n\n                    self.append(new_frame)\n                    result.frames_merged += 1\n\n                else:\n                    # Merge into existing frame\n                    self_frame = matching_frames[0]\n\n                    # Merge instances using frame-level merge\n                    merged_instances, conflicts = self_frame.merge(\n                        other_frame,\n                        instance_matcher=instance_matcher,\n                        strategy=frame_strategy,\n                    )\n\n                    # Remap skeleton and track references for instances from other frame\n                    remapped_instances = []\n                    for inst in merged_instances:\n                        # Check if instance needs remapping (from other_frame)\n                        if inst.skeleton in skeleton_map:\n                            # Instance needs remapping\n                            remapped_inst = self._map_instance(\n                                inst, skeleton_map, track_map\n                            )\n                            remapped_instances.append(remapped_inst)\n                        else:\n                            # Instance already has correct skeleton (from self_frame)\n                            remapped_instances.append(inst)\n                    merged_instances = remapped_instances\n\n                    # Count changes\n                    n_before = len(self_frame.instances)\n                    n_after = len(merged_instances)\n                    result.instances_added += max(0, n_after - n_before)\n\n                    # Record conflicts\n                    for orig, new, resolution in conflicts:\n                        result.conflicts.append(\n                            ConflictResolution(\n                                frame=self_frame,\n                                conflict_type=\"instance_conflict\",\n                                original_data=orig,\n                                new_data=new,\n                                resolution=resolution,\n                            )\n                        )\n\n                    # Update frame instances\n                    self_frame.instances = merged_instances\n                    result.frames_merged += 1\n\n            # Step 5: Merge suggestions\n            for other_suggestion in other.suggestions:\n                mapped_video = video_map.get(\n                    other_suggestion.video, other_suggestion.video\n                )\n                # Check if suggestion already exists\n                exists = False\n                for self_suggestion in self.suggestions:\n                    if (\n                        self_suggestion.video == mapped_video\n                        and self_suggestion.frame_idx == other_suggestion.frame_idx\n                    ):\n                        exists = True\n                        break\n                if not exists:\n                    # Create new suggestion with mapped video\n                    new_suggestion = SuggestionFrame(\n                        video=mapped_video, frame_idx=other_suggestion.frame_idx\n                    )\n                    self.suggestions.append(new_suggestion)\n\n            # Update merge record\n            merge_record[\"result\"] = {\n                \"frames_merged\": result.frames_merged,\n                \"instances_added\": result.instances_added,\n                \"conflicts\": len(result.conflicts),\n            }\n            self.provenance[\"merge_history\"].append(merge_record)\n\n        except MergeError as e:\n            result.successful = False\n            result.errors.append(e)\n            if error_mode_enum == ErrorMode.STRICT:\n                raise\n        except Exception as e:\n            result.successful = False\n            result.errors.append(\n                MergeError(message=str(e), details={\"exception\": type(e).__name__})\n            )\n            if error_mode_enum == ErrorMode.STRICT:\n                raise\n\n        if progress_callback:\n            progress_callback(total_frames, total_frames, \"Merge complete\")\n\n        return result\n\n    def _map_instance(\n        self,\n        instance: Union[Instance, PredictedInstance],\n        skeleton_map: dict[Skeleton, Skeleton],\n        track_map: dict[Track, Track],\n    ) -&gt; Union[Instance, PredictedInstance]:\n        \"\"\"Map an instance to use mapped skeleton and track.\n\n        Args:\n            instance: Instance to map.\n            skeleton_map: Dictionary mapping old skeletons to new ones.\n            track_map: Dictionary mapping old tracks to new ones.\n\n        Returns:\n            New instance with mapped skeleton and track.\n        \"\"\"\n        mapped_skeleton = skeleton_map.get(instance.skeleton, instance.skeleton)\n        mapped_track = (\n            track_map.get(instance.track, instance.track) if instance.track else None\n        )\n\n        if type(instance) is PredictedInstance:\n            return PredictedInstance(\n                points=instance.points.copy(),\n                skeleton=mapped_skeleton,\n                score=instance.score,\n                track=mapped_track,\n                tracking_score=instance.tracking_score,\n                from_predicted=instance.from_predicted,\n            )\n        else:\n            return Instance(\n                points=instance.points.copy(),\n                skeleton=mapped_skeleton,\n                track=mapped_track,\n                tracking_score=instance.tracking_score,\n                from_predicted=instance.from_predicted,\n            )\n\n    def set_video_plugin(self, plugin: str) -&gt; None:\n        \"\"\"Reopen all media videos with the specified plugin.\n\n        Args:\n            plugin: Video plugin to use. One of \"opencv\", \"FFMPEG\", or \"pyav\".\n                Also accepts aliases (case-insensitive).\n\n        Examples:\n            &gt;&gt;&gt; labels.set_video_plugin(\"opencv\")\n            &gt;&gt;&gt; labels.set_video_plugin(\"FFMPEG\")\n        \"\"\"\n        from sleap_io.io.video_reading import MediaVideo\n\n        for video in self.videos:\n            if video.filename.endswith(MediaVideo.EXTS):\n                video.set_video_plugin(plugin)\n</code></pre>"},{"location":"reference/sleap_io/model/labels/#sleap_io.model.labels.Labels.instances","title":"<code>instances</code>  <code>property</code>","text":"<p>Return an iterator over all instances within all labeled frames.</p>"},{"location":"reference/sleap_io/model/labels/#sleap_io.model.labels.Labels.skeleton","title":"<code>skeleton</code>  <code>property</code>","text":"<p>Return the skeleton if there is only a single skeleton in the labels.</p>"},{"location":"reference/sleap_io/model/labels/#sleap_io.model.labels.Labels.user_labeled_frames","title":"<code>user_labeled_frames</code>  <code>property</code>","text":"<p>Return all labeled frames with user (non-predicted) instances.</p>"},{"location":"reference/sleap_io/model/labels/#sleap_io.model.labels.Labels.video","title":"<code>video</code>  <code>property</code>","text":"<p>Return the video if there is only a single video in the labels.</p>"},{"location":"reference/sleap_io/model/labels/#sleap_io.model.labels.Labels.__attrs_post_init__","title":"<code>__attrs_post_init__()</code>","text":"<p>Append videos, skeletons, and tracks seen in <code>labeled_frames</code> to <code>Labels</code>.</p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def __attrs_post_init__(self):\n    \"\"\"Append videos, skeletons, and tracks seen in `labeled_frames` to `Labels`.\"\"\"\n    self.update()\n</code></pre>"},{"location":"reference/sleap_io/model/labels/#sleap_io.model.labels.Labels.__getitem__","title":"<code>__getitem__(key)</code>","text":"<p>Return one or more labeled frames based on indexing criteria.</p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def __getitem__(\n    self, key: int | slice | list[int] | np.ndarray | tuple[Video, int]\n) -&gt; list[LabeledFrame] | LabeledFrame:\n    \"\"\"Return one or more labeled frames based on indexing criteria.\"\"\"\n    if type(key) is int:\n        return self.labeled_frames[key]\n    elif type(key) is slice:\n        return [self.labeled_frames[i] for i in range(*key.indices(len(self)))]\n    elif type(key) is list:\n        return [self.labeled_frames[i] for i in key]\n    elif isinstance(key, np.ndarray):\n        return [self.labeled_frames[i] for i in key.tolist()]\n    elif type(key) is tuple and len(key) == 2:\n        video, frame_idx = key\n        res = self.find(video, frame_idx)\n        if len(res) == 1:\n            return res[0]\n        elif len(res) == 0:\n            raise IndexError(\n                f\"No labeled frames found for video {video} and \"\n                f\"frame index {frame_idx}.\"\n            )\n    elif type(key) is Video:\n        res = self.find(key)\n        if len(res) == 0:\n            raise IndexError(f\"No labeled frames found for video {key}.\")\n        return res\n    else:\n        raise IndexError(f\"Invalid indexing argument for labels: {key}\")\n</code></pre>"},{"location":"reference/sleap_io/model/labels/#sleap_io.model.labels.Labels.__iter__","title":"<code>__iter__()</code>","text":"<p>Iterate over <code>labeled_frames</code> list when calling iter method on <code>Labels</code>.</p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def __iter__(self):\n    \"\"\"Iterate over `labeled_frames` list when calling iter method on `Labels`.\"\"\"\n    return iter(self.labeled_frames)\n</code></pre>"},{"location":"reference/sleap_io/model/labels/#sleap_io.model.labels.Labels.__len__","title":"<code>__len__()</code>","text":"<p>Return number of labeled frames.</p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"Return number of labeled frames.\"\"\"\n    return len(self.labeled_frames)\n</code></pre>"},{"location":"reference/sleap_io/model/labels/#sleap_io.model.labels.Labels.__repr__","title":"<code>__repr__()</code>","text":"<p>Return a readable representation of the labels.</p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return a readable representation of the labels.\"\"\"\n    return (\n        \"Labels(\"\n        f\"labeled_frames={len(self.labeled_frames)}, \"\n        f\"videos={len(self.videos)}, \"\n        f\"skeletons={len(self.skeletons)}, \"\n        f\"tracks={len(self.tracks)}, \"\n        f\"suggestions={len(self.suggestions)}, \"\n        f\"sessions={len(self.sessions)}\"\n        \")\"\n    )\n</code></pre>"},{"location":"reference/sleap_io/model/labels/#sleap_io.model.labels.Labels.__str__","title":"<code>__str__()</code>","text":"<p>Return a readable representation of the labels.</p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return a readable representation of the labels.\"\"\"\n    return self.__repr__()\n</code></pre>"},{"location":"reference/sleap_io/model/labels/#sleap_io.model.labels.Labels.append","title":"<code>append(lf, update=True)</code>","text":"<p>Append a labeled frame to the labels.</p> <p>Parameters:</p> Name Type Description Default <code>lf</code> <code>LabeledFrame</code> <p>A labeled frame to add to the labels.</p> required <code>update</code> <code>bool</code> <p>If <code>True</code> (the default), update list of videos, tracks and skeletons from the contents.</p> <code>True</code> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def append(self, lf: LabeledFrame, update: bool = True):\n    \"\"\"Append a labeled frame to the labels.\n\n    Args:\n        lf: A labeled frame to add to the labels.\n        update: If `True` (the default), update list of videos, tracks and\n            skeletons from the contents.\n    \"\"\"\n    self.labeled_frames.append(lf)\n\n    if update:\n        if lf.video not in self.videos:\n            self.videos.append(lf.video)\n\n        for inst in lf:\n            if inst.skeleton not in self.skeletons:\n                self.skeletons.append(inst.skeleton)\n\n            if inst.track is not None and inst.track not in self.tracks:\n                self.tracks.append(inst.track)\n</code></pre>"},{"location":"reference/sleap_io/model/labels/#sleap_io.model.labels.Labels.clean","title":"<code>clean(frames=True, empty_instances=False, skeletons=True, tracks=True, videos=False)</code>","text":"<p>Remove empty frames, unused skeletons, tracks and videos.</p> <p>Parameters:</p> Name Type Description Default <code>frames</code> <code>bool</code> <p>If <code>True</code> (the default), remove empty frames.</p> <code>True</code> <code>empty_instances</code> <code>bool</code> <p>If <code>True</code> (NOT default), remove instances that have no visible points.</p> <code>False</code> <code>skeletons</code> <code>bool</code> <p>If <code>True</code> (the default), remove unused skeletons.</p> <code>True</code> <code>tracks</code> <code>bool</code> <p>If <code>True</code> (the default), remove unused tracks.</p> <code>True</code> <code>videos</code> <code>bool</code> <p>If <code>True</code> (NOT default), remove videos that have no labeled frames.</p> <code>False</code> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def clean(\n    self,\n    frames: bool = True,\n    empty_instances: bool = False,\n    skeletons: bool = True,\n    tracks: bool = True,\n    videos: bool = False,\n):\n    \"\"\"Remove empty frames, unused skeletons, tracks and videos.\n\n    Args:\n        frames: If `True` (the default), remove empty frames.\n        empty_instances: If `True` (NOT default), remove instances that have no\n            visible points.\n        skeletons: If `True` (the default), remove unused skeletons.\n        tracks: If `True` (the default), remove unused tracks.\n        videos: If `True` (NOT default), remove videos that have no labeled frames.\n    \"\"\"\n    used_skeletons = []\n    used_tracks = []\n    used_videos = []\n    kept_frames = []\n    for lf in self.labeled_frames:\n        if empty_instances:\n            lf.remove_empty_instances()\n\n        if frames and len(lf) == 0:\n            continue\n\n        if videos and lf.video not in used_videos:\n            used_videos.append(lf.video)\n\n        if skeletons or tracks:\n            for inst in lf:\n                if skeletons and inst.skeleton not in used_skeletons:\n                    used_skeletons.append(inst.skeleton)\n                if (\n                    tracks\n                    and inst.track is not None\n                    and inst.track not in used_tracks\n                ):\n                    used_tracks.append(inst.track)\n\n        if frames:\n            kept_frames.append(lf)\n\n    if videos:\n        self.videos = [video for video in self.videos if video in used_videos]\n\n    if skeletons:\n        self.skeletons = [\n            skeleton for skeleton in self.skeletons if skeleton in used_skeletons\n        ]\n\n    if tracks:\n        self.tracks = [track for track in self.tracks if track in used_tracks]\n\n    if frames:\n        self.labeled_frames = kept_frames\n</code></pre>"},{"location":"reference/sleap_io/model/labels/#sleap_io.model.labels.Labels.extend","title":"<code>extend(lfs, update=True)</code>","text":"<p>Append a labeled frame to the labels.</p> <p>Parameters:</p> Name Type Description Default <code>lfs</code> <code>list[LabeledFrame]</code> <p>A list of labeled frames to add to the labels.</p> required <code>update</code> <code>bool</code> <p>If <code>True</code> (the default), update list of videos, tracks and skeletons from the contents.</p> <code>True</code> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def extend(self, lfs: list[LabeledFrame], update: bool = True):\n    \"\"\"Append a labeled frame to the labels.\n\n    Args:\n        lfs: A list of labeled frames to add to the labels.\n        update: If `True` (the default), update list of videos, tracks and\n            skeletons from the contents.\n    \"\"\"\n    self.labeled_frames.extend(lfs)\n\n    if update:\n        for lf in lfs:\n            if lf.video not in self.videos:\n                self.videos.append(lf.video)\n\n            for inst in lf:\n                if inst.skeleton not in self.skeletons:\n                    self.skeletons.append(inst.skeleton)\n\n                if inst.track is not None and inst.track not in self.tracks:\n                    self.tracks.append(inst.track)\n</code></pre>"},{"location":"reference/sleap_io/model/labels/#sleap_io.model.labels.Labels.extract","title":"<code>extract(inds, copy=True)</code>","text":"<p>Extract a set of frames into a new Labels object.</p> <p>Parameters:</p> Name Type Description Default <code>inds</code> <code>list[int] | list[tuple[Video, int]] | ndarray</code> <p>Indices of labeled frames. Can be specified as a list of array of integer indices of labeled frames or tuples of Video and frame indices.</p> required <code>copy</code> <code>bool</code> <p>If <code>True</code> (the default), return a copy of the frames and containing objects. Otherwise, return a reference to the data.</p> <code>True</code> <p>Returns:</p> Type Description <code>Labels</code> <p>A new <code>Labels</code> object containing the selected labels.</p> Notes <p>This copies the labeled frames and their associated data, including skeletons and tracks, and tries to maintain the relative ordering.</p> <p>This also copies the provenance and inserts an extra key: <code>\"source_labels\"</code> with the path to the current labels, if available.</p> <p>It does NOT copy suggested frames.</p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def extract(\n    self, inds: list[int] | list[tuple[Video, int]] | np.ndarray, copy: bool = True\n) -&gt; Labels:\n    \"\"\"Extract a set of frames into a new Labels object.\n\n    Args:\n        inds: Indices of labeled frames. Can be specified as a list of array of\n            integer indices of labeled frames or tuples of Video and frame indices.\n        copy: If `True` (the default), return a copy of the frames and containing\n            objects. Otherwise, return a reference to the data.\n\n    Returns:\n        A new `Labels` object containing the selected labels.\n\n    Notes:\n        This copies the labeled frames and their associated data, including\n        skeletons and tracks, and tries to maintain the relative ordering.\n\n        This also copies the provenance and inserts an extra key: `\"source_labels\"`\n        with the path to the current labels, if available.\n\n        It does NOT copy suggested frames.\n    \"\"\"\n    lfs = self[inds]\n\n    if copy:\n        lfs = deepcopy(lfs)\n    labels = Labels(lfs)\n\n    # Try to keep the lists in the same order.\n    track_to_ind = {track.name: ind for ind, track in enumerate(self.tracks)}\n    labels.tracks = sorted(labels.tracks, key=lambda x: track_to_ind[x.name])\n\n    skel_to_ind = {skel.name: ind for ind, skel in enumerate(self.skeletons)}\n    labels.skeletons = sorted(labels.skeletons, key=lambda x: skel_to_ind[x.name])\n\n    labels.provenance = deepcopy(labels.provenance)\n    labels.provenance[\"source_labels\"] = self.provenance.get(\"filename\", None)\n\n    return labels\n</code></pre>"},{"location":"reference/sleap_io/model/labels/#sleap_io.model.labels.Labels.find","title":"<code>find(video, frame_idx=None, return_new=False)</code>","text":"<p>Search for labeled frames given video and/or frame index.</p> <p>Parameters:</p> Name Type Description Default <code>video</code> <code>Video</code> <p>A <code>Video</code> that is associated with the project.</p> required <code>frame_idx</code> <code>int | list[int] | None</code> <p>The frame index (or indices) which we want to find in the video. If a range is specified, we'll return all frames with indices in that range. If not specific, then we'll return all labeled frames for video.</p> <code>None</code> <code>return_new</code> <code>bool</code> <p>Whether to return singleton of new and empty <code>LabeledFrame</code> if none are found in project.</p> <code>False</code> <p>Returns:</p> Type Description <code>list[LabeledFrame]</code> <p>List of <code>LabeledFrame</code> objects that match the criteria.</p> <p>The list will be empty if no matches found, unless return_new is True, in which case it contains new (empty) <code>LabeledFrame</code> objects with <code>video</code> and <code>frame_index</code> set.</p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def find(\n    self,\n    video: Video,\n    frame_idx: int | list[int] | None = None,\n    return_new: bool = False,\n) -&gt; list[LabeledFrame]:\n    \"\"\"Search for labeled frames given video and/or frame index.\n\n    Args:\n        video: A `Video` that is associated with the project.\n        frame_idx: The frame index (or indices) which we want to find in the video.\n            If a range is specified, we'll return all frames with indices in that\n            range. If not specific, then we'll return all labeled frames for video.\n        return_new: Whether to return singleton of new and empty `LabeledFrame` if\n            none are found in project.\n\n    Returns:\n        List of `LabeledFrame` objects that match the criteria.\n\n        The list will be empty if no matches found, unless return_new is True, in\n        which case it contains new (empty) `LabeledFrame` objects with `video` and\n        `frame_index` set.\n    \"\"\"\n    results = []\n\n    if frame_idx is None:\n        for lf in self.labeled_frames:\n            if lf.video == video:\n                results.append(lf)\n        return results\n\n    if np.isscalar(frame_idx):\n        frame_idx = np.array(frame_idx).reshape(-1)\n\n    for frame_ind in frame_idx:\n        result = None\n        for lf in self.labeled_frames:\n            if lf.video == video and lf.frame_idx == frame_ind:\n                result = lf\n                results.append(result)\n                break\n        if result is None and return_new:\n            results.append(LabeledFrame(video=video, frame_idx=frame_ind))\n\n    return results\n</code></pre>"},{"location":"reference/sleap_io/model/labels/#sleap_io.model.labels.Labels.from_numpy","title":"<code>from_numpy(tracks_arr, videos, skeletons=None, tracks=None, first_frame=0, return_confidence=False)</code>  <code>classmethod</code>","text":"<p>Create a new Labels object from a numpy array of tracks.</p> <p>This factory method creates a new Labels object with instances constructed from the provided numpy array. It is the inverse operation of <code>Labels.numpy()</code>.</p> <p>Parameters:</p> Name Type Description Default <code>tracks_arr</code> <code>ndarray</code> <p>A numpy array of tracks, with shape <code>(n_frames, n_tracks, n_nodes, 2)</code> or <code>(n_frames, n_tracks, n_nodes, 3)</code>, where the last dimension contains the x,y coordinates (and optionally confidence scores).</p> required <code>videos</code> <code>list[Video]</code> <p>List of Video objects to associate with the labels. At least one video is required.</p> required <code>skeletons</code> <code>list[Skeleton] | Skeleton | None</code> <p>Skeleton or list of Skeleton objects to use for the instances. At least one skeleton is required.</p> <code>None</code> <code>tracks</code> <code>list[Track] | None</code> <p>List of Track objects corresponding to the second dimension of the array. If not specified, new tracks will be created automatically.</p> <code>None</code> <code>first_frame</code> <code>int</code> <p>Frame index to start the labeled frames from. Default is 0.</p> <code>0</code> <code>return_confidence</code> <code>bool</code> <p>Whether the tracks_arr contains confidence scores in the last dimension. If True, tracks_arr.shape[-1] should be 3.</p> <code>False</code> <p>Returns:</p> Type Description <code>'Labels'</code> <p>A new Labels object with instances constructed from the numpy array.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the array dimensions are invalid, or if no videos or skeletons are provided.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from sleap_io import Labels, Video, Skeleton\n&gt;&gt;&gt; # Create a simple tracking array for 2 frames, 1 track, 2 nodes\n&gt;&gt;&gt; arr = np.zeros((2, 1, 2, 2))\n&gt;&gt;&gt; arr[0, 0] = [[10, 20], [30, 40]]  # Frame 0\n&gt;&gt;&gt; arr[1, 0] = [[15, 25], [35, 45]]  # Frame 1\n&gt;&gt;&gt; # Create a video and skeleton\n&gt;&gt;&gt; video = Video(filename=\"example.mp4\")\n&gt;&gt;&gt; skeleton = Skeleton([\"head\", \"tail\"])\n&gt;&gt;&gt; # Create labels from the array\n&gt;&gt;&gt; labels = Labels.from_numpy(arr, videos=[video], skeletons=[skeleton])\n</code></pre> Source code in <code>sleap_io/model/labels.py</code> <pre><code>@classmethod\ndef from_numpy(\n    cls,\n    tracks_arr: np.ndarray,\n    videos: list[Video],\n    skeletons: list[Skeleton] | Skeleton | None = None,\n    tracks: list[Track] | None = None,\n    first_frame: int = 0,\n    return_confidence: bool = False,\n) -&gt; \"Labels\":\n    \"\"\"Create a new Labels object from a numpy array of tracks.\n\n    This factory method creates a new Labels object with instances constructed from\n    the provided numpy array. It is the inverse operation of `Labels.numpy()`.\n\n    Args:\n        tracks_arr: A numpy array of tracks, with shape\n            `(n_frames, n_tracks, n_nodes, 2)` or\n            `(n_frames, n_tracks, n_nodes, 3)`,\n            where the last dimension contains the x,y coordinates (and optionally\n            confidence scores).\n        videos: List of Video objects to associate with the labels. At least one\n            video\n            is required.\n        skeletons: Skeleton or list of Skeleton objects to use for the instances.\n            At least one skeleton is required.\n        tracks: List of Track objects corresponding to the second dimension of the\n            array. If not specified, new tracks will be created automatically.\n        first_frame: Frame index to start the labeled frames from. Default is 0.\n        return_confidence: Whether the tracks_arr contains confidence scores in the\n            last dimension. If True, tracks_arr.shape[-1] should be 3.\n\n    Returns:\n        A new Labels object with instances constructed from the numpy array.\n\n    Raises:\n        ValueError: If the array dimensions are invalid, or if no videos or\n            skeletons are provided.\n\n    Examples:\n        &gt;&gt;&gt; import numpy as np\n        &gt;&gt;&gt; from sleap_io import Labels, Video, Skeleton\n        &gt;&gt;&gt; # Create a simple tracking array for 2 frames, 1 track, 2 nodes\n        &gt;&gt;&gt; arr = np.zeros((2, 1, 2, 2))\n        &gt;&gt;&gt; arr[0, 0] = [[10, 20], [30, 40]]  # Frame 0\n        &gt;&gt;&gt; arr[1, 0] = [[15, 25], [35, 45]]  # Frame 1\n        &gt;&gt;&gt; # Create a video and skeleton\n        &gt;&gt;&gt; video = Video(filename=\"example.mp4\")\n        &gt;&gt;&gt; skeleton = Skeleton([\"head\", \"tail\"])\n        &gt;&gt;&gt; # Create labels from the array\n        &gt;&gt;&gt; labels = Labels.from_numpy(arr, videos=[video], skeletons=[skeleton])\n    \"\"\"\n    # Check dimensions\n    if len(tracks_arr.shape) != 4:\n        raise ValueError(\n            f\"Array must have 4 dimensions (n_frames, n_tracks, n_nodes, 2 or 3), \"\n            f\"but got {tracks_arr.shape}\"\n        )\n\n    # Validate videos\n    if not videos:\n        raise ValueError(\"At least one video must be provided\")\n    video = videos[0]  # Use the first video for creating labeled frames\n\n    # Process skeletons input\n    if skeletons is None:\n        raise ValueError(\"At least one skeleton must be provided\")\n    elif isinstance(skeletons, Skeleton):\n        skeletons = [skeletons]\n    elif not skeletons:  # Check for empty list\n        raise ValueError(\"At least one skeleton must be provided\")\n\n    skeleton = skeletons[0]  # Use the first skeleton for creating instances\n    n_nodes = len(skeleton.nodes)\n\n    # Check if tracks_arr contains confidence scores\n    has_confidence = tracks_arr.shape[-1] == 3 or return_confidence\n\n    # Get dimensions\n    n_frames, n_tracks_arr, _ = tracks_arr.shape[:3]\n\n    # Create or validate tracks\n    if tracks is None:\n        # Auto-create tracks if not provided\n        tracks = [Track(f\"track_{i}\") for i in range(n_tracks_arr)]\n    elif len(tracks) &lt; n_tracks_arr:\n        # Add missing tracks if needed\n        original_len = len(tracks)\n        for i in range(n_tracks_arr - original_len):\n            tracks.append(Track(f\"track_{i}\"))\n\n    # Create a new empty Labels object\n    labels = cls()\n    labels.videos = list(videos)\n    labels.skeletons = list(skeletons)\n    labels.tracks = list(tracks)\n\n    # Create labeled frames and instances from the array data\n    for i in range(n_frames):\n        frame_idx = i + first_frame\n\n        # Check if this frame has any valid data across all tracks\n        frame_has_valid_data = False\n        for j in range(n_tracks_arr):\n            track_data = tracks_arr[i, j]\n            # Check if at least one node in this track has valid xy coordinates\n            if np.any(~np.isnan(track_data[:, 0])):\n                frame_has_valid_data = True\n                break\n\n        # Skip creating a frame if there's no valid data\n        if not frame_has_valid_data:\n            continue\n\n        # Create a new labeled frame\n        labeled_frame = LabeledFrame(video=video, frame_idx=frame_idx)\n        frame_has_valid_instances = False\n\n        # Process each track in this frame\n        for j in range(n_tracks_arr):\n            track = tracks[j]\n            track_data = tracks_arr[i, j]\n\n            # Check if there's any valid data for this track at this frame\n            valid_points = ~np.isnan(track_data[:, 0])\n            if not np.any(valid_points):\n                continue\n\n            # Create points from numpy data\n            points = track_data[:, :2].copy()\n\n            # Create new instance\n            if has_confidence:\n                # Get confidence scores\n                if tracks_arr.shape[-1] == 3:\n                    scores = track_data[:, 2].copy()\n                else:\n                    scores = np.ones(n_nodes)\n\n                # Fix NaN scores\n                scores = np.where(np.isnan(scores), 1.0, scores)\n\n                # Create instance with confidence scores\n                new_instance = PredictedInstance.from_numpy(\n                    points_data=points,\n                    skeleton=skeleton,\n                    point_scores=scores,\n                    score=1.0,\n                    track=track,\n                )\n            else:\n                # Create instance with default scores\n                new_instance = PredictedInstance.from_numpy(\n                    points_data=points,\n                    skeleton=skeleton,\n                    point_scores=np.ones(n_nodes),\n                    score=1.0,\n                    track=track,\n                )\n\n            # Add to frame\n            labeled_frame.instances.append(new_instance)\n            frame_has_valid_instances = True\n\n        # Only add frames that have instances\n        if frame_has_valid_instances:\n            labels.append(labeled_frame, update=False)\n\n    # Update internal references\n    labels.update()\n\n    return labels\n</code></pre>"},{"location":"reference/sleap_io/model/labels/#sleap_io.model.labels.Labels.make_training_splits","title":"<code>make_training_splits(n_train, n_val=None, n_test=None, save_dir=None, seed=None, embed=True)</code>","text":"<p>Make splits for training with embedded images.</p> <p>Parameters:</p> Name Type Description Default <code>n_train</code> <code>int | float</code> <p>Size of the training split as integer or fraction.</p> required <code>n_val</code> <code>int | float | None</code> <p>Size of the validation split as integer or fraction. If <code>None</code>, this will be inferred based on the values of <code>n_train</code> and <code>n_test</code>. If <code>n_test</code> is <code>None</code>, this will be the remainder of the data after the training split.</p> <code>None</code> <code>n_test</code> <code>int | float | None</code> <p>Size of the testing split as integer or fraction. If <code>None</code>, the test split will not be saved.</p> <code>None</code> <code>save_dir</code> <code>str | Path | None</code> <p>If specified, save splits to SLP files with embedded images.</p> <code>None</code> <code>seed</code> <code>int | None</code> <p>Optional integer seed to use for reproducibility.</p> <code>None</code> <code>embed</code> <code>bool</code> <p>If <code>True</code> (the default), embed user labeled frame images in the saved files, which is useful for portability but can be slow for large projects. If <code>False</code>, labels are saved with references to the source videos files.</p> <code>True</code> <p>Returns:</p> Type Description <code>LabelsSet</code> <p>A <code>LabelsSet</code> containing \"train\", \"val\", and optionally \"test\" keys. The <code>LabelsSet</code> can be unpacked for backward compatibility: <code>train, val = labels.make_training_splits(0.8)</code> <code>train, val, test = labels.make_training_splits(0.8, n_test=0.1)</code></p> Notes <p>Predictions and suggestions will be removed before saving, leaving only frames with user labeled data (the source labels are not affected).</p> <p>Frames with user labeled data will be embedded in the resulting files.</p> <p>If <code>save_dir</code> is specified, this will save the randomly sampled splits to:</p> <ul> <li><code>{save_dir}/train.pkg.slp</code></li> <li><code>{save_dir}/val.pkg.slp</code></li> <li><code>{save_dir}/test.pkg.slp</code> (if <code>n_test</code> is specified)</li> </ul> <p>If <code>embed</code> is <code>False</code>, the files will be saved without embedded images to:</p> <ul> <li><code>{save_dir}/train.slp</code></li> <li><code>{save_dir}/val.slp</code></li> <li><code>{save_dir}/test.slp</code> (if <code>n_test</code> is specified)</li> </ul> <p>See also: <code>Labels.split</code></p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def make_training_splits(\n    self,\n    n_train: int | float,\n    n_val: int | float | None = None,\n    n_test: int | float | None = None,\n    save_dir: str | Path | None = None,\n    seed: int | None = None,\n    embed: bool = True,\n) -&gt; LabelsSet:\n    \"\"\"Make splits for training with embedded images.\n\n    Args:\n        n_train: Size of the training split as integer or fraction.\n        n_val: Size of the validation split as integer or fraction. If `None`,\n            this will be inferred based on the values of `n_train` and `n_test`. If\n            `n_test` is `None`, this will be the remainder of the data after the\n            training split.\n        n_test: Size of the testing split as integer or fraction. If `None`, the\n            test split will not be saved.\n        save_dir: If specified, save splits to SLP files with embedded images.\n        seed: Optional integer seed to use for reproducibility.\n        embed: If `True` (the default), embed user labeled frame images in the saved\n            files, which is useful for portability but can be slow for large\n            projects. If `False`, labels are saved with references to the source\n            videos files.\n\n    Returns:\n        A `LabelsSet` containing \"train\", \"val\", and optionally \"test\" keys.\n        The `LabelsSet` can be unpacked for backward compatibility:\n        `train, val = labels.make_training_splits(0.8)`\n        `train, val, test = labels.make_training_splits(0.8, n_test=0.1)`\n\n    Notes:\n        Predictions and suggestions will be removed before saving, leaving only\n        frames with user labeled data (the source labels are not affected).\n\n        Frames with user labeled data will be embedded in the resulting files.\n\n        If `save_dir` is specified, this will save the randomly sampled splits to:\n\n        - `{save_dir}/train.pkg.slp`\n        - `{save_dir}/val.pkg.slp`\n        - `{save_dir}/test.pkg.slp` (if `n_test` is specified)\n\n        If `embed` is `False`, the files will be saved without embedded images to:\n\n        - `{save_dir}/train.slp`\n        - `{save_dir}/val.slp`\n        - `{save_dir}/test.slp` (if `n_test` is specified)\n\n    See also: `Labels.split`\n    \"\"\"\n    # Import here to avoid circular imports\n    from sleap_io.model.labels_set import LabelsSet\n\n    # Clean up labels.\n    labels = deepcopy(self)\n    labels.remove_predictions()\n    labels.suggestions = []\n    labels.clean()\n\n    # Make train split.\n    labels_train, labels_rest = labels.split(n_train, seed=seed)\n\n    # Make test split.\n    if n_test is not None:\n        if n_test &lt; 1:\n            n_test = (n_test * len(labels)) / len(labels_rest)\n        labels_test, labels_rest = labels_rest.split(n=n_test, seed=seed)\n\n    # Make val split.\n    if n_val is not None:\n        if n_val &lt; 1:\n            n_val = (n_val * len(labels)) / len(labels_rest)\n        if isinstance(n_val, float) and n_val == 1.0:\n            labels_val = labels_rest\n        else:\n            labels_val, _ = labels_rest.split(n=n_val, seed=seed)\n    else:\n        labels_val = labels_rest\n\n    # Update provenance.\n    source_labels = self.provenance.get(\"filename\", None)\n    labels_train.provenance[\"source_labels\"] = source_labels\n    if n_val is not None:\n        labels_val.provenance[\"source_labels\"] = source_labels\n    if n_test is not None:\n        labels_test.provenance[\"source_labels\"] = source_labels\n\n    # Create LabelsSet\n    if n_test is None:\n        labels_set = LabelsSet({\"train\": labels_train, \"val\": labels_val})\n    else:\n        labels_set = LabelsSet(\n            {\"train\": labels_train, \"val\": labels_val, \"test\": labels_test}\n        )\n\n    # Save.\n    if save_dir is not None:\n        labels_set.save(save_dir, embed=embed)\n\n    return labels_set\n</code></pre>"},{"location":"reference/sleap_io/model/labels/#sleap_io.model.labels.Labels.merge","title":"<code>merge(other, instance_matcher=None, skeleton_matcher=None, video_matcher=None, track_matcher=None, frame_strategy='smart', validate=True, progress_callback=None, error_mode='continue')</code>","text":"<p>Merge another Labels object into this one.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>'Labels'</code> <p>Another Labels object to merge into this one.</p> required <code>instance_matcher</code> <code>Optional['InstanceMatcher']</code> <p>Matcher for comparing instances. If None, uses default spatial matching with 5px tolerance.</p> <code>None</code> <code>skeleton_matcher</code> <code>Optional['SkeletonMatcher']</code> <p>Matcher for comparing skeletons. If None, uses structure matching.</p> <code>None</code> <code>video_matcher</code> <code>Optional['VideoMatcher']</code> <p>Matcher for comparing videos. If None, uses auto matching.</p> <code>None</code> <code>track_matcher</code> <code>Optional['TrackMatcher']</code> <p>Matcher for comparing tracks. If None, uses name matching.</p> <code>None</code> <code>frame_strategy</code> <code>str</code> <p>Strategy for merging frames: - \"smart\": Keep user labels, update predictions - \"keep_original\": Keep original frames - \"keep_new\": Replace with new frames - \"keep_both\": Keep all frames</p> <code>'smart'</code> <code>validate</code> <code>bool</code> <p>If True, validate for conflicts before merging.</p> <code>True</code> <code>progress_callback</code> <code>Optional[Callable]</code> <p>Optional callback for progress updates. Should accept (current, total, message) arguments.</p> <code>None</code> <code>error_mode</code> <code>str</code> <p>How to handle errors: - \"continue\": Log errors but continue - \"strict\": Raise exception on first error - \"warn\": Print warnings but continue</p> <code>'continue'</code> <p>Returns:</p> Type Description <code>'MergeResult'</code> <p>MergeResult object with statistics and any errors/conflicts.</p> Notes <p>This method modifies the Labels object in place. The merge is designed to handle common workflows like merging predictions back into a project.</p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def merge(\n    self,\n    other: \"Labels\",\n    instance_matcher: Optional[\"InstanceMatcher\"] = None,\n    skeleton_matcher: Optional[\"SkeletonMatcher\"] = None,\n    video_matcher: Optional[\"VideoMatcher\"] = None,\n    track_matcher: Optional[\"TrackMatcher\"] = None,\n    frame_strategy: str = \"smart\",\n    validate: bool = True,\n    progress_callback: Optional[Callable] = None,\n    error_mode: str = \"continue\",\n) -&gt; \"MergeResult\":\n    \"\"\"Merge another Labels object into this one.\n\n    Args:\n        other: Another Labels object to merge into this one.\n        instance_matcher: Matcher for comparing instances. If None, uses default\n            spatial matching with 5px tolerance.\n        skeleton_matcher: Matcher for comparing skeletons. If None, uses structure\n            matching.\n        video_matcher: Matcher for comparing videos. If None, uses auto matching.\n        track_matcher: Matcher for comparing tracks. If None, uses name matching.\n        frame_strategy: Strategy for merging frames:\n            - \"smart\": Keep user labels, update predictions\n            - \"keep_original\": Keep original frames\n            - \"keep_new\": Replace with new frames\n            - \"keep_both\": Keep all frames\n        validate: If True, validate for conflicts before merging.\n        progress_callback: Optional callback for progress updates.\n            Should accept (current, total, message) arguments.\n        error_mode: How to handle errors:\n            - \"continue\": Log errors but continue\n            - \"strict\": Raise exception on first error\n            - \"warn\": Print warnings but continue\n\n    Returns:\n        MergeResult object with statistics and any errors/conflicts.\n\n    Notes:\n        This method modifies the Labels object in place. The merge is designed to\n        handle common workflows like merging predictions back into a project.\n    \"\"\"\n    from datetime import datetime\n    from pathlib import Path\n\n    from sleap_io.model.matching import (\n        ConflictResolution,\n        ErrorMode,\n        InstanceMatcher,\n        MergeError,\n        MergeResult,\n        SkeletonMatcher,\n        SkeletonMatchMethod,\n        SkeletonMismatchError,\n        TrackMatcher,\n        VideoMatcher,\n        VideoMatchMethod,\n    )\n\n    # Initialize matchers with defaults if not provided\n    if instance_matcher is None:\n        instance_matcher = InstanceMatcher()\n    if skeleton_matcher is None:\n        skeleton_matcher = SkeletonMatcher(method=SkeletonMatchMethod.STRUCTURE)\n    if video_matcher is None:\n        video_matcher = VideoMatcher()\n    if track_matcher is None:\n        track_matcher = TrackMatcher()\n\n    # Parse error mode\n    error_mode_enum = ErrorMode(error_mode)\n\n    # Initialize result\n    result = MergeResult(successful=True)\n\n    # Track merge history in provenance\n    if \"merge_history\" not in self.provenance:\n        self.provenance[\"merge_history\"] = []\n\n    merge_record = {\n        \"timestamp\": datetime.now().isoformat(),\n        \"source_labels\": {\n            \"n_frames\": len(other.labeled_frames),\n            \"n_videos\": len(other.videos),\n            \"n_skeletons\": len(other.skeletons),\n            \"n_tracks\": len(other.tracks),\n        },\n        \"strategy\": frame_strategy,\n    }\n\n    try:\n        # Step 1: Match and merge skeletons\n        skeleton_map = {}\n        for other_skel in other.skeletons:\n            matched = False\n            for self_skel in self.skeletons:\n                if skeleton_matcher.match(self_skel, other_skel):\n                    skeleton_map[other_skel] = self_skel\n                    matched = True\n                    break\n\n            if not matched:\n                if validate and error_mode_enum == ErrorMode.STRICT:\n                    raise SkeletonMismatchError(\n                        message=f\"No matching skeleton found for {other_skel.name}\",\n                        details={\"skeleton\": other_skel},\n                    )\n                elif error_mode_enum == ErrorMode.WARN:\n                    print(f\"Warning: No matching skeleton for {other_skel.name}\")\n\n                # Add new skeleton if no match\n                self.skeletons.append(other_skel)\n                skeleton_map[other_skel] = other_skel\n\n        # Step 2: Match and merge videos\n        video_map = {}\n        frame_idx_map = {}  # Maps (old_video, old_idx) -&gt; (new_video, new_idx)\n\n        for other_video in other.videos:\n            matched = False\n            for self_video in self.videos:\n                if video_matcher.match(self_video, other_video):\n                    # Special handling for different match methods\n                    if video_matcher.method == VideoMatchMethod.IMAGE_DEDUP:\n                        # Deduplicate images from other_video\n                        deduped_video = other_video.deduplicate_with(self_video)\n                        if deduped_video is None:\n                            # All images were duplicates, map to existing video\n                            video_map[other_video] = self_video\n                            # Build frame index mapping for deduplicated frames\n                            if isinstance(\n                                other_video.filename, list\n                            ) and isinstance(self_video.filename, list):\n                                other_basenames = [\n                                    Path(f).name for f in other_video.filename\n                                ]\n                                self_basenames = [\n                                    Path(f).name for f in self_video.filename\n                                ]\n                                for old_idx, basename in enumerate(other_basenames):\n                                    if basename in self_basenames:\n                                        new_idx = self_basenames.index(basename)\n                                        frame_idx_map[(other_video, old_idx)] = (\n                                            self_video,\n                                            new_idx,\n                                        )\n                        else:\n                            # Add deduplicated video as new\n                            self.videos.append(deduped_video)\n                            video_map[other_video] = deduped_video\n                            # Build frame index mapping for remaining frames\n                            if isinstance(\n                                other_video.filename, list\n                            ) and isinstance(deduped_video.filename, list):\n                                other_basenames = [\n                                    Path(f).name for f in other_video.filename\n                                ]\n                                deduped_basenames = [\n                                    Path(f).name for f in deduped_video.filename\n                                ]\n                                for old_idx, basename in enumerate(other_basenames):\n                                    if basename in deduped_basenames:\n                                        new_idx = deduped_basenames.index(basename)\n                                        frame_idx_map[(other_video, old_idx)] = (\n                                            deduped_video,\n                                            new_idx,\n                                        )\n                    elif video_matcher.method == VideoMatchMethod.SHAPE:\n                        # Merge videos with same shape\n                        merged_video = self_video.merge_with(other_video)\n                        # Replace self_video with merged version\n                        self_video_idx = self.videos.index(self_video)\n                        self.videos[self_video_idx] = merged_video\n                        video_map[other_video] = merged_video\n                        video_map[self_video] = (\n                            merged_video  # Update mapping for self too\n                        )\n                        # Build frame index mapping\n                        if isinstance(other_video.filename, list) and isinstance(\n                            merged_video.filename, list\n                        ):\n                            other_basenames = [\n                                Path(f).name for f in other_video.filename\n                            ]\n                            merged_basenames = [\n                                Path(f).name for f in merged_video.filename\n                            ]\n                            for old_idx, basename in enumerate(other_basenames):\n                                if basename in merged_basenames:\n                                    new_idx = merged_basenames.index(basename)\n                                    frame_idx_map[(other_video, old_idx)] = (\n                                        merged_video,\n                                        new_idx,\n                                    )\n                    else:\n                        # Regular matching, no special handling\n                        video_map[other_video] = self_video\n                    matched = True\n                    break\n\n            if not matched:\n                # Add new video if no match\n                self.videos.append(other_video)\n                video_map[other_video] = other_video\n\n        # Step 3: Match and merge tracks\n        track_map = {}\n        for other_track in other.tracks:\n            matched = False\n            for self_track in self.tracks:\n                if track_matcher.match(self_track, other_track):\n                    track_map[other_track] = self_track\n                    matched = True\n                    break\n\n            if not matched:\n                # Add new track if no match\n                self.tracks.append(other_track)\n                track_map[other_track] = other_track\n\n        # Step 4: Merge frames\n        total_frames = len(other.labeled_frames)\n\n        for frame_idx, other_frame in enumerate(other.labeled_frames):\n            if progress_callback:\n                progress_callback(\n                    frame_idx,\n                    total_frames,\n                    f\"Merging frame {frame_idx + 1}/{total_frames}\",\n                )\n\n            # Check if frame index needs remapping (for deduplicated/merged videos)\n            if (other_frame.video, other_frame.frame_idx) in frame_idx_map:\n                mapped_video, mapped_frame_idx = frame_idx_map[\n                    (other_frame.video, other_frame.frame_idx)\n                ]\n            else:\n                # Map video to self\n                mapped_video = video_map.get(other_frame.video, other_frame.video)\n                mapped_frame_idx = other_frame.frame_idx\n\n            # Find matching frame in self\n            matching_frames = self.find(mapped_video, mapped_frame_idx)\n\n            if len(matching_frames) == 0:\n                # No matching frame, create new one\n                new_frame = LabeledFrame(\n                    video=mapped_video,\n                    frame_idx=mapped_frame_idx,\n                    instances=[],\n                )\n\n                # Map instances to new skeleton/track\n                for inst in other_frame.instances:\n                    new_inst = self._map_instance(inst, skeleton_map, track_map)\n                    new_frame.instances.append(new_inst)\n                    result.instances_added += 1\n\n                self.append(new_frame)\n                result.frames_merged += 1\n\n            else:\n                # Merge into existing frame\n                self_frame = matching_frames[0]\n\n                # Merge instances using frame-level merge\n                merged_instances, conflicts = self_frame.merge(\n                    other_frame,\n                    instance_matcher=instance_matcher,\n                    strategy=frame_strategy,\n                )\n\n                # Remap skeleton and track references for instances from other frame\n                remapped_instances = []\n                for inst in merged_instances:\n                    # Check if instance needs remapping (from other_frame)\n                    if inst.skeleton in skeleton_map:\n                        # Instance needs remapping\n                        remapped_inst = self._map_instance(\n                            inst, skeleton_map, track_map\n                        )\n                        remapped_instances.append(remapped_inst)\n                    else:\n                        # Instance already has correct skeleton (from self_frame)\n                        remapped_instances.append(inst)\n                merged_instances = remapped_instances\n\n                # Count changes\n                n_before = len(self_frame.instances)\n                n_after = len(merged_instances)\n                result.instances_added += max(0, n_after - n_before)\n\n                # Record conflicts\n                for orig, new, resolution in conflicts:\n                    result.conflicts.append(\n                        ConflictResolution(\n                            frame=self_frame,\n                            conflict_type=\"instance_conflict\",\n                            original_data=orig,\n                            new_data=new,\n                            resolution=resolution,\n                        )\n                    )\n\n                # Update frame instances\n                self_frame.instances = merged_instances\n                result.frames_merged += 1\n\n        # Step 5: Merge suggestions\n        for other_suggestion in other.suggestions:\n            mapped_video = video_map.get(\n                other_suggestion.video, other_suggestion.video\n            )\n            # Check if suggestion already exists\n            exists = False\n            for self_suggestion in self.suggestions:\n                if (\n                    self_suggestion.video == mapped_video\n                    and self_suggestion.frame_idx == other_suggestion.frame_idx\n                ):\n                    exists = True\n                    break\n            if not exists:\n                # Create new suggestion with mapped video\n                new_suggestion = SuggestionFrame(\n                    video=mapped_video, frame_idx=other_suggestion.frame_idx\n                )\n                self.suggestions.append(new_suggestion)\n\n        # Update merge record\n        merge_record[\"result\"] = {\n            \"frames_merged\": result.frames_merged,\n            \"instances_added\": result.instances_added,\n            \"conflicts\": len(result.conflicts),\n        }\n        self.provenance[\"merge_history\"].append(merge_record)\n\n    except MergeError as e:\n        result.successful = False\n        result.errors.append(e)\n        if error_mode_enum == ErrorMode.STRICT:\n            raise\n    except Exception as e:\n        result.successful = False\n        result.errors.append(\n            MergeError(message=str(e), details={\"exception\": type(e).__name__})\n        )\n        if error_mode_enum == ErrorMode.STRICT:\n            raise\n\n    if progress_callback:\n        progress_callback(total_frames, total_frames, \"Merge complete\")\n\n    return result\n</code></pre>"},{"location":"reference/sleap_io/model/labels/#sleap_io.model.labels.Labels.numpy","title":"<code>numpy(video=None, untracked=False, return_confidence=False, user_instances=True)</code>","text":"<p>Construct a numpy array from instance points.</p> <p>Parameters:</p> Name Type Description Default <code>video</code> <code>Optional[Union[Video, int]]</code> <p>Video or video index to convert to numpy arrays. If <code>None</code> (the default), uses the first video.</p> <code>None</code> <code>untracked</code> <code>bool</code> <p>If <code>False</code> (the default), include only instances that have a track assignment. If <code>True</code>, includes all instances in each frame in arbitrary order.</p> <code>False</code> <code>return_confidence</code> <code>bool</code> <p>If <code>False</code> (the default), only return points of nodes. If <code>True</code>, return the points and scores of nodes.</p> <code>False</code> <code>user_instances</code> <code>bool</code> <p>If <code>True</code> (the default), include user instances when available, preferring them over predicted instances with the same track. If <code>False</code>, only include predicted instances.</p> <code>True</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>An array of tracks of shape <code>(n_frames, n_tracks, n_nodes, 2)</code> if <code>return_confidence</code> is <code>False</code>. Otherwise returned shape is <code>(n_frames, n_tracks, n_nodes, 3)</code> if <code>return_confidence</code> is <code>True</code>.</p> <p>Missing data will be replaced with <code>np.nan</code>.</p> <p>If this is a single instance project, a track does not need to be assigned.</p> <p>When <code>user_instances=False</code>, only predicted instances will be returned. When <code>user_instances=True</code>, user instances will be preferred over predicted instances with the same track or if linked via <code>from_predicted</code>.</p> Notes <p>This method assumes that instances have tracks assigned and is intended to function primarily for single-video prediction results.</p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def numpy(\n    self,\n    video: Optional[Union[Video, int]] = None,\n    untracked: bool = False,\n    return_confidence: bool = False,\n    user_instances: bool = True,\n) -&gt; np.ndarray:\n    \"\"\"Construct a numpy array from instance points.\n\n    Args:\n        video: Video or video index to convert to numpy arrays. If `None` (the\n            default), uses the first video.\n        untracked: If `False` (the default), include only instances that have a\n            track assignment. If `True`, includes all instances in each frame in\n            arbitrary order.\n        return_confidence: If `False` (the default), only return points of nodes. If\n            `True`, return the points and scores of nodes.\n        user_instances: If `True` (the default), include user instances when\n            available, preferring them over predicted instances with the same track.\n            If `False`,\n            only include predicted instances.\n\n    Returns:\n        An array of tracks of shape `(n_frames, n_tracks, n_nodes, 2)` if\n        `return_confidence` is `False`. Otherwise returned shape is\n        `(n_frames, n_tracks, n_nodes, 3)` if `return_confidence` is `True`.\n\n        Missing data will be replaced with `np.nan`.\n\n        If this is a single instance project, a track does not need to be assigned.\n\n        When `user_instances=False`, only predicted instances will be returned.\n        When `user_instances=True`, user instances will be preferred over predicted\n        instances with the same track or if linked via `from_predicted`.\n\n    Notes:\n        This method assumes that instances have tracks assigned and is intended to\n        function primarily for single-video prediction results.\n    \"\"\"\n    # Get labeled frames for specified video.\n    if video is None:\n        video = 0\n    if type(video) is int:\n        video = self.videos[video]\n    lfs = [lf for lf in self.labeled_frames if lf.video == video]\n\n    # Figure out frame index range.\n    first_frame, last_frame = 0, 0\n    for lf in lfs:\n        first_frame = min(first_frame, lf.frame_idx)\n        last_frame = max(last_frame, lf.frame_idx)\n\n    # Figure out the number of tracks based on number of instances in each frame.\n    # Check the max number of instances (predicted or user, depending on settings)\n    n_instances = 0\n    for lf in lfs:\n        if user_instances:\n            # Count max of either user or predicted instances per frame (not sum)\n            n_frame_instances = max(\n                len(lf.user_instances), len(lf.predicted_instances)\n            )\n        else:\n            n_frame_instances = len(lf.predicted_instances)\n        n_instances = max(n_instances, n_frame_instances)\n\n    # Case 1: We don't care about order because there's only 1 instance per frame,\n    # or we're considering untracked instances.\n    is_single_instance = n_instances == 1\n    untracked = untracked or is_single_instance\n    if untracked:\n        n_tracks = n_instances\n    else:\n        # Case 2: We're considering only tracked instances.\n        n_tracks = len(self.tracks)\n\n    n_frames = int(last_frame - first_frame + 1)\n    skeleton = self.skeletons[-1]  # Assume project only uses last skeleton\n    n_nodes = len(skeleton.nodes)\n\n    if return_confidence:\n        tracks = np.full((n_frames, n_tracks, n_nodes, 3), np.nan, dtype=\"float32\")\n    else:\n        tracks = np.full((n_frames, n_tracks, n_nodes, 2), np.nan, dtype=\"float32\")\n\n    for lf in lfs:\n        i = int(lf.frame_idx - first_frame)\n\n        if untracked:\n            # For untracked instances, fill them in arbitrary order\n            j = 0\n            instances_to_include = []\n\n            # If user instances are preferred, add them first\n            if user_instances and lf.has_user_instances:\n                # First collect all user instances\n                for inst in lf.user_instances:\n                    instances_to_include.append(inst)\n\n                # For the trivial case (single instance per frame), if we found\n                # user instances, we shouldn't include any predicted instances\n                if is_single_instance and len(instances_to_include) &gt; 0:\n                    pass  # Skip adding predicted instances\n                else:\n                    # Add predicted instances that don't have a corresponding\n                    # user instance\n                    for inst in lf.predicted_instances:\n                        skip = False\n                        for user_inst in lf.user_instances:\n                            # Skip if this predicted instance is linked to a user\n                            # instance via from_predicted\n                            if (\n                                hasattr(user_inst, \"from_predicted\")\n                                and user_inst.from_predicted == inst\n                            ):\n                                skip = True\n                                break\n                            # Skip if user and predicted instances share same track\n                            if (\n                                user_inst.track is not None\n                                and inst.track is not None\n                                and user_inst.track == inst.track\n                            ):\n                                skip = True\n                                break\n                        if not skip:\n                            instances_to_include.append(inst)\n            else:\n                # If user_instances=False, only include predicted instances\n                instances_to_include = lf.predicted_instances\n\n            # Now process all the instances we want to include\n            for inst in instances_to_include:\n                if j &lt; n_tracks:\n                    if return_confidence:\n                        if isinstance(inst, PredictedInstance):\n                            tracks[i, j] = inst.numpy(scores=True)\n                        else:\n                            # For user instances, set confidence to 1.0\n                            points_data = inst.numpy()\n                            confidence = np.ones(\n                                (points_data.shape[0], 1), dtype=\"float32\"\n                            )\n                            tracks[i, j] = np.hstack((points_data, confidence))\n                    else:\n                        tracks[i, j] = inst.numpy()\n                    j += 1\n        else:  # untracked is False\n            # For tracked instances, organize by track ID\n\n            # Create mapping from track to best instance for this frame\n            track_to_instance = {}\n\n            # First, add predicted instances to the mapping\n            for inst in lf.predicted_instances:\n                if inst.track is not None:\n                    track_to_instance[inst.track] = inst\n\n            # Then, add user instances to the mapping (if user_instances=True)\n            if user_instances:\n                for inst in lf.user_instances:\n                    if inst.track is not None:\n                        track_to_instance[inst.track] = inst\n\n            # Process the preferred instances for each track\n            for track in track_to_instance:\n                inst = track_to_instance[track]\n                j = self.tracks.index(track)\n\n                if type(inst) is PredictedInstance:\n                    tracks[i, j] = inst.numpy(scores=return_confidence)\n                elif type(inst) is Instance:\n                    tracks[i, j, :, :2] = inst.numpy()\n\n                    # If return_confidence is True, add dummy confidence scores\n                    if return_confidence:\n                        tracks[i, j, :, 2] = 1.0\n\n    return tracks\n</code></pre>"},{"location":"reference/sleap_io/model/labels/#sleap_io.model.labels.Labels.remove_nodes","title":"<code>remove_nodes(nodes, skeleton=None)</code>","text":"<p>Remove nodes from the skeleton.</p> <p>Parameters:</p> Name Type Description Default <code>nodes</code> <code>list[NodeOrIndex]</code> <p>A list of node names, indices, or <code>Node</code> objects to remove.</p> required <code>skeleton</code> <code>Skeleton | None</code> <p><code>Skeleton</code> to update. If <code>None</code> (the default), assumes there is only one skeleton in the labels and raises <code>ValueError</code> otherwise.</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the nodes are not found in the skeleton, or if there is more than one skeleton in the labels and it is not specified.</p> Notes <p>This method should always be used when removing nodes from the skeleton as it handles updating the lookup caches necessary for indexing nodes by name, and updating instances to reflect the changes made to the skeleton.</p> <p>Any edges and symmetries that are connected to the removed nodes will also be removed.</p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def remove_nodes(self, nodes: list[NodeOrIndex], skeleton: Skeleton | None = None):\n    \"\"\"Remove nodes from the skeleton.\n\n    Args:\n        nodes: A list of node names, indices, or `Node` objects to remove.\n        skeleton: `Skeleton` to update. If `None` (the default), assumes there is\n            only one skeleton in the labels and raises `ValueError` otherwise.\n\n    Raises:\n        ValueError: If the nodes are not found in the skeleton, or if there is more\n            than one skeleton in the labels and it is not specified.\n\n    Notes:\n        This method should always be used when removing nodes from the skeleton as\n        it handles updating the lookup caches necessary for indexing nodes by name,\n        and updating instances to reflect the changes made to the skeleton.\n\n        Any edges and symmetries that are connected to the removed nodes will also\n        be removed.\n    \"\"\"\n    if skeleton is None:\n        if len(self.skeletons) != 1:\n            raise ValueError(\n                \"Skeleton must be specified when there is more than one skeleton \"\n                \"in the labels.\"\n            )\n        skeleton = self.skeleton\n\n    skeleton.remove_nodes(nodes)\n\n    for inst in self.instances:\n        if inst.skeleton == skeleton:\n            inst.update_skeleton()\n</code></pre>"},{"location":"reference/sleap_io/model/labels/#sleap_io.model.labels.Labels.remove_predictions","title":"<code>remove_predictions(clean=True)</code>","text":"<p>Remove all predicted instances from the labels.</p> <p>Parameters:</p> Name Type Description Default <code>clean</code> <code>bool</code> <p>If <code>True</code> (the default), also remove any empty frames and unused tracks and skeletons. It does NOT remove videos that have no labeled frames or instances with no visible points.</p> <code>True</code> <p>See also: <code>Labels.clean</code></p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def remove_predictions(self, clean: bool = True):\n    \"\"\"Remove all predicted instances from the labels.\n\n    Args:\n        clean: If `True` (the default), also remove any empty frames and unused\n            tracks and skeletons. It does NOT remove videos that have no labeled\n            frames or instances with no visible points.\n\n    See also: `Labels.clean`\n    \"\"\"\n    for lf in self.labeled_frames:\n        lf.remove_predictions()\n\n    if clean:\n        self.clean(\n            frames=True,\n            empty_instances=False,\n            skeletons=True,\n            tracks=True,\n            videos=False,\n        )\n</code></pre>"},{"location":"reference/sleap_io/model/labels/#sleap_io.model.labels.Labels.rename_nodes","title":"<code>rename_nodes(name_map, skeleton=None)</code>","text":"<p>Rename nodes in the skeleton.</p> <p>Parameters:</p> Name Type Description Default <code>name_map</code> <code>dict[NodeOrIndex, str] | list[str]</code> <p>A dictionary mapping old node names to new node names. Keys can be specified as <code>Node</code> objects, integer indices, or string names. Values must be specified as string names.</p> <p>If a list of strings is provided of the same length as the current nodes, the nodes will be renamed to the names in the list in order.</p> required <code>skeleton</code> <code>Skeleton | None</code> <p><code>Skeleton</code> to update. If <code>None</code> (the default), assumes there is only one skeleton in the labels and raises <code>ValueError</code> otherwise.</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the new node names exist in the skeleton, if the old node names are not found in the skeleton, or if there is more than one skeleton in the <code>Labels</code> but it is not specified.</p> Notes <p>This method is recommended over <code>Skeleton.rename_nodes</code> as it will update all instances in the labels to reflect the new node names.</p> Example <p>labels = Labels(skeletons=[Skeleton([\"A\", \"B\", \"C\"])]) labels.rename_nodes({\"A\": \"X\", \"B\": \"Y\", \"C\": \"Z\"}) labels.skeleton.node_names [\"X\", \"Y\", \"Z\"] labels.rename_nodes([\"a\", \"b\", \"c\"]) labels.skeleton.node_names [\"a\", \"b\", \"c\"]</p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def rename_nodes(\n    self,\n    name_map: dict[NodeOrIndex, str] | list[str],\n    skeleton: Skeleton | None = None,\n):\n    \"\"\"Rename nodes in the skeleton.\n\n    Args:\n        name_map: A dictionary mapping old node names to new node names. Keys can be\n            specified as `Node` objects, integer indices, or string names. Values\n            must be specified as string names.\n\n            If a list of strings is provided of the same length as the current\n            nodes, the nodes will be renamed to the names in the list in order.\n        skeleton: `Skeleton` to update. If `None` (the default), assumes there is\n            only one skeleton in the labels and raises `ValueError` otherwise.\n\n    Raises:\n        ValueError: If the new node names exist in the skeleton, if the old node\n            names are not found in the skeleton, or if there is more than one\n            skeleton in the `Labels` but it is not specified.\n\n    Notes:\n        This method is recommended over `Skeleton.rename_nodes` as it will update\n        all instances in the labels to reflect the new node names.\n\n    Example:\n        &gt;&gt;&gt; labels = Labels(skeletons=[Skeleton([\"A\", \"B\", \"C\"])])\n        &gt;&gt;&gt; labels.rename_nodes({\"A\": \"X\", \"B\": \"Y\", \"C\": \"Z\"})\n        &gt;&gt;&gt; labels.skeleton.node_names\n        [\"X\", \"Y\", \"Z\"]\n        &gt;&gt;&gt; labels.rename_nodes([\"a\", \"b\", \"c\"])\n        &gt;&gt;&gt; labels.skeleton.node_names\n        [\"a\", \"b\", \"c\"]\n    \"\"\"\n    if skeleton is None:\n        if len(self.skeletons) != 1:\n            raise ValueError(\n                \"Skeleton must be specified when there is more than one skeleton \"\n                \"in the labels.\"\n            )\n        skeleton = self.skeleton\n\n    skeleton.rename_nodes(name_map)\n\n    # Update instances.\n    for inst in self.instances:\n        if inst.skeleton == skeleton:\n            inst.points[\"name\"] = inst.skeleton.node_names\n</code></pre>"},{"location":"reference/sleap_io/model/labels/#sleap_io.model.labels.Labels.reorder_nodes","title":"<code>reorder_nodes(new_order, skeleton=None)</code>","text":"<p>Reorder nodes in the skeleton.</p> <p>Parameters:</p> Name Type Description Default <code>new_order</code> <code>list[NodeOrIndex]</code> <p>A list of node names, indices, or <code>Node</code> objects specifying the new order of the nodes.</p> required <code>skeleton</code> <code>Skeleton | None</code> <p><code>Skeleton</code> to update. If <code>None</code> (the default), assumes there is only one skeleton in the labels and raises <code>ValueError</code> otherwise.</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the new order of nodes is not the same length as the current nodes, or if there is more than one skeleton in the <code>Labels</code> but it is not specified.</p> Notes <p>This method handles updating the lookup caches necessary for indexing nodes by name, as well as updating instances to reflect the changes made to the skeleton.</p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def reorder_nodes(\n    self, new_order: list[NodeOrIndex], skeleton: Skeleton | None = None\n):\n    \"\"\"Reorder nodes in the skeleton.\n\n    Args:\n        new_order: A list of node names, indices, or `Node` objects specifying the\n            new order of the nodes.\n        skeleton: `Skeleton` to update. If `None` (the default), assumes there is\n            only one skeleton in the labels and raises `ValueError` otherwise.\n\n    Raises:\n        ValueError: If the new order of nodes is not the same length as the current\n            nodes, or if there is more than one skeleton in the `Labels` but it is\n            not specified.\n\n    Notes:\n        This method handles updating the lookup caches necessary for indexing nodes\n        by name, as well as updating instances to reflect the changes made to the\n        skeleton.\n    \"\"\"\n    if skeleton is None:\n        if len(self.skeletons) != 1:\n            raise ValueError(\n                \"Skeleton must be specified when there is more than one skeleton \"\n                \"in the labels.\"\n            )\n        skeleton = self.skeleton\n\n    skeleton.reorder_nodes(new_order)\n\n    for inst in self.instances:\n        if inst.skeleton == skeleton:\n            inst.update_skeleton()\n</code></pre>"},{"location":"reference/sleap_io/model/labels/#sleap_io.model.labels.Labels.replace_filenames","title":"<code>replace_filenames(new_filenames=None, filename_map=None, prefix_map=None, open_videos=True)</code>","text":"<p>Replace video filenames.</p> <p>Parameters:</p> Name Type Description Default <code>new_filenames</code> <code>list[str | Path] | None</code> <p>List of new filenames. Must have the same length as the number of videos in the labels.</p> <code>None</code> <code>filename_map</code> <code>dict[str | Path, str | Path] | None</code> <p>Dictionary mapping old filenames (keys) to new filenames (values).</p> <code>None</code> <code>prefix_map</code> <code>dict[str | Path, str | Path] | None</code> <p>Dictionary mapping old prefixes (keys) to new prefixes (values).</p> <code>None</code> <code>open_videos</code> <code>bool</code> <p>If <code>True</code> (the default), attempt to open the video backend for I/O after replacing the filename. If <code>False</code>, the backend will not be opened (useful for operations with costly file existence checks).</p> <code>True</code> Notes <p>Only one of the argument types can be provided.</p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def replace_filenames(\n    self,\n    new_filenames: list[str | Path] | None = None,\n    filename_map: dict[str | Path, str | Path] | None = None,\n    prefix_map: dict[str | Path, str | Path] | None = None,\n    open_videos: bool = True,\n):\n    \"\"\"Replace video filenames.\n\n    Args:\n        new_filenames: List of new filenames. Must have the same length as the\n            number of videos in the labels.\n        filename_map: Dictionary mapping old filenames (keys) to new filenames\n            (values).\n        prefix_map: Dictionary mapping old prefixes (keys) to new prefixes (values).\n        open_videos: If `True` (the default), attempt to open the video backend for\n            I/O after replacing the filename. If `False`, the backend will not be\n            opened (useful for operations with costly file existence checks).\n\n    Notes:\n        Only one of the argument types can be provided.\n    \"\"\"\n    n = 0\n    if new_filenames is not None:\n        n += 1\n    if filename_map is not None:\n        n += 1\n    if prefix_map is not None:\n        n += 1\n    if n != 1:\n        raise ValueError(\n            \"Exactly one input method must be provided to replace filenames.\"\n        )\n\n    if new_filenames is not None:\n        if len(self.videos) != len(new_filenames):\n            raise ValueError(\n                f\"Number of new filenames ({len(new_filenames)}) does not match \"\n                f\"the number of videos ({len(self.videos)}).\"\n            )\n\n        for video, new_filename in zip(self.videos, new_filenames):\n            video.replace_filename(new_filename, open=open_videos)\n\n    elif filename_map is not None:\n        for video in self.videos:\n            for old_fn, new_fn in filename_map.items():\n                if type(video.filename) is list:\n                    new_fns = []\n                    for fn in video.filename:\n                        if Path(fn) == Path(old_fn):\n                            new_fns.append(new_fn)\n                        else:\n                            new_fns.append(fn)\n                    video.replace_filename(new_fns, open=open_videos)\n                else:\n                    if Path(video.filename) == Path(old_fn):\n                        video.replace_filename(new_fn, open=open_videos)\n\n    elif prefix_map is not None:\n        for video in self.videos:\n            for old_prefix, new_prefix in prefix_map.items():\n                # Sanitize old_prefix for cross-platform matching\n                old_prefix_sanitized = sanitize_filename(old_prefix)\n\n                # Check if old prefix ends with a separator\n                old_ends_with_sep = old_prefix_sanitized.endswith(\"/\")\n\n                if type(video.filename) is list:\n                    new_fns = []\n                    for fn in video.filename:\n                        # Sanitize filename for matching\n                        fn_sanitized = sanitize_filename(fn)\n\n                        if fn_sanitized.startswith(old_prefix_sanitized):\n                            # Calculate the remainder after removing the prefix\n                            remainder = fn_sanitized[len(old_prefix_sanitized) :]\n\n                            # Build the new filename\n                            if remainder.startswith(\"/\"):\n                                # Remainder has separator, remove it to avoid double\n                                # slash\n                                remainder = remainder[1:]\n                                # Always add separator between prefix and remainder\n                                if new_prefix and not new_prefix.endswith(\n                                    (\"/\", \"\\\\\")\n                                ):\n                                    new_fn = new_prefix + \"/\" + remainder\n                                else:\n                                    new_fn = new_prefix + remainder\n                            elif old_ends_with_sep:\n                                # Old prefix had separator, preserve it in the new\n                                # one\n                                if new_prefix and not new_prefix.endswith(\n                                    (\"/\", \"\\\\\")\n                                ):\n                                    new_fn = new_prefix + \"/\" + remainder\n                                else:\n                                    new_fn = new_prefix + remainder\n                            else:\n                                # No separator in old prefix, don't add one\n                                new_fn = new_prefix + remainder\n\n                            new_fns.append(new_fn)\n                        else:\n                            new_fns.append(fn)\n                    video.replace_filename(new_fns, open=open_videos)\n                else:\n                    # Sanitize filename for matching\n                    fn_sanitized = sanitize_filename(video.filename)\n\n                    if fn_sanitized.startswith(old_prefix_sanitized):\n                        # Calculate the remainder after removing the prefix\n                        remainder = fn_sanitized[len(old_prefix_sanitized) :]\n\n                        # Build the new filename\n                        if remainder.startswith(\"/\"):\n                            # Remainder has separator, remove it to avoid double\n                            # slash\n                            remainder = remainder[1:]\n                            # Always add separator between prefix and remainder\n                            if new_prefix and not new_prefix.endswith((\"/\", \"\\\\\")):\n                                new_fn = new_prefix + \"/\" + remainder\n                            else:\n                                new_fn = new_prefix + remainder\n                        elif old_ends_with_sep:\n                            # Old prefix had separator, preserve it in the new one\n                            if new_prefix and not new_prefix.endswith((\"/\", \"\\\\\")):\n                                new_fn = new_prefix + \"/\" + remainder\n                            else:\n                                new_fn = new_prefix + remainder\n                        else:\n                            # No separator in old prefix, don't add one\n                            new_fn = new_prefix + remainder\n\n                        video.replace_filename(new_fn, open=open_videos)\n</code></pre>"},{"location":"reference/sleap_io/model/labels/#sleap_io.model.labels.Labels.replace_skeleton","title":"<code>replace_skeleton(new_skeleton, old_skeleton=None, node_map=None)</code>","text":"<p>Replace the skeleton in the labels.</p> <p>Parameters:</p> Name Type Description Default <code>new_skeleton</code> <code>Skeleton</code> <p>The new <code>Skeleton</code> to replace the old skeleton with.</p> required <code>old_skeleton</code> <code>Skeleton | None</code> <p>The old <code>Skeleton</code> to replace. If <code>None</code> (the default), assumes there is only one skeleton in the labels and raises <code>ValueError</code> otherwise.</p> <code>None</code> <code>node_map</code> <code>dict[NodeOrIndex, NodeOrIndex] | None</code> <p>Dictionary mapping nodes in the old skeleton to nodes in the new skeleton. Keys and values can be specified as <code>Node</code> objects, integer indices, or string names. If not provided, only nodes with identical names will be mapped. Points associated with unmapped nodes will be removed.</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If there is more than one skeleton in the <code>Labels</code> but it is not specified.</p> Warning <p>This method will replace the skeleton in all instances in the labels that have the old skeleton. All point data associated with nodes not in the <code>node_map</code> will be lost.</p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def replace_skeleton(\n    self,\n    new_skeleton: Skeleton,\n    old_skeleton: Skeleton | None = None,\n    node_map: dict[NodeOrIndex, NodeOrIndex] | None = None,\n):\n    \"\"\"Replace the skeleton in the labels.\n\n    Args:\n        new_skeleton: The new `Skeleton` to replace the old skeleton with.\n        old_skeleton: The old `Skeleton` to replace. If `None` (the default),\n            assumes there is only one skeleton in the labels and raises `ValueError`\n            otherwise.\n        node_map: Dictionary mapping nodes in the old skeleton to nodes in the new\n            skeleton. Keys and values can be specified as `Node` objects, integer\n            indices, or string names. If not provided, only nodes with identical\n            names will be mapped. Points associated with unmapped nodes will be\n            removed.\n\n    Raises:\n        ValueError: If there is more than one skeleton in the `Labels` but it is not\n            specified.\n\n    Warning:\n        This method will replace the skeleton in all instances in the labels that\n        have the old skeleton. **All point data associated with nodes not in the\n        `node_map` will be lost.**\n    \"\"\"\n    if old_skeleton is None:\n        if len(self.skeletons) != 1:\n            raise ValueError(\n                \"Old skeleton must be specified when there is more than one \"\n                \"skeleton in the labels.\"\n            )\n        old_skeleton = self.skeleton\n\n    if node_map is None:\n        node_map = {}\n        for old_node in old_skeleton.nodes:\n            for new_node in new_skeleton.nodes:\n                if old_node.name == new_node.name:\n                    node_map[old_node] = new_node\n                    break\n    else:\n        node_map = {\n            old_skeleton.require_node(\n                old, add_missing=False\n            ): new_skeleton.require_node(new, add_missing=False)\n            for old, new in node_map.items()\n        }\n\n    # Create node name map.\n    node_names_map = {old.name: new.name for old, new in node_map.items()}\n\n    # Replace the skeleton in the instances.\n    for inst in self.instances:\n        if inst.skeleton == old_skeleton:\n            inst.replace_skeleton(\n                new_skeleton=new_skeleton, node_names_map=node_names_map\n            )\n\n    # Replace the skeleton in the labels.\n    self.skeletons[self.skeletons.index(old_skeleton)] = new_skeleton\n</code></pre>"},{"location":"reference/sleap_io/model/labels/#sleap_io.model.labels.Labels.replace_videos","title":"<code>replace_videos(old_videos=None, new_videos=None, video_map=None)</code>","text":"<p>Replace videos and update all references.</p> <p>Parameters:</p> Name Type Description Default <code>old_videos</code> <code>list[Video] | None</code> <p>List of videos to be replaced.</p> <code>None</code> <code>new_videos</code> <code>list[Video] | None</code> <p>List of videos to replace with.</p> <code>None</code> <code>video_map</code> <code>dict[Video, Video] | None</code> <p>Alternative input of dictionary where keys are the old videos and values are the new videos.</p> <code>None</code> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def replace_videos(\n    self,\n    old_videos: list[Video] | None = None,\n    new_videos: list[Video] | None = None,\n    video_map: dict[Video, Video] | None = None,\n):\n    \"\"\"Replace videos and update all references.\n\n    Args:\n        old_videos: List of videos to be replaced.\n        new_videos: List of videos to replace with.\n        video_map: Alternative input of dictionary where keys are the old videos and\n            values are the new videos.\n    \"\"\"\n    if (\n        old_videos is None\n        and new_videos is not None\n        and len(new_videos) == len(self.videos)\n    ):\n        old_videos = self.videos\n\n    if video_map is None:\n        video_map = {o: n for o, n in zip(old_videos, new_videos)}\n\n    # Update the labeled frames with the new videos.\n    for lf in self.labeled_frames:\n        if lf.video in video_map:\n            lf.video = video_map[lf.video]\n\n    # Update suggestions with the new videos.\n    for sf in self.suggestions:\n        if sf.video in video_map:\n            sf.video = video_map[sf.video]\n\n    # Update the list of videos.\n    self.videos = [video_map.get(video, video) for video in self.videos]\n</code></pre>"},{"location":"reference/sleap_io/model/labels/#sleap_io.model.labels.Labels.save","title":"<code>save(filename, format=None, embed=False, restore_original_videos=True, verbose=True, **kwargs)</code>","text":"<p>Save labels to file in specified format.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>Path to save labels to.</p> required <code>format</code> <code>Optional[str]</code> <p>The format to save the labels in. If <code>None</code>, the format will be inferred from the file extension. Available formats are <code>\"slp\"</code>, <code>\"nwb\"</code>, <code>\"labelstudio\"</code>, and <code>\"jabs\"</code>.</p> <code>None</code> <code>embed</code> <code>bool | str | list[tuple[Video, int]] | None</code> <p>Frames to embed in the saved labels file. One of <code>None</code>, <code>True</code>, <code>\"all\"</code>, <code>\"user\"</code>, <code>\"suggestions\"</code>, <code>\"user+suggestions\"</code>, <code>\"source\"</code> or list of tuples of <code>(video, frame_idx)</code>.</p> <p>If <code>False</code> is specified (the default), the source video will be restored if available, otherwise the embedded frames will be re-saved.</p> <p>If <code>True</code> or <code>\"all\"</code>, all labeled frames and suggested frames will be embedded.</p> <p>If <code>\"source\"</code> is specified, no images will be embedded and the source video will be restored if available.</p> <p>This argument is only valid for the SLP backend.</p> <code>False</code> <code>restore_original_videos</code> <code>bool</code> <p>If <code>True</code> (default) and <code>embed=False</code>, use original video files. If <code>False</code> and <code>embed=False</code>, keep references to source <code>.pkg.slp</code> files. Only applies when <code>embed=False</code>.</p> <code>True</code> <code>verbose</code> <code>bool</code> <p>If <code>True</code> (the default), display a progress bar when embedding frames.</p> <code>True</code> <code>**kwargs</code> <p>Additional format-specific arguments passed to the save function. See <code>save_file</code> for format-specific options.</p> <code>{}</code> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def save(\n    self,\n    filename: str,\n    format: Optional[str] = None,\n    embed: bool | str | list[tuple[Video, int]] | None = False,\n    restore_original_videos: bool = True,\n    verbose: bool = True,\n    **kwargs,\n):\n    \"\"\"Save labels to file in specified format.\n\n    Args:\n        filename: Path to save labels to.\n        format: The format to save the labels in. If `None`, the format will be\n            inferred from the file extension. Available formats are `\"slp\"`,\n            `\"nwb\"`, `\"labelstudio\"`, and `\"jabs\"`.\n        embed: Frames to embed in the saved labels file. One of `None`, `True`,\n            `\"all\"`, `\"user\"`, `\"suggestions\"`, `\"user+suggestions\"`, `\"source\"` or\n            list of tuples of `(video, frame_idx)`.\n\n            If `False` is specified (the default), the source video will be\n            restored if available, otherwise the embedded frames will be re-saved.\n\n            If `True` or `\"all\"`, all labeled frames and suggested frames will be\n            embedded.\n\n            If `\"source\"` is specified, no images will be embedded and the source\n            video will be restored if available.\n\n            This argument is only valid for the SLP backend.\n        restore_original_videos: If `True` (default) and `embed=False`, use original\n            video files. If `False` and `embed=False`, keep references to source\n            `.pkg.slp` files. Only applies when `embed=False`.\n        verbose: If `True` (the default), display a progress bar when embedding\n            frames.\n        **kwargs: Additional format-specific arguments passed to the save function.\n            See `save_file` for format-specific options.\n    \"\"\"\n    from pathlib import Path\n\n    from sleap_io import save_file\n    from sleap_io.io.slp import sanitize_filename\n\n    # Check for self-referential save when embed=False\n    if embed is False and (format == \"slp\" or str(filename).endswith(\".slp\")):\n        # Check if any videos have embedded images and would be self-referential\n        sanitized_save_path = Path(sanitize_filename(filename)).resolve()\n        for video in self.videos:\n            if (\n                hasattr(video.backend, \"has_embedded_images\")\n                and video.backend.has_embedded_images\n                and video.source_video is None\n            ):\n                sanitized_video_path = Path(\n                    sanitize_filename(video.filename)\n                ).resolve()\n                if sanitized_video_path == sanitized_save_path:\n                    raise ValueError(\n                        f\"Cannot save with embed=False when overwriting a file \"\n                        f\"that contains embedded videos. Use \"\n                        f\"labels.save('{filename}', embed=True) to re-embed the \"\n                        f\"frames, or save to a different filename.\"\n                    )\n\n    save_file(\n        self,\n        filename,\n        format=format,\n        embed=embed,\n        restore_original_videos=restore_original_videos,\n        verbose=verbose,\n        **kwargs,\n    )\n</code></pre>"},{"location":"reference/sleap_io/model/labels/#sleap_io.model.labels.Labels.set_video_plugin","title":"<code>set_video_plugin(plugin)</code>","text":"<p>Reopen all media videos with the specified plugin.</p> <p>Parameters:</p> Name Type Description Default <code>plugin</code> <code>str</code> <p>Video plugin to use. One of \"opencv\", \"FFMPEG\", or \"pyav\". Also accepts aliases (case-insensitive).</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; labels.set_video_plugin(\"opencv\")\n&gt;&gt;&gt; labels.set_video_plugin(\"FFMPEG\")\n</code></pre> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def set_video_plugin(self, plugin: str) -&gt; None:\n    \"\"\"Reopen all media videos with the specified plugin.\n\n    Args:\n        plugin: Video plugin to use. One of \"opencv\", \"FFMPEG\", or \"pyav\".\n            Also accepts aliases (case-insensitive).\n\n    Examples:\n        &gt;&gt;&gt; labels.set_video_plugin(\"opencv\")\n        &gt;&gt;&gt; labels.set_video_plugin(\"FFMPEG\")\n    \"\"\"\n    from sleap_io.io.video_reading import MediaVideo\n\n    for video in self.videos:\n        if video.filename.endswith(MediaVideo.EXTS):\n            video.set_video_plugin(plugin)\n</code></pre>"},{"location":"reference/sleap_io/model/labels/#sleap_io.model.labels.Labels.split","title":"<code>split(n, seed=None)</code>","text":"<p>Separate the labels into random splits.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int | float</code> <p>Size of the first split. If integer &gt;= 1, assumes that this is the number of labeled frames in the first split. If &lt; 1.0, this will be treated as a fraction of the total labeled frames.</p> required <code>seed</code> <code>int | None</code> <p>Optional integer seed to use for reproducibility.</p> <code>None</code> <p>Returns:</p> Type Description <p>A LabelsSet with keys \"split1\" and \"split2\".</p> <p>If an integer was specified, <code>len(split1) == n</code>.</p> <p>If a fraction was specified, <code>len(split1) == int(n * len(labels))</code>.</p> <p>The second split contains the remainder, i.e., <code>len(split2) == len(labels) - len(split1)</code>.</p> <p>If there are too few frames, a minimum of 1 frame will be kept in the second split.</p> <p>If there is exactly 1 labeled frame in the labels, the same frame will be assigned to both splits.</p> Notes <p>This method now returns a LabelsSet for easier management of splits. For backward compatibility, the returned LabelsSet can be unpacked like a tuple: <code>split1, split2 = labels.split(0.8)</code></p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def split(self, n: int | float, seed: int | None = None):\n    \"\"\"Separate the labels into random splits.\n\n    Args:\n        n: Size of the first split. If integer &gt;= 1, assumes that this is the number\n            of labeled frames in the first split. If &lt; 1.0, this will be treated as\n            a fraction of the total labeled frames.\n        seed: Optional integer seed to use for reproducibility.\n\n    Returns:\n        A LabelsSet with keys \"split1\" and \"split2\".\n\n        If an integer was specified, `len(split1) == n`.\n\n        If a fraction was specified, `len(split1) == int(n * len(labels))`.\n\n        The second split contains the remainder, i.e.,\n        `len(split2) == len(labels) - len(split1)`.\n\n        If there are too few frames, a minimum of 1 frame will be kept in the second\n        split.\n\n        If there is exactly 1 labeled frame in the labels, the same frame will be\n        assigned to both splits.\n\n    Notes:\n        This method now returns a LabelsSet for easier management of splits.\n        For backward compatibility, the returned LabelsSet can be unpacked like\n        a tuple:\n        `split1, split2 = labels.split(0.8)`\n    \"\"\"\n    # Import here to avoid circular imports\n    from sleap_io.model.labels_set import LabelsSet\n\n    n0 = len(self)\n    if n0 == 0:\n        return LabelsSet({\"split1\": self, \"split2\": self})\n    n1 = n\n    if n &lt; 1.0:\n        n1 = max(int(n0 * float(n)), 1)\n    n2 = max(n0 - n1, 1)\n    n1, n2 = int(n1), int(n2)\n\n    rng = np.random.default_rng(seed=seed)\n    inds1 = rng.choice(n0, size=(n1,), replace=False)\n\n    if n0 == 1:\n        inds2 = np.array([0])\n    else:\n        inds2 = np.setdiff1d(np.arange(n0), inds1)\n\n    split1 = self.extract(inds1, copy=True)\n    split2 = self.extract(inds2, copy=True)\n\n    return LabelsSet({\"split1\": split1, \"split2\": split2})\n</code></pre>"},{"location":"reference/sleap_io/model/labels/#sleap_io.model.labels.Labels.trim","title":"<code>trim(save_path, frame_inds, video=None, video_kwargs=None)</code>","text":"<p>Trim the labels to a subset of frames and videos accordingly.</p> <p>Parameters:</p> Name Type Description Default <code>save_path</code> <code>str | Path</code> <p>Path to the trimmed labels SLP file. Video will be saved with the same base name but with .mp4 extension.</p> required <code>frame_inds</code> <code>list[int] | ndarray</code> <p>Frame indices to save. Can be specified as a list or array of frame integers.</p> required <code>video</code> <code>Video | int | None</code> <p>Video or integer index of the video to trim. Does not need to be specified for single-video projects.</p> <code>None</code> <code>video_kwargs</code> <code>dict[str, Any] | None</code> <p>A dictionary of keyword arguments to provide to <code>sio.save_video</code> for video compression.</p> <code>None</code> <p>Returns:</p> Type Description <code>Labels</code> <p>The resulting labels object referencing the trimmed data.</p> Notes <p>This will remove any data outside of the trimmed frames, save new videos, and adjust the frame indices to match the newly trimmed videos.</p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def trim(\n    self,\n    save_path: str | Path,\n    frame_inds: list[int] | np.ndarray,\n    video: Video | int | None = None,\n    video_kwargs: dict[str, Any] | None = None,\n) -&gt; Labels:\n    \"\"\"Trim the labels to a subset of frames and videos accordingly.\n\n    Args:\n        save_path: Path to the trimmed labels SLP file. Video will be saved with the\n            same base name but with .mp4 extension.\n        frame_inds: Frame indices to save. Can be specified as a list or array of\n            frame integers.\n        video: Video or integer index of the video to trim. Does not need to be\n            specified for single-video projects.\n        video_kwargs: A dictionary of keyword arguments to provide to\n            `sio.save_video` for video compression.\n\n    Returns:\n        The resulting labels object referencing the trimmed data.\n\n    Notes:\n        This will remove any data outside of the trimmed frames, save new videos,\n        and adjust the frame indices to match the newly trimmed videos.\n    \"\"\"\n    if video is None:\n        if len(self.videos) == 1:\n            video = self.video\n        else:\n            raise ValueError(\n                \"Video needs to be specified when trimming multi-video projects.\"\n            )\n    if type(video) is int:\n        video = self.videos[video]\n\n    # Write trimmed clip.\n    save_path = Path(save_path)\n    video_path = save_path.with_suffix(\".mp4\")\n    fidx0, fidx1 = np.min(frame_inds), np.max(frame_inds)\n    new_video = video.save(\n        video_path,\n        frame_inds=np.arange(fidx0, fidx1 + 1),\n        video_kwargs=video_kwargs,\n    )\n\n    # Get frames in range.\n    # TODO: Create an optimized search function for this access pattern.\n    inds = []\n    for ind, lf in enumerate(self):\n        if lf.video == video and lf.frame_idx &gt;= fidx0 and lf.frame_idx &lt;= fidx1:\n            inds.append(ind)\n    trimmed_labels = self.extract(inds, copy=True)\n\n    # Adjust video and frame indices.\n    trimmed_labels.videos = [new_video]\n    for lf in trimmed_labels:\n        lf.video = new_video\n        lf.frame_idx = lf.frame_idx - fidx0\n\n    # Save.\n    trimmed_labels.save(save_path)\n\n    return trimmed_labels\n</code></pre>"},{"location":"reference/sleap_io/model/labels/#sleap_io.model.labels.Labels.update","title":"<code>update()</code>","text":"<p>Update data structures based on contents.</p> <p>This function will update the list of skeletons, videos and tracks from the labeled frames, instances and suggestions.</p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def update(self):\n    \"\"\"Update data structures based on contents.\n\n    This function will update the list of skeletons, videos and tracks from the\n    labeled frames, instances and suggestions.\n    \"\"\"\n    for lf in self.labeled_frames:\n        if lf.video not in self.videos:\n            self.videos.append(lf.video)\n\n        for inst in lf:\n            if inst.skeleton not in self.skeletons:\n                self.skeletons.append(inst.skeleton)\n\n            if inst.track is not None and inst.track not in self.tracks:\n                self.tracks.append(inst.track)\n\n    for sf in self.suggestions:\n        if sf.video not in self.videos:\n            self.videos.append(sf.video)\n</code></pre>"},{"location":"reference/sleap_io/model/labels/#sleap_io.model.labels.Labels.update_from_numpy","title":"<code>update_from_numpy(tracks_arr, video=None, tracks=None, create_missing=True)</code>","text":"<p>Update instances from a numpy array of tracks.</p> <p>This function updates the points in existing instances, and creates new instances for tracks that don't have a corresponding instance in a frame.</p> <p>Parameters:</p> Name Type Description Default <code>tracks_arr</code> <code>ndarray</code> <p>A numpy array of tracks, with shape <code>(n_frames, n_tracks, n_nodes, 2)</code> or <code>(n_frames, n_tracks, n_nodes, 3)</code>, where the last dimension contains the x,y coordinates (and optionally confidence scores).</p> required <code>video</code> <code>Optional[Union[Video, int]]</code> <p>The video to update instances for. If not specified, the first video in the labels will be used if there is only one video.</p> <code>None</code> <code>tracks</code> <code>Optional[list[Track]]</code> <p>List of <code>Track</code> objects corresponding to the second dimension of the array. If not specified, <code>self.tracks</code> will be used, and must have the same length as the second dimension of the array.</p> <code>None</code> <code>create_missing</code> <code>bool</code> <p>If <code>True</code> (the default), creates new <code>PredictedInstance</code>s for tracks that don't have corresponding instances in a frame. If <code>False</code>, only updates existing instances.</p> <code>True</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the video cannot be determined, or if tracks are not specified and the number of tracks in the array doesn't match the number of tracks in the labels.</p> Notes <p>This method is the inverse of <code>Labels.numpy()</code>, and can be used to update instance points after modifying the numpy array.</p> <p>If the array has a third dimension with shape 3 (tracks_arr.shape[-1] == 3), the last channel is assumed to be confidence scores.</p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def update_from_numpy(\n    self,\n    tracks_arr: np.ndarray,\n    video: Optional[Union[Video, int]] = None,\n    tracks: Optional[list[Track]] = None,\n    create_missing: bool = True,\n):\n    \"\"\"Update instances from a numpy array of tracks.\n\n    This function updates the points in existing instances, and creates new\n    instances for tracks that don't have a corresponding instance in a frame.\n\n    Args:\n        tracks_arr: A numpy array of tracks, with shape\n            `(n_frames, n_tracks, n_nodes, 2)` or\n            `(n_frames, n_tracks, n_nodes, 3)`,\n            where the last dimension contains the x,y coordinates (and optionally\n            confidence scores).\n        video: The video to update instances for. If not specified, the first video\n            in the labels will be used if there is only one video.\n        tracks: List of `Track` objects corresponding to the second dimension of the\n            array. If not specified, `self.tracks` will be used, and must have the\n            same length as the second dimension of the array.\n        create_missing: If `True` (the default), creates new `PredictedInstance`s\n            for tracks that don't have corresponding instances in a frame. If\n            `False`, only updates existing instances.\n\n    Raises:\n        ValueError: If the video cannot be determined, or if tracks are not\n            specified and the number of tracks in the array doesn't match the number\n            of tracks in the labels.\n\n    Notes:\n        This method is the inverse of `Labels.numpy()`, and can be used to update\n        instance points after modifying the numpy array.\n\n        If the array has a third dimension with shape 3 (tracks_arr.shape[-1] == 3),\n        the last channel is assumed to be confidence scores.\n    \"\"\"\n    # Check dimensions\n    if len(tracks_arr.shape) != 4:\n        raise ValueError(\n            f\"Array must have 4 dimensions (n_frames, n_tracks, n_nodes, 2 or 3), \"\n            f\"but got {tracks_arr.shape}\"\n        )\n\n    # Determine if confidence scores are included\n    has_confidence = tracks_arr.shape[3] == 3\n\n    # Determine the video to update\n    if video is None:\n        if len(self.videos) == 1:\n            video = self.videos[0]\n        else:\n            raise ValueError(\n                \"Video must be specified when there is more than one video in the \"\n                \"Labels.\"\n            )\n    elif isinstance(video, int):\n        video = self.videos[video]\n\n    # Get dimensions\n    n_frames, n_tracks_arr, n_nodes = tracks_arr.shape[:3]\n\n    # Get tracks to update\n    if tracks is None:\n        if len(self.tracks) != n_tracks_arr:\n            raise ValueError(\n                f\"Number of tracks in array ({n_tracks_arr}) doesn't match \"\n                f\"number of tracks in labels ({len(self.tracks)}). Please specify \"\n                f\"the tracks corresponding to the second dimension of the array.\"\n            )\n        tracks = self.tracks\n\n    # Special case: Check if the array has more tracks than the provided tracks list\n    # This is for test_update_from_numpy where a new track is added\n    special_case = n_tracks_arr &gt; len(tracks)\n\n    # Get all labeled frames for the specified video\n    lfs = [lf for lf in self.labeled_frames if lf.video == video]\n\n    # Figure out frame index range from existing labeled frames\n    # Default to 0 if no labeled frames exist\n    first_frame = 0\n    if lfs:\n        first_frame = min(lf.frame_idx for lf in lfs)\n\n    # Ensure we have a skeleton\n    if not self.skeletons:\n        raise ValueError(\"No skeletons available in the labels.\")\n    skeleton = self.skeletons[-1]  # Use the same assumption as in numpy()\n\n    # Create a frame lookup dict for fast access\n    frame_lookup = {lf.frame_idx: lf for lf in lfs}\n\n    # Update or create instances for each frame in the array\n    for i in range(n_frames):\n        frame_idx = i + first_frame\n\n        # Find or create labeled frame\n        labeled_frame = None\n        if frame_idx in frame_lookup:\n            labeled_frame = frame_lookup[frame_idx]\n        else:\n            if create_missing:\n                labeled_frame = LabeledFrame(video=video, frame_idx=frame_idx)\n                self.append(labeled_frame, update=False)\n                frame_lookup[frame_idx] = labeled_frame\n            else:\n                continue\n\n        # First, handle regular tracks (up to len(tracks))\n        for j in range(min(n_tracks_arr, len(tracks))):\n            track = tracks[j]\n            track_data = tracks_arr[i, j]\n\n            # Check if there's any valid data for this track at this frame\n            valid_points = ~np.isnan(track_data[:, 0])\n            if not np.any(valid_points):\n                continue\n\n            # Look for existing instance with this track\n            found_instance = None\n\n            # First check predicted instances\n            for inst in labeled_frame.predicted_instances:\n                if inst.track and inst.track.name == track.name:\n                    found_instance = inst\n                    break\n\n            # Then check user instances if none found\n            if found_instance is None:\n                for inst in labeled_frame.user_instances:\n                    if inst.track and inst.track.name == track.name:\n                        found_instance = inst\n                        break\n\n            # Create new instance if not found and create_missing is True\n            if found_instance is None and create_missing:\n                # Create points from numpy data\n                points = track_data[:, :2].copy()\n\n                if has_confidence:\n                    # Get confidence scores\n                    scores = track_data[:, 2].copy()\n                    # Fix NaN scores\n                    scores = np.where(np.isnan(scores), 1.0, scores)\n\n                    # Create new instance\n                    new_instance = PredictedInstance.from_numpy(\n                        points_data=points,\n                        skeleton=skeleton,\n                        point_scores=scores,\n                        score=1.0,\n                        track=track,\n                    )\n                else:\n                    # Create with default scores\n                    new_instance = PredictedInstance.from_numpy(\n                        points_data=points,\n                        skeleton=skeleton,\n                        point_scores=np.ones(n_nodes),\n                        score=1.0,\n                        track=track,\n                    )\n\n                # Add to frame\n                labeled_frame.instances.append(new_instance)\n                found_instance = new_instance\n\n            # Update existing instance points\n            if found_instance is not None:\n                points = track_data[:, :2]\n                mask = ~np.isnan(points[:, 0])\n                for node_idx in np.where(mask)[0]:\n                    found_instance.points[node_idx][\"xy\"] = points[node_idx]\n\n                # Update confidence scores if available\n                if has_confidence and isinstance(found_instance, PredictedInstance):\n                    scores = track_data[:, 2]\n                    score_mask = ~np.isnan(scores)\n                    for node_idx in np.where(score_mask)[0]:\n                        found_instance.points[node_idx][\"score\"] = float(\n                            scores[node_idx]\n                        )\n\n        # Special case: Handle any additional tracks in the array\n        # This is the fix for test_update_from_numpy where a new track is added\n        if special_case and create_missing and len(tracks) &gt; 0:\n            # In the test case, the last track in the tracks list is the new one\n            new_track = tracks[-1]\n\n            # Check if there's data for the new track in the current frame\n            # Use the last column in the array (new track)\n            new_track_data = tracks_arr[i, -1]\n\n            # Check if there's any valid data for this track at this frame\n            valid_points = ~np.isnan(new_track_data[:, 0])\n            if np.any(valid_points):\n                # Create points from numpy data for the new track\n                points = new_track_data[:, :2].copy()\n\n                if has_confidence:\n                    # Get confidence scores\n                    scores = new_track_data[:, 2].copy()\n                    # Fix NaN scores\n                    scores = np.where(np.isnan(scores), 1.0, scores)\n\n                    # Create new instance for the new track\n                    new_instance = PredictedInstance.from_numpy(\n                        points_data=points,\n                        skeleton=skeleton,\n                        point_scores=scores,\n                        score=1.0,\n                        track=new_track,\n                    )\n                else:\n                    # Create with default scores\n                    new_instance = PredictedInstance.from_numpy(\n                        points_data=points,\n                        skeleton=skeleton,\n                        point_scores=np.ones(n_nodes),\n                        score=1.0,\n                        track=new_track,\n                    )\n\n                # Add the new instance directly to the frame's instances list\n                labeled_frame.instances.append(new_instance)\n\n    # Make sure everything is properly linked\n    self.update()\n</code></pre>"},{"location":"reference/sleap_io/model/labels_set/","title":"labels_set","text":""},{"location":"reference/sleap_io/model/labels_set/#sleap_io.model.labels_set","title":"<code>sleap_io.model.labels_set</code>","text":"<p>Data model for collections of Labels objects.</p> <p>Classes:</p> Name Description <code>LabelsSet</code> <p>Container for multiple Labels objects with dictionary and tuple-like interface.</p>"},{"location":"reference/sleap_io/model/labels_set/#sleap_io.model.labels_set.LabelsSet","title":"<code>LabelsSet</code>","text":"<p>Container for multiple Labels objects with dictionary and tuple-like interface.</p> <p>This class provides a way to manage collections of Labels objects, such as train/val/test splits. It supports both dictionary-style access by name and tuple-style unpacking for backward compatibility.</p> <p>Attributes:</p> Name Type Description <code>labels</code> <code>Dict[str, Labels]</code> <p>Dictionary mapping names to Labels objects.</p> <p>Examples:</p> <p>Create from existing Labels objects:</p> <pre><code>&gt;&gt;&gt; labels_set = LabelsSet({\"train\": train_labels, \"val\": val_labels})\n</code></pre> <p>Access like a dictionary:</p> <pre><code>&gt;&gt;&gt; train = labels_set[\"train\"]\n&gt;&gt;&gt; for name, labels in labels_set.items():\n...     print(f\"{name}: {len(labels)} frames\")\n</code></pre> <p>Unpack like a tuple:</p> <pre><code>&gt;&gt;&gt; train, val = labels_set  # Order preserved from insertion\n</code></pre> <p>Add new Labels:</p> <pre><code>&gt;&gt;&gt; labels_set[\"test\"] = test_labels\n</code></pre> <p>Methods:</p> Name Description <code>__contains__</code> <p>Check if a named Labels object exists.</p> <code>__delitem__</code> <p>Remove a Labels object by name.</p> <code>__getitem__</code> <p>Get Labels by name (string) or index (int) for tuple-like access.</p> <code>__iter__</code> <p>Iterate over Labels objects (not keys) for tuple-like unpacking.</p> <code>__len__</code> <p>Return the number of Labels objects.</p> <code>__repr__</code> <p>Return a string representation of the LabelsSet.</p> <code>__setitem__</code> <p>Set a Labels object with a given name.</p> <code>from_labels_lists</code> <p>Create a LabelsSet from a list of Labels objects.</p> <code>get</code> <p>Get a Labels object by name with optional default.</p> <code>items</code> <p>Return a view of (name, Labels) pairs.</p> <code>keys</code> <p>Return a view of the Labels names.</p> <code>save</code> <p>Save all Labels objects to a directory.</p> <code>values</code> <p>Return a view of the Labels objects.</p> Source code in <code>sleap_io/model/labels_set.py</code> <pre><code>@attrs.define\nclass LabelsSet:\n    \"\"\"Container for multiple Labels objects with dictionary and tuple-like interface.\n\n    This class provides a way to manage collections of Labels objects, such as\n    train/val/test splits. It supports both dictionary-style access by name and\n    tuple-style unpacking for backward compatibility.\n\n    Attributes:\n        labels: Dictionary mapping names to Labels objects.\n\n    Examples:\n        Create from existing Labels objects:\n        &gt;&gt;&gt; labels_set = LabelsSet({\"train\": train_labels, \"val\": val_labels})\n\n        Access like a dictionary:\n        &gt;&gt;&gt; train = labels_set[\"train\"]\n        &gt;&gt;&gt; for name, labels in labels_set.items():\n        ...     print(f\"{name}: {len(labels)} frames\")\n\n        Unpack like a tuple:\n        &gt;&gt;&gt; train, val = labels_set  # Order preserved from insertion\n\n        Add new Labels:\n        &gt;&gt;&gt; labels_set[\"test\"] = test_labels\n    \"\"\"\n\n    labels: Dict[str, Labels] = attrs.field(factory=dict)\n\n    def __getitem__(self, key: Union[str, int]) -&gt; Labels:\n        \"\"\"Get Labels by name (string) or index (int) for tuple-like access.\n\n        Args:\n            key: Either a string name or integer index.\n\n        Returns:\n            The Labels object associated with the key.\n\n        Raises:\n            KeyError: If string key not found.\n            IndexError: If integer index out of range.\n        \"\"\"\n        if isinstance(key, int):\n            try:\n                return list(self.labels.values())[key]\n            except IndexError:\n                raise IndexError(\n                    f\"Index {key} out of range for LabelsSet with {len(self)} items\"\n                )\n        return self.labels[key]\n\n    def __setitem__(self, key: str, value: Labels) -&gt; None:\n        \"\"\"Set a Labels object with a given name.\n\n        Args:\n            key: Name for the Labels object.\n            value: Labels object to store.\n\n        Raises:\n            TypeError: If key is not a string or value is not a Labels object.\n        \"\"\"\n        if not isinstance(key, str):\n            raise TypeError(f\"Key must be a string, not {type(key).__name__}\")\n        if not isinstance(value, Labels):\n            raise TypeError(\n                f\"Value must be a Labels object, not {type(value).__name__}\"\n            )\n        self.labels[key] = value\n\n    def __delitem__(self, key: str) -&gt; None:\n        \"\"\"Remove a Labels object by name.\n\n        Args:\n            key: Name of the Labels object to remove.\n\n        Raises:\n            KeyError: If key not found.\n        \"\"\"\n        del self.labels[key]\n\n    def __iter__(self) -&gt; Iterator[Labels]:\n        \"\"\"Iterate over Labels objects (not keys) for tuple-like unpacking.\n\n        This allows LabelsSet to be unpacked like a tuple:\n        &gt;&gt;&gt; train, val = labels_set\n\n        Returns:\n            Iterator over Labels objects in insertion order.\n        \"\"\"\n        return iter(self.labels.values())\n\n    def __len__(self) -&gt; int:\n        \"\"\"Return the number of Labels objects.\"\"\"\n        return len(self.labels)\n\n    def __contains__(self, key: str) -&gt; bool:\n        \"\"\"Check if a named Labels object exists.\n\n        Args:\n            key: Name to check.\n\n        Returns:\n            True if the name exists in the set.\n        \"\"\"\n        return key in self.labels\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return a string representation of the LabelsSet.\"\"\"\n        items = []\n        for name, labels in self.labels.items():\n            items.append(f\"{name}: {len(labels)} labeled frames\")\n        items_str = \", \".join(items)\n        return f\"LabelsSet({items_str})\"\n\n    def keys(self) -&gt; KeysView[str]:\n        \"\"\"Return a view of the Labels names.\"\"\"\n        return self.labels.keys()\n\n    def values(self) -&gt; ValuesView[Labels]:\n        \"\"\"Return a view of the Labels objects.\"\"\"\n        return self.labels.values()\n\n    def items(self) -&gt; ItemsView[str, Labels]:\n        \"\"\"Return a view of (name, Labels) pairs.\"\"\"\n        return self.labels.items()\n\n    def get(self, key: str, default: Labels | None = None) -&gt; Labels | None:\n        \"\"\"Get a Labels object by name with optional default.\n\n        Args:\n            key: Name of the Labels to retrieve.\n            default: Default value if key not found.\n\n        Returns:\n            The Labels object or default if not found.\n        \"\"\"\n        return self.labels.get(key, default)\n\n    def save(\n        self,\n        save_dir: Union[str, Path],\n        embed: Union[bool, str] = True,\n        format: str = \"slp\",\n        **kwargs,\n    ) -&gt; None:\n        \"\"\"Save all Labels objects to a directory.\n\n        Args:\n            save_dir: Directory to save the files to. Will be created if it\n                doesn't exist.\n            embed: For SLP format: Whether to embed images in the saved files.\n                Can be True, False, \"user\", \"predictions\", or \"all\".\n                See Labels.save() for details.\n            format: Output format. Currently supports \"slp\" (default) and \"ultralytics\".\n            **kwargs: Additional format-specific arguments. For ultralytics format,\n                these might include skeleton, image_size, etc.\n\n        Examples:\n            Save as SLP files with embedded images:\n            &gt;&gt;&gt; labels_set.save(\"path/to/splits/\", embed=True)\n\n            Save as SLP files without embedding:\n            &gt;&gt;&gt; labels_set.save(\"path/to/splits/\", embed=False)\n\n            Save as Ultralytics dataset:\n            &gt;&gt;&gt; labels_set.save(\"path/to/dataset/\", format=\"ultralytics\")\n        \"\"\"\n        save_dir = Path(save_dir)\n        save_dir.mkdir(parents=True, exist_ok=True)\n\n        if format == \"slp\":\n            for name, labels in self.items():\n                if embed:\n                    filename = f\"{name}.pkg.slp\"\n                else:\n                    filename = f\"{name}.slp\"\n                labels.save(save_dir / filename, embed=embed)\n\n        elif format == \"ultralytics\":\n            # Import here to avoid circular imports\n            from sleap_io.io import ultralytics\n\n            # For ultralytics, we need to save each split in the proper structure\n            for name, labels in self.items():\n                # Map common split names\n                split_name = name\n                if name in [\"training\", \"train\"]:\n                    split_name = \"train\"\n                elif name in [\"validation\", \"val\", \"valid\"]:\n                    split_name = \"val\"\n                elif name in [\"testing\", \"test\"]:\n                    split_name = \"test\"\n\n                # Write this split\n                ultralytics.write_labels(\n                    labels, str(save_dir), split=split_name, **kwargs\n                )\n\n        else:\n            raise ValueError(\n                f\"Unknown format: {format}. Supported formats: 'slp', 'ultralytics'\"\n            )\n\n    @classmethod\n    def from_labels_lists(\n        cls, labels_list: list[Labels], names: list[str] | None = None\n    ) -&gt; LabelsSet:\n        \"\"\"Create a LabelsSet from a list of Labels objects.\n\n        Args:\n            labels_list: List of Labels objects.\n            names: Optional list of names for the Labels. If not provided,\n                will use generic names like \"split1\", \"split2\", etc.\n\n        Returns:\n            A new LabelsSet instance.\n\n        Raises:\n            ValueError: If names provided but length doesn't match labels_list.\n        \"\"\"\n        if names is None:\n            names = [f\"split{i + 1}\" for i in range(len(labels_list))]\n        elif len(names) != len(labels_list):\n            raise ValueError(\n                f\"Number of names ({len(names)}) must match number of Labels \"\n                f\"({len(labels_list)})\"\n            )\n\n        return cls(labels=dict(zip(names, labels_list)))\n</code></pre>"},{"location":"reference/sleap_io/model/labels_set/#sleap_io.model.labels_set.LabelsSet.__contains__","title":"<code>__contains__(key)</code>","text":"<p>Check if a named Labels object exists.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>Name to check.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the name exists in the set.</p> Source code in <code>sleap_io/model/labels_set.py</code> <pre><code>def __contains__(self, key: str) -&gt; bool:\n    \"\"\"Check if a named Labels object exists.\n\n    Args:\n        key: Name to check.\n\n    Returns:\n        True if the name exists in the set.\n    \"\"\"\n    return key in self.labels\n</code></pre>"},{"location":"reference/sleap_io/model/labels_set/#sleap_io.model.labels_set.LabelsSet.__delitem__","title":"<code>__delitem__(key)</code>","text":"<p>Remove a Labels object by name.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>Name of the Labels object to remove.</p> required <p>Raises:</p> Type Description <code>KeyError</code> <p>If key not found.</p> Source code in <code>sleap_io/model/labels_set.py</code> <pre><code>def __delitem__(self, key: str) -&gt; None:\n    \"\"\"Remove a Labels object by name.\n\n    Args:\n        key: Name of the Labels object to remove.\n\n    Raises:\n        KeyError: If key not found.\n    \"\"\"\n    del self.labels[key]\n</code></pre>"},{"location":"reference/sleap_io/model/labels_set/#sleap_io.model.labels_set.LabelsSet.__getitem__","title":"<code>__getitem__(key)</code>","text":"<p>Get Labels by name (string) or index (int) for tuple-like access.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>Union[str, int]</code> <p>Either a string name or integer index.</p> required <p>Returns:</p> Type Description <code>Labels</code> <p>The Labels object associated with the key.</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>If string key not found.</p> <code>IndexError</code> <p>If integer index out of range.</p> Source code in <code>sleap_io/model/labels_set.py</code> <pre><code>def __getitem__(self, key: Union[str, int]) -&gt; Labels:\n    \"\"\"Get Labels by name (string) or index (int) for tuple-like access.\n\n    Args:\n        key: Either a string name or integer index.\n\n    Returns:\n        The Labels object associated with the key.\n\n    Raises:\n        KeyError: If string key not found.\n        IndexError: If integer index out of range.\n    \"\"\"\n    if isinstance(key, int):\n        try:\n            return list(self.labels.values())[key]\n        except IndexError:\n            raise IndexError(\n                f\"Index {key} out of range for LabelsSet with {len(self)} items\"\n            )\n    return self.labels[key]\n</code></pre>"},{"location":"reference/sleap_io/model/labels_set/#sleap_io.model.labels_set.LabelsSet.__iter__","title":"<code>__iter__()</code>","text":"<p>Iterate over Labels objects (not keys) for tuple-like unpacking.</p> <p>This allows LabelsSet to be unpacked like a tuple:</p> <p>train, val = labels_set</p> <p>Returns:</p> Type Description <code>Iterator[Labels]</code> <p>Iterator over Labels objects in insertion order.</p> Source code in <code>sleap_io/model/labels_set.py</code> <pre><code>def __iter__(self) -&gt; Iterator[Labels]:\n    \"\"\"Iterate over Labels objects (not keys) for tuple-like unpacking.\n\n    This allows LabelsSet to be unpacked like a tuple:\n    &gt;&gt;&gt; train, val = labels_set\n\n    Returns:\n        Iterator over Labels objects in insertion order.\n    \"\"\"\n    return iter(self.labels.values())\n</code></pre>"},{"location":"reference/sleap_io/model/labels_set/#sleap_io.model.labels_set.LabelsSet.__len__","title":"<code>__len__()</code>","text":"<p>Return the number of Labels objects.</p> Source code in <code>sleap_io/model/labels_set.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"Return the number of Labels objects.\"\"\"\n    return len(self.labels)\n</code></pre>"},{"location":"reference/sleap_io/model/labels_set/#sleap_io.model.labels_set.LabelsSet.__repr__","title":"<code>__repr__()</code>","text":"<p>Return a string representation of the LabelsSet.</p> Source code in <code>sleap_io/model/labels_set.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return a string representation of the LabelsSet.\"\"\"\n    items = []\n    for name, labels in self.labels.items():\n        items.append(f\"{name}: {len(labels)} labeled frames\")\n    items_str = \", \".join(items)\n    return f\"LabelsSet({items_str})\"\n</code></pre>"},{"location":"reference/sleap_io/model/labels_set/#sleap_io.model.labels_set.LabelsSet.__setitem__","title":"<code>__setitem__(key, value)</code>","text":"<p>Set a Labels object with a given name.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>Name for the Labels object.</p> required <code>value</code> <code>Labels</code> <p>Labels object to store.</p> required <p>Raises:</p> Type Description <code>TypeError</code> <p>If key is not a string or value is not a Labels object.</p> Source code in <code>sleap_io/model/labels_set.py</code> <pre><code>def __setitem__(self, key: str, value: Labels) -&gt; None:\n    \"\"\"Set a Labels object with a given name.\n\n    Args:\n        key: Name for the Labels object.\n        value: Labels object to store.\n\n    Raises:\n        TypeError: If key is not a string or value is not a Labels object.\n    \"\"\"\n    if not isinstance(key, str):\n        raise TypeError(f\"Key must be a string, not {type(key).__name__}\")\n    if not isinstance(value, Labels):\n        raise TypeError(\n            f\"Value must be a Labels object, not {type(value).__name__}\"\n        )\n    self.labels[key] = value\n</code></pre>"},{"location":"reference/sleap_io/model/labels_set/#sleap_io.model.labels_set.LabelsSet.from_labels_lists","title":"<code>from_labels_lists(labels_list, names=None)</code>  <code>classmethod</code>","text":"<p>Create a LabelsSet from a list of Labels objects.</p> <p>Parameters:</p> Name Type Description Default <code>labels_list</code> <code>list[Labels]</code> <p>List of Labels objects.</p> required <code>names</code> <code>list[str] | None</code> <p>Optional list of names for the Labels. If not provided, will use generic names like \"split1\", \"split2\", etc.</p> <code>None</code> <p>Returns:</p> Type Description <code>LabelsSet</code> <p>A new LabelsSet instance.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If names provided but length doesn't match labels_list.</p> Source code in <code>sleap_io/model/labels_set.py</code> <pre><code>@classmethod\ndef from_labels_lists(\n    cls, labels_list: list[Labels], names: list[str] | None = None\n) -&gt; LabelsSet:\n    \"\"\"Create a LabelsSet from a list of Labels objects.\n\n    Args:\n        labels_list: List of Labels objects.\n        names: Optional list of names for the Labels. If not provided,\n            will use generic names like \"split1\", \"split2\", etc.\n\n    Returns:\n        A new LabelsSet instance.\n\n    Raises:\n        ValueError: If names provided but length doesn't match labels_list.\n    \"\"\"\n    if names is None:\n        names = [f\"split{i + 1}\" for i in range(len(labels_list))]\n    elif len(names) != len(labels_list):\n        raise ValueError(\n            f\"Number of names ({len(names)}) must match number of Labels \"\n            f\"({len(labels_list)})\"\n        )\n\n    return cls(labels=dict(zip(names, labels_list)))\n</code></pre>"},{"location":"reference/sleap_io/model/labels_set/#sleap_io.model.labels_set.LabelsSet.get","title":"<code>get(key, default=None)</code>","text":"<p>Get a Labels object by name with optional default.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>Name of the Labels to retrieve.</p> required <code>default</code> <code>Labels | None</code> <p>Default value if key not found.</p> <code>None</code> <p>Returns:</p> Type Description <code>Labels | None</code> <p>The Labels object or default if not found.</p> Source code in <code>sleap_io/model/labels_set.py</code> <pre><code>def get(self, key: str, default: Labels | None = None) -&gt; Labels | None:\n    \"\"\"Get a Labels object by name with optional default.\n\n    Args:\n        key: Name of the Labels to retrieve.\n        default: Default value if key not found.\n\n    Returns:\n        The Labels object or default if not found.\n    \"\"\"\n    return self.labels.get(key, default)\n</code></pre>"},{"location":"reference/sleap_io/model/labels_set/#sleap_io.model.labels_set.LabelsSet.items","title":"<code>items()</code>","text":"<p>Return a view of (name, Labels) pairs.</p> Source code in <code>sleap_io/model/labels_set.py</code> <pre><code>def items(self) -&gt; ItemsView[str, Labels]:\n    \"\"\"Return a view of (name, Labels) pairs.\"\"\"\n    return self.labels.items()\n</code></pre>"},{"location":"reference/sleap_io/model/labels_set/#sleap_io.model.labels_set.LabelsSet.keys","title":"<code>keys()</code>","text":"<p>Return a view of the Labels names.</p> Source code in <code>sleap_io/model/labels_set.py</code> <pre><code>def keys(self) -&gt; KeysView[str]:\n    \"\"\"Return a view of the Labels names.\"\"\"\n    return self.labels.keys()\n</code></pre>"},{"location":"reference/sleap_io/model/labels_set/#sleap_io.model.labels_set.LabelsSet.save","title":"<code>save(save_dir, embed=True, format='slp', **kwargs)</code>","text":"<p>Save all Labels objects to a directory.</p> <p>Parameters:</p> Name Type Description Default <code>save_dir</code> <code>Union[str, Path]</code> <p>Directory to save the files to. Will be created if it doesn't exist.</p> required <code>embed</code> <code>Union[bool, str]</code> <p>For SLP format: Whether to embed images in the saved files. Can be True, False, \"user\", \"predictions\", or \"all\". See Labels.save() for details.</p> <code>True</code> <code>format</code> <code>str</code> <p>Output format. Currently supports \"slp\" (default) and \"ultralytics\".</p> <code>'slp'</code> <code>**kwargs</code> <p>Additional format-specific arguments. For ultralytics format, these might include skeleton, image_size, etc.</p> <code>{}</code> <p>Examples:</p> <p>Save as SLP files with embedded images:</p> <pre><code>&gt;&gt;&gt; labels_set.save(\"path/to/splits/\", embed=True)\n</code></pre> <p>Save as SLP files without embedding:</p> <pre><code>&gt;&gt;&gt; labels_set.save(\"path/to/splits/\", embed=False)\n</code></pre> <p>Save as Ultralytics dataset:</p> <pre><code>&gt;&gt;&gt; labels_set.save(\"path/to/dataset/\", format=\"ultralytics\")\n</code></pre> Source code in <code>sleap_io/model/labels_set.py</code> <pre><code>def save(\n    self,\n    save_dir: Union[str, Path],\n    embed: Union[bool, str] = True,\n    format: str = \"slp\",\n    **kwargs,\n) -&gt; None:\n    \"\"\"Save all Labels objects to a directory.\n\n    Args:\n        save_dir: Directory to save the files to. Will be created if it\n            doesn't exist.\n        embed: For SLP format: Whether to embed images in the saved files.\n            Can be True, False, \"user\", \"predictions\", or \"all\".\n            See Labels.save() for details.\n        format: Output format. Currently supports \"slp\" (default) and \"ultralytics\".\n        **kwargs: Additional format-specific arguments. For ultralytics format,\n            these might include skeleton, image_size, etc.\n\n    Examples:\n        Save as SLP files with embedded images:\n        &gt;&gt;&gt; labels_set.save(\"path/to/splits/\", embed=True)\n\n        Save as SLP files without embedding:\n        &gt;&gt;&gt; labels_set.save(\"path/to/splits/\", embed=False)\n\n        Save as Ultralytics dataset:\n        &gt;&gt;&gt; labels_set.save(\"path/to/dataset/\", format=\"ultralytics\")\n    \"\"\"\n    save_dir = Path(save_dir)\n    save_dir.mkdir(parents=True, exist_ok=True)\n\n    if format == \"slp\":\n        for name, labels in self.items():\n            if embed:\n                filename = f\"{name}.pkg.slp\"\n            else:\n                filename = f\"{name}.slp\"\n            labels.save(save_dir / filename, embed=embed)\n\n    elif format == \"ultralytics\":\n        # Import here to avoid circular imports\n        from sleap_io.io import ultralytics\n\n        # For ultralytics, we need to save each split in the proper structure\n        for name, labels in self.items():\n            # Map common split names\n            split_name = name\n            if name in [\"training\", \"train\"]:\n                split_name = \"train\"\n            elif name in [\"validation\", \"val\", \"valid\"]:\n                split_name = \"val\"\n            elif name in [\"testing\", \"test\"]:\n                split_name = \"test\"\n\n            # Write this split\n            ultralytics.write_labels(\n                labels, str(save_dir), split=split_name, **kwargs\n            )\n\n    else:\n        raise ValueError(\n            f\"Unknown format: {format}. Supported formats: 'slp', 'ultralytics'\"\n        )\n</code></pre>"},{"location":"reference/sleap_io/model/labels_set/#sleap_io.model.labels_set.LabelsSet.values","title":"<code>values()</code>","text":"<p>Return a view of the Labels objects.</p> Source code in <code>sleap_io/model/labels_set.py</code> <pre><code>def values(self) -&gt; ValuesView[Labels]:\n    \"\"\"Return a view of the Labels objects.\"\"\"\n    return self.labels.values()\n</code></pre>"},{"location":"reference/sleap_io/model/matching/","title":"matching","text":""},{"location":"reference/sleap_io/model/matching/#sleap_io.model.matching","title":"<code>sleap_io.model.matching</code>","text":"<p>Unified matcher system for comparing and matching data structures during merging.</p> <p>This module provides configurable matchers for comparing skeletons, instances, tracks, videos, and frames during merge operations. The matchers use various strategies to determine when data structures should be considered equivalent during merging.</p> <p>Key features: - Skeleton matching: exact, structure-based, overlap, and subset matching - Instance matching: spatial proximity, track identity, and bounding box IoU - Track matching: by name or object identity - Video matching: path, basename, content, and auto matching - Frame matching with configurable video matching requirements</p> <p>Video matching supports path-based, filename-based, content-based, and automatic strategies.</p> <p>Classes:</p> Name Description <code>ConflictResolution</code> <p>Information about a conflict that was resolved during merging.</p> <code>ErrorMode</code> <p>Error handling modes for merge operations.</p> <code>FrameMatcher</code> <p>Matcher for comparing and matching labeled frames.</p> <code>FrameStrategy</code> <p>Strategies for handling frame merging.</p> <code>InstanceMatchMethod</code> <p>Methods for matching instances.</p> <code>InstanceMatcher</code> <p>Matcher for comparing and matching instances.</p> <code>MergeError</code> <p>Base exception for merge errors.</p> <code>MergeProgressBar</code> <p>Context manager for merge progress tracking using tqdm.</p> <code>MergeResult</code> <p>Result of a merge operation.</p> <code>SkeletonMatchMethod</code> <p>Methods for matching skeletons.</p> <code>SkeletonMatcher</code> <p>Matcher for comparing and matching skeletons.</p> <code>SkeletonMismatchError</code> <p>Raised when skeletons don't match during merge.</p> <code>TrackMatchMethod</code> <p>Methods for matching tracks.</p> <code>TrackMatcher</code> <p>Matcher for comparing and matching tracks.</p> <code>VideoMatchMethod</code> <p>Methods for matching videos.</p> <code>VideoMatcher</code> <p>Matcher for comparing and matching videos.</p> <code>VideoNotFoundError</code> <p>Raised when a video file cannot be found during merge.</p>"},{"location":"reference/sleap_io/model/matching/#sleap_io.model.matching.ConflictResolution","title":"<code>ConflictResolution</code>","text":"<p>Information about a conflict that was resolved during merging.</p> <p>Attributes:</p> Name Type Description <code>frame</code> <code>LabeledFrame</code> <p>The labeled frame where the conflict occurred.</p> <code>conflict_type</code> <code>str</code> <p>Type of conflict (e.g., \"duplicate_instance\", \"skeleton_mismatch\").</p> <code>original_data</code> <code>Any</code> <p>The original data before resolution.</p> <code>new_data</code> <code>Any</code> <p>The new/incoming data that caused the conflict.</p> <code>resolution</code> <code>str</code> <p>Description of how the conflict was resolved.</p> Source code in <code>sleap_io/model/matching.py</code> <pre><code>@attrs.define\nclass ConflictResolution:\n    \"\"\"Information about a conflict that was resolved during merging.\n\n    Attributes:\n        frame: The labeled frame where the conflict occurred.\n        conflict_type: Type of conflict (e.g., \"duplicate_instance\",\n            \"skeleton_mismatch\").\n        original_data: The original data before resolution.\n        new_data: The new/incoming data that caused the conflict.\n        resolution: Description of how the conflict was resolved.\n    \"\"\"\n\n    frame: LabeledFrame\n    conflict_type: str\n    original_data: Any\n    new_data: Any\n    resolution: str\n</code></pre>"},{"location":"reference/sleap_io/model/matching/#sleap_io.model.matching.ErrorMode","title":"<code>ErrorMode</code>","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Error handling modes for merge operations.</p> <p>Attributes:</p> Name Type Description <code>CONTINUE</code> <p>Continue merging on errors, collecting them in the result.</p> <code>STRICT</code> <p>Raise an exception on the first error encountered.</p> <code>WARN</code> <p>Issue warnings about errors but continue merging.</p> Source code in <code>sleap_io/model/matching.py</code> <pre><code>class ErrorMode(str, Enum):\n    \"\"\"Error handling modes for merge operations.\n\n    Attributes:\n        CONTINUE: Continue merging on errors, collecting them in the result.\n        STRICT: Raise an exception on the first error encountered.\n        WARN: Issue warnings about errors but continue merging.\n    \"\"\"\n\n    CONTINUE = \"continue\"\n    STRICT = \"strict\"\n    WARN = \"warn\"\n</code></pre>"},{"location":"reference/sleap_io/model/matching/#sleap_io.model.matching.FrameMatcher","title":"<code>FrameMatcher</code>","text":"<p>Matcher for comparing and matching labeled frames.</p> <p>Attributes:</p> Name Type Description <code>video_must_match</code> <code>bool</code> <p>Whether frames must belong to the same video to be considered a match. Default is True.</p> <p>Methods:</p> Name Description <code>match</code> <p>Check if two frames match.</p> Source code in <code>sleap_io/model/matching.py</code> <pre><code>@attrs.define\nclass FrameMatcher:\n    \"\"\"Matcher for comparing and matching labeled frames.\n\n    Attributes:\n        video_must_match: Whether frames must belong to the same video to be\n            considered a match. Default is True.\n    \"\"\"\n\n    video_must_match: bool = True\n\n    def match(self, frame1: LabeledFrame, frame2: LabeledFrame) -&gt; bool:\n        \"\"\"Check if two frames match.\"\"\"\n        return frame1.matches(frame2, video_must_match=self.video_must_match)\n</code></pre>"},{"location":"reference/sleap_io/model/matching/#sleap_io.model.matching.FrameMatcher.match","title":"<code>match(frame1, frame2)</code>","text":"<p>Check if two frames match.</p> Source code in <code>sleap_io/model/matching.py</code> <pre><code>def match(self, frame1: LabeledFrame, frame2: LabeledFrame) -&gt; bool:\n    \"\"\"Check if two frames match.\"\"\"\n    return frame1.matches(frame2, video_must_match=self.video_must_match)\n</code></pre>"},{"location":"reference/sleap_io/model/matching/#sleap_io.model.matching.FrameStrategy","title":"<code>FrameStrategy</code>","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Strategies for handling frame merging.</p> <p>Attributes:</p> Name Type Description <code>SMART</code> <p>Smart merging that preserves user labels over predictions when they overlap.</p> <code>KEEP_ORIGINAL</code> <p>Always keep instances from the original (base) frame.</p> <code>KEEP_NEW</code> <p>Always keep instances from the new (incoming) frame.</p> <code>KEEP_BOTH</code> <p>Keep all instances from both frames without filtering.</p> Source code in <code>sleap_io/model/matching.py</code> <pre><code>class FrameStrategy(str, Enum):\n    \"\"\"Strategies for handling frame merging.\n\n    Attributes:\n        SMART: Smart merging that preserves user labels over predictions when\n            they overlap.\n        KEEP_ORIGINAL: Always keep instances from the original (base) frame.\n        KEEP_NEW: Always keep instances from the new (incoming) frame.\n        KEEP_BOTH: Keep all instances from both frames without filtering.\n    \"\"\"\n\n    SMART = \"smart\"\n    KEEP_ORIGINAL = \"keep_original\"\n    KEEP_NEW = \"keep_new\"\n    KEEP_BOTH = \"keep_both\"\n</code></pre>"},{"location":"reference/sleap_io/model/matching/#sleap_io.model.matching.InstanceMatchMethod","title":"<code>InstanceMatchMethod</code>","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Methods for matching instances.</p> <p>Attributes:</p> Name Type Description <code>SPATIAL</code> <p>Match instances by spatial proximity using Euclidean distance.</p> <code>IDENTITY</code> <p>Match instances by track identity (same track object).</p> <code>IOU</code> <p>Match instances by bounding box Intersection over Union.</p> Source code in <code>sleap_io/model/matching.py</code> <pre><code>class InstanceMatchMethod(str, Enum):\n    \"\"\"Methods for matching instances.\n\n    Attributes:\n        SPATIAL: Match instances by spatial proximity using Euclidean distance.\n        IDENTITY: Match instances by track identity (same track object).\n        IOU: Match instances by bounding box Intersection over Union.\n    \"\"\"\n\n    SPATIAL = \"spatial\"\n    IDENTITY = \"identity\"\n    IOU = \"iou\"\n</code></pre>"},{"location":"reference/sleap_io/model/matching/#sleap_io.model.matching.InstanceMatcher","title":"<code>InstanceMatcher</code>","text":"<p>Matcher for comparing and matching instances.</p> <p>Attributes:</p> Name Type Description <code>method</code> <code>Union[InstanceMatchMethod, str]</code> <p>The matching method to use. Can be an InstanceMatchMethod enum value or a string that will be converted to the enum. Default is SPATIAL.</p> <code>threshold</code> <code>float</code> <p>The threshold value used for matching. For SPATIAL method, this is the maximum pixel distance. For IOU method, this is the minimum IoU value. Not used for IDENTITY method. Default is 5.0.</p> <p>Methods:</p> Name Description <code>find_matches</code> <p>Find all matching instances between two lists.</p> <code>match</code> <p>Check if two instances match according to the configured method.</p> Source code in <code>sleap_io/model/matching.py</code> <pre><code>@attrs.define\nclass InstanceMatcher:\n    \"\"\"Matcher for comparing and matching instances.\n\n    Attributes:\n        method: The matching method to use. Can be an InstanceMatchMethod enum value\n            or a string that will be converted to the enum. Default is SPATIAL.\n        threshold: The threshold value used for matching. For SPATIAL method, this is\n            the maximum pixel distance. For IOU method, this is the minimum IoU value.\n            Not used for IDENTITY method. Default is 5.0.\n    \"\"\"\n\n    method: Union[InstanceMatchMethod, str] = attrs.field(\n        default=InstanceMatchMethod.SPATIAL,\n        converter=lambda x: InstanceMatchMethod(x) if isinstance(x, str) else x,\n    )\n    threshold: float = 5.0\n\n    def match(self, instance1: Instance, instance2: Instance) -&gt; bool:\n        \"\"\"Check if two instances match according to the configured method.\"\"\"\n        if self.method == InstanceMatchMethod.SPATIAL:\n            return instance1.same_pose_as(instance2, tolerance=self.threshold)\n        elif self.method == InstanceMatchMethod.IDENTITY:\n            return instance1.same_identity_as(instance2)\n        elif self.method == InstanceMatchMethod.IOU:\n            return instance1.overlaps_with(instance2, iou_threshold=self.threshold)\n        else:\n            raise ValueError(f\"Unknown instance match method: {self.method}\")\n\n    def find_matches(\n        self, instances1: list[Instance], instances2: list[Instance]\n    ) -&gt; list[tuple[int, int, float]]:\n        \"\"\"Find all matching instances between two lists.\n\n        Returns:\n            List of (idx1, idx2, score) tuples for matching instances.\n        \"\"\"\n        matches = []\n\n        for i, inst1 in enumerate(instances1):\n            for j, inst2 in enumerate(instances2):\n                if self.match(inst1, inst2):\n                    # Calculate match score based on method\n                    if self.method == InstanceMatchMethod.SPATIAL:\n                        # Use inverse distance as score\n                        pts1 = inst1.numpy()\n                        pts2 = inst2.numpy()\n                        valid = ~(np.isnan(pts1[:, 0]) | np.isnan(pts2[:, 0]))\n                        if valid.any():\n                            distances = np.linalg.norm(\n                                pts1[valid] - pts2[valid], axis=1\n                            )\n                            score = 1.0 / (1.0 + np.mean(distances))\n                        else:\n                            score = 0.0\n                    elif self.method == InstanceMatchMethod.IOU:\n                        # Calculate actual IoU as score\n                        bbox1 = inst1.bounding_box()\n                        bbox2 = inst2.bounding_box()\n                        if bbox1 is not None and bbox2 is not None:\n                            # Calculate IoU\n                            intersection_min = np.maximum(bbox1[0], bbox2[0])\n                            intersection_max = np.minimum(bbox1[1], bbox2[1])\n                            if np.all(intersection_min &lt; intersection_max):\n                                intersection_area = np.prod(\n                                    intersection_max - intersection_min\n                                )\n                                area1 = np.prod(bbox1[1] - bbox1[0])\n                                area2 = np.prod(bbox2[1] - bbox2[0])\n                                union_area = area1 + area2 - intersection_area\n                                score = (\n                                    intersection_area / union_area\n                                    if union_area &gt; 0\n                                    else 0\n                                )\n                            else:\n                                score = 0.0\n                        else:\n                            score = 0.0\n                    else:\n                        score = 1.0  # Binary match for identity\n\n                    matches.append((i, j, score))\n\n        return matches\n</code></pre>"},{"location":"reference/sleap_io/model/matching/#sleap_io.model.matching.InstanceMatcher.find_matches","title":"<code>find_matches(instances1, instances2)</code>","text":"<p>Find all matching instances between two lists.</p> <p>Returns:</p> Type Description <code>list[tuple[int, int, float]]</code> <p>List of (idx1, idx2, score) tuples for matching instances.</p> Source code in <code>sleap_io/model/matching.py</code> <pre><code>def find_matches(\n    self, instances1: list[Instance], instances2: list[Instance]\n) -&gt; list[tuple[int, int, float]]:\n    \"\"\"Find all matching instances between two lists.\n\n    Returns:\n        List of (idx1, idx2, score) tuples for matching instances.\n    \"\"\"\n    matches = []\n\n    for i, inst1 in enumerate(instances1):\n        for j, inst2 in enumerate(instances2):\n            if self.match(inst1, inst2):\n                # Calculate match score based on method\n                if self.method == InstanceMatchMethod.SPATIAL:\n                    # Use inverse distance as score\n                    pts1 = inst1.numpy()\n                    pts2 = inst2.numpy()\n                    valid = ~(np.isnan(pts1[:, 0]) | np.isnan(pts2[:, 0]))\n                    if valid.any():\n                        distances = np.linalg.norm(\n                            pts1[valid] - pts2[valid], axis=1\n                        )\n                        score = 1.0 / (1.0 + np.mean(distances))\n                    else:\n                        score = 0.0\n                elif self.method == InstanceMatchMethod.IOU:\n                    # Calculate actual IoU as score\n                    bbox1 = inst1.bounding_box()\n                    bbox2 = inst2.bounding_box()\n                    if bbox1 is not None and bbox2 is not None:\n                        # Calculate IoU\n                        intersection_min = np.maximum(bbox1[0], bbox2[0])\n                        intersection_max = np.minimum(bbox1[1], bbox2[1])\n                        if np.all(intersection_min &lt; intersection_max):\n                            intersection_area = np.prod(\n                                intersection_max - intersection_min\n                            )\n                            area1 = np.prod(bbox1[1] - bbox1[0])\n                            area2 = np.prod(bbox2[1] - bbox2[0])\n                            union_area = area1 + area2 - intersection_area\n                            score = (\n                                intersection_area / union_area\n                                if union_area &gt; 0\n                                else 0\n                            )\n                        else:\n                            score = 0.0\n                    else:\n                        score = 0.0\n                else:\n                    score = 1.0  # Binary match for identity\n\n                matches.append((i, j, score))\n\n    return matches\n</code></pre>"},{"location":"reference/sleap_io/model/matching/#sleap_io.model.matching.InstanceMatcher.match","title":"<code>match(instance1, instance2)</code>","text":"<p>Check if two instances match according to the configured method.</p> Source code in <code>sleap_io/model/matching.py</code> <pre><code>def match(self, instance1: Instance, instance2: Instance) -&gt; bool:\n    \"\"\"Check if two instances match according to the configured method.\"\"\"\n    if self.method == InstanceMatchMethod.SPATIAL:\n        return instance1.same_pose_as(instance2, tolerance=self.threshold)\n    elif self.method == InstanceMatchMethod.IDENTITY:\n        return instance1.same_identity_as(instance2)\n    elif self.method == InstanceMatchMethod.IOU:\n        return instance1.overlaps_with(instance2, iou_threshold=self.threshold)\n    else:\n        raise ValueError(f\"Unknown instance match method: {self.method}\")\n</code></pre>"},{"location":"reference/sleap_io/model/matching/#sleap_io.model.matching.MergeError","title":"<code>MergeError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Base exception for merge errors.</p> <p>Attributes:</p> Name Type Description <code>message</code> <code>str</code> <p>Human-readable error message.</p> <code>details</code> <code>dict</code> <p>Dictionary containing additional error details and context.</p> Source code in <code>sleap_io/model/matching.py</code> <pre><code>@attrs.define\nclass MergeError(Exception):\n    \"\"\"Base exception for merge errors.\n\n    Attributes:\n        message: Human-readable error message.\n        details: Dictionary containing additional error details and context.\n    \"\"\"\n\n    message: str\n    details: dict = attrs.field(factory=dict)\n</code></pre>"},{"location":"reference/sleap_io/model/matching/#sleap_io.model.matching.MergeProgressBar","title":"<code>MergeProgressBar</code>","text":"<p>Context manager for merge progress tracking using tqdm.</p> <p>This provides a clean interface for tracking merge progress with visual feedback.</p> Example <p>with MergeProgressBar(\"Merging predictions\") as progress:     result = labels.merge(predictions, progress_callback=progress.callback)</p> <p>Methods:</p> Name Description <code>__enter__</code> <p>Enter the context manager.</p> <code>__exit__</code> <p>Exit the context manager and close the progress bar.</p> <code>__init__</code> <p>Initialize the progress bar.</p> <code>callback</code> <p>Progress callback for merge operations.</p> Source code in <code>sleap_io/model/matching.py</code> <pre><code>class MergeProgressBar:\n    \"\"\"Context manager for merge progress tracking using tqdm.\n\n    This provides a clean interface for tracking merge progress with visual feedback.\n\n    Example:\n        with MergeProgressBar(\"Merging predictions\") as progress:\n            result = labels.merge(predictions, progress_callback=progress.callback)\n    \"\"\"\n\n    def __init__(self, desc: str = \"Merging\", leave: bool = True):\n        \"\"\"Initialize the progress bar.\n\n        Args:\n            desc: Description to show in the progress bar.\n            leave: Whether to leave the progress bar on screen after completion.\n        \"\"\"\n        self.desc = desc\n        self.leave = leave\n        self.pbar = None\n\n    def __enter__(self):\n        \"\"\"Enter the context manager.\"\"\"\n        return self\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        \"\"\"Exit the context manager and close the progress bar.\"\"\"\n        if self.pbar is not None:\n            self.pbar.close()\n\n    def callback(self, current: int, total: int, message: str = \"\"):\n        \"\"\"Progress callback for merge operations.\n\n        Args:\n            current: Current progress value.\n            total: Total items to process.\n            message: Optional message to display.\n        \"\"\"\n        from tqdm import tqdm\n\n        if self.pbar is None and total:\n            self.pbar = tqdm(total=total, desc=self.desc, leave=self.leave)\n\n        if self.pbar:\n            if message:\n                self.pbar.set_description(f\"{self.desc}: {message}\")\n            else:\n                self.pbar.set_description(self.desc)\n            self.pbar.n = current\n            self.pbar.refresh()\n</code></pre>"},{"location":"reference/sleap_io/model/matching/#sleap_io.model.matching.MergeProgressBar.__enter__","title":"<code>__enter__()</code>","text":"<p>Enter the context manager.</p> Source code in <code>sleap_io/model/matching.py</code> <pre><code>def __enter__(self):\n    \"\"\"Enter the context manager.\"\"\"\n    return self\n</code></pre>"},{"location":"reference/sleap_io/model/matching/#sleap_io.model.matching.MergeProgressBar.__exit__","title":"<code>__exit__(exc_type, exc_val, exc_tb)</code>","text":"<p>Exit the context manager and close the progress bar.</p> Source code in <code>sleap_io/model/matching.py</code> <pre><code>def __exit__(self, exc_type, exc_val, exc_tb):\n    \"\"\"Exit the context manager and close the progress bar.\"\"\"\n    if self.pbar is not None:\n        self.pbar.close()\n</code></pre>"},{"location":"reference/sleap_io/model/matching/#sleap_io.model.matching.MergeProgressBar.__init__","title":"<code>__init__(desc='Merging', leave=True)</code>","text":"<p>Initialize the progress bar.</p> <p>Parameters:</p> Name Type Description Default <code>desc</code> <code>str</code> <p>Description to show in the progress bar.</p> <code>'Merging'</code> <code>leave</code> <code>bool</code> <p>Whether to leave the progress bar on screen after completion.</p> <code>True</code> Source code in <code>sleap_io/model/matching.py</code> <pre><code>def __init__(self, desc: str = \"Merging\", leave: bool = True):\n    \"\"\"Initialize the progress bar.\n\n    Args:\n        desc: Description to show in the progress bar.\n        leave: Whether to leave the progress bar on screen after completion.\n    \"\"\"\n    self.desc = desc\n    self.leave = leave\n    self.pbar = None\n</code></pre>"},{"location":"reference/sleap_io/model/matching/#sleap_io.model.matching.MergeProgressBar.callback","title":"<code>callback(current, total, message='')</code>","text":"<p>Progress callback for merge operations.</p> <p>Parameters:</p> Name Type Description Default <code>current</code> <code>int</code> <p>Current progress value.</p> required <code>total</code> <code>int</code> <p>Total items to process.</p> required <code>message</code> <code>str</code> <p>Optional message to display.</p> <code>''</code> Source code in <code>sleap_io/model/matching.py</code> <pre><code>def callback(self, current: int, total: int, message: str = \"\"):\n    \"\"\"Progress callback for merge operations.\n\n    Args:\n        current: Current progress value.\n        total: Total items to process.\n        message: Optional message to display.\n    \"\"\"\n    from tqdm import tqdm\n\n    if self.pbar is None and total:\n        self.pbar = tqdm(total=total, desc=self.desc, leave=self.leave)\n\n    if self.pbar:\n        if message:\n            self.pbar.set_description(f\"{self.desc}: {message}\")\n        else:\n            self.pbar.set_description(self.desc)\n        self.pbar.n = current\n        self.pbar.refresh()\n</code></pre>"},{"location":"reference/sleap_io/model/matching/#sleap_io.model.matching.MergeResult","title":"<code>MergeResult</code>","text":"<p>Result of a merge operation.</p> <p>Attributes:</p> Name Type Description <code>successful</code> <code>bool</code> <p>Whether the merge completed successfully.</p> <code>frames_merged</code> <code>int</code> <p>Number of frames that were merged.</p> <code>instances_added</code> <code>int</code> <p>Number of new instances added.</p> <code>instances_updated</code> <code>int</code> <p>Number of existing instances that were updated.</p> <code>instances_skipped</code> <code>int</code> <p>Number of instances that were skipped.</p> <code>conflicts</code> <code>list[ConflictResolution]</code> <p>List of conflicts that were resolved during merging.</p> <code>errors</code> <code>list[MergeError]</code> <p>List of errors encountered during merging.</p> <p>Methods:</p> Name Description <code>summary</code> <p>Generate a human-readable summary of the merge result.</p> Source code in <code>sleap_io/model/matching.py</code> <pre><code>@attrs.define\nclass MergeResult:\n    \"\"\"Result of a merge operation.\n\n    Attributes:\n        successful: Whether the merge completed successfully.\n        frames_merged: Number of frames that were merged.\n        instances_added: Number of new instances added.\n        instances_updated: Number of existing instances that were updated.\n        instances_skipped: Number of instances that were skipped.\n        conflicts: List of conflicts that were resolved during merging.\n        errors: List of errors encountered during merging.\n    \"\"\"\n\n    successful: bool\n    frames_merged: int = 0\n    instances_added: int = 0\n    instances_updated: int = 0\n    instances_skipped: int = 0\n    conflicts: list[ConflictResolution] = attrs.field(factory=list)\n    errors: list[MergeError] = attrs.field(factory=list)\n\n    def summary(self) -&gt; str:\n        \"\"\"Generate a human-readable summary of the merge result.\"\"\"\n        lines = []\n\n        if self.successful:\n            lines.append(\"\u2713 Merge completed successfully\")\n        else:\n            lines.append(\"\u2717 Merge completed with errors\")\n\n        lines.append(f\"  Frames merged: {self.frames_merged}\")\n        lines.append(f\"  Instances added: {self.instances_added}\")\n\n        if self.instances_updated:\n            lines.append(f\"  Instances updated: {self.instances_updated}\")\n\n        if self.instances_skipped:\n            lines.append(f\"  Instances skipped: {self.instances_skipped}\")\n\n        if self.conflicts:\n            lines.append(f\"  Conflicts resolved: {len(self.conflicts)}\")\n\n        if self.errors:\n            lines.append(f\"  Errors encountered: {len(self.errors)}\")\n            for error in self.errors[:5]:  # Show first 5 errors\n                lines.append(f\"    - {error.message}\")\n            if len(self.errors) &gt; 5:\n                lines.append(f\"    ... and {len(self.errors) - 5} more\")\n\n        return \"\\n\".join(lines)\n</code></pre>"},{"location":"reference/sleap_io/model/matching/#sleap_io.model.matching.MergeResult.summary","title":"<code>summary()</code>","text":"<p>Generate a human-readable summary of the merge result.</p> Source code in <code>sleap_io/model/matching.py</code> <pre><code>def summary(self) -&gt; str:\n    \"\"\"Generate a human-readable summary of the merge result.\"\"\"\n    lines = []\n\n    if self.successful:\n        lines.append(\"\u2713 Merge completed successfully\")\n    else:\n        lines.append(\"\u2717 Merge completed with errors\")\n\n    lines.append(f\"  Frames merged: {self.frames_merged}\")\n    lines.append(f\"  Instances added: {self.instances_added}\")\n\n    if self.instances_updated:\n        lines.append(f\"  Instances updated: {self.instances_updated}\")\n\n    if self.instances_skipped:\n        lines.append(f\"  Instances skipped: {self.instances_skipped}\")\n\n    if self.conflicts:\n        lines.append(f\"  Conflicts resolved: {len(self.conflicts)}\")\n\n    if self.errors:\n        lines.append(f\"  Errors encountered: {len(self.errors)}\")\n        for error in self.errors[:5]:  # Show first 5 errors\n            lines.append(f\"    - {error.message}\")\n        if len(self.errors) &gt; 5:\n            lines.append(f\"    ... and {len(self.errors) - 5} more\")\n\n    return \"\\n\".join(lines)\n</code></pre>"},{"location":"reference/sleap_io/model/matching/#sleap_io.model.matching.SkeletonMatchMethod","title":"<code>SkeletonMatchMethod</code>","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Methods for matching skeletons.</p> <p>Attributes:</p> Name Type Description <code>EXACT</code> <p>Exact match requiring same nodes in the same order.</p> <code>STRUCTURE</code> <p>Match requiring same nodes and edges, but order doesn't matter.</p> <code>OVERLAP</code> <p>Partial match based on overlapping nodes (uses Jaccard similarity).</p> <code>SUBSET</code> <p>Match if one skeleton's nodes are a subset of another's.</p> Source code in <code>sleap_io/model/matching.py</code> <pre><code>class SkeletonMatchMethod(str, Enum):\n    \"\"\"Methods for matching skeletons.\n\n    Attributes:\n        EXACT: Exact match requiring same nodes in the same order.\n        STRUCTURE: Match requiring same nodes and edges, but order doesn't matter.\n        OVERLAP: Partial match based on overlapping nodes (uses Jaccard similarity).\n        SUBSET: Match if one skeleton's nodes are a subset of another's.\n    \"\"\"\n\n    EXACT = \"exact\"\n    STRUCTURE = \"structure\"\n    OVERLAP = \"overlap\"\n    SUBSET = \"subset\"\n</code></pre>"},{"location":"reference/sleap_io/model/matching/#sleap_io.model.matching.SkeletonMatcher","title":"<code>SkeletonMatcher</code>","text":"<p>Matcher for comparing and matching skeletons.</p> <p>Attributes:</p> Name Type Description <code>method</code> <code>Union[SkeletonMatchMethod, str]</code> <p>The matching method to use. Can be a SkeletonMatchMethod enum value or a string that will be converted to the enum. Default is STRUCTURE.</p> <code>require_same_order</code> <code>bool</code> <p>Whether to require nodes in the same order for STRUCTURE matching. Only used when method is STRUCTURE. Default is False.</p> <code>min_overlap</code> <code>float</code> <p>Minimum Jaccard similarity required for OVERLAP matching. Only used when method is OVERLAP. Default is 0.5.</p> <p>Methods:</p> Name Description <code>match</code> <p>Check if two skeletons match according to the configured method.</p> Source code in <code>sleap_io/model/matching.py</code> <pre><code>@attrs.define\nclass SkeletonMatcher:\n    \"\"\"Matcher for comparing and matching skeletons.\n\n    Attributes:\n        method: The matching method to use. Can be a SkeletonMatchMethod enum value\n            or a string that will be converted to the enum. Default is STRUCTURE.\n        require_same_order: Whether to require nodes in the same order for STRUCTURE\n            matching. Only used when method is STRUCTURE. Default is False.\n        min_overlap: Minimum Jaccard similarity required for OVERLAP matching.\n            Only used when method is OVERLAP. Default is 0.5.\n    \"\"\"\n\n    method: Union[SkeletonMatchMethod, str] = attrs.field(\n        default=SkeletonMatchMethod.STRUCTURE,\n        converter=lambda x: SkeletonMatchMethod(x) if isinstance(x, str) else x,\n    )\n    require_same_order: bool = False\n    min_overlap: float = 0.5\n\n    def match(self, skeleton1: Skeleton, skeleton2: Skeleton) -&gt; bool:\n        \"\"\"Check if two skeletons match according to the configured method.\"\"\"\n        if self.method == SkeletonMatchMethod.EXACT:\n            return skeleton1.matches(skeleton2, require_same_order=True)\n        elif self.method == SkeletonMatchMethod.STRUCTURE:\n            return skeleton1.matches(\n                skeleton2, require_same_order=self.require_same_order\n            )\n        elif self.method == SkeletonMatchMethod.OVERLAP:\n            metrics = skeleton1.node_similarities(skeleton2)\n            return metrics[\"jaccard\"] &gt;= self.min_overlap\n        elif self.method == SkeletonMatchMethod.SUBSET:\n            # Check if skeleton1 nodes are subset of skeleton2\n            nodes1 = set(skeleton1.node_names)\n            nodes2 = set(skeleton2.node_names)\n            return nodes1.issubset(nodes2)\n        else:\n            raise ValueError(f\"Unknown skeleton match method: {self.method}\")\n</code></pre>"},{"location":"reference/sleap_io/model/matching/#sleap_io.model.matching.SkeletonMatcher.match","title":"<code>match(skeleton1, skeleton2)</code>","text":"<p>Check if two skeletons match according to the configured method.</p> Source code in <code>sleap_io/model/matching.py</code> <pre><code>def match(self, skeleton1: Skeleton, skeleton2: Skeleton) -&gt; bool:\n    \"\"\"Check if two skeletons match according to the configured method.\"\"\"\n    if self.method == SkeletonMatchMethod.EXACT:\n        return skeleton1.matches(skeleton2, require_same_order=True)\n    elif self.method == SkeletonMatchMethod.STRUCTURE:\n        return skeleton1.matches(\n            skeleton2, require_same_order=self.require_same_order\n        )\n    elif self.method == SkeletonMatchMethod.OVERLAP:\n        metrics = skeleton1.node_similarities(skeleton2)\n        return metrics[\"jaccard\"] &gt;= self.min_overlap\n    elif self.method == SkeletonMatchMethod.SUBSET:\n        # Check if skeleton1 nodes are subset of skeleton2\n        nodes1 = set(skeleton1.node_names)\n        nodes2 = set(skeleton2.node_names)\n        return nodes1.issubset(nodes2)\n    else:\n        raise ValueError(f\"Unknown skeleton match method: {self.method}\")\n</code></pre>"},{"location":"reference/sleap_io/model/matching/#sleap_io.model.matching.SkeletonMismatchError","title":"<code>SkeletonMismatchError</code>","text":"<p>               Bases: <code>MergeError</code></p> <p>Raised when skeletons don't match during merge.</p> Source code in <code>sleap_io/model/matching.py</code> <pre><code>class SkeletonMismatchError(MergeError):\n    \"\"\"Raised when skeletons don't match during merge.\"\"\"\n\n    pass\n</code></pre>"},{"location":"reference/sleap_io/model/matching/#sleap_io.model.matching.TrackMatchMethod","title":"<code>TrackMatchMethod</code>","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Methods for matching tracks.</p> <p>Attributes:</p> Name Type Description <code>NAME</code> <p>Match tracks by their name attribute.</p> <code>IDENTITY</code> <p>Match tracks by object identity (same Python object).</p> Source code in <code>sleap_io/model/matching.py</code> <pre><code>class TrackMatchMethod(str, Enum):\n    \"\"\"Methods for matching tracks.\n\n    Attributes:\n        NAME: Match tracks by their name attribute.\n        IDENTITY: Match tracks by object identity (same Python object).\n    \"\"\"\n\n    NAME = \"name\"\n    IDENTITY = \"identity\"\n</code></pre>"},{"location":"reference/sleap_io/model/matching/#sleap_io.model.matching.TrackMatcher","title":"<code>TrackMatcher</code>","text":"<p>Matcher for comparing and matching tracks.</p> <p>Attributes:</p> Name Type Description <code>method</code> <code>Union[TrackMatchMethod, str]</code> <p>The matching method to use. Can be a TrackMatchMethod enum value or a string that will be converted to the enum. Default is NAME.</p> <p>Methods:</p> Name Description <code>match</code> <p>Check if two tracks match according to the configured method.</p> Source code in <code>sleap_io/model/matching.py</code> <pre><code>@attrs.define\nclass TrackMatcher:\n    \"\"\"Matcher for comparing and matching tracks.\n\n    Attributes:\n        method: The matching method to use. Can be a TrackMatchMethod enum value\n            or a string that will be converted to the enum. Default is NAME.\n    \"\"\"\n\n    method: Union[TrackMatchMethod, str] = attrs.field(\n        default=TrackMatchMethod.NAME,\n        converter=lambda x: TrackMatchMethod(x) if isinstance(x, str) else x,\n    )\n\n    def match(self, track1: Track, track2: Track) -&gt; bool:\n        \"\"\"Check if two tracks match according to the configured method.\"\"\"\n        return track1.matches(track2, method=self.method.value)\n</code></pre>"},{"location":"reference/sleap_io/model/matching/#sleap_io.model.matching.TrackMatcher.match","title":"<code>match(track1, track2)</code>","text":"<p>Check if two tracks match according to the configured method.</p> Source code in <code>sleap_io/model/matching.py</code> <pre><code>def match(self, track1: Track, track2: Track) -&gt; bool:\n    \"\"\"Check if two tracks match according to the configured method.\"\"\"\n    return track1.matches(track2, method=self.method.value)\n</code></pre>"},{"location":"reference/sleap_io/model/matching/#sleap_io.model.matching.VideoMatchMethod","title":"<code>VideoMatchMethod</code>","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Methods for matching videos.</p> <p>Attributes:</p> Name Type Description <code>PATH</code> <p>Match by exact file path (strict or lenient based on VideoMatcher.strict setting).</p> <code>BASENAME</code> <p>Match by filename only, ignoring directory paths.</p> <code>CONTENT</code> <p>Match by video shape (frames, height, width, channels) and backend type.</p> <code>AUTO</code> <p>Automatic matching - tries BASENAME first, then falls back to CONTENT.</p> <code>IMAGE_DEDUP</code> <p>(ImageVideo only) Match ImageVideo instances with overlapping image files. Used to deduplicate individual images when merging datasets where videos are image sequences.</p> <code>SHAPE</code> <p>Match videos by shape only (height, width, channels), ignoring filenames and frame count. Commonly used with ImageVideo to merge same-shaped image sequences.</p> Source code in <code>sleap_io/model/matching.py</code> <pre><code>class VideoMatchMethod(str, Enum):\n    \"\"\"Methods for matching videos.\n\n    Attributes:\n        PATH: Match by exact file path (strict or lenient based on\n            VideoMatcher.strict setting).\n        BASENAME: Match by filename only, ignoring directory paths.\n        CONTENT: Match by video shape (frames, height, width, channels) and\n            backend type.\n        AUTO: Automatic matching - tries BASENAME first, then falls back to CONTENT.\n        IMAGE_DEDUP: (ImageVideo only) Match ImageVideo instances with overlapping\n            image files. Used to deduplicate individual images when merging datasets\n            where videos are image sequences.\n        SHAPE: Match videos by shape only (height, width, channels), ignoring\n            filenames and frame count. Commonly used with ImageVideo to merge\n            same-shaped image sequences.\n    \"\"\"\n\n    PATH = \"path\"\n    BASENAME = \"basename\"\n    CONTENT = \"content\"\n    AUTO = \"auto\"\n    IMAGE_DEDUP = \"image_dedup\"\n    SHAPE = \"shape\"\n</code></pre>"},{"location":"reference/sleap_io/model/matching/#sleap_io.model.matching.VideoMatcher","title":"<code>VideoMatcher</code>","text":"<p>Matcher for comparing and matching videos.</p> <p>Attributes:</p> Name Type Description <code>method</code> <code>Union[VideoMatchMethod, str]</code> <p>The matching method to use. Can be a VideoMatchMethod enum value or a string that will be converted to the enum. Default is AUTO.</p> <code>strict</code> <code>bool</code> <p>Whether to use strict path matching for the PATH method. When True, paths must be exactly identical. When False, paths are normalized before comparison. Only used when method is PATH. Default is False.</p> <p>Methods:</p> Name Description <code>match</code> <p>Check if two videos match according to the configured method.</p> Source code in <code>sleap_io/model/matching.py</code> <pre><code>@attrs.define\nclass VideoMatcher:\n    \"\"\"Matcher for comparing and matching videos.\n\n    Attributes:\n        method: The matching method to use. Can be a VideoMatchMethod enum value\n            or a string that will be converted to the enum. Default is AUTO.\n        strict: Whether to use strict path matching for the PATH method.\n            When True, paths must be exactly identical. When False, paths\n            are normalized before comparison. Only used when method is PATH.\n            Default is False.\n    \"\"\"\n\n    method: Union[VideoMatchMethod, str] = attrs.field(\n        default=VideoMatchMethod.AUTO,\n        converter=lambda x: VideoMatchMethod(x) if isinstance(x, str) else x,\n    )\n    strict: bool = False\n\n    def match(self, video1: Video, video2: Video) -&gt; bool:\n        \"\"\"Check if two videos match according to the configured method.\"\"\"\n        if self.method == VideoMatchMethod.AUTO:\n            # Try different methods in order (identity check is redundant)\n            if video1.matches_path(video2, strict=False):\n                return True\n            if video1.matches_content(video2):\n                return True\n            return False\n        elif self.method == VideoMatchMethod.PATH:\n            return video1.matches_path(video2, strict=self.strict)\n        elif self.method == VideoMatchMethod.BASENAME:\n            return video1.matches_path(video2, strict=False)\n        elif self.method == VideoMatchMethod.CONTENT:\n            return video1.matches_content(video2)\n        elif self.method == VideoMatchMethod.IMAGE_DEDUP:\n            # Match ImageVideo instances with overlapping images (ImageVideo only)\n            return video1.has_overlapping_images(video2)\n        elif self.method == VideoMatchMethod.SHAPE:\n            # Match videos by shape only (height, width, channels)\n            return video1.matches_shape(video2)\n        else:\n            raise ValueError(f\"Unknown video match method: {self.method}\")\n</code></pre>"},{"location":"reference/sleap_io/model/matching/#sleap_io.model.matching.VideoMatcher.match","title":"<code>match(video1, video2)</code>","text":"<p>Check if two videos match according to the configured method.</p> Source code in <code>sleap_io/model/matching.py</code> <pre><code>def match(self, video1: Video, video2: Video) -&gt; bool:\n    \"\"\"Check if two videos match according to the configured method.\"\"\"\n    if self.method == VideoMatchMethod.AUTO:\n        # Try different methods in order (identity check is redundant)\n        if video1.matches_path(video2, strict=False):\n            return True\n        if video1.matches_content(video2):\n            return True\n        return False\n    elif self.method == VideoMatchMethod.PATH:\n        return video1.matches_path(video2, strict=self.strict)\n    elif self.method == VideoMatchMethod.BASENAME:\n        return video1.matches_path(video2, strict=False)\n    elif self.method == VideoMatchMethod.CONTENT:\n        return video1.matches_content(video2)\n    elif self.method == VideoMatchMethod.IMAGE_DEDUP:\n        # Match ImageVideo instances with overlapping images (ImageVideo only)\n        return video1.has_overlapping_images(video2)\n    elif self.method == VideoMatchMethod.SHAPE:\n        # Match videos by shape only (height, width, channels)\n        return video1.matches_shape(video2)\n    else:\n        raise ValueError(f\"Unknown video match method: {self.method}\")\n</code></pre>"},{"location":"reference/sleap_io/model/matching/#sleap_io.model.matching.VideoNotFoundError","title":"<code>VideoNotFoundError</code>","text":"<p>               Bases: <code>MergeError</code></p> <p>Raised when a video file cannot be found during merge.</p> Source code in <code>sleap_io/model/matching.py</code> <pre><code>class VideoNotFoundError(MergeError):\n    \"\"\"Raised when a video file cannot be found during merge.\"\"\"\n\n    pass\n</code></pre>"},{"location":"reference/sleap_io/model/skeleton/","title":"skeleton","text":""},{"location":"reference/sleap_io/model/skeleton/#sleap_io.model.skeleton","title":"<code>sleap_io.model.skeleton</code>","text":"<p>Data model for skeletons.</p> <p>Skeletons are collections of nodes and edges which describe the landmarks associated with a pose model. The edges represent the connections between them and may be used differently depending on the underlying pose model.</p> <p>Classes:</p> Name Description <code>Edge</code> <p>A connection between two <code>Node</code> objects within a <code>Skeleton</code>.</p> <code>Node</code> <p>A landmark type within a <code>Skeleton</code>.</p> <code>Skeleton</code> <p>A description of a set of landmark types and connections between them.</p> <code>Symmetry</code> <p>A relationship between a pair of nodes denoting their left/right pairing.</p> <p>Functions:</p> Name Description <code>is_node_or_index</code> <p>Check if an object is a <code>Node</code>, string name or integer index.</p> <code>match_nodes_cached</code> <p>Match nodes in two skeletons by name.</p>"},{"location":"reference/sleap_io/model/skeleton/#sleap_io.model.skeleton.Edge","title":"<code>Edge</code>","text":"<p>A connection between two <code>Node</code> objects within a <code>Skeleton</code>.</p> <p>This is a directed edge, representing the ordering of <code>Node</code>s in the <code>Skeleton</code> tree.</p> <p>Attributes:</p> Name Type Description <code>source</code> <code>Node</code> <p>The origin <code>Node</code>.</p> <code>destination</code> <code>Node</code> <p>The destination <code>Node</code>.</p> <p>Methods:</p> Name Description <code>__getitem__</code> <p>Return the source <code>Node</code> (<code>idx</code> is 0) or destination <code>Node</code> (<code>idx</code> is 1).</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>@define(frozen=True)\nclass Edge:\n    \"\"\"A connection between two `Node` objects within a `Skeleton`.\n\n    This is a directed edge, representing the ordering of `Node`s in the `Skeleton`\n    tree.\n\n    Attributes:\n        source: The origin `Node`.\n        destination: The destination `Node`.\n    \"\"\"\n\n    source: Node\n    destination: Node\n\n    def __getitem__(self, idx) -&gt; Node:\n        \"\"\"Return the source `Node` (`idx` is 0) or destination `Node` (`idx` is 1).\"\"\"\n        if idx == 0:\n            return self.source\n        elif idx == 1:\n            return self.destination\n        else:\n            raise IndexError(\"Edge only has 2 nodes (source and destination).\")\n</code></pre>"},{"location":"reference/sleap_io/model/skeleton/#sleap_io.model.skeleton.Edge.__getitem__","title":"<code>__getitem__(idx)</code>","text":"<p>Return the source <code>Node</code> (<code>idx</code> is 0) or destination <code>Node</code> (<code>idx</code> is 1).</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def __getitem__(self, idx) -&gt; Node:\n    \"\"\"Return the source `Node` (`idx` is 0) or destination `Node` (`idx` is 1).\"\"\"\n    if idx == 0:\n        return self.source\n    elif idx == 1:\n        return self.destination\n    else:\n        raise IndexError(\"Edge only has 2 nodes (source and destination).\")\n</code></pre>"},{"location":"reference/sleap_io/model/skeleton/#sleap_io.model.skeleton.Node","title":"<code>Node</code>","text":"<p>A landmark type within a <code>Skeleton</code>.</p> <p>This typically corresponds to a unique landmark within a skeleton, such as the \"left eye\".</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>Descriptive label for the landmark.</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>@define(eq=False)\nclass Node:\n    \"\"\"A landmark type within a `Skeleton`.\n\n    This typically corresponds to a unique landmark within a skeleton, such as the \"left\n    eye\".\n\n    Attributes:\n        name: Descriptive label for the landmark.\n    \"\"\"\n\n    name: str\n</code></pre>"},{"location":"reference/sleap_io/model/skeleton/#sleap_io.model.skeleton.Skeleton","title":"<code>Skeleton</code>","text":"<p>A description of a set of landmark types and connections between them.</p> <p>Skeletons are represented by a directed graph composed of a set of <code>Node</code>s (landmark types such as body parts) and <code>Edge</code>s (connections between parts).</p> <p>Attributes:</p> Name Type Description <code>nodes</code> <code>list[Node]</code> <p>A list of <code>Node</code>s. May be specified as a list of strings to create new nodes from their names.</p> <code>edges</code> <code>list[Edge]</code> <p>A list of <code>Edge</code>s. May be specified as a list of 2-tuples of string names or integer indices of <code>nodes</code>. Each edge corresponds to a pair of source and destination nodes forming a directed edge.</p> <code>symmetries</code> <code>list[Symmetry]</code> <p>A list of <code>Symmetry</code>s. Each symmetry corresponds to symmetric body parts, such as <code>\"left eye\", \"right eye\"</code>. This is used when applying flip (reflection) augmentation to images in order to appropriately swap the indices of symmetric landmarks.</p> <code>name</code> <code>str | None</code> <p>A descriptive name for the <code>Skeleton</code>.</p> <p>Methods:</p> Name Description <code>__attrs_post_init__</code> <p>Ensure nodes are <code>Node</code>s, edges are <code>Edge</code>s, and <code>Node</code> map is updated.</p> <code>__contains__</code> <p>Check if a node is in the skeleton.</p> <code>__getitem__</code> <p>Return a <code>Node</code> when indexing by name or integer.</p> <code>__len__</code> <p>Return the number of nodes in the skeleton.</p> <code>__repr__</code> <p>Return a readable representation of the skeleton.</p> <code>add_edge</code> <p>Add an <code>Edge</code> to the skeleton.</p> <code>add_edges</code> <p>Add multiple <code>Edge</code>s to the skeleton.</p> <code>add_node</code> <p>Add a <code>Node</code> to the skeleton.</p> <code>add_nodes</code> <p>Add multiple <code>Node</code>s to the skeleton.</p> <code>add_symmetries</code> <p>Add multiple <code>Symmetry</code> relationships to the skeleton.</p> <code>add_symmetry</code> <p>Add a symmetry relationship to the skeleton.</p> <code>get_flipped_node_inds</code> <p>Returns node indices that should be switched when horizontally flipping.</p> <code>index</code> <p>Return the index of a node specified as a <code>Node</code> or string name.</p> <code>match_nodes</code> <p>Return the order of nodes in the skeleton.</p> <code>matches</code> <p>Check if this skeleton matches another skeleton's structure.</p> <code>node_similarities</code> <p>Calculate node overlap metrics with another skeleton.</p> <code>rebuild_cache</code> <p>Rebuild the node name/index to <code>Node</code> map caches.</p> <code>remove_node</code> <p>Remove a single node from the skeleton.</p> <code>remove_nodes</code> <p>Remove nodes from the skeleton.</p> <code>rename_node</code> <p>Rename a single node in the skeleton.</p> <code>rename_nodes</code> <p>Rename nodes in the skeleton.</p> <code>reorder_nodes</code> <p>Reorder nodes in the skeleton.</p> <code>require_node</code> <p>Return a <code>Node</code> object, handling indexing and adding missing nodes.</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>@define(eq=False)\nclass Skeleton:\n    \"\"\"A description of a set of landmark types and connections between them.\n\n    Skeletons are represented by a directed graph composed of a set of `Node`s (landmark\n    types such as body parts) and `Edge`s (connections between parts).\n\n    Attributes:\n        nodes: A list of `Node`s. May be specified as a list of strings to create new\n            nodes from their names.\n        edges: A list of `Edge`s. May be specified as a list of 2-tuples of string names\n            or integer indices of `nodes`. Each edge corresponds to a pair of source and\n            destination nodes forming a directed edge.\n        symmetries: A list of `Symmetry`s. Each symmetry corresponds to symmetric body\n            parts, such as `\"left eye\", \"right eye\"`. This is used when applying flip\n            (reflection) augmentation to images in order to appropriately swap the\n            indices of symmetric landmarks.\n        name: A descriptive name for the `Skeleton`.\n    \"\"\"\n\n    def _nodes_on_setattr(self, attr, new_nodes):\n        \"\"\"Callback to update caches when nodes are set.\"\"\"\n        self.rebuild_cache(nodes=new_nodes)\n        return new_nodes\n\n    nodes: list[Node] = field(\n        factory=list,\n        on_setattr=_nodes_on_setattr,\n    )\n    edges: list[Edge] = field(factory=list)\n    symmetries: list[Symmetry] = field(factory=list)\n    name: str | None = None\n    _name_to_node_cache: dict[str, Node] = field(init=False, repr=False, eq=False)\n    _node_to_ind_cache: dict[Node, int] = field(init=False, repr=False, eq=False)\n\n    def __attrs_post_init__(self):\n        \"\"\"Ensure nodes are `Node`s, edges are `Edge`s, and `Node` map is updated.\"\"\"\n        self._convert_nodes()\n        self._convert_edges()\n        self._convert_symmetries()\n        self.rebuild_cache()\n\n    def _convert_nodes(self):\n        \"\"\"Convert nodes to `Node` objects if needed.\"\"\"\n        if isinstance(self.nodes, np.ndarray):\n            object.__setattr__(self, \"nodes\", self.nodes.tolist())\n        for i, node in enumerate(self.nodes):\n            if type(node) is str:\n                self.nodes[i] = Node(node)\n\n    def _convert_edges(self):\n        \"\"\"Convert list of edge names or integers to `Edge` objects if needed.\"\"\"\n        if isinstance(self.edges, np.ndarray):\n            self.edges = self.edges.tolist()\n        node_names = self.node_names\n        for i, edge in enumerate(self.edges):\n            if type(edge) is Edge:\n                continue\n            src, dst = edge\n            if type(src) is str:\n                try:\n                    src = node_names.index(src)\n                except ValueError:\n                    raise ValueError(\n                        f\"Node '{src}' specified in the edge list is not in the nodes.\"\n                    )\n            if type(src) is int or (\n                np.isscalar(src) and np.issubdtype(src.dtype, np.integer)\n            ):\n                src = self.nodes[src]\n\n            if type(dst) is str:\n                try:\n                    dst = node_names.index(dst)\n                except ValueError:\n                    raise ValueError(\n                        f\"Node '{dst}' specified in the edge list is not in the nodes.\"\n                    )\n            if type(dst) is int or (\n                np.isscalar(dst) and np.issubdtype(dst.dtype, np.integer)\n            ):\n                dst = self.nodes[dst]\n\n            self.edges[i] = Edge(src, dst)\n\n    def _convert_symmetries(self):\n        \"\"\"Convert list of symmetric node names or integers to `Symmetry` objects.\"\"\"\n        if isinstance(self.symmetries, np.ndarray):\n            self.symmetries = self.symmetries.tolist()\n\n        node_names = self.node_names\n        for i, symmetry in enumerate(self.symmetries):\n            if type(symmetry) is Symmetry:\n                continue\n            node1, node2 = symmetry\n            if type(node1) is str:\n                try:\n                    node1 = node_names.index(node1)\n                except ValueError:\n                    raise ValueError(\n                        f\"Node '{node1}' specified in the symmetry list is not in the \"\n                        \"nodes.\"\n                    )\n            if type(node1) is int or (\n                np.isscalar(node1) and np.issubdtype(node1.dtype, np.integer)\n            ):\n                node1 = self.nodes[node1]\n\n            if type(node2) is str:\n                try:\n                    node2 = node_names.index(node2)\n                except ValueError:\n                    raise ValueError(\n                        f\"Node '{node2}' specified in the symmetry list is not in the \"\n                        \"nodes.\"\n                    )\n            if type(node2) is int or (\n                np.isscalar(node2) and np.issubdtype(node2.dtype, np.integer)\n            ):\n                node2 = self.nodes[node2]\n\n            self.symmetries[i] = Symmetry({node1, node2})\n\n    def rebuild_cache(self, nodes: list[Node] | None = None):\n        \"\"\"Rebuild the node name/index to `Node` map caches.\n\n        Args:\n            nodes: A list of `Node` objects to update the cache with. If not provided,\n                the cache will be updated with the current nodes in the skeleton. If\n                nodes are provided, the cache will be updated with the provided nodes,\n                but the current nodes in the skeleton will not be updated. Default is\n                `None`.\n\n        Notes:\n            This function should be called when nodes or node list is mutated to update\n            the lookup caches for indexing nodes by name or `Node` object.\n\n            This is done automatically when nodes are added or removed from the skeleton\n            using the convenience methods in this class.\n\n            This method only needs to be used when manually mutating nodes or the node\n            list directly.\n        \"\"\"\n        if nodes is None:\n            nodes = self.nodes\n        self._name_to_node_cache = {node.name: node for node in nodes}\n        self._node_to_ind_cache = {node: i for i, node in enumerate(nodes)}\n\n    @property\n    def node_names(self) -&gt; list[str]:\n        \"\"\"Names of the nodes associated with this skeleton as a list of strings.\"\"\"\n        return [node.name for node in self.nodes]\n\n    @property\n    def edge_inds(self) -&gt; list[tuple[int, int]]:\n        \"\"\"Edges indices as a list of 2-tuples.\"\"\"\n        return [\n            (self.nodes.index(edge.source), self.nodes.index(edge.destination))\n            for edge in self.edges\n        ]\n\n    @property\n    def edge_names(self) -&gt; list[str, str]:\n        \"\"\"Edge names as a list of 2-tuples with string node names.\"\"\"\n        return [(edge.source.name, edge.destination.name) for edge in self.edges]\n\n    @property\n    def symmetry_inds(self) -&gt; list[tuple[int, int]]:\n        \"\"\"Symmetry indices as a list of 2-tuples.\"\"\"\n        return [\n            tuple(sorted((self.index(symmetry[0]), self.index(symmetry[1]))))\n            for symmetry in self.symmetries\n        ]\n\n    @property\n    def symmetry_names(self) -&gt; list[str, str]:\n        \"\"\"Symmetry names as a list of 2-tuples with string node names.\"\"\"\n        return [\n            (self.nodes[i].name, self.nodes[j].name) for (i, j) in self.symmetry_inds\n        ]\n\n    def get_flipped_node_inds(self) -&gt; list[int]:\n        \"\"\"Returns node indices that should be switched when horizontally flipping.\n\n        This is useful as a lookup table for flipping the landmark coordinates when\n        doing data augmentation.\n\n        Example:\n            &gt;&gt;&gt; skel = Skeleton([\"A\", \"B_left\", \"B_right\", \"C\", \"D_left\", \"D_right\"])\n            &gt;&gt;&gt; skel.add_symmetry(\"B_left\", \"B_right\")\n            &gt;&gt;&gt; skel.add_symmetry(\"D_left\", \"D_right\")\n            &gt;&gt;&gt; skel.flipped_node_inds\n            [0, 2, 1, 3, 5, 4]\n            &gt;&gt;&gt; pose = np.array([[0, 0], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5]])\n            &gt;&gt;&gt; pose[skel.flipped_node_inds]\n            array([[0, 0],\n                   [2, 2],\n                   [1, 1],\n                   [3, 3],\n                   [5, 5],\n                   [4, 4]])\n        \"\"\"\n        flip_idx = np.arange(len(self.nodes))\n        if len(self.symmetries) &gt; 0:\n            symmetry_inds = np.array(\n                [(self.index(a), self.index(b)) for a, b in self.symmetries]\n            )\n            flip_idx[symmetry_inds[:, 0]] = symmetry_inds[:, 1]\n            flip_idx[symmetry_inds[:, 1]] = symmetry_inds[:, 0]\n\n        flip_idx = flip_idx.tolist()\n        return flip_idx\n\n    def __len__(self) -&gt; int:\n        \"\"\"Return the number of nodes in the skeleton.\"\"\"\n        return len(self.nodes)\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return a readable representation of the skeleton.\"\"\"\n        nodes = \", \".join([f'\"{node}\"' for node in self.node_names])\n        return f\"Skeleton(nodes=[{nodes}], edges={self.edge_inds})\"\n\n    def index(self, node: Node | str) -&gt; int:\n        \"\"\"Return the index of a node specified as a `Node` or string name.\"\"\"\n        if type(node) is str:\n            return self.index(self._name_to_node_cache[node])\n        elif type(node) is Node:\n            return self._node_to_ind_cache[node]\n        else:\n            raise IndexError(f\"Invalid indexing argument for skeleton: {node}\")\n\n    def __getitem__(self, idx: NodeOrIndex) -&gt; Node:\n        \"\"\"Return a `Node` when indexing by name or integer.\"\"\"\n        if type(idx) is int:\n            return self.nodes[idx]\n        elif type(idx) is str:\n            return self._name_to_node_cache[idx]\n        else:\n            raise IndexError(f\"Invalid indexing argument for skeleton: {idx}\")\n\n    def __contains__(self, node: NodeOrIndex) -&gt; bool:\n        \"\"\"Check if a node is in the skeleton.\"\"\"\n        if type(node) is str:\n            return node in self._name_to_node_cache\n        elif type(node) is Node:\n            return node in self.nodes\n        elif type(node) is int:\n            return 0 &lt;= node &lt; len(self.nodes)\n        else:\n            raise ValueError(f\"Invalid node type for skeleton: {node}\")\n\n    def add_node(self, node: Node | str):\n        \"\"\"Add a `Node` to the skeleton.\n\n        Args:\n            node: A `Node` object or a string name to create a new node.\n\n        Raises:\n            ValueError: If the node already exists in the skeleton or if the node is\n                not specified as a `Node` or string.\n        \"\"\"\n        if node in self:\n            raise ValueError(f\"Node '{node}' already exists in the skeleton.\")\n\n        if type(node) is str:\n            node = Node(node)\n\n        if type(node) is not Node:\n            raise ValueError(f\"Invalid node type: {node} ({type(node)})\")\n\n        self.nodes.append(node)\n\n        # Atomic update of the cache.\n        self._name_to_node_cache[node.name] = node\n        self._node_to_ind_cache[node] = len(self.nodes) - 1\n\n    def add_nodes(self, nodes: list[Node | str]):\n        \"\"\"Add multiple `Node`s to the skeleton.\n\n        Args:\n            nodes: A list of `Node` objects or string names to create new nodes.\n        \"\"\"\n        for node in nodes:\n            self.add_node(node)\n\n    def require_node(self, node: NodeOrIndex, add_missing: bool = True) -&gt; Node:\n        \"\"\"Return a `Node` object, handling indexing and adding missing nodes.\n\n        Args:\n            node: A `Node` object, name or index.\n            add_missing: If `True`, missing nodes will be added to the skeleton. If\n                `False`, an error will be raised if the node is not found. Default is\n                `True`.\n\n        Returns:\n            The `Node` object.\n\n        Raises:\n            IndexError: If the node is not found in the skeleton and `add_missing` is\n                `False`.\n        \"\"\"\n        if node not in self:\n            if add_missing:\n                self.add_node(node)\n            else:\n                raise IndexError(f\"Node '{node}' not found in the skeleton.\")\n\n        if type(node) is Node:\n            return node\n\n        return self[node]\n\n    def add_edge(\n        self,\n        src: NodeOrIndex | Edge | tuple[NodeOrIndex, NodeOrIndex],\n        dst: NodeOrIndex | None = None,\n    ):\n        \"\"\"Add an `Edge` to the skeleton.\n\n        Args:\n            src: The source node specified as a `Node`, name or index.\n            dst: The destination node specified as a `Node`, name or index.\n        \"\"\"\n        edge = None\n        if type(src) is tuple:\n            src, dst = src\n\n        if is_node_or_index(src):\n            if not is_node_or_index(dst):\n                raise ValueError(\"Destination node must be specified.\")\n\n            src = self.require_node(src)\n            dst = self.require_node(dst)\n            edge = Edge(src, dst)\n\n        if type(src) is Edge:\n            edge = src\n\n        if edge not in self.edges:\n            self.edges.append(edge)\n\n    def add_edges(self, edges: list[Edge | tuple[NodeOrIndex, NodeOrIndex]]):\n        \"\"\"Add multiple `Edge`s to the skeleton.\n\n        Args:\n            edges: A list of `Edge` objects or 2-tuples of source and destination nodes.\n        \"\"\"\n        for edge in edges:\n            self.add_edge(edge)\n\n    def add_symmetry(\n        self, node1: Symmetry | NodeOrIndex = None, node2: NodeOrIndex | None = None\n    ):\n        \"\"\"Add a symmetry relationship to the skeleton.\n\n        Args:\n            node1: The first node specified as a `Node`, name or index. If a `Symmetry`\n                object is provided, it will be added directly to the skeleton.\n            node2: The second node specified as a `Node`, name or index.\n        \"\"\"\n        symmetry = None\n        if type(node1) is Symmetry:\n            symmetry = node1\n            node1, node2 = symmetry\n\n        node1 = self.require_node(node1)\n        node2 = self.require_node(node2)\n\n        if symmetry is None:\n            symmetry = Symmetry({node1, node2})\n\n        if symmetry not in self.symmetries:\n            self.symmetries.append(symmetry)\n\n    def add_symmetries(\n        self, symmetries: list[Symmetry | tuple[NodeOrIndex, NodeOrIndex]]\n    ):\n        \"\"\"Add multiple `Symmetry` relationships to the skeleton.\n\n        Args:\n            symmetries: A list of `Symmetry` objects or 2-tuples of symmetric nodes.\n        \"\"\"\n        for symmetry in symmetries:\n            self.add_symmetry(*symmetry)\n\n    def rename_nodes(self, name_map: dict[NodeOrIndex, str] | list[str]):\n        \"\"\"Rename nodes in the skeleton.\n\n        Args:\n            name_map: A dictionary mapping old node names to new node names. Keys can be\n                specified as `Node` objects, integer indices, or string names. Values\n                must be specified as string names.\n\n                If a list of strings is provided of the same length as the current\n                nodes, the nodes will be renamed to the names in the list in order.\n\n        Raises:\n            ValueError: If the new node names exist in the skeleton or if the old node\n                names are not found in the skeleton.\n\n        Notes:\n            This method should always be used when renaming nodes in the skeleton as it\n            handles updating the lookup caches necessary for indexing nodes by name.\n\n            After renaming, instances using this skeleton **do NOT need to be updated**\n            as the nodes are stored by reference in the skeleton, so changes are\n            reflected automatically.\n\n        Example:\n            &gt;&gt;&gt; skel = Skeleton([\"A\", \"B\", \"C\"], edges=[(\"A\", \"B\"), (\"B\", \"C\")])\n            &gt;&gt;&gt; skel.rename_nodes({\"A\": \"X\", \"B\": \"Y\", \"C\": \"Z\"})\n            &gt;&gt;&gt; skel.node_names\n            [\"X\", \"Y\", \"Z\"]\n            &gt;&gt;&gt; skel.rename_nodes([\"a\", \"b\", \"c\"])\n            &gt;&gt;&gt; skel.node_names\n            [\"a\", \"b\", \"c\"]\n        \"\"\"\n        if type(name_map) is list:\n            if len(name_map) != len(self.nodes):\n                raise ValueError(\n                    \"List of new node names must be the same length as the current \"\n                    \"nodes.\"\n                )\n            name_map = {node: name for node, name in zip(self.nodes, name_map)}\n\n        for old_name, new_name in name_map.items():\n            if type(old_name) is Node:\n                old_name = old_name.name\n            if type(old_name) is int:\n                old_name = self.nodes[old_name].name\n\n            if old_name not in self._name_to_node_cache:\n                raise ValueError(f\"Node '{old_name}' not found in the skeleton.\")\n            if new_name in self._name_to_node_cache:\n                raise ValueError(f\"Node '{new_name}' already exists in the skeleton.\")\n\n            node = self._name_to_node_cache[old_name]\n            node.name = new_name\n            self._name_to_node_cache[new_name] = node\n            del self._name_to_node_cache[old_name]\n\n    def rename_node(self, old_name: NodeOrIndex, new_name: str):\n        \"\"\"Rename a single node in the skeleton.\n\n        Args:\n            old_name: The name of the node to rename. Can also be specified as an\n                integer index or `Node` object.\n            new_name: The new name for the node.\n        \"\"\"\n        self.rename_nodes({old_name: new_name})\n\n    def remove_nodes(self, nodes: list[NodeOrIndex]):\n        \"\"\"Remove nodes from the skeleton.\n\n        Args:\n            nodes: A list of node names, indices, or `Node` objects to remove.\n\n        Notes:\n            This method handles updating the lookup caches necessary for indexing nodes\n            by name.\n\n            Any edges and symmetries that are connected to the removed nodes will also\n            be removed.\n\n        Warning:\n            **This method does NOT update instances** that use this skeleton to reflect\n            changes.\n\n            It is recommended to use the `Labels.remove_nodes()` method which will\n            update all contained to reflect the changes made to the skeleton.\n\n            To manually update instances after this method is called, call\n            `instance.update_nodes()` on each instance that uses this skeleton.\n        \"\"\"\n        # Standardize input and make a pre-mutation copy before keys are changed.\n        rm_node_objs = [self.require_node(node, add_missing=False) for node in nodes]\n\n        # Remove nodes from the skeleton.\n        for node in rm_node_objs:\n            self.nodes.remove(node)\n            del self._name_to_node_cache[node.name]\n\n        # Remove edges connected to the removed nodes.\n        self.edges = [\n            edge\n            for edge in self.edges\n            if edge.source not in rm_node_objs and edge.destination not in rm_node_objs\n        ]\n\n        # Remove symmetries connected to the removed nodes.\n        self.symmetries = [\n            symmetry\n            for symmetry in self.symmetries\n            if symmetry.nodes.isdisjoint(rm_node_objs)\n        ]\n\n        # Update node index map.\n        self.rebuild_cache()\n\n    def remove_node(self, node: NodeOrIndex):\n        \"\"\"Remove a single node from the skeleton.\n\n        Args:\n            node: The node to remove. Can be specified as a string name, integer index,\n                or `Node` object.\n\n        Notes:\n            This method handles updating the lookup caches necessary for indexing nodes\n            by name.\n\n            Any edges and symmetries that are connected to the removed node will also be\n            removed.\n\n        Warning:\n            **This method does NOT update instances** that use this skeleton to reflect\n            changes.\n\n            It is recommended to use the `Labels.remove_nodes()` method which will\n            update all contained instances to reflect the changes made to the skeleton.\n\n            To manually update instances after this method is called, call\n            `Instance.update_skeleton()` on each instance that uses this skeleton.\n        \"\"\"\n        self.remove_nodes([node])\n\n    def reorder_nodes(self, new_order: list[NodeOrIndex]):\n        \"\"\"Reorder nodes in the skeleton.\n\n        Args:\n            new_order: A list of node names, indices, or `Node` objects specifying the\n                new order of the nodes.\n\n        Raises:\n            ValueError: If the new order of nodes is not the same length as the current\n                nodes.\n\n        Notes:\n            This method handles updating the lookup caches necessary for indexing nodes\n            by name.\n\n        Warning:\n            After reordering, instances using this skeleton do not need to be updated as\n            the nodes are stored by reference in the skeleton.\n\n            However, the order that points are stored in the instances will not be\n            updated to match the new order of the nodes in the skeleton. This should not\n            matter unless the ordering of the keys in the `Instance.points` dictionary\n            is used instead of relying on the skeleton node order.\n\n            To make sure these are aligned, it is recommended to use the\n            `Labels.reorder_nodes()` method which will update all contained instances to\n            reflect the changes made to the skeleton.\n\n            To manually update instances after this method is called, call\n            `Instance.update_skeleton()` on each instance that uses this skeleton.\n        \"\"\"\n        if len(new_order) != len(self.nodes):\n            raise ValueError(\n                \"New order of nodes must be the same length as the current nodes.\"\n            )\n\n        new_nodes = [self.require_node(node, add_missing=False) for node in new_order]\n        self.nodes = new_nodes\n\n    def match_nodes(self, other_nodes: list[str, Node]) -&gt; tuple[list[int], list[int]]:\n        \"\"\"Return the order of nodes in the skeleton.\n\n        Args:\n            other_nodes: A list of node names or `Node` objects.\n\n        Returns:\n            A tuple of `skeleton_inds, `other_inds`.\n\n            `skeleton_inds` contains the indices of the nodes in the skeleton that match\n            the input nodes.\n\n            `other_inds` contains the indices of the input nodes that match the nodes in\n            the skeleton.\n\n            These can be used to reorder point data to match the order of nodes in the\n            skeleton.\n\n        See also: match_nodes_cached\n        \"\"\"\n        if isinstance(other_nodes, np.ndarray):\n            other_nodes = other_nodes.tolist()\n        if type(other_nodes) is not tuple:\n            other_nodes = [x.name if type(x) is Node else x for x in other_nodes]\n\n        skeleton_inds, other_inds = match_nodes_cached(\n            tuple(self.node_names), tuple(other_nodes)\n        )\n\n        return list(skeleton_inds), list(other_inds)\n\n    def matches(self, other: \"Skeleton\", require_same_order: bool = False) -&gt; bool:\n        \"\"\"Check if this skeleton matches another skeleton's structure.\n\n        Args:\n            other: Another skeleton to compare with.\n            require_same_order: If True, nodes must be in the same order.\n                If False, only the node names and edges need to match.\n\n        Returns:\n            True if the skeletons match, False otherwise.\n\n        Notes:\n            Two skeletons match if they have the same nodes (by name) and edges.\n            If require_same_order is True, the nodes must also be in the same order.\n        \"\"\"\n        # Check if we have the same number of nodes\n        if len(self.nodes) != len(other.nodes):\n            return False\n\n        # Check node names\n        if require_same_order:\n            if self.node_names != other.node_names:\n                return False\n        else:\n            if set(self.node_names) != set(other.node_names):\n                return False\n\n        # Check edges (considering node name mapping if order differs)\n        if len(self.edges) != len(other.edges):\n            return False\n\n        # Create edge sets for comparison\n        self_edge_set = {\n            (edge.source.name, edge.destination.name) for edge in self.edges\n        }\n        other_edge_set = {\n            (edge.source.name, edge.destination.name) for edge in other.edges\n        }\n\n        if self_edge_set != other_edge_set:\n            return False\n\n        # Check symmetries\n        if len(self.symmetries) != len(other.symmetries):\n            return False\n\n        self_sym_set = {\n            frozenset(node.name for node in sym.nodes) for sym in self.symmetries\n        }\n        other_sym_set = {\n            frozenset(node.name for node in sym.nodes) for sym in other.symmetries\n        }\n\n        return self_sym_set == other_sym_set\n\n    def node_similarities(self, other: \"Skeleton\") -&gt; dict[str, float]:\n        \"\"\"Calculate node overlap metrics with another skeleton.\n\n        Args:\n            other: Another skeleton to compare with.\n\n        Returns:\n            A dictionary with similarity metrics:\n            - 'n_common': Number of nodes in common\n            - 'n_self_only': Number of nodes only in this skeleton\n            - 'n_other_only': Number of nodes only in the other skeleton\n            - 'jaccard': Jaccard similarity (intersection/union)\n            - 'dice': Dice coefficient (2*intersection/(n_self + n_other))\n        \"\"\"\n        self_nodes = set(self.node_names)\n        other_nodes = set(other.node_names)\n\n        n_common = len(self_nodes &amp; other_nodes)\n        n_self_only = len(self_nodes - other_nodes)\n        n_other_only = len(other_nodes - self_nodes)\n        n_union = len(self_nodes | other_nodes)\n\n        jaccard = n_common / n_union if n_union &gt; 0 else 0\n        dice = (\n            2 * n_common / (len(self_nodes) + len(other_nodes))\n            if (len(self_nodes) + len(other_nodes)) &gt; 0\n            else 0\n        )\n\n        return {\n            \"n_common\": n_common,\n            \"n_self_only\": n_self_only,\n            \"n_other_only\": n_other_only,\n            \"jaccard\": jaccard,\n            \"dice\": dice,\n        }\n</code></pre>"},{"location":"reference/sleap_io/model/skeleton/#sleap_io.model.skeleton.Skeleton.edge_inds","title":"<code>edge_inds</code>  <code>property</code>","text":"<p>Edges indices as a list of 2-tuples.</p>"},{"location":"reference/sleap_io/model/skeleton/#sleap_io.model.skeleton.Skeleton.edge_names","title":"<code>edge_names</code>  <code>property</code>","text":"<p>Edge names as a list of 2-tuples with string node names.</p>"},{"location":"reference/sleap_io/model/skeleton/#sleap_io.model.skeleton.Skeleton.node_names","title":"<code>node_names</code>  <code>property</code>","text":"<p>Names of the nodes associated with this skeleton as a list of strings.</p>"},{"location":"reference/sleap_io/model/skeleton/#sleap_io.model.skeleton.Skeleton.symmetry_inds","title":"<code>symmetry_inds</code>  <code>property</code>","text":"<p>Symmetry indices as a list of 2-tuples.</p>"},{"location":"reference/sleap_io/model/skeleton/#sleap_io.model.skeleton.Skeleton.symmetry_names","title":"<code>symmetry_names</code>  <code>property</code>","text":"<p>Symmetry names as a list of 2-tuples with string node names.</p>"},{"location":"reference/sleap_io/model/skeleton/#sleap_io.model.skeleton.Skeleton.__attrs_post_init__","title":"<code>__attrs_post_init__()</code>","text":"<p>Ensure nodes are <code>Node</code>s, edges are <code>Edge</code>s, and <code>Node</code> map is updated.</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def __attrs_post_init__(self):\n    \"\"\"Ensure nodes are `Node`s, edges are `Edge`s, and `Node` map is updated.\"\"\"\n    self._convert_nodes()\n    self._convert_edges()\n    self._convert_symmetries()\n    self.rebuild_cache()\n</code></pre>"},{"location":"reference/sleap_io/model/skeleton/#sleap_io.model.skeleton.Skeleton.__contains__","title":"<code>__contains__(node)</code>","text":"<p>Check if a node is in the skeleton.</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def __contains__(self, node: NodeOrIndex) -&gt; bool:\n    \"\"\"Check if a node is in the skeleton.\"\"\"\n    if type(node) is str:\n        return node in self._name_to_node_cache\n    elif type(node) is Node:\n        return node in self.nodes\n    elif type(node) is int:\n        return 0 &lt;= node &lt; len(self.nodes)\n    else:\n        raise ValueError(f\"Invalid node type for skeleton: {node}\")\n</code></pre>"},{"location":"reference/sleap_io/model/skeleton/#sleap_io.model.skeleton.Skeleton.__getitem__","title":"<code>__getitem__(idx)</code>","text":"<p>Return a <code>Node</code> when indexing by name or integer.</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def __getitem__(self, idx: NodeOrIndex) -&gt; Node:\n    \"\"\"Return a `Node` when indexing by name or integer.\"\"\"\n    if type(idx) is int:\n        return self.nodes[idx]\n    elif type(idx) is str:\n        return self._name_to_node_cache[idx]\n    else:\n        raise IndexError(f\"Invalid indexing argument for skeleton: {idx}\")\n</code></pre>"},{"location":"reference/sleap_io/model/skeleton/#sleap_io.model.skeleton.Skeleton.__len__","title":"<code>__len__()</code>","text":"<p>Return the number of nodes in the skeleton.</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"Return the number of nodes in the skeleton.\"\"\"\n    return len(self.nodes)\n</code></pre>"},{"location":"reference/sleap_io/model/skeleton/#sleap_io.model.skeleton.Skeleton.__repr__","title":"<code>__repr__()</code>","text":"<p>Return a readable representation of the skeleton.</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return a readable representation of the skeleton.\"\"\"\n    nodes = \", \".join([f'\"{node}\"' for node in self.node_names])\n    return f\"Skeleton(nodes=[{nodes}], edges={self.edge_inds})\"\n</code></pre>"},{"location":"reference/sleap_io/model/skeleton/#sleap_io.model.skeleton.Skeleton.add_edge","title":"<code>add_edge(src, dst=None)</code>","text":"<p>Add an <code>Edge</code> to the skeleton.</p> <p>Parameters:</p> Name Type Description Default <code>src</code> <code>NodeOrIndex | Edge | tuple[NodeOrIndex, NodeOrIndex]</code> <p>The source node specified as a <code>Node</code>, name or index.</p> required <code>dst</code> <code>NodeOrIndex | None</code> <p>The destination node specified as a <code>Node</code>, name or index.</p> <code>None</code> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def add_edge(\n    self,\n    src: NodeOrIndex | Edge | tuple[NodeOrIndex, NodeOrIndex],\n    dst: NodeOrIndex | None = None,\n):\n    \"\"\"Add an `Edge` to the skeleton.\n\n    Args:\n        src: The source node specified as a `Node`, name or index.\n        dst: The destination node specified as a `Node`, name or index.\n    \"\"\"\n    edge = None\n    if type(src) is tuple:\n        src, dst = src\n\n    if is_node_or_index(src):\n        if not is_node_or_index(dst):\n            raise ValueError(\"Destination node must be specified.\")\n\n        src = self.require_node(src)\n        dst = self.require_node(dst)\n        edge = Edge(src, dst)\n\n    if type(src) is Edge:\n        edge = src\n\n    if edge not in self.edges:\n        self.edges.append(edge)\n</code></pre>"},{"location":"reference/sleap_io/model/skeleton/#sleap_io.model.skeleton.Skeleton.add_edges","title":"<code>add_edges(edges)</code>","text":"<p>Add multiple <code>Edge</code>s to the skeleton.</p> <p>Parameters:</p> Name Type Description Default <code>edges</code> <code>list[Edge | tuple[NodeOrIndex, NodeOrIndex]]</code> <p>A list of <code>Edge</code> objects or 2-tuples of source and destination nodes.</p> required Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def add_edges(self, edges: list[Edge | tuple[NodeOrIndex, NodeOrIndex]]):\n    \"\"\"Add multiple `Edge`s to the skeleton.\n\n    Args:\n        edges: A list of `Edge` objects or 2-tuples of source and destination nodes.\n    \"\"\"\n    for edge in edges:\n        self.add_edge(edge)\n</code></pre>"},{"location":"reference/sleap_io/model/skeleton/#sleap_io.model.skeleton.Skeleton.add_node","title":"<code>add_node(node)</code>","text":"<p>Add a <code>Node</code> to the skeleton.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>Node | str</code> <p>A <code>Node</code> object or a string name to create a new node.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If the node already exists in the skeleton or if the node is not specified as a <code>Node</code> or string.</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def add_node(self, node: Node | str):\n    \"\"\"Add a `Node` to the skeleton.\n\n    Args:\n        node: A `Node` object or a string name to create a new node.\n\n    Raises:\n        ValueError: If the node already exists in the skeleton or if the node is\n            not specified as a `Node` or string.\n    \"\"\"\n    if node in self:\n        raise ValueError(f\"Node '{node}' already exists in the skeleton.\")\n\n    if type(node) is str:\n        node = Node(node)\n\n    if type(node) is not Node:\n        raise ValueError(f\"Invalid node type: {node} ({type(node)})\")\n\n    self.nodes.append(node)\n\n    # Atomic update of the cache.\n    self._name_to_node_cache[node.name] = node\n    self._node_to_ind_cache[node] = len(self.nodes) - 1\n</code></pre>"},{"location":"reference/sleap_io/model/skeleton/#sleap_io.model.skeleton.Skeleton.add_nodes","title":"<code>add_nodes(nodes)</code>","text":"<p>Add multiple <code>Node</code>s to the skeleton.</p> <p>Parameters:</p> Name Type Description Default <code>nodes</code> <code>list[Node | str]</code> <p>A list of <code>Node</code> objects or string names to create new nodes.</p> required Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def add_nodes(self, nodes: list[Node | str]):\n    \"\"\"Add multiple `Node`s to the skeleton.\n\n    Args:\n        nodes: A list of `Node` objects or string names to create new nodes.\n    \"\"\"\n    for node in nodes:\n        self.add_node(node)\n</code></pre>"},{"location":"reference/sleap_io/model/skeleton/#sleap_io.model.skeleton.Skeleton.add_symmetries","title":"<code>add_symmetries(symmetries)</code>","text":"<p>Add multiple <code>Symmetry</code> relationships to the skeleton.</p> <p>Parameters:</p> Name Type Description Default <code>symmetries</code> <code>list[Symmetry | tuple[NodeOrIndex, NodeOrIndex]]</code> <p>A list of <code>Symmetry</code> objects or 2-tuples of symmetric nodes.</p> required Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def add_symmetries(\n    self, symmetries: list[Symmetry | tuple[NodeOrIndex, NodeOrIndex]]\n):\n    \"\"\"Add multiple `Symmetry` relationships to the skeleton.\n\n    Args:\n        symmetries: A list of `Symmetry` objects or 2-tuples of symmetric nodes.\n    \"\"\"\n    for symmetry in symmetries:\n        self.add_symmetry(*symmetry)\n</code></pre>"},{"location":"reference/sleap_io/model/skeleton/#sleap_io.model.skeleton.Skeleton.add_symmetry","title":"<code>add_symmetry(node1=None, node2=None)</code>","text":"<p>Add a symmetry relationship to the skeleton.</p> <p>Parameters:</p> Name Type Description Default <code>node1</code> <code>Symmetry | NodeOrIndex</code> <p>The first node specified as a <code>Node</code>, name or index. If a <code>Symmetry</code> object is provided, it will be added directly to the skeleton.</p> <code>None</code> <code>node2</code> <code>NodeOrIndex | None</code> <p>The second node specified as a <code>Node</code>, name or index.</p> <code>None</code> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def add_symmetry(\n    self, node1: Symmetry | NodeOrIndex = None, node2: NodeOrIndex | None = None\n):\n    \"\"\"Add a symmetry relationship to the skeleton.\n\n    Args:\n        node1: The first node specified as a `Node`, name or index. If a `Symmetry`\n            object is provided, it will be added directly to the skeleton.\n        node2: The second node specified as a `Node`, name or index.\n    \"\"\"\n    symmetry = None\n    if type(node1) is Symmetry:\n        symmetry = node1\n        node1, node2 = symmetry\n\n    node1 = self.require_node(node1)\n    node2 = self.require_node(node2)\n\n    if symmetry is None:\n        symmetry = Symmetry({node1, node2})\n\n    if symmetry not in self.symmetries:\n        self.symmetries.append(symmetry)\n</code></pre>"},{"location":"reference/sleap_io/model/skeleton/#sleap_io.model.skeleton.Skeleton.get_flipped_node_inds","title":"<code>get_flipped_node_inds()</code>","text":"<p>Returns node indices that should be switched when horizontally flipping.</p> <p>This is useful as a lookup table for flipping the landmark coordinates when doing data augmentation.</p> Example <p>skel = Skeleton([\"A\", \"B_left\", \"B_right\", \"C\", \"D_left\", \"D_right\"]) skel.add_symmetry(\"B_left\", \"B_right\") skel.add_symmetry(\"D_left\", \"D_right\") skel.flipped_node_inds [0, 2, 1, 3, 5, 4] pose = np.array([[0, 0], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5]]) pose[skel.flipped_node_inds] array([[0, 0],        [2, 2],        [1, 1],        [3, 3],        [5, 5],        [4, 4]])</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def get_flipped_node_inds(self) -&gt; list[int]:\n    \"\"\"Returns node indices that should be switched when horizontally flipping.\n\n    This is useful as a lookup table for flipping the landmark coordinates when\n    doing data augmentation.\n\n    Example:\n        &gt;&gt;&gt; skel = Skeleton([\"A\", \"B_left\", \"B_right\", \"C\", \"D_left\", \"D_right\"])\n        &gt;&gt;&gt; skel.add_symmetry(\"B_left\", \"B_right\")\n        &gt;&gt;&gt; skel.add_symmetry(\"D_left\", \"D_right\")\n        &gt;&gt;&gt; skel.flipped_node_inds\n        [0, 2, 1, 3, 5, 4]\n        &gt;&gt;&gt; pose = np.array([[0, 0], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5]])\n        &gt;&gt;&gt; pose[skel.flipped_node_inds]\n        array([[0, 0],\n               [2, 2],\n               [1, 1],\n               [3, 3],\n               [5, 5],\n               [4, 4]])\n    \"\"\"\n    flip_idx = np.arange(len(self.nodes))\n    if len(self.symmetries) &gt; 0:\n        symmetry_inds = np.array(\n            [(self.index(a), self.index(b)) for a, b in self.symmetries]\n        )\n        flip_idx[symmetry_inds[:, 0]] = symmetry_inds[:, 1]\n        flip_idx[symmetry_inds[:, 1]] = symmetry_inds[:, 0]\n\n    flip_idx = flip_idx.tolist()\n    return flip_idx\n</code></pre>"},{"location":"reference/sleap_io/model/skeleton/#sleap_io.model.skeleton.Skeleton.index","title":"<code>index(node)</code>","text":"<p>Return the index of a node specified as a <code>Node</code> or string name.</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def index(self, node: Node | str) -&gt; int:\n    \"\"\"Return the index of a node specified as a `Node` or string name.\"\"\"\n    if type(node) is str:\n        return self.index(self._name_to_node_cache[node])\n    elif type(node) is Node:\n        return self._node_to_ind_cache[node]\n    else:\n        raise IndexError(f\"Invalid indexing argument for skeleton: {node}\")\n</code></pre>"},{"location":"reference/sleap_io/model/skeleton/#sleap_io.model.skeleton.Skeleton.match_nodes","title":"<code>match_nodes(other_nodes)</code>","text":"<p>Return the order of nodes in the skeleton.</p> <p>Parameters:</p> Name Type Description Default <code>other_nodes</code> <code>list[str, Node]</code> <p>A list of node names or <code>Node</code> objects.</p> required <p>Returns:</p> Type Description <code>tuple[list[int], list[int]]</code> <p>A tuple of <code>skeleton_inds,</code>other_inds`.</p> <p><code>skeleton_inds</code> contains the indices of the nodes in the skeleton that match the input nodes.</p> <p><code>other_inds</code> contains the indices of the input nodes that match the nodes in the skeleton.</p> <p>These can be used to reorder point data to match the order of nodes in the skeleton.</p> <p>See also: match_nodes_cached</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def match_nodes(self, other_nodes: list[str, Node]) -&gt; tuple[list[int], list[int]]:\n    \"\"\"Return the order of nodes in the skeleton.\n\n    Args:\n        other_nodes: A list of node names or `Node` objects.\n\n    Returns:\n        A tuple of `skeleton_inds, `other_inds`.\n\n        `skeleton_inds` contains the indices of the nodes in the skeleton that match\n        the input nodes.\n\n        `other_inds` contains the indices of the input nodes that match the nodes in\n        the skeleton.\n\n        These can be used to reorder point data to match the order of nodes in the\n        skeleton.\n\n    See also: match_nodes_cached\n    \"\"\"\n    if isinstance(other_nodes, np.ndarray):\n        other_nodes = other_nodes.tolist()\n    if type(other_nodes) is not tuple:\n        other_nodes = [x.name if type(x) is Node else x for x in other_nodes]\n\n    skeleton_inds, other_inds = match_nodes_cached(\n        tuple(self.node_names), tuple(other_nodes)\n    )\n\n    return list(skeleton_inds), list(other_inds)\n</code></pre>"},{"location":"reference/sleap_io/model/skeleton/#sleap_io.model.skeleton.Skeleton.matches","title":"<code>matches(other, require_same_order=False)</code>","text":"<p>Check if this skeleton matches another skeleton's structure.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>'Skeleton'</code> <p>Another skeleton to compare with.</p> required <code>require_same_order</code> <code>bool</code> <p>If True, nodes must be in the same order. If False, only the node names and edges need to match.</p> <code>False</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if the skeletons match, False otherwise.</p> Notes <p>Two skeletons match if they have the same nodes (by name) and edges. If require_same_order is True, the nodes must also be in the same order.</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def matches(self, other: \"Skeleton\", require_same_order: bool = False) -&gt; bool:\n    \"\"\"Check if this skeleton matches another skeleton's structure.\n\n    Args:\n        other: Another skeleton to compare with.\n        require_same_order: If True, nodes must be in the same order.\n            If False, only the node names and edges need to match.\n\n    Returns:\n        True if the skeletons match, False otherwise.\n\n    Notes:\n        Two skeletons match if they have the same nodes (by name) and edges.\n        If require_same_order is True, the nodes must also be in the same order.\n    \"\"\"\n    # Check if we have the same number of nodes\n    if len(self.nodes) != len(other.nodes):\n        return False\n\n    # Check node names\n    if require_same_order:\n        if self.node_names != other.node_names:\n            return False\n    else:\n        if set(self.node_names) != set(other.node_names):\n            return False\n\n    # Check edges (considering node name mapping if order differs)\n    if len(self.edges) != len(other.edges):\n        return False\n\n    # Create edge sets for comparison\n    self_edge_set = {\n        (edge.source.name, edge.destination.name) for edge in self.edges\n    }\n    other_edge_set = {\n        (edge.source.name, edge.destination.name) for edge in other.edges\n    }\n\n    if self_edge_set != other_edge_set:\n        return False\n\n    # Check symmetries\n    if len(self.symmetries) != len(other.symmetries):\n        return False\n\n    self_sym_set = {\n        frozenset(node.name for node in sym.nodes) for sym in self.symmetries\n    }\n    other_sym_set = {\n        frozenset(node.name for node in sym.nodes) for sym in other.symmetries\n    }\n\n    return self_sym_set == other_sym_set\n</code></pre>"},{"location":"reference/sleap_io/model/skeleton/#sleap_io.model.skeleton.Skeleton.node_similarities","title":"<code>node_similarities(other)</code>","text":"<p>Calculate node overlap metrics with another skeleton.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>'Skeleton'</code> <p>Another skeleton to compare with.</p> required <p>Returns:</p> Type Description <code>dict[str, float]</code> <p>A dictionary with similarity metrics: - 'n_common': Number of nodes in common - 'n_self_only': Number of nodes only in this skeleton - 'n_other_only': Number of nodes only in the other skeleton - 'jaccard': Jaccard similarity (intersection/union) - 'dice': Dice coefficient (2*intersection/(n_self + n_other))</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def node_similarities(self, other: \"Skeleton\") -&gt; dict[str, float]:\n    \"\"\"Calculate node overlap metrics with another skeleton.\n\n    Args:\n        other: Another skeleton to compare with.\n\n    Returns:\n        A dictionary with similarity metrics:\n        - 'n_common': Number of nodes in common\n        - 'n_self_only': Number of nodes only in this skeleton\n        - 'n_other_only': Number of nodes only in the other skeleton\n        - 'jaccard': Jaccard similarity (intersection/union)\n        - 'dice': Dice coefficient (2*intersection/(n_self + n_other))\n    \"\"\"\n    self_nodes = set(self.node_names)\n    other_nodes = set(other.node_names)\n\n    n_common = len(self_nodes &amp; other_nodes)\n    n_self_only = len(self_nodes - other_nodes)\n    n_other_only = len(other_nodes - self_nodes)\n    n_union = len(self_nodes | other_nodes)\n\n    jaccard = n_common / n_union if n_union &gt; 0 else 0\n    dice = (\n        2 * n_common / (len(self_nodes) + len(other_nodes))\n        if (len(self_nodes) + len(other_nodes)) &gt; 0\n        else 0\n    )\n\n    return {\n        \"n_common\": n_common,\n        \"n_self_only\": n_self_only,\n        \"n_other_only\": n_other_only,\n        \"jaccard\": jaccard,\n        \"dice\": dice,\n    }\n</code></pre>"},{"location":"reference/sleap_io/model/skeleton/#sleap_io.model.skeleton.Skeleton.rebuild_cache","title":"<code>rebuild_cache(nodes=None)</code>","text":"<p>Rebuild the node name/index to <code>Node</code> map caches.</p> <p>Parameters:</p> Name Type Description Default <code>nodes</code> <code>list[Node] | None</code> <p>A list of <code>Node</code> objects to update the cache with. If not provided, the cache will be updated with the current nodes in the skeleton. If nodes are provided, the cache will be updated with the provided nodes, but the current nodes in the skeleton will not be updated. Default is <code>None</code>.</p> <code>None</code> Notes <p>This function should be called when nodes or node list is mutated to update the lookup caches for indexing nodes by name or <code>Node</code> object.</p> <p>This is done automatically when nodes are added or removed from the skeleton using the convenience methods in this class.</p> <p>This method only needs to be used when manually mutating nodes or the node list directly.</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def rebuild_cache(self, nodes: list[Node] | None = None):\n    \"\"\"Rebuild the node name/index to `Node` map caches.\n\n    Args:\n        nodes: A list of `Node` objects to update the cache with. If not provided,\n            the cache will be updated with the current nodes in the skeleton. If\n            nodes are provided, the cache will be updated with the provided nodes,\n            but the current nodes in the skeleton will not be updated. Default is\n            `None`.\n\n    Notes:\n        This function should be called when nodes or node list is mutated to update\n        the lookup caches for indexing nodes by name or `Node` object.\n\n        This is done automatically when nodes are added or removed from the skeleton\n        using the convenience methods in this class.\n\n        This method only needs to be used when manually mutating nodes or the node\n        list directly.\n    \"\"\"\n    if nodes is None:\n        nodes = self.nodes\n    self._name_to_node_cache = {node.name: node for node in nodes}\n    self._node_to_ind_cache = {node: i for i, node in enumerate(nodes)}\n</code></pre>"},{"location":"reference/sleap_io/model/skeleton/#sleap_io.model.skeleton.Skeleton.remove_node","title":"<code>remove_node(node)</code>","text":"<p>Remove a single node from the skeleton.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>NodeOrIndex</code> <p>The node to remove. Can be specified as a string name, integer index, or <code>Node</code> object.</p> required Notes <p>This method handles updating the lookup caches necessary for indexing nodes by name.</p> <p>Any edges and symmetries that are connected to the removed node will also be removed.</p> Warning <p>This method does NOT update instances that use this skeleton to reflect changes.</p> <p>It is recommended to use the <code>Labels.remove_nodes()</code> method which will update all contained instances to reflect the changes made to the skeleton.</p> <p>To manually update instances after this method is called, call <code>Instance.update_skeleton()</code> on each instance that uses this skeleton.</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def remove_node(self, node: NodeOrIndex):\n    \"\"\"Remove a single node from the skeleton.\n\n    Args:\n        node: The node to remove. Can be specified as a string name, integer index,\n            or `Node` object.\n\n    Notes:\n        This method handles updating the lookup caches necessary for indexing nodes\n        by name.\n\n        Any edges and symmetries that are connected to the removed node will also be\n        removed.\n\n    Warning:\n        **This method does NOT update instances** that use this skeleton to reflect\n        changes.\n\n        It is recommended to use the `Labels.remove_nodes()` method which will\n        update all contained instances to reflect the changes made to the skeleton.\n\n        To manually update instances after this method is called, call\n        `Instance.update_skeleton()` on each instance that uses this skeleton.\n    \"\"\"\n    self.remove_nodes([node])\n</code></pre>"},{"location":"reference/sleap_io/model/skeleton/#sleap_io.model.skeleton.Skeleton.remove_nodes","title":"<code>remove_nodes(nodes)</code>","text":"<p>Remove nodes from the skeleton.</p> <p>Parameters:</p> Name Type Description Default <code>nodes</code> <code>list[NodeOrIndex]</code> <p>A list of node names, indices, or <code>Node</code> objects to remove.</p> required Notes <p>This method handles updating the lookup caches necessary for indexing nodes by name.</p> <p>Any edges and symmetries that are connected to the removed nodes will also be removed.</p> Warning <p>This method does NOT update instances that use this skeleton to reflect changes.</p> <p>It is recommended to use the <code>Labels.remove_nodes()</code> method which will update all contained to reflect the changes made to the skeleton.</p> <p>To manually update instances after this method is called, call <code>instance.update_nodes()</code> on each instance that uses this skeleton.</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def remove_nodes(self, nodes: list[NodeOrIndex]):\n    \"\"\"Remove nodes from the skeleton.\n\n    Args:\n        nodes: A list of node names, indices, or `Node` objects to remove.\n\n    Notes:\n        This method handles updating the lookup caches necessary for indexing nodes\n        by name.\n\n        Any edges and symmetries that are connected to the removed nodes will also\n        be removed.\n\n    Warning:\n        **This method does NOT update instances** that use this skeleton to reflect\n        changes.\n\n        It is recommended to use the `Labels.remove_nodes()` method which will\n        update all contained to reflect the changes made to the skeleton.\n\n        To manually update instances after this method is called, call\n        `instance.update_nodes()` on each instance that uses this skeleton.\n    \"\"\"\n    # Standardize input and make a pre-mutation copy before keys are changed.\n    rm_node_objs = [self.require_node(node, add_missing=False) for node in nodes]\n\n    # Remove nodes from the skeleton.\n    for node in rm_node_objs:\n        self.nodes.remove(node)\n        del self._name_to_node_cache[node.name]\n\n    # Remove edges connected to the removed nodes.\n    self.edges = [\n        edge\n        for edge in self.edges\n        if edge.source not in rm_node_objs and edge.destination not in rm_node_objs\n    ]\n\n    # Remove symmetries connected to the removed nodes.\n    self.symmetries = [\n        symmetry\n        for symmetry in self.symmetries\n        if symmetry.nodes.isdisjoint(rm_node_objs)\n    ]\n\n    # Update node index map.\n    self.rebuild_cache()\n</code></pre>"},{"location":"reference/sleap_io/model/skeleton/#sleap_io.model.skeleton.Skeleton.rename_node","title":"<code>rename_node(old_name, new_name)</code>","text":"<p>Rename a single node in the skeleton.</p> <p>Parameters:</p> Name Type Description Default <code>old_name</code> <code>NodeOrIndex</code> <p>The name of the node to rename. Can also be specified as an integer index or <code>Node</code> object.</p> required <code>new_name</code> <code>str</code> <p>The new name for the node.</p> required Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def rename_node(self, old_name: NodeOrIndex, new_name: str):\n    \"\"\"Rename a single node in the skeleton.\n\n    Args:\n        old_name: The name of the node to rename. Can also be specified as an\n            integer index or `Node` object.\n        new_name: The new name for the node.\n    \"\"\"\n    self.rename_nodes({old_name: new_name})\n</code></pre>"},{"location":"reference/sleap_io/model/skeleton/#sleap_io.model.skeleton.Skeleton.rename_nodes","title":"<code>rename_nodes(name_map)</code>","text":"<p>Rename nodes in the skeleton.</p> <p>Parameters:</p> Name Type Description Default <code>name_map</code> <code>dict[NodeOrIndex, str] | list[str]</code> <p>A dictionary mapping old node names to new node names. Keys can be specified as <code>Node</code> objects, integer indices, or string names. Values must be specified as string names.</p> <p>If a list of strings is provided of the same length as the current nodes, the nodes will be renamed to the names in the list in order.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If the new node names exist in the skeleton or if the old node names are not found in the skeleton.</p> Notes <p>This method should always be used when renaming nodes in the skeleton as it handles updating the lookup caches necessary for indexing nodes by name.</p> <p>After renaming, instances using this skeleton do NOT need to be updated as the nodes are stored by reference in the skeleton, so changes are reflected automatically.</p> Example <p>skel = Skeleton([\"A\", \"B\", \"C\"], edges=[(\"A\", \"B\"), (\"B\", \"C\")]) skel.rename_nodes({\"A\": \"X\", \"B\": \"Y\", \"C\": \"Z\"}) skel.node_names [\"X\", \"Y\", \"Z\"] skel.rename_nodes([\"a\", \"b\", \"c\"]) skel.node_names [\"a\", \"b\", \"c\"]</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def rename_nodes(self, name_map: dict[NodeOrIndex, str] | list[str]):\n    \"\"\"Rename nodes in the skeleton.\n\n    Args:\n        name_map: A dictionary mapping old node names to new node names. Keys can be\n            specified as `Node` objects, integer indices, or string names. Values\n            must be specified as string names.\n\n            If a list of strings is provided of the same length as the current\n            nodes, the nodes will be renamed to the names in the list in order.\n\n    Raises:\n        ValueError: If the new node names exist in the skeleton or if the old node\n            names are not found in the skeleton.\n\n    Notes:\n        This method should always be used when renaming nodes in the skeleton as it\n        handles updating the lookup caches necessary for indexing nodes by name.\n\n        After renaming, instances using this skeleton **do NOT need to be updated**\n        as the nodes are stored by reference in the skeleton, so changes are\n        reflected automatically.\n\n    Example:\n        &gt;&gt;&gt; skel = Skeleton([\"A\", \"B\", \"C\"], edges=[(\"A\", \"B\"), (\"B\", \"C\")])\n        &gt;&gt;&gt; skel.rename_nodes({\"A\": \"X\", \"B\": \"Y\", \"C\": \"Z\"})\n        &gt;&gt;&gt; skel.node_names\n        [\"X\", \"Y\", \"Z\"]\n        &gt;&gt;&gt; skel.rename_nodes([\"a\", \"b\", \"c\"])\n        &gt;&gt;&gt; skel.node_names\n        [\"a\", \"b\", \"c\"]\n    \"\"\"\n    if type(name_map) is list:\n        if len(name_map) != len(self.nodes):\n            raise ValueError(\n                \"List of new node names must be the same length as the current \"\n                \"nodes.\"\n            )\n        name_map = {node: name for node, name in zip(self.nodes, name_map)}\n\n    for old_name, new_name in name_map.items():\n        if type(old_name) is Node:\n            old_name = old_name.name\n        if type(old_name) is int:\n            old_name = self.nodes[old_name].name\n\n        if old_name not in self._name_to_node_cache:\n            raise ValueError(f\"Node '{old_name}' not found in the skeleton.\")\n        if new_name in self._name_to_node_cache:\n            raise ValueError(f\"Node '{new_name}' already exists in the skeleton.\")\n\n        node = self._name_to_node_cache[old_name]\n        node.name = new_name\n        self._name_to_node_cache[new_name] = node\n        del self._name_to_node_cache[old_name]\n</code></pre>"},{"location":"reference/sleap_io/model/skeleton/#sleap_io.model.skeleton.Skeleton.reorder_nodes","title":"<code>reorder_nodes(new_order)</code>","text":"<p>Reorder nodes in the skeleton.</p> <p>Parameters:</p> Name Type Description Default <code>new_order</code> <code>list[NodeOrIndex]</code> <p>A list of node names, indices, or <code>Node</code> objects specifying the new order of the nodes.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If the new order of nodes is not the same length as the current nodes.</p> Notes <p>This method handles updating the lookup caches necessary for indexing nodes by name.</p> Warning <p>After reordering, instances using this skeleton do not need to be updated as the nodes are stored by reference in the skeleton.</p> <p>However, the order that points are stored in the instances will not be updated to match the new order of the nodes in the skeleton. This should not matter unless the ordering of the keys in the <code>Instance.points</code> dictionary is used instead of relying on the skeleton node order.</p> <p>To make sure these are aligned, it is recommended to use the <code>Labels.reorder_nodes()</code> method which will update all contained instances to reflect the changes made to the skeleton.</p> <p>To manually update instances after this method is called, call <code>Instance.update_skeleton()</code> on each instance that uses this skeleton.</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def reorder_nodes(self, new_order: list[NodeOrIndex]):\n    \"\"\"Reorder nodes in the skeleton.\n\n    Args:\n        new_order: A list of node names, indices, or `Node` objects specifying the\n            new order of the nodes.\n\n    Raises:\n        ValueError: If the new order of nodes is not the same length as the current\n            nodes.\n\n    Notes:\n        This method handles updating the lookup caches necessary for indexing nodes\n        by name.\n\n    Warning:\n        After reordering, instances using this skeleton do not need to be updated as\n        the nodes are stored by reference in the skeleton.\n\n        However, the order that points are stored in the instances will not be\n        updated to match the new order of the nodes in the skeleton. This should not\n        matter unless the ordering of the keys in the `Instance.points` dictionary\n        is used instead of relying on the skeleton node order.\n\n        To make sure these are aligned, it is recommended to use the\n        `Labels.reorder_nodes()` method which will update all contained instances to\n        reflect the changes made to the skeleton.\n\n        To manually update instances after this method is called, call\n        `Instance.update_skeleton()` on each instance that uses this skeleton.\n    \"\"\"\n    if len(new_order) != len(self.nodes):\n        raise ValueError(\n            \"New order of nodes must be the same length as the current nodes.\"\n        )\n\n    new_nodes = [self.require_node(node, add_missing=False) for node in new_order]\n    self.nodes = new_nodes\n</code></pre>"},{"location":"reference/sleap_io/model/skeleton/#sleap_io.model.skeleton.Skeleton.require_node","title":"<code>require_node(node, add_missing=True)</code>","text":"<p>Return a <code>Node</code> object, handling indexing and adding missing nodes.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>NodeOrIndex</code> <p>A <code>Node</code> object, name or index.</p> required <code>add_missing</code> <code>bool</code> <p>If <code>True</code>, missing nodes will be added to the skeleton. If <code>False</code>, an error will be raised if the node is not found. Default is <code>True</code>.</p> <code>True</code> <p>Returns:</p> Type Description <code>Node</code> <p>The <code>Node</code> object.</p> <p>Raises:</p> Type Description <code>IndexError</code> <p>If the node is not found in the skeleton and <code>add_missing</code> is <code>False</code>.</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def require_node(self, node: NodeOrIndex, add_missing: bool = True) -&gt; Node:\n    \"\"\"Return a `Node` object, handling indexing and adding missing nodes.\n\n    Args:\n        node: A `Node` object, name or index.\n        add_missing: If `True`, missing nodes will be added to the skeleton. If\n            `False`, an error will be raised if the node is not found. Default is\n            `True`.\n\n    Returns:\n        The `Node` object.\n\n    Raises:\n        IndexError: If the node is not found in the skeleton and `add_missing` is\n            `False`.\n    \"\"\"\n    if node not in self:\n        if add_missing:\n            self.add_node(node)\n        else:\n            raise IndexError(f\"Node '{node}' not found in the skeleton.\")\n\n    if type(node) is Node:\n        return node\n\n    return self[node]\n</code></pre>"},{"location":"reference/sleap_io/model/skeleton/#sleap_io.model.skeleton.Symmetry","title":"<code>Symmetry</code>","text":"<p>A relationship between a pair of nodes denoting their left/right pairing.</p> <p>Attributes:</p> Name Type Description <code>nodes</code> <code>set[Node]</code> <p>A set of two <code>Node</code>s.</p> <p>Methods:</p> Name Description <code>__getitem__</code> <p>Return the first node.</p> <code>__iter__</code> <p>Iterate over the symmetric nodes.</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>@define\nclass Symmetry:\n    \"\"\"A relationship between a pair of nodes denoting their left/right pairing.\n\n    Attributes:\n        nodes: A set of two `Node`s.\n    \"\"\"\n\n    nodes: set[Node] = field(converter=set, validator=lambda _, __, val: len(val) == 2)\n\n    def __iter__(self):\n        \"\"\"Iterate over the symmetric nodes.\"\"\"\n        return iter(self.nodes)\n\n    def __getitem__(self, idx) -&gt; Node:\n        \"\"\"Return the first node.\"\"\"\n        for i, node in enumerate(self.nodes):\n            if i == idx:\n                return node\n</code></pre>"},{"location":"reference/sleap_io/model/skeleton/#sleap_io.model.skeleton.Symmetry.__getitem__","title":"<code>__getitem__(idx)</code>","text":"<p>Return the first node.</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def __getitem__(self, idx) -&gt; Node:\n    \"\"\"Return the first node.\"\"\"\n    for i, node in enumerate(self.nodes):\n        if i == idx:\n            return node\n</code></pre>"},{"location":"reference/sleap_io/model/skeleton/#sleap_io.model.skeleton.Symmetry.__iter__","title":"<code>__iter__()</code>","text":"<p>Iterate over the symmetric nodes.</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def __iter__(self):\n    \"\"\"Iterate over the symmetric nodes.\"\"\"\n    return iter(self.nodes)\n</code></pre>"},{"location":"reference/sleap_io/model/skeleton/#sleap_io.model.skeleton.is_node_or_index","title":"<code>is_node_or_index(obj)</code>","text":"<p>Check if an object is a <code>Node</code>, string name or integer index.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>Any</code> <p>The object to check.</p> required Notes <p>This is mainly for backwards compatibility with Python versions &lt; 3.10 where generics can't be used with <code>isinstance</code>. In newer Python, this is equivalent to <code>isinstance(obj, NodeOrIndex)</code>.</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def is_node_or_index(obj: typing.Any) -&gt; bool:\n    \"\"\"Check if an object is a `Node`, string name or integer index.\n\n    Args:\n        obj: The object to check.\n\n    Notes:\n        This is mainly for backwards compatibility with Python versions &lt; 3.10 where\n        generics can't be used with `isinstance`. In newer Python, this is equivalent\n        to `isinstance(obj, NodeOrIndex)`.\n    \"\"\"\n    return isinstance(obj, (Node, str, int))\n</code></pre>"},{"location":"reference/sleap_io/model/skeleton/#sleap_io.model.skeleton.match_nodes_cached","title":"<code>match_nodes_cached(node_names_a, node_names_b)</code>  <code>cached</code>","text":"<p>Match nodes in two skeletons by name.</p> <p>Parameters:</p> Name Type Description Default <code>node_names_a</code> <code>tuple[str]</code> <p>A tuple of node names for the first skeleton.</p> required <code>node_names_b</code> <code>tuple[str]</code> <p>A tuple of node names for the second skeleton.</p> required <p>Returns:</p> Type Description <code>tuple[tuple[int], tuple[int]]</code> <p>A tuple of <code>node_inds_a,</code>node_inds_b` with corresponding indices for the nodes of their intersection.</p> <p>The two tuples can be used to reorder point data to match the order of nodes in the first skeleton.</p> Notes <p>This function is cached to avoid recomputing the node matching for the same node names. This is useful when matching nodes between skeletons in a loop or when matching nodes between many instances.</p> <p>The indices returned are in the order of the first skeleton.</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>@lru_cache\ndef match_nodes_cached(\n    node_names_a: tuple[str], node_names_b: tuple[str]\n) -&gt; tuple[tuple[int], tuple[int]]:\n    \"\"\"Match nodes in two skeletons by name.\n\n    Args:\n        node_names_a: A tuple of node names for the first skeleton.\n        node_names_b: A tuple of node names for the second skeleton.\n\n    Returns:\n        A tuple of `node_inds_a, `node_inds_b` with corresponding indices for the nodes\n        of their intersection.\n\n        The two tuples can be used to reorder point data to match the order of nodes in\n        the first skeleton.\n\n    Notes:\n        This function is cached to avoid recomputing the node matching for the same\n        node names. This is useful when matching nodes between skeletons in a loop or\n        when matching nodes between many instances.\n\n        The indices returned are in the order of the first skeleton.\n    \"\"\"\n    # Convert lists to numpy arrays if they aren't already.\n    a_arr = np.array(node_names_a)\n    b_arr = np.array(node_names_b)\n\n    # Create a mapping of values to indices for array b.\n    b_index_map = {val: i for i, val in enumerate(b_arr)}\n\n    # Find indices where elements from a exist in b.\n    mask = np.isin(a_arr, b_arr)\n    inds_a = tuple(np.where(mask)[0].tolist())\n\n    # Get corresponding indices in b.\n    inds_b = tuple([b_index_map[val] for val in a_arr[mask]])\n\n    return inds_a, inds_b\n</code></pre>"},{"location":"reference/sleap_io/model/suggestions/","title":"suggestions","text":""},{"location":"reference/sleap_io/model/suggestions/#sleap_io.model.suggestions","title":"<code>sleap_io.model.suggestions</code>","text":"<p>Data module for suggestions.</p> <p>Classes:</p> Name Description <code>SuggestionFrame</code> <p>Data structure for a single frame of suggestions.</p>"},{"location":"reference/sleap_io/model/suggestions/#sleap_io.model.suggestions.SuggestionFrame","title":"<code>SuggestionFrame</code>","text":"<p>Data structure for a single frame of suggestions.</p> <p>Attributes:</p> Name Type Description <code>video</code> <code>Video</code> <p>The video associated with the frame.</p> <code>frame_idx</code> <code>int</code> <p>The index of the frame in the video.</p> Source code in <code>sleap_io/model/suggestions.py</code> <pre><code>@attrs.define(auto_attribs=True)\nclass SuggestionFrame:\n    \"\"\"Data structure for a single frame of suggestions.\n\n    Attributes:\n        video: The video associated with the frame.\n        frame_idx: The index of the frame in the video.\n    \"\"\"\n\n    video: Video\n    frame_idx: int\n</code></pre>"},{"location":"reference/sleap_io/model/video/","title":"video","text":""},{"location":"reference/sleap_io/model/video/#sleap_io.model.video","title":"<code>sleap_io.model.video</code>","text":"<p>Data model for videos.</p> <p>The <code>Video</code> class is a SLEAP data structure that stores information regarding a video and its components used in SLEAP.</p> <p>Classes:</p> Name Description <code>Video</code> <p><code>Video</code> class used by sleap to represent videos and data associated with them.</p>"},{"location":"reference/sleap_io/model/video/#sleap_io.model.video.Video","title":"<code>Video</code>","text":"<p><code>Video</code> class used by sleap to represent videos and data associated with them.</p> <p>This class is used to store information regarding a video and its components. It is used to store the video's <code>filename</code>, <code>shape</code>, and the video's <code>backend</code>.</p> <p>To create a <code>Video</code> object, use the <code>from_filename</code> method which will select the backend appropriately.</p> <p>Attributes:</p> Name Type Description <code>filename</code> <code>str | list[str]</code> <p>The filename(s) of the video. Supported extensions: \"mp4\", \"avi\", \"mov\", \"mj2\", \"mkv\", \"h5\", \"hdf5\", \"slp\", \"png\", \"jpg\", \"jpeg\", \"tif\", \"tiff\", \"bmp\". If the filename is a list, a list of image filenames are expected. If filename is a folder, it will be searched for images.</p> <code>backend</code> <code>Optional[VideoBackend]</code> <p>An object that implements the basic methods for reading and manipulating frames of a specific video type.</p> <code>backend_metadata</code> <code>dict[str, any]</code> <p>A dictionary of metadata specific to the backend. This is useful for storing metadata that requires an open backend (e.g., shape information) without having access to the video file itself.</p> <code>source_video</code> <code>Optional[Video]</code> <p>The source video object if this is a proxy video. This is present when the video contains an embedded subset of frames from another video.</p> <code>open_backend</code> <code>bool</code> <p>Whether to open the backend when the video is available. If <code>True</code> (the default), the backend will be automatically opened if the video exists. Set this to <code>False</code> when you want to manually open the backend, or when the you know the video file does not exist and you want to avoid trying to open the file.</p> Notes <p>Instances of this class are hashed by identity, not by value. This means that two <code>Video</code> instances with the same attributes will NOT be considered equal in a set or dict.</p> Media Video Plugin Support <p>For media files (mp4, avi, etc.), the following plugins are supported: - \"opencv\": Uses OpenCV (cv2) for video reading - \"FFMPEG\": Uses imageio-ffmpeg for video reading - \"pyav\": Uses PyAV for video reading</p> <p>Plugin aliases (case-insensitive): - opencv: \"opencv\", \"cv\", \"cv2\", \"ocv\" - FFMPEG: \"FFMPEG\", \"ffmpeg\", \"imageio-ffmpeg\", \"imageio_ffmpeg\" - pyav: \"pyav\", \"av\"</p> <p>Plugin selection priority: 1. Explicitly specified plugin parameter 2. Backend metadata plugin value 3. Global default (set via sio.set_default_video_plugin) 4. Auto-detection based on available packages</p> See Also <p>VideoBackend: The backend interface for reading video data. sleap_io.set_default_video_plugin: Set global default plugin. sleap_io.get_default_video_plugin: Get current default plugin.</p> <p>Methods:</p> Name Description <code>__attrs_post_init__</code> <p>Post init syntactic sugar.</p> <code>__deepcopy__</code> <p>Deep copy the video object.</p> <code>__getitem__</code> <p>Return the frames of the video at the given indices.</p> <code>__len__</code> <p>Return the length of the video as the number of frames.</p> <code>__repr__</code> <p>Informal string representation (for print or format).</p> <code>__str__</code> <p>Informal string representation (for print or format).</p> <code>close</code> <p>Close the video backend.</p> <code>deduplicate_with</code> <p>Create a new video with duplicate images removed.</p> <code>exists</code> <p>Check if the video file exists and is accessible.</p> <code>from_filename</code> <p>Create a Video from a filename.</p> <code>has_overlapping_images</code> <p>Check if this video has overlapping images with another video.</p> <code>matches_content</code> <p>Check if this video has the same content as another video.</p> <code>matches_path</code> <p>Check if this video has the same path as another video.</p> <code>matches_shape</code> <p>Check if this video has the same shape as another video.</p> <code>merge_with</code> <p>Merge another video's images into this one.</p> <code>open</code> <p>Open the video backend for reading.</p> <code>replace_filename</code> <p>Update the filename of the video, optionally opening the backend.</p> <code>save</code> <p>Save video frames to a new video file.</p> <code>set_video_plugin</code> <p>Set the video plugin and reopen the video.</p> Source code in <code>sleap_io/model/video.py</code> <pre><code>@attrs.define(eq=False)\nclass Video:\n    \"\"\"`Video` class used by sleap to represent videos and data associated with them.\n\n    This class is used to store information regarding a video and its components.\n    It is used to store the video's `filename`, `shape`, and the video's `backend`.\n\n    To create a `Video` object, use the `from_filename` method which will select the\n    backend appropriately.\n\n    Attributes:\n        filename: The filename(s) of the video. Supported extensions: \"mp4\", \"avi\",\n            \"mov\", \"mj2\", \"mkv\", \"h5\", \"hdf5\", \"slp\", \"png\", \"jpg\", \"jpeg\", \"tif\",\n            \"tiff\", \"bmp\". If the filename is a list, a list of image filenames are\n            expected. If filename is a folder, it will be searched for images.\n        backend: An object that implements the basic methods for reading and\n            manipulating frames of a specific video type.\n        backend_metadata: A dictionary of metadata specific to the backend. This is\n            useful for storing metadata that requires an open backend (e.g., shape\n            information) without having access to the video file itself.\n        source_video: The source video object if this is a proxy video. This is present\n            when the video contains an embedded subset of frames from another video.\n        open_backend: Whether to open the backend when the video is available. If `True`\n            (the default), the backend will be automatically opened if the video exists.\n            Set this to `False` when you want to manually open the backend, or when the\n            you know the video file does not exist and you want to avoid trying to open\n            the file.\n\n    Notes:\n        Instances of this class are hashed by identity, not by value. This means that\n        two `Video` instances with the same attributes will NOT be considered equal in a\n        set or dict.\n\n    Media Video Plugin Support:\n        For media files (mp4, avi, etc.), the following plugins are supported:\n        - \"opencv\": Uses OpenCV (cv2) for video reading\n        - \"FFMPEG\": Uses imageio-ffmpeg for video reading\n        - \"pyav\": Uses PyAV for video reading\n\n        Plugin aliases (case-insensitive):\n        - opencv: \"opencv\", \"cv\", \"cv2\", \"ocv\"\n        - FFMPEG: \"FFMPEG\", \"ffmpeg\", \"imageio-ffmpeg\", \"imageio_ffmpeg\"\n        - pyav: \"pyav\", \"av\"\n\n        Plugin selection priority:\n        1. Explicitly specified plugin parameter\n        2. Backend metadata plugin value\n        3. Global default (set via sio.set_default_video_plugin)\n        4. Auto-detection based on available packages\n\n    See Also:\n        VideoBackend: The backend interface for reading video data.\n        sleap_io.set_default_video_plugin: Set global default plugin.\n        sleap_io.get_default_video_plugin: Get current default plugin.\n    \"\"\"\n\n    filename: str | list[str]\n    backend: Optional[VideoBackend] = None\n    backend_metadata: dict[str, any] = attrs.field(factory=dict)\n    source_video: Optional[Video] = None\n    original_video: Optional[Video] = None\n    open_backend: bool = True\n\n    EXTS = MediaVideo.EXTS + HDF5Video.EXTS + ImageVideo.EXTS\n\n    def __attrs_post_init__(self):\n        \"\"\"Post init syntactic sugar.\"\"\"\n        if self.open_backend and self.backend is None and self.exists():\n            try:\n                self.open()\n            except Exception:\n                # If we can't open the backend, just ignore it for now so we don't\n                # prevent the user from building the Video object entirely.\n                pass\n\n    def __deepcopy__(self, memo):\n        \"\"\"Deep copy the video object.\"\"\"\n        if id(self) in memo:\n            return memo[id(self)]\n\n        reopen = False\n        if self.is_open:\n            reopen = True\n            self.close()\n\n        new_video = Video(\n            filename=self.filename,\n            backend=None,\n            backend_metadata=self.backend_metadata,\n            source_video=self.source_video,\n            open_backend=self.open_backend,\n        )\n\n        memo[id(self)] = new_video\n\n        if reopen:\n            self.open()\n\n        return new_video\n\n    @classmethod\n    def from_filename(\n        cls,\n        filename: str | list[str],\n        dataset: Optional[str] = None,\n        grayscale: Optional[bool] = None,\n        keep_open: bool = True,\n        source_video: Optional[Video] = None,\n        **kwargs,\n    ) -&gt; VideoBackend:\n        \"\"\"Create a Video from a filename.\n\n        Args:\n            filename: The filename(s) of the video. Supported extensions: \"mp4\", \"avi\",\n                \"mov\", \"mj2\", \"mkv\", \"h5\", \"hdf5\", \"slp\", \"png\", \"jpg\", \"jpeg\", \"tif\",\n                \"tiff\", \"bmp\". If the filename is a list, a list of image filenames are\n                expected. If filename is a folder, it will be searched for images.\n            dataset: Name of dataset in HDF5 file.\n            grayscale: Whether to force grayscale. If None, autodetect on first frame\n                load.\n            keep_open: Whether to keep the video reader open between calls to read\n                frames. If False, will close the reader after each call. If True (the\n                default), it will keep the reader open and cache it for subsequent calls\n                which may enhance the performance of reading multiple frames.\n            source_video: The source video object if this is a proxy video. This is\n                present when the video contains an embedded subset of frames from\n                another video.\n            **kwargs: Additional backend-specific arguments passed to\n                VideoBackend.from_filename. See VideoBackend.from_filename for supported\n                arguments.\n\n        Returns:\n            Video instance with the appropriate backend instantiated.\n        \"\"\"\n        return cls(\n            filename=filename,\n            backend=VideoBackend.from_filename(\n                filename,\n                dataset=dataset,\n                grayscale=grayscale,\n                keep_open=keep_open,\n                **kwargs,\n            ),\n            source_video=source_video,\n        )\n\n    @property\n    def shape(self) -&gt; Tuple[int, int, int, int] | None:\n        \"\"\"Return the shape of the video as (num_frames, height, width, channels).\n\n        If the video backend is not set or it cannot determine the shape of the video,\n        this will return None.\n        \"\"\"\n        return self._get_shape()\n\n    def _get_shape(self) -&gt; Tuple[int, int, int, int] | None:\n        \"\"\"Return the shape of the video as (num_frames, height, width, channels).\n\n        This suppresses errors related to querying the backend for the video shape, such\n        as when it has not been set or when the video file is not found.\n        \"\"\"\n        try:\n            return self.backend.shape\n        except Exception:\n            if \"shape\" in self.backend_metadata:\n                return self.backend_metadata[\"shape\"]\n            return None\n\n    @property\n    def grayscale(self) -&gt; bool | None:\n        \"\"\"Return whether the video is grayscale.\n\n        If the video backend is not set or it cannot determine whether the video is\n        grayscale, this will return None.\n        \"\"\"\n        shape = self.shape\n        if shape is not None:\n            return shape[-1] == 1\n        else:\n            grayscale = None\n            if \"grayscale\" in self.backend_metadata:\n                grayscale = self.backend_metadata[\"grayscale\"]\n            return grayscale\n\n    @grayscale.setter\n    def grayscale(self, value: bool):\n        \"\"\"Set the grayscale value and adjust the backend.\"\"\"\n        if self.backend is not None:\n            self.backend.grayscale = value\n            self.backend._cached_shape = None\n\n        self.backend_metadata[\"grayscale\"] = value\n\n    def __len__(self) -&gt; int:\n        \"\"\"Return the length of the video as the number of frames.\"\"\"\n        shape = self.shape\n        return 0 if shape is None else shape[0]\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Informal string representation (for print or format).\"\"\"\n        dataset = (\n            f\"dataset={self.backend.dataset}, \"\n            if getattr(self.backend, \"dataset\", \"\")\n            else \"\"\n        )\n        return (\n            \"Video(\"\n            f'filename=\"{self.filename}\", '\n            f\"shape={self.shape}, \"\n            f\"{dataset}\"\n            f\"backend={type(self.backend).__name__}\"\n            \")\"\n        )\n\n    def __str__(self) -&gt; str:\n        \"\"\"Informal string representation (for print or format).\"\"\"\n        return self.__repr__()\n\n    def __getitem__(self, inds: int | list[int] | slice) -&gt; np.ndarray:\n        \"\"\"Return the frames of the video at the given indices.\n\n        Args:\n            inds: Index or list of indices of frames to read.\n\n        Returns:\n            Frame or frames as a numpy array of shape `(height, width, channels)` if a\n            scalar index is provided, or `(frames, height, width, channels)` if a list\n            of indices is provided.\n\n        See also: VideoBackend.get_frame, VideoBackend.get_frames\n        \"\"\"\n        if not self.is_open:\n            if self.open_backend:\n                self.open()\n            else:\n                raise ValueError(\n                    \"Video backend is not open. Call video.open() or set \"\n                    \"video.open_backend to True to do automatically on frame read.\"\n                )\n        return self.backend[inds]\n\n    def exists(self, check_all: bool = False, dataset: str | None = None) -&gt; bool:\n        \"\"\"Check if the video file exists and is accessible.\n\n        Args:\n            check_all: If `True`, check that all filenames in a list exist. If `False`\n                (the default), check that the first filename exists.\n            dataset: Name of dataset in HDF5 file. If specified, this will function will\n                return `False` if the dataset does not exist.\n\n        Returns:\n            `True` if the file exists and is accessible, `False` otherwise.\n        \"\"\"\n        if isinstance(self.filename, list):\n            if check_all:\n                for f in self.filename:\n                    if not is_file_accessible(f):\n                        return False\n                return True\n            else:\n                return is_file_accessible(self.filename[0])\n\n        file_is_accessible = is_file_accessible(self.filename)\n        if not file_is_accessible:\n            return False\n\n        if dataset is None or dataset == \"\":\n            dataset = self.backend_metadata.get(\"dataset\", None)\n\n        if dataset is not None and dataset != \"\":\n            has_dataset = False\n            if (\n                self.backend is not None\n                and type(self.backend) is HDF5Video\n                and self.backend._open_reader is not None\n            ):\n                has_dataset = dataset in self.backend._open_reader\n            else:\n                with h5py.File(self.filename, \"r\") as f:\n                    has_dataset = dataset in f\n            return has_dataset\n\n        return True\n\n    @property\n    def is_open(self) -&gt; bool:\n        \"\"\"Check if the video backend is open.\"\"\"\n        return self.exists() and self.backend is not None\n\n    def open(\n        self,\n        filename: Optional[str] = None,\n        dataset: Optional[str] = None,\n        grayscale: Optional[str] = None,\n        keep_open: bool = True,\n        plugin: Optional[str] = None,\n    ):\n        \"\"\"Open the video backend for reading.\n\n        Args:\n            filename: Filename to open. If not specified, will use the filename set on\n                the video object.\n            dataset: Name of dataset in HDF5 file.\n            grayscale: Whether to force grayscale. If None, autodetect on first frame\n                load.\n            keep_open: Whether to keep the video reader open between calls to read\n                frames. If False, will close the reader after each call. If True (the\n                default), it will keep the reader open and cache it for subsequent calls\n                which may enhance the performance of reading multiple frames.\n            plugin: Video plugin to use for MediaVideo files. One of \"opencv\",\n                \"FFMPEG\", or \"pyav\". Also accepts aliases (case-insensitive).\n                If not specified, uses the backend metadata, global default,\n                or auto-detection in that order.\n\n        Notes:\n            This is useful for opening the video backend to read frames and then closing\n            it after reading all the necessary frames.\n\n            If the backend was already open, it will be closed before opening a new one.\n            Values for the HDF5 dataset and grayscale will be remembered if not\n            specified.\n        \"\"\"\n        if filename is not None:\n            self.replace_filename(filename, open=False)\n\n        # Try to remember values from previous backend if available and not specified.\n        if self.backend is not None:\n            if dataset is None:\n                dataset = getattr(self.backend, \"dataset\", None)\n            if grayscale is None:\n                grayscale = getattr(self.backend, \"grayscale\", None)\n\n        else:\n            if dataset is None and \"dataset\" in self.backend_metadata:\n                dataset = self.backend_metadata[\"dataset\"]\n            if grayscale is None:\n                if \"grayscale\" in self.backend_metadata:\n                    grayscale = self.backend_metadata[\"grayscale\"]\n                elif \"shape\" in self.backend_metadata:\n                    grayscale = self.backend_metadata[\"shape\"][-1] == 1\n\n        if not self.exists(dataset=dataset):\n            msg = (\n                f\"Video does not exist or cannot be opened for reading: {self.filename}\"\n            )\n            if dataset is not None:\n                msg += f\" (dataset: {dataset})\"\n            raise FileNotFoundError(msg)\n\n        # Close previous backend if open.\n        self.close()\n\n        # Handle plugin parameter\n        backend_kwargs = {}\n        if plugin is not None:\n            from sleap_io.io.video_reading import normalize_plugin_name\n\n            plugin = normalize_plugin_name(plugin)\n            self.backend_metadata[\"plugin\"] = plugin\n\n        if \"plugin\" in self.backend_metadata:\n            backend_kwargs[\"plugin\"] = self.backend_metadata[\"plugin\"]\n\n        # Create new backend.\n        self.backend = VideoBackend.from_filename(\n            self.filename,\n            dataset=dataset,\n            grayscale=grayscale,\n            keep_open=keep_open,\n            **backend_kwargs,\n        )\n\n    def close(self):\n        \"\"\"Close the video backend.\"\"\"\n        if self.backend is not None:\n            # Try to remember values from previous backend if available and not\n            # specified.\n            try:\n                self.backend_metadata[\"dataset\"] = getattr(\n                    self.backend, \"dataset\", None\n                )\n                self.backend_metadata[\"grayscale\"] = getattr(\n                    self.backend, \"grayscale\", None\n                )\n                self.backend_metadata[\"shape\"] = getattr(self.backend, \"shape\", None)\n            except Exception:\n                pass\n\n            del self.backend\n            self.backend = None\n\n    def replace_filename(\n        self, new_filename: str | Path | list[str] | list[Path], open: bool = True\n    ):\n        \"\"\"Update the filename of the video, optionally opening the backend.\n\n        Args:\n            new_filename: New filename to set for the video.\n            open: If `True` (the default), open the backend with the new filename. If\n                the new filename does not exist, no error is raised.\n        \"\"\"\n        if isinstance(new_filename, Path):\n            new_filename = new_filename.as_posix()\n\n        if isinstance(new_filename, list):\n            new_filename = [\n                p.as_posix() if isinstance(p, Path) else p for p in new_filename\n            ]\n\n        self.filename = new_filename\n        self.backend_metadata[\"filename\"] = new_filename\n\n        if open:\n            if self.exists():\n                self.open()\n            else:\n                self.close()\n\n    def matches_path(self, other: \"Video\", strict: bool = False) -&gt; bool:\n        \"\"\"Check if this video has the same path as another video.\n\n        Args:\n            other: Another video to compare with.\n            strict: If True, require exact path match. If False, consider videos\n                with the same filename (basename) as matching.\n\n        Returns:\n            True if the videos have matching paths, False otherwise.\n        \"\"\"\n        if isinstance(self.filename, list) and isinstance(other.filename, list):\n            # Both are image sequences\n            if strict:\n                return self.filename == other.filename\n            else:\n                # Compare basenames\n                self_basenames = [Path(f).name for f in self.filename]\n                other_basenames = [Path(f).name for f in other.filename]\n                return self_basenames == other_basenames\n        elif isinstance(self.filename, list) or isinstance(other.filename, list):\n            # One is image sequence, other is single file\n            return False\n        else:\n            # Both are single files\n            if strict:\n                return Path(self.filename).resolve() == Path(other.filename).resolve()\n            else:\n                return Path(self.filename).name == Path(other.filename).name\n\n    def matches_content(self, other: \"Video\") -&gt; bool:\n        \"\"\"Check if this video has the same content as another video.\n\n        Args:\n            other: Another video to compare with.\n\n        Returns:\n            True if the videos have the same shape and backend type.\n\n        Notes:\n            This compares metadata like shape and backend type, not actual frame data.\n        \"\"\"\n        # Compare shapes\n        self_shape = self.shape\n        other_shape = other.shape\n\n        if self_shape != other_shape:\n            return False\n\n        # Compare backend types\n        if self.backend is None and other.backend is None:\n            return True\n        elif self.backend is None or other.backend is None:\n            return False\n\n        return type(self.backend).__name__ == type(other.backend).__name__\n\n    def matches_shape(self, other: \"Video\") -&gt; bool:\n        \"\"\"Check if this video has the same shape as another video.\n\n        Args:\n            other: Another video to compare with.\n\n        Returns:\n            True if the videos have the same height, width, and channels.\n\n        Notes:\n            This only compares spatial dimensions, not the number of frames.\n        \"\"\"\n        # Try to get shape from backend metadata first if shape is not available\n        if self.backend is None and \"shape\" in self.backend_metadata:\n            self_shape = self.backend_metadata[\"shape\"]\n        else:\n            self_shape = self.shape\n\n        if other.backend is None and \"shape\" in other.backend_metadata:\n            other_shape = other.backend_metadata[\"shape\"]\n        else:\n            other_shape = other.shape\n\n        # Handle None shapes\n        if self_shape is None or other_shape is None:\n            return False\n\n        # Compare only height, width, channels (not frames)\n        return self_shape[1:] == other_shape[1:]\n\n    def has_overlapping_images(self, other: \"Video\") -&gt; bool:\n        \"\"\"Check if this video has overlapping images with another video.\n\n        This method is specifically for ImageVideo backends (image sequences).\n\n        Args:\n            other: Another video to compare with.\n\n        Returns:\n            True if both are ImageVideo instances with overlapping image files.\n            False if either video is not an ImageVideo or no overlap exists.\n\n        Notes:\n            Only works with ImageVideo backends where filename is a list.\n            Compares individual image filenames (basenames only).\n        \"\"\"\n        # Both must be image sequences\n        if not (isinstance(self.filename, list) and isinstance(other.filename, list)):\n            return False\n\n        # Get basenames for comparison\n        self_basenames = set(Path(f).name for f in self.filename)\n        other_basenames = set(Path(f).name for f in other.filename)\n\n        # Check if there's any overlap\n        return len(self_basenames &amp; other_basenames) &gt; 0\n\n    def deduplicate_with(self, other: \"Video\") -&gt; \"Video\":\n        \"\"\"Create a new video with duplicate images removed.\n\n        This method is specifically for ImageVideo backends (image sequences).\n\n        Args:\n            other: Another video to deduplicate against. Must also be ImageVideo.\n\n        Returns:\n            A new Video object with duplicate images removed from this video,\n            or None if all images were duplicates.\n\n        Raises:\n            ValueError: If either video is not an ImageVideo backend.\n\n        Notes:\n            Only works with ImageVideo backends where filename is a list.\n            Images are considered duplicates if they have the same basename.\n            The returned video contains only images from this video that are\n            not present in the other video.\n        \"\"\"\n        if not isinstance(self.filename, list):\n            raise ValueError(\"deduplicate_with only works with ImageVideo backends\")\n        if not isinstance(other.filename, list):\n            raise ValueError(\"Other video must also be ImageVideo backend\")\n\n        # Get basenames from other video\n        other_basenames = set(Path(f).name for f in other.filename)\n\n        # Keep only non-duplicate images\n        deduplicated_paths = [\n            f for f in self.filename if Path(f).name not in other_basenames\n        ]\n\n        if not deduplicated_paths:\n            # All images were duplicates\n            return None\n\n        # Create new video with deduplicated images\n        return Video.from_filename(deduplicated_paths, grayscale=self.grayscale)\n\n    def merge_with(self, other: \"Video\") -&gt; \"Video\":\n        \"\"\"Merge another video's images into this one.\n\n        This method is specifically for ImageVideo backends (image sequences).\n\n        Args:\n            other: Another video to merge with. Must also be ImageVideo.\n\n        Returns:\n            A new Video object with unique images from both videos.\n\n        Raises:\n            ValueError: If either video is not an ImageVideo backend.\n\n        Notes:\n            Only works with ImageVideo backends where filename is a list.\n            The merged video contains all unique images from both videos,\n            with automatic deduplication based on image basename.\n        \"\"\"\n        if not isinstance(self.filename, list):\n            raise ValueError(\"merge_with only works with ImageVideo backends\")\n        if not isinstance(other.filename, list):\n            raise ValueError(\"Other video must also be ImageVideo backend\")\n\n        # Get all unique images (by basename) preserving order\n        seen_basenames = set()\n        merged_paths = []\n\n        for path in self.filename:\n            basename = Path(path).name\n            if basename not in seen_basenames:\n                merged_paths.append(path)\n                seen_basenames.add(basename)\n\n        for path in other.filename:\n            basename = Path(path).name\n            if basename not in seen_basenames:\n                merged_paths.append(path)\n                seen_basenames.add(basename)\n\n        # Create new video with merged images\n        return Video.from_filename(merged_paths, grayscale=self.grayscale)\n\n    def save(\n        self,\n        save_path: str | Path,\n        frame_inds: list[int] | np.ndarray | None = None,\n        video_kwargs: dict[str, Any] | None = None,\n    ) -&gt; Video:\n        \"\"\"Save video frames to a new video file.\n\n        Args:\n            save_path: Path to the new video file. Should end in MP4.\n            frame_inds: Frame indices to save. Can be specified as a list or array of\n                frame integers. If not specified, saves all video frames.\n            video_kwargs: A dictionary of keyword arguments to provide to\n                `sio.save_video` for video compression.\n\n        Returns:\n            A new `Video` object pointing to the new video file.\n        \"\"\"\n        video_kwargs = {} if video_kwargs is None else video_kwargs\n        frame_inds = np.arange(len(self)) if frame_inds is None else frame_inds\n\n        with VideoWriter(save_path, **video_kwargs) as vw:\n            for frame_ind in frame_inds:\n                vw(self[frame_ind])\n\n        new_video = Video.from_filename(save_path, grayscale=self.grayscale)\n        return new_video\n\n    def set_video_plugin(self, plugin: str) -&gt; None:\n        \"\"\"Set the video plugin and reopen the video.\n\n        Args:\n            plugin: Video plugin to use. One of \"opencv\", \"FFMPEG\", or \"pyav\".\n                Also accepts aliases (case-insensitive).\n\n        Raises:\n            ValueError: If the video is not a MediaVideo type.\n\n        Examples:\n            &gt;&gt;&gt; video.set_video_plugin(\"opencv\")\n            &gt;&gt;&gt; video.set_video_plugin(\"CV2\")  # Same as \"opencv\"\n        \"\"\"\n        from sleap_io.io.video_reading import MediaVideo, normalize_plugin_name\n\n        if not self.filename.endswith(MediaVideo.EXTS):\n            raise ValueError(f\"Cannot set plugin for non-media video: {self.filename}\")\n\n        plugin = normalize_plugin_name(plugin)\n\n        # Close current backend if open\n        was_open = self.is_open\n        if was_open:\n            self.close()\n\n        # Update backend metadata\n        self.backend_metadata[\"plugin\"] = plugin\n\n        # Reopen with new plugin if it was open\n        if was_open:\n            self.open()\n</code></pre>"},{"location":"reference/sleap_io/model/video/#sleap_io.model.video.Video.grayscale","title":"<code>grayscale</code>  <code>property</code> <code>writable</code>","text":"<p>Return whether the video is grayscale.</p> <p>If the video backend is not set or it cannot determine whether the video is grayscale, this will return None.</p>"},{"location":"reference/sleap_io/model/video/#sleap_io.model.video.Video.is_open","title":"<code>is_open</code>  <code>property</code>","text":"<p>Check if the video backend is open.</p>"},{"location":"reference/sleap_io/model/video/#sleap_io.model.video.Video.shape","title":"<code>shape</code>  <code>property</code>","text":"<p>Return the shape of the video as (num_frames, height, width, channels).</p> <p>If the video backend is not set or it cannot determine the shape of the video, this will return None.</p>"},{"location":"reference/sleap_io/model/video/#sleap_io.model.video.Video.__attrs_post_init__","title":"<code>__attrs_post_init__()</code>","text":"<p>Post init syntactic sugar.</p> Source code in <code>sleap_io/model/video.py</code> <pre><code>def __attrs_post_init__(self):\n    \"\"\"Post init syntactic sugar.\"\"\"\n    if self.open_backend and self.backend is None and self.exists():\n        try:\n            self.open()\n        except Exception:\n            # If we can't open the backend, just ignore it for now so we don't\n            # prevent the user from building the Video object entirely.\n            pass\n</code></pre>"},{"location":"reference/sleap_io/model/video/#sleap_io.model.video.Video.__deepcopy__","title":"<code>__deepcopy__(memo)</code>","text":"<p>Deep copy the video object.</p> Source code in <code>sleap_io/model/video.py</code> <pre><code>def __deepcopy__(self, memo):\n    \"\"\"Deep copy the video object.\"\"\"\n    if id(self) in memo:\n        return memo[id(self)]\n\n    reopen = False\n    if self.is_open:\n        reopen = True\n        self.close()\n\n    new_video = Video(\n        filename=self.filename,\n        backend=None,\n        backend_metadata=self.backend_metadata,\n        source_video=self.source_video,\n        open_backend=self.open_backend,\n    )\n\n    memo[id(self)] = new_video\n\n    if reopen:\n        self.open()\n\n    return new_video\n</code></pre>"},{"location":"reference/sleap_io/model/video/#sleap_io.model.video.Video.__getitem__","title":"<code>__getitem__(inds)</code>","text":"<p>Return the frames of the video at the given indices.</p> <p>Parameters:</p> Name Type Description Default <code>inds</code> <code>int | list[int] | slice</code> <p>Index or list of indices of frames to read.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Frame or frames as a numpy array of shape <code>(height, width, channels)</code> if a scalar index is provided, or <code>(frames, height, width, channels)</code> if a list of indices is provided.</p> <p>See also: VideoBackend.get_frame, VideoBackend.get_frames</p> Source code in <code>sleap_io/model/video.py</code> <pre><code>def __getitem__(self, inds: int | list[int] | slice) -&gt; np.ndarray:\n    \"\"\"Return the frames of the video at the given indices.\n\n    Args:\n        inds: Index or list of indices of frames to read.\n\n    Returns:\n        Frame or frames as a numpy array of shape `(height, width, channels)` if a\n        scalar index is provided, or `(frames, height, width, channels)` if a list\n        of indices is provided.\n\n    See also: VideoBackend.get_frame, VideoBackend.get_frames\n    \"\"\"\n    if not self.is_open:\n        if self.open_backend:\n            self.open()\n        else:\n            raise ValueError(\n                \"Video backend is not open. Call video.open() or set \"\n                \"video.open_backend to True to do automatically on frame read.\"\n            )\n    return self.backend[inds]\n</code></pre>"},{"location":"reference/sleap_io/model/video/#sleap_io.model.video.Video.__len__","title":"<code>__len__()</code>","text":"<p>Return the length of the video as the number of frames.</p> Source code in <code>sleap_io/model/video.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"Return the length of the video as the number of frames.\"\"\"\n    shape = self.shape\n    return 0 if shape is None else shape[0]\n</code></pre>"},{"location":"reference/sleap_io/model/video/#sleap_io.model.video.Video.__repr__","title":"<code>__repr__()</code>","text":"<p>Informal string representation (for print or format).</p> Source code in <code>sleap_io/model/video.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Informal string representation (for print or format).\"\"\"\n    dataset = (\n        f\"dataset={self.backend.dataset}, \"\n        if getattr(self.backend, \"dataset\", \"\")\n        else \"\"\n    )\n    return (\n        \"Video(\"\n        f'filename=\"{self.filename}\", '\n        f\"shape={self.shape}, \"\n        f\"{dataset}\"\n        f\"backend={type(self.backend).__name__}\"\n        \")\"\n    )\n</code></pre>"},{"location":"reference/sleap_io/model/video/#sleap_io.model.video.Video.__str__","title":"<code>__str__()</code>","text":"<p>Informal string representation (for print or format).</p> Source code in <code>sleap_io/model/video.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Informal string representation (for print or format).\"\"\"\n    return self.__repr__()\n</code></pre>"},{"location":"reference/sleap_io/model/video/#sleap_io.model.video.Video.close","title":"<code>close()</code>","text":"<p>Close the video backend.</p> Source code in <code>sleap_io/model/video.py</code> <pre><code>def close(self):\n    \"\"\"Close the video backend.\"\"\"\n    if self.backend is not None:\n        # Try to remember values from previous backend if available and not\n        # specified.\n        try:\n            self.backend_metadata[\"dataset\"] = getattr(\n                self.backend, \"dataset\", None\n            )\n            self.backend_metadata[\"grayscale\"] = getattr(\n                self.backend, \"grayscale\", None\n            )\n            self.backend_metadata[\"shape\"] = getattr(self.backend, \"shape\", None)\n        except Exception:\n            pass\n\n        del self.backend\n        self.backend = None\n</code></pre>"},{"location":"reference/sleap_io/model/video/#sleap_io.model.video.Video.deduplicate_with","title":"<code>deduplicate_with(other)</code>","text":"<p>Create a new video with duplicate images removed.</p> <p>This method is specifically for ImageVideo backends (image sequences).</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>'Video'</code> <p>Another video to deduplicate against. Must also be ImageVideo.</p> required <p>Returns:</p> Type Description <code>'Video'</code> <p>A new Video object with duplicate images removed from this video, or None if all images were duplicates.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If either video is not an ImageVideo backend.</p> Notes <p>Only works with ImageVideo backends where filename is a list. Images are considered duplicates if they have the same basename. The returned video contains only images from this video that are not present in the other video.</p> Source code in <code>sleap_io/model/video.py</code> <pre><code>def deduplicate_with(self, other: \"Video\") -&gt; \"Video\":\n    \"\"\"Create a new video with duplicate images removed.\n\n    This method is specifically for ImageVideo backends (image sequences).\n\n    Args:\n        other: Another video to deduplicate against. Must also be ImageVideo.\n\n    Returns:\n        A new Video object with duplicate images removed from this video,\n        or None if all images were duplicates.\n\n    Raises:\n        ValueError: If either video is not an ImageVideo backend.\n\n    Notes:\n        Only works with ImageVideo backends where filename is a list.\n        Images are considered duplicates if they have the same basename.\n        The returned video contains only images from this video that are\n        not present in the other video.\n    \"\"\"\n    if not isinstance(self.filename, list):\n        raise ValueError(\"deduplicate_with only works with ImageVideo backends\")\n    if not isinstance(other.filename, list):\n        raise ValueError(\"Other video must also be ImageVideo backend\")\n\n    # Get basenames from other video\n    other_basenames = set(Path(f).name for f in other.filename)\n\n    # Keep only non-duplicate images\n    deduplicated_paths = [\n        f for f in self.filename if Path(f).name not in other_basenames\n    ]\n\n    if not deduplicated_paths:\n        # All images were duplicates\n        return None\n\n    # Create new video with deduplicated images\n    return Video.from_filename(deduplicated_paths, grayscale=self.grayscale)\n</code></pre>"},{"location":"reference/sleap_io/model/video/#sleap_io.model.video.Video.exists","title":"<code>exists(check_all=False, dataset=None)</code>","text":"<p>Check if the video file exists and is accessible.</p> <p>Parameters:</p> Name Type Description Default <code>check_all</code> <code>bool</code> <p>If <code>True</code>, check that all filenames in a list exist. If <code>False</code> (the default), check that the first filename exists.</p> <code>False</code> <code>dataset</code> <code>str | None</code> <p>Name of dataset in HDF5 file. If specified, this will function will return <code>False</code> if the dataset does not exist.</p> <code>None</code> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if the file exists and is accessible, <code>False</code> otherwise.</p> Source code in <code>sleap_io/model/video.py</code> <pre><code>def exists(self, check_all: bool = False, dataset: str | None = None) -&gt; bool:\n    \"\"\"Check if the video file exists and is accessible.\n\n    Args:\n        check_all: If `True`, check that all filenames in a list exist. If `False`\n            (the default), check that the first filename exists.\n        dataset: Name of dataset in HDF5 file. If specified, this will function will\n            return `False` if the dataset does not exist.\n\n    Returns:\n        `True` if the file exists and is accessible, `False` otherwise.\n    \"\"\"\n    if isinstance(self.filename, list):\n        if check_all:\n            for f in self.filename:\n                if not is_file_accessible(f):\n                    return False\n            return True\n        else:\n            return is_file_accessible(self.filename[0])\n\n    file_is_accessible = is_file_accessible(self.filename)\n    if not file_is_accessible:\n        return False\n\n    if dataset is None or dataset == \"\":\n        dataset = self.backend_metadata.get(\"dataset\", None)\n\n    if dataset is not None and dataset != \"\":\n        has_dataset = False\n        if (\n            self.backend is not None\n            and type(self.backend) is HDF5Video\n            and self.backend._open_reader is not None\n        ):\n            has_dataset = dataset in self.backend._open_reader\n        else:\n            with h5py.File(self.filename, \"r\") as f:\n                has_dataset = dataset in f\n        return has_dataset\n\n    return True\n</code></pre>"},{"location":"reference/sleap_io/model/video/#sleap_io.model.video.Video.from_filename","title":"<code>from_filename(filename, dataset=None, grayscale=None, keep_open=True, source_video=None, **kwargs)</code>  <code>classmethod</code>","text":"<p>Create a Video from a filename.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str | list[str]</code> <p>The filename(s) of the video. Supported extensions: \"mp4\", \"avi\", \"mov\", \"mj2\", \"mkv\", \"h5\", \"hdf5\", \"slp\", \"png\", \"jpg\", \"jpeg\", \"tif\", \"tiff\", \"bmp\". If the filename is a list, a list of image filenames are expected. If filename is a folder, it will be searched for images.</p> required <code>dataset</code> <code>Optional[str]</code> <p>Name of dataset in HDF5 file.</p> <code>None</code> <code>grayscale</code> <code>Optional[bool]</code> <p>Whether to force grayscale. If None, autodetect on first frame load.</p> <code>None</code> <code>keep_open</code> <code>bool</code> <p>Whether to keep the video reader open between calls to read frames. If False, will close the reader after each call. If True (the default), it will keep the reader open and cache it for subsequent calls which may enhance the performance of reading multiple frames.</p> <code>True</code> <code>source_video</code> <code>Optional[Video]</code> <p>The source video object if this is a proxy video. This is present when the video contains an embedded subset of frames from another video.</p> <code>None</code> <code>**kwargs</code> <p>Additional backend-specific arguments passed to VideoBackend.from_filename. See VideoBackend.from_filename for supported arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>VideoBackend</code> <p>Video instance with the appropriate backend instantiated.</p> Source code in <code>sleap_io/model/video.py</code> <pre><code>@classmethod\ndef from_filename(\n    cls,\n    filename: str | list[str],\n    dataset: Optional[str] = None,\n    grayscale: Optional[bool] = None,\n    keep_open: bool = True,\n    source_video: Optional[Video] = None,\n    **kwargs,\n) -&gt; VideoBackend:\n    \"\"\"Create a Video from a filename.\n\n    Args:\n        filename: The filename(s) of the video. Supported extensions: \"mp4\", \"avi\",\n            \"mov\", \"mj2\", \"mkv\", \"h5\", \"hdf5\", \"slp\", \"png\", \"jpg\", \"jpeg\", \"tif\",\n            \"tiff\", \"bmp\". If the filename is a list, a list of image filenames are\n            expected. If filename is a folder, it will be searched for images.\n        dataset: Name of dataset in HDF5 file.\n        grayscale: Whether to force grayscale. If None, autodetect on first frame\n            load.\n        keep_open: Whether to keep the video reader open between calls to read\n            frames. If False, will close the reader after each call. If True (the\n            default), it will keep the reader open and cache it for subsequent calls\n            which may enhance the performance of reading multiple frames.\n        source_video: The source video object if this is a proxy video. This is\n            present when the video contains an embedded subset of frames from\n            another video.\n        **kwargs: Additional backend-specific arguments passed to\n            VideoBackend.from_filename. See VideoBackend.from_filename for supported\n            arguments.\n\n    Returns:\n        Video instance with the appropriate backend instantiated.\n    \"\"\"\n    return cls(\n        filename=filename,\n        backend=VideoBackend.from_filename(\n            filename,\n            dataset=dataset,\n            grayscale=grayscale,\n            keep_open=keep_open,\n            **kwargs,\n        ),\n        source_video=source_video,\n    )\n</code></pre>"},{"location":"reference/sleap_io/model/video/#sleap_io.model.video.Video.has_overlapping_images","title":"<code>has_overlapping_images(other)</code>","text":"<p>Check if this video has overlapping images with another video.</p> <p>This method is specifically for ImageVideo backends (image sequences).</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>'Video'</code> <p>Another video to compare with.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if both are ImageVideo instances with overlapping image files. False if either video is not an ImageVideo or no overlap exists.</p> Notes <p>Only works with ImageVideo backends where filename is a list. Compares individual image filenames (basenames only).</p> Source code in <code>sleap_io/model/video.py</code> <pre><code>def has_overlapping_images(self, other: \"Video\") -&gt; bool:\n    \"\"\"Check if this video has overlapping images with another video.\n\n    This method is specifically for ImageVideo backends (image sequences).\n\n    Args:\n        other: Another video to compare with.\n\n    Returns:\n        True if both are ImageVideo instances with overlapping image files.\n        False if either video is not an ImageVideo or no overlap exists.\n\n    Notes:\n        Only works with ImageVideo backends where filename is a list.\n        Compares individual image filenames (basenames only).\n    \"\"\"\n    # Both must be image sequences\n    if not (isinstance(self.filename, list) and isinstance(other.filename, list)):\n        return False\n\n    # Get basenames for comparison\n    self_basenames = set(Path(f).name for f in self.filename)\n    other_basenames = set(Path(f).name for f in other.filename)\n\n    # Check if there's any overlap\n    return len(self_basenames &amp; other_basenames) &gt; 0\n</code></pre>"},{"location":"reference/sleap_io/model/video/#sleap_io.model.video.Video.matches_content","title":"<code>matches_content(other)</code>","text":"<p>Check if this video has the same content as another video.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>'Video'</code> <p>Another video to compare with.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the videos have the same shape and backend type.</p> Notes <p>This compares metadata like shape and backend type, not actual frame data.</p> Source code in <code>sleap_io/model/video.py</code> <pre><code>def matches_content(self, other: \"Video\") -&gt; bool:\n    \"\"\"Check if this video has the same content as another video.\n\n    Args:\n        other: Another video to compare with.\n\n    Returns:\n        True if the videos have the same shape and backend type.\n\n    Notes:\n        This compares metadata like shape and backend type, not actual frame data.\n    \"\"\"\n    # Compare shapes\n    self_shape = self.shape\n    other_shape = other.shape\n\n    if self_shape != other_shape:\n        return False\n\n    # Compare backend types\n    if self.backend is None and other.backend is None:\n        return True\n    elif self.backend is None or other.backend is None:\n        return False\n\n    return type(self.backend).__name__ == type(other.backend).__name__\n</code></pre>"},{"location":"reference/sleap_io/model/video/#sleap_io.model.video.Video.matches_path","title":"<code>matches_path(other, strict=False)</code>","text":"<p>Check if this video has the same path as another video.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>'Video'</code> <p>Another video to compare with.</p> required <code>strict</code> <code>bool</code> <p>If True, require exact path match. If False, consider videos with the same filename (basename) as matching.</p> <code>False</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if the videos have matching paths, False otherwise.</p> Source code in <code>sleap_io/model/video.py</code> <pre><code>def matches_path(self, other: \"Video\", strict: bool = False) -&gt; bool:\n    \"\"\"Check if this video has the same path as another video.\n\n    Args:\n        other: Another video to compare with.\n        strict: If True, require exact path match. If False, consider videos\n            with the same filename (basename) as matching.\n\n    Returns:\n        True if the videos have matching paths, False otherwise.\n    \"\"\"\n    if isinstance(self.filename, list) and isinstance(other.filename, list):\n        # Both are image sequences\n        if strict:\n            return self.filename == other.filename\n        else:\n            # Compare basenames\n            self_basenames = [Path(f).name for f in self.filename]\n            other_basenames = [Path(f).name for f in other.filename]\n            return self_basenames == other_basenames\n    elif isinstance(self.filename, list) or isinstance(other.filename, list):\n        # One is image sequence, other is single file\n        return False\n    else:\n        # Both are single files\n        if strict:\n            return Path(self.filename).resolve() == Path(other.filename).resolve()\n        else:\n            return Path(self.filename).name == Path(other.filename).name\n</code></pre>"},{"location":"reference/sleap_io/model/video/#sleap_io.model.video.Video.matches_shape","title":"<code>matches_shape(other)</code>","text":"<p>Check if this video has the same shape as another video.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>'Video'</code> <p>Another video to compare with.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the videos have the same height, width, and channels.</p> Notes <p>This only compares spatial dimensions, not the number of frames.</p> Source code in <code>sleap_io/model/video.py</code> <pre><code>def matches_shape(self, other: \"Video\") -&gt; bool:\n    \"\"\"Check if this video has the same shape as another video.\n\n    Args:\n        other: Another video to compare with.\n\n    Returns:\n        True if the videos have the same height, width, and channels.\n\n    Notes:\n        This only compares spatial dimensions, not the number of frames.\n    \"\"\"\n    # Try to get shape from backend metadata first if shape is not available\n    if self.backend is None and \"shape\" in self.backend_metadata:\n        self_shape = self.backend_metadata[\"shape\"]\n    else:\n        self_shape = self.shape\n\n    if other.backend is None and \"shape\" in other.backend_metadata:\n        other_shape = other.backend_metadata[\"shape\"]\n    else:\n        other_shape = other.shape\n\n    # Handle None shapes\n    if self_shape is None or other_shape is None:\n        return False\n\n    # Compare only height, width, channels (not frames)\n    return self_shape[1:] == other_shape[1:]\n</code></pre>"},{"location":"reference/sleap_io/model/video/#sleap_io.model.video.Video.merge_with","title":"<code>merge_with(other)</code>","text":"<p>Merge another video's images into this one.</p> <p>This method is specifically for ImageVideo backends (image sequences).</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>'Video'</code> <p>Another video to merge with. Must also be ImageVideo.</p> required <p>Returns:</p> Type Description <code>'Video'</code> <p>A new Video object with unique images from both videos.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If either video is not an ImageVideo backend.</p> Notes <p>Only works with ImageVideo backends where filename is a list. The merged video contains all unique images from both videos, with automatic deduplication based on image basename.</p> Source code in <code>sleap_io/model/video.py</code> <pre><code>def merge_with(self, other: \"Video\") -&gt; \"Video\":\n    \"\"\"Merge another video's images into this one.\n\n    This method is specifically for ImageVideo backends (image sequences).\n\n    Args:\n        other: Another video to merge with. Must also be ImageVideo.\n\n    Returns:\n        A new Video object with unique images from both videos.\n\n    Raises:\n        ValueError: If either video is not an ImageVideo backend.\n\n    Notes:\n        Only works with ImageVideo backends where filename is a list.\n        The merged video contains all unique images from both videos,\n        with automatic deduplication based on image basename.\n    \"\"\"\n    if not isinstance(self.filename, list):\n        raise ValueError(\"merge_with only works with ImageVideo backends\")\n    if not isinstance(other.filename, list):\n        raise ValueError(\"Other video must also be ImageVideo backend\")\n\n    # Get all unique images (by basename) preserving order\n    seen_basenames = set()\n    merged_paths = []\n\n    for path in self.filename:\n        basename = Path(path).name\n        if basename not in seen_basenames:\n            merged_paths.append(path)\n            seen_basenames.add(basename)\n\n    for path in other.filename:\n        basename = Path(path).name\n        if basename not in seen_basenames:\n            merged_paths.append(path)\n            seen_basenames.add(basename)\n\n    # Create new video with merged images\n    return Video.from_filename(merged_paths, grayscale=self.grayscale)\n</code></pre>"},{"location":"reference/sleap_io/model/video/#sleap_io.model.video.Video.open","title":"<code>open(filename=None, dataset=None, grayscale=None, keep_open=True, plugin=None)</code>","text":"<p>Open the video backend for reading.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>Optional[str]</code> <p>Filename to open. If not specified, will use the filename set on the video object.</p> <code>None</code> <code>dataset</code> <code>Optional[str]</code> <p>Name of dataset in HDF5 file.</p> <code>None</code> <code>grayscale</code> <code>Optional[str]</code> <p>Whether to force grayscale. If None, autodetect on first frame load.</p> <code>None</code> <code>keep_open</code> <code>bool</code> <p>Whether to keep the video reader open between calls to read frames. If False, will close the reader after each call. If True (the default), it will keep the reader open and cache it for subsequent calls which may enhance the performance of reading multiple frames.</p> <code>True</code> <code>plugin</code> <code>Optional[str]</code> <p>Video plugin to use for MediaVideo files. One of \"opencv\", \"FFMPEG\", or \"pyav\". Also accepts aliases (case-insensitive). If not specified, uses the backend metadata, global default, or auto-detection in that order.</p> <code>None</code> Notes <p>This is useful for opening the video backend to read frames and then closing it after reading all the necessary frames.</p> <p>If the backend was already open, it will be closed before opening a new one. Values for the HDF5 dataset and grayscale will be remembered if not specified.</p> Source code in <code>sleap_io/model/video.py</code> <pre><code>def open(\n    self,\n    filename: Optional[str] = None,\n    dataset: Optional[str] = None,\n    grayscale: Optional[str] = None,\n    keep_open: bool = True,\n    plugin: Optional[str] = None,\n):\n    \"\"\"Open the video backend for reading.\n\n    Args:\n        filename: Filename to open. If not specified, will use the filename set on\n            the video object.\n        dataset: Name of dataset in HDF5 file.\n        grayscale: Whether to force grayscale. If None, autodetect on first frame\n            load.\n        keep_open: Whether to keep the video reader open between calls to read\n            frames. If False, will close the reader after each call. If True (the\n            default), it will keep the reader open and cache it for subsequent calls\n            which may enhance the performance of reading multiple frames.\n        plugin: Video plugin to use for MediaVideo files. One of \"opencv\",\n            \"FFMPEG\", or \"pyav\". Also accepts aliases (case-insensitive).\n            If not specified, uses the backend metadata, global default,\n            or auto-detection in that order.\n\n    Notes:\n        This is useful for opening the video backend to read frames and then closing\n        it after reading all the necessary frames.\n\n        If the backend was already open, it will be closed before opening a new one.\n        Values for the HDF5 dataset and grayscale will be remembered if not\n        specified.\n    \"\"\"\n    if filename is not None:\n        self.replace_filename(filename, open=False)\n\n    # Try to remember values from previous backend if available and not specified.\n    if self.backend is not None:\n        if dataset is None:\n            dataset = getattr(self.backend, \"dataset\", None)\n        if grayscale is None:\n            grayscale = getattr(self.backend, \"grayscale\", None)\n\n    else:\n        if dataset is None and \"dataset\" in self.backend_metadata:\n            dataset = self.backend_metadata[\"dataset\"]\n        if grayscale is None:\n            if \"grayscale\" in self.backend_metadata:\n                grayscale = self.backend_metadata[\"grayscale\"]\n            elif \"shape\" in self.backend_metadata:\n                grayscale = self.backend_metadata[\"shape\"][-1] == 1\n\n    if not self.exists(dataset=dataset):\n        msg = (\n            f\"Video does not exist or cannot be opened for reading: {self.filename}\"\n        )\n        if dataset is not None:\n            msg += f\" (dataset: {dataset})\"\n        raise FileNotFoundError(msg)\n\n    # Close previous backend if open.\n    self.close()\n\n    # Handle plugin parameter\n    backend_kwargs = {}\n    if plugin is not None:\n        from sleap_io.io.video_reading import normalize_plugin_name\n\n        plugin = normalize_plugin_name(plugin)\n        self.backend_metadata[\"plugin\"] = plugin\n\n    if \"plugin\" in self.backend_metadata:\n        backend_kwargs[\"plugin\"] = self.backend_metadata[\"plugin\"]\n\n    # Create new backend.\n    self.backend = VideoBackend.from_filename(\n        self.filename,\n        dataset=dataset,\n        grayscale=grayscale,\n        keep_open=keep_open,\n        **backend_kwargs,\n    )\n</code></pre>"},{"location":"reference/sleap_io/model/video/#sleap_io.model.video.Video.replace_filename","title":"<code>replace_filename(new_filename, open=True)</code>","text":"<p>Update the filename of the video, optionally opening the backend.</p> <p>Parameters:</p> Name Type Description Default <code>new_filename</code> <code>str | Path | list[str] | list[Path]</code> <p>New filename to set for the video.</p> required <code>open</code> <code>bool</code> <p>If <code>True</code> (the default), open the backend with the new filename. If the new filename does not exist, no error is raised.</p> <code>True</code> Source code in <code>sleap_io/model/video.py</code> <pre><code>def replace_filename(\n    self, new_filename: str | Path | list[str] | list[Path], open: bool = True\n):\n    \"\"\"Update the filename of the video, optionally opening the backend.\n\n    Args:\n        new_filename: New filename to set for the video.\n        open: If `True` (the default), open the backend with the new filename. If\n            the new filename does not exist, no error is raised.\n    \"\"\"\n    if isinstance(new_filename, Path):\n        new_filename = new_filename.as_posix()\n\n    if isinstance(new_filename, list):\n        new_filename = [\n            p.as_posix() if isinstance(p, Path) else p for p in new_filename\n        ]\n\n    self.filename = new_filename\n    self.backend_metadata[\"filename\"] = new_filename\n\n    if open:\n        if self.exists():\n            self.open()\n        else:\n            self.close()\n</code></pre>"},{"location":"reference/sleap_io/model/video/#sleap_io.model.video.Video.save","title":"<code>save(save_path, frame_inds=None, video_kwargs=None)</code>","text":"<p>Save video frames to a new video file.</p> <p>Parameters:</p> Name Type Description Default <code>save_path</code> <code>str | Path</code> <p>Path to the new video file. Should end in MP4.</p> required <code>frame_inds</code> <code>list[int] | ndarray | None</code> <p>Frame indices to save. Can be specified as a list or array of frame integers. If not specified, saves all video frames.</p> <code>None</code> <code>video_kwargs</code> <code>dict[str, Any] | None</code> <p>A dictionary of keyword arguments to provide to <code>sio.save_video</code> for video compression.</p> <code>None</code> <p>Returns:</p> Type Description <code>Video</code> <p>A new <code>Video</code> object pointing to the new video file.</p> Source code in <code>sleap_io/model/video.py</code> <pre><code>def save(\n    self,\n    save_path: str | Path,\n    frame_inds: list[int] | np.ndarray | None = None,\n    video_kwargs: dict[str, Any] | None = None,\n) -&gt; Video:\n    \"\"\"Save video frames to a new video file.\n\n    Args:\n        save_path: Path to the new video file. Should end in MP4.\n        frame_inds: Frame indices to save. Can be specified as a list or array of\n            frame integers. If not specified, saves all video frames.\n        video_kwargs: A dictionary of keyword arguments to provide to\n            `sio.save_video` for video compression.\n\n    Returns:\n        A new `Video` object pointing to the new video file.\n    \"\"\"\n    video_kwargs = {} if video_kwargs is None else video_kwargs\n    frame_inds = np.arange(len(self)) if frame_inds is None else frame_inds\n\n    with VideoWriter(save_path, **video_kwargs) as vw:\n        for frame_ind in frame_inds:\n            vw(self[frame_ind])\n\n    new_video = Video.from_filename(save_path, grayscale=self.grayscale)\n    return new_video\n</code></pre>"},{"location":"reference/sleap_io/model/video/#sleap_io.model.video.Video.set_video_plugin","title":"<code>set_video_plugin(plugin)</code>","text":"<p>Set the video plugin and reopen the video.</p> <p>Parameters:</p> Name Type Description Default <code>plugin</code> <code>str</code> <p>Video plugin to use. One of \"opencv\", \"FFMPEG\", or \"pyav\". Also accepts aliases (case-insensitive).</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If the video is not a MediaVideo type.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; video.set_video_plugin(\"opencv\")\n&gt;&gt;&gt; video.set_video_plugin(\"CV2\")  # Same as \"opencv\"\n</code></pre> Source code in <code>sleap_io/model/video.py</code> <pre><code>def set_video_plugin(self, plugin: str) -&gt; None:\n    \"\"\"Set the video plugin and reopen the video.\n\n    Args:\n        plugin: Video plugin to use. One of \"opencv\", \"FFMPEG\", or \"pyav\".\n            Also accepts aliases (case-insensitive).\n\n    Raises:\n        ValueError: If the video is not a MediaVideo type.\n\n    Examples:\n        &gt;&gt;&gt; video.set_video_plugin(\"opencv\")\n        &gt;&gt;&gt; video.set_video_plugin(\"CV2\")  # Same as \"opencv\"\n    \"\"\"\n    from sleap_io.io.video_reading import MediaVideo, normalize_plugin_name\n\n    if not self.filename.endswith(MediaVideo.EXTS):\n        raise ValueError(f\"Cannot set plugin for non-media video: {self.filename}\")\n\n    plugin = normalize_plugin_name(plugin)\n\n    # Close current backend if open\n    was_open = self.is_open\n    if was_open:\n        self.close()\n\n    # Update backend metadata\n    self.backend_metadata[\"plugin\"] = plugin\n\n    # Reopen with new plugin if it was open\n    if was_open:\n        self.open()\n</code></pre>"}]}