{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"sleap-io","text":"<p>Standalone utilities for working with animal pose tracking data.</p> <p>This is intended to be a complement to the core SLEAP package that aims to provide functionality for interacting with pose tracking-related data structures and file formats with minimal dependencies. This package does not have any functionality related to labeling, training, or inference.</p>"},{"location":"#installation","title":"Installation","text":"<pre><code>pip install sleap-io\n</code></pre> <p>For development, use one of the following syntaxes: <pre><code>conda env create -f environment.yml\n</code></pre> <pre><code>pip install -e .[dev]\n</code></pre></p>"},{"location":"#usage","title":"Usage","text":""},{"location":"#load-and-save-in-different-formats","title":"Load and save in different formats","text":"<pre><code>import sleap_io as sio\n\n# Load from SLEAP file.\nlabels = sio.load_file(\"predictions.slp\")\n\n# Save to NWB file.\nlabels.save(\"predictions.nwb\")\n</code></pre> <p>See also: <code>Labels.save</code> and Formats</p>"},{"location":"#convert-labels-to-raw-arrays","title":"Convert labels to raw arrays","text":"<pre><code>import sleap_io as sio\n\nlabels = sio.load_slp(\"tests/data/slp/centered_pair_predictions.slp\")\n\n# Convert predictions to point coordinates in a single array.\ntrx = labels.numpy()\nn_frames, n_tracks, n_nodes, xy = trx.shape\nassert xy == 2\n\n# Convert to array with confidence scores appended.\ntrx_with_scores = labels.numpy(return_confidence=True)\nn_frames, n_tracks, n_nodes, xy_score = trx.shape \nassert xy_score == 3\n</code></pre> <p>See also: <code>Labels.numpy</code></p>"},{"location":"#read-video-data","title":"Read video data","text":"<pre><code>import sleap_io as sio\n\nvideo = sio.load_video(\"test.mp4\")\nn_frames, height, width, channels = video.shape\n\nframe = video[0]\nheight, width, channels = frame.shape\n</code></pre> <p>See also: <code>sio.load_video</code> and <code>Video</code></p>"},{"location":"#create-labels-from-raw-data","title":"Create labels from raw data","text":"<pre><code>import sleap_io as sio\nimport numpy as np\n\n# Create skeleton.\nskeleton = sio.Skeleton(\n    nodes=[\"head\", \"thorax\", \"abdomen\"],\n    edges=[(\"head\", \"thorax\"), (\"thorax\", \"abdomen\")]\n)\n\n# Create video.\nvideo = sio.load_video(\"test.mp4\")\n\n# Create instance.\ninstance = sio.Instance.from_numpy(\n    points=np.array([\n        [10.2, 20.4],\n        [5.8, 15.1],\n        [0.3, 10.6],\n    ]),\n    skeleton=skeleton\n)\n\n# Create labeled frame.\nlf = sio.LabeledFrame(video=video, frame_idx=0, instances=[instance])\n\n# Create labels.\nlabels = sio.Labels(videos=[video], skeletons=[skeleton], labeled_frames=[lf])\n\n# Save.\nlabels.save(\"labels.slp\")\n</code></pre> <p>See also: Model, <code>Labels</code>, <code>LabeledFrame</code>, <code>Instance</code>, <code>PredictedInstance</code>, <code>Skeleton</code>, <code>Video</code>, <code>Track</code>, <code>SuggestionFrame</code></p>"},{"location":"#fix-video-paths","title":"Fix video paths","text":"<pre><code>import sleap_io as sio\n\nlabels = sio.load_file(\"labels.v001.slp\")\n\n# Fix paths using prefixes.\nlabels.replace_filenames(prefix_map={\n    \"D:/data/sleap_projects\": \"/home/user/sleap_projects\",\n    \"C:/Users/sleaper/Desktop/test\": \"/home/user/sleap_projects\",\n})\n\nlabels.save(\"labels.v002.slp\")\n</code></pre> <p>See also: <code>Labels.replace_filenames</code></p>"},{"location":"#save-labels-with-embedded-images","title":"Save labels with embedded images","text":"<pre><code>import sleap_io as sio\n\n# Load source labels.\nlabels = sio.load_file(\"labels.v001.slp\")\n\n# Save with embedded images for frames with user labeled data and suggested frames.\nlabels.save(\"labels.v001.pkg.slp\", embed=\"user+suggestions\")\n</code></pre> <p>See also: <code>Labels.save</code></p>"},{"location":"#make-trainingvalidationtest-splits","title":"Make training/validation/test splits","text":"<pre><code>import sleap_io as sio\n\n# Load source labels.\nlabels = sio.load_file(\"labels.v001.slp\")\n\n# Make splits and export with embedded images.\nlabels.make_training_splits(n_train=0.8, n_val=0.1, n_test=0.1, save_dir=\"split1\", seed=42)\n\n# Splits will be saved as self-contained SLP package files with images and labels.\nlabels_train = sio.load_file(\"split1/train.pkg.slp\")\nlabels_val = sio.load_file(\"split1/val.pkg.slp\")\nlabels_test = sio.load_file(\"split1/test.pkg.slp\")\n</code></pre> <p>See also: <code>Labels.make_training_splits</code></p>"},{"location":"#support","title":"Support","text":"<p>For technical inquiries specific to this package, please open an Issue with a description of your problem or request.</p> <p>For general SLEAP usage, see the main website.</p> <p>Other questions? Reach out to <code>talmo@salk.edu</code>.</p>"},{"location":"#license","title":"License","text":"<p>This package is distributed under a BSD 3-Clause License and can be used without restrictions. See <code>LICENSE</code> for details.</p>"},{"location":"formats/","title":"Data formats","text":""},{"location":"formats/#sleap_io.load_file","title":"<code>sleap_io.load_file(filename, format=None, **kwargs)</code>","text":"<p>Load a file and return the appropriate object.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str | Path</code> <p>Path to a file.</p> required <code>format</code> <code>Optional[str]</code> <p>Optional format to load as. If not provided, will be inferred from the file extension. Available formats are: \"slp\", \"nwb\", \"labelstudio\", \"jabs\" and \"video\".</p> <code>None</code> <p>Returns:</p> Type Description <code>Union[Labels, Video]</code> <p>A <code>Labels</code> or <code>Video</code> object.</p> Source code in <code>sleap_io/io/main.py</code> <pre><code>def load_file(\n    filename: str | Path, format: Optional[str] = None, **kwargs\n) -&gt; Union[Labels, Video]:\n    \"\"\"Load a file and return the appropriate object.\n\n    Args:\n        filename: Path to a file.\n        format: Optional format to load as. If not provided, will be inferred from the\n            file extension. Available formats are: \"slp\", \"nwb\", \"labelstudio\", \"jabs\"\n            and \"video\".\n\n    Returns:\n        A `Labels` or `Video` object.\n    \"\"\"\n    if isinstance(filename, Path):\n        filename = filename.as_posix()\n\n    if format is None:\n        if filename.endswith(\".slp\"):\n            format = \"slp\"\n        elif filename.endswith(\".nwb\"):\n            format = \"nwb\"\n        elif filename.endswith(\".json\"):\n            format = \"json\"\n        elif filename.endswith(\".h5\"):\n            format = \"jabs\"\n        else:\n            for vid_ext in Video.EXTS:\n                if filename.endswith(vid_ext):\n                    format = \"video\"\n                    break\n        if format is None:\n            raise ValueError(f\"Could not infer format from filename: '{filename}'.\")\n\n    if filename.endswith(\".slp\"):\n        return load_slp(filename, **kwargs)\n    elif filename.endswith(\".nwb\"):\n        return load_nwb(filename, **kwargs)\n    elif filename.endswith(\".json\"):\n        return load_labelstudio(filename, **kwargs)\n    elif filename.endswith(\".h5\"):\n        return load_jabs(filename, **kwargs)\n    elif format == \"video\":\n        return load_video(filename, **kwargs)\n</code></pre>"},{"location":"formats/#sleap_io.save_file","title":"<code>sleap_io.save_file(labels, filename, format=None, **kwargs)</code>","text":"<p>Save a file based on the extension.</p> <p>Parameters:</p> Name Type Description Default <code>labels</code> <code>Labels</code> <p>A SLEAP <code>Labels</code> object (see <code>load_slp</code>).</p> required <code>filename</code> <code>str | Path</code> <p>Path to save labels to.</p> required <code>format</code> <code>Optional[str]</code> <p>Optional format to save as. If not provided, will be inferred from the file extension. Available formats are: \"slp\", \"nwb\", \"labelstudio\" and \"jabs\".</p> <code>None</code> Source code in <code>sleap_io/io/main.py</code> <pre><code>def save_file(\n    labels: Labels, filename: str | Path, format: Optional[str] = None, **kwargs\n):\n    \"\"\"Save a file based on the extension.\n\n    Args:\n        labels: A SLEAP `Labels` object (see `load_slp`).\n        filename: Path to save labels to.\n        format: Optional format to save as. If not provided, will be inferred from the\n            file extension. Available formats are: \"slp\", \"nwb\", \"labelstudio\" and\n            \"jabs\".\n    \"\"\"\n    if isinstance(filename, Path):\n        filename = str(filename)\n\n    if format is None:\n        if filename.endswith(\".slp\"):\n            format = \"slp\"\n        elif filename.endswith(\".nwb\"):\n            format = \"nwb\"\n        elif filename.endswith(\".json\"):\n            format = \"labelstudio\"\n        elif \"pose_version\" in kwargs:\n            format = \"jabs\"\n\n    if format == \"slp\":\n        save_slp(labels, filename, **kwargs)\n    elif format == \"nwb\":\n        save_nwb(labels, filename, **kwargs)\n    elif format == \"labelstudio\":\n        save_labelstudio(labels, filename, **kwargs)\n    elif format == \"jabs\":\n        pose_version = kwargs.pop(\"pose_version\", 5)\n        save_jabs(labels, pose_version, filename, **kwargs)\n    else:\n        raise ValueError(f\"Unknown format '{format}' for filename: '{filename}'.\")\n</code></pre>"},{"location":"formats/#sleap_io.load_video","title":"<code>sleap_io.load_video(filename, **kwargs)</code>","text":"<p>Load a video file.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>The filename(s) of the video. Supported extensions: \"mp4\", \"avi\", \"mov\", \"mj2\", \"mkv\", \"h5\", \"hdf5\", \"slp\", \"png\", \"jpg\", \"jpeg\", \"tif\", \"tiff\", \"bmp\". If the filename is a list, a list of image filenames are expected. If filename is a folder, it will be searched for images.</p> required <p>Returns:</p> Type Description <code>Video</code> <p>A <code>Video</code> object.</p> Source code in <code>sleap_io/io/main.py</code> <pre><code>def load_video(filename: str, **kwargs) -&gt; Video:\n    \"\"\"Load a video file.\n\n    Args:\n        filename: The filename(s) of the video. Supported extensions: \"mp4\", \"avi\",\n            \"mov\", \"mj2\", \"mkv\", \"h5\", \"hdf5\", \"slp\", \"png\", \"jpg\", \"jpeg\", \"tif\",\n            \"tiff\", \"bmp\". If the filename is a list, a list of image filenames are\n            expected. If filename is a folder, it will be searched for images.\n\n    Returns:\n        A `Video` object.\n    \"\"\"\n    return Video.from_filename(filename, **kwargs)\n</code></pre>"},{"location":"formats/#sleap_io.load_slp","title":"<code>sleap_io.load_slp(filename)</code>","text":"<p>Load a SLEAP dataset.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>Path to a SLEAP labels file (<code>.slp</code>).</p> required <p>Returns:</p> Type Description <code>Labels</code> <p>The dataset as a <code>Labels</code> object.</p> Source code in <code>sleap_io/io/main.py</code> <pre><code>def load_slp(filename: str) -&gt; Labels:\n    \"\"\"Load a SLEAP dataset.\n\n    Args:\n        filename: Path to a SLEAP labels file (`.slp`).\n\n    Returns:\n        The dataset as a `Labels` object.\n    \"\"\"\n    return slp.read_labels(filename)\n</code></pre>"},{"location":"formats/#sleap_io.save_slp","title":"<code>sleap_io.save_slp(labels, filename, embed=None)</code>","text":"<p>Save a SLEAP dataset to a <code>.slp</code> file.</p> <p>Parameters:</p> Name Type Description Default <code>labels</code> <code>Labels</code> <p>A SLEAP <code>Labels</code> object (see <code>load_slp</code>).</p> required <code>filename</code> <code>str</code> <p>Path to save labels to ending with <code>.slp</code>.</p> required <code>embed</code> <code>bool | str | list[tuple[Video, int]] | None</code> <p>Frames to embed in the saved labels file. One of <code>None</code>, <code>True</code>, <code>\"all\"</code>, <code>\"user\"</code>, <code>\"suggestions\"</code>, <code>\"user+suggestions\"</code>, <code>\"source\"</code> or list of tuples of <code>(video, frame_idx)</code>.</p> <p>If <code>None</code> is specified (the default) and the labels contains embedded frames, those embedded frames will be re-saved to the new file.</p> <p>If <code>True</code> or <code>\"all\"</code>, all labeled frames and suggested frames will be embedded.</p> <p>If <code>\"source\"</code> is specified, no images will be embedded and the source video will be restored if available.</p> <p>This argument is only valid for the SLP backend.</p> <code>None</code> Source code in <code>sleap_io/io/main.py</code> <pre><code>def save_slp(\n    labels: Labels,\n    filename: str,\n    embed: bool | str | list[tuple[Video, int]] | None = None,\n):\n    \"\"\"Save a SLEAP dataset to a `.slp` file.\n\n    Args:\n        labels: A SLEAP `Labels` object (see `load_slp`).\n        filename: Path to save labels to ending with `.slp`.\n        embed: Frames to embed in the saved labels file. One of `None`, `True`,\n            `\"all\"`, `\"user\"`, `\"suggestions\"`, `\"user+suggestions\"`, `\"source\"` or list\n            of tuples of `(video, frame_idx)`.\n\n            If `None` is specified (the default) and the labels contains embedded\n            frames, those embedded frames will be re-saved to the new file.\n\n            If `True` or `\"all\"`, all labeled frames and suggested frames will be\n            embedded.\n\n            If `\"source\"` is specified, no images will be embedded and the source video\n            will be restored if available.\n\n            This argument is only valid for the SLP backend.\n    \"\"\"\n    return slp.write_labels(filename, labels, embed=embed)\n</code></pre>"},{"location":"formats/#sleap_io.load_nwb","title":"<code>sleap_io.load_nwb(filename)</code>","text":"<p>Load an NWB dataset as a SLEAP <code>Labels</code> object.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>Path to a NWB file (<code>.nwb</code>).</p> required <p>Returns:</p> Type Description <code>Labels</code> <p>The dataset as a <code>Labels</code> object.</p> Source code in <code>sleap_io/io/main.py</code> <pre><code>def load_nwb(filename: str) -&gt; Labels:\n    \"\"\"Load an NWB dataset as a SLEAP `Labels` object.\n\n    Args:\n        filename: Path to a NWB file (`.nwb`).\n\n    Returns:\n        The dataset as a `Labels` object.\n    \"\"\"\n    return nwb.read_nwb(filename)\n</code></pre>"},{"location":"formats/#sleap_io.save_nwb","title":"<code>sleap_io.save_nwb(labels, filename, append=True)</code>","text":"<p>Save a SLEAP dataset to NWB format.</p> <p>Parameters:</p> Name Type Description Default <code>labels</code> <code>Labels</code> <p>A SLEAP <code>Labels</code> object (see <code>load_slp</code>).</p> required <code>filename</code> <code>str</code> <p>Path to NWB file to save to. Must end in <code>.nwb</code>.</p> required <code>append</code> <code>bool</code> <p>If <code>True</code> (the default), append to existing NWB file. File will be created if it does not exist.</p> <code>True</code> <p>See also: nwb.write_nwb, nwb.append_nwb</p> Source code in <code>sleap_io/io/main.py</code> <pre><code>def save_nwb(labels: Labels, filename: str, append: bool = True):\n    \"\"\"Save a SLEAP dataset to NWB format.\n\n    Args:\n        labels: A SLEAP `Labels` object (see `load_slp`).\n        filename: Path to NWB file to save to. Must end in `.nwb`.\n        append: If `True` (the default), append to existing NWB file. File will be\n            created if it does not exist.\n\n    See also: nwb.write_nwb, nwb.append_nwb\n    \"\"\"\n    if append and Path(filename).exists():\n        nwb.append_nwb(labels, filename)\n    else:\n        nwb.write_nwb(labels, filename)\n</code></pre>"},{"location":"formats/#sleap_io.load_jabs","title":"<code>sleap_io.load_jabs(filename, skeleton=None)</code>","text":"<p>Read JABS-style predictions from a file and return a <code>Labels</code> object.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>Path to the jabs h5 pose file.</p> required <code>skeleton</code> <code>Optional[Skeleton]</code> <p>An optional <code>Skeleton</code> object.</p> <code>None</code> <p>Returns:</p> Type Description <code>Labels</code> <p>Parsed labels as a <code>Labels</code> instance.</p> Source code in <code>sleap_io/io/main.py</code> <pre><code>def load_jabs(filename: str, skeleton: Optional[Skeleton] = None) -&gt; Labels:\n    \"\"\"Read JABS-style predictions from a file and return a `Labels` object.\n\n    Args:\n        filename: Path to the jabs h5 pose file.\n        skeleton: An optional `Skeleton` object.\n\n    Returns:\n        Parsed labels as a `Labels` instance.\n    \"\"\"\n    return jabs.read_labels(filename, skeleton=skeleton)\n</code></pre>"},{"location":"formats/#sleap_io.save_jabs","title":"<code>sleap_io.save_jabs(labels, pose_version, root_folder=None)</code>","text":"<p>Save a SLEAP dataset to JABS pose file format.</p> <p>Parameters:</p> Name Type Description Default <code>labels</code> <code>Labels</code> <p>SLEAP <code>Labels</code> object.</p> required <code>pose_version</code> <code>int</code> <p>The JABS pose version to write data out.</p> required <code>root_folder</code> <code>Optional[str]</code> <p>Optional root folder where the files should be saved.</p> <code>None</code> Note <p>Filenames for JABS poses are based on video filenames.</p> Source code in <code>sleap_io/io/main.py</code> <pre><code>def save_jabs(labels: Labels, pose_version: int, root_folder: Optional[str] = None):\n    \"\"\"Save a SLEAP dataset to JABS pose file format.\n\n    Args:\n        labels: SLEAP `Labels` object.\n        pose_version: The JABS pose version to write data out.\n        root_folder: Optional root folder where the files should be saved.\n\n    Note:\n        Filenames for JABS poses are based on video filenames.\n    \"\"\"\n    jabs.write_labels(labels, pose_version, root_folder)\n</code></pre>"},{"location":"formats/#sleap_io.load_labelstudio","title":"<code>sleap_io.load_labelstudio(filename, skeleton=None)</code>","text":"<p>Read Label Studio-style annotations from a file and return a <code>Labels</code> object.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>Path to the label-studio annotation file in JSON format.</p> required <code>skeleton</code> <code>Optional[Union[Skeleton, list[str]]]</code> <p>An optional <code>Skeleton</code> object or list of node names. If not provided (the default), skeleton will be inferred from the data. It may be useful to provide this so the keypoint label types can be filtered to just the ones in the skeleton.</p> <code>None</code> <p>Returns:</p> Type Description <code>Labels</code> <p>Parsed labels as a <code>Labels</code> instance.</p> Source code in <code>sleap_io/io/main.py</code> <pre><code>def load_labelstudio(\n    filename: str, skeleton: Optional[Union[Skeleton, list[str]]] = None\n) -&gt; Labels:\n    \"\"\"Read Label Studio-style annotations from a file and return a `Labels` object.\n\n    Args:\n        filename: Path to the label-studio annotation file in JSON format.\n        skeleton: An optional `Skeleton` object or list of node names. If not provided\n            (the default), skeleton will be inferred from the data. It may be useful to\n            provide this so the keypoint label types can be filtered to just the ones in\n            the skeleton.\n\n    Returns:\n        Parsed labels as a `Labels` instance.\n    \"\"\"\n    return labelstudio.read_labels(filename, skeleton=skeleton)\n</code></pre>"},{"location":"formats/#sleap_io.save_labelstudio","title":"<code>sleap_io.save_labelstudio(labels, filename)</code>","text":"<p>Save a SLEAP dataset to Label Studio format.</p> <p>Parameters:</p> Name Type Description Default <code>labels</code> <code>Labels</code> <p>A SLEAP <code>Labels</code> object (see <code>load_slp</code>).</p> required <code>filename</code> <code>str</code> <p>Path to save labels to ending with <code>.json</code>.</p> required Source code in <code>sleap_io/io/main.py</code> <pre><code>def save_labelstudio(labels: Labels, filename: str):\n    \"\"\"Save a SLEAP dataset to Label Studio format.\n\n    Args:\n        labels: A SLEAP `Labels` object (see `load_slp`).\n        filename: Path to save labels to ending with `.json`.\n    \"\"\"\n    labelstudio.write_labels(labels, filename)\n</code></pre>"},{"location":"model/","title":"Data model","text":"<p><code>sleap-io</code> implements the core data structures used in SLEAP for storing data related to multi-instance pose tracking, including for annotation, training and inference.</p>"},{"location":"model/#sleap_io.Labels","title":"<code>sleap_io.Labels</code>","text":"<p>Pose data for a set of videos that have user labels and/or predictions.</p> <p>Attributes:</p> Name Type Description <code>labeled_frames</code> <code>list[LabeledFrame]</code> <p>A list of <code>LabeledFrame</code>s that are associated with this dataset.</p> <code>videos</code> <code>list[Video]</code> <p>A list of <code>Video</code>s that are associated with this dataset. Videos do not need to have corresponding <code>LabeledFrame</code>s if they do not have any labels or predictions yet.</p> <code>skeletons</code> <code>list[Skeleton]</code> <p>A list of <code>Skeleton</code>s that are associated with this dataset. This should generally only contain a single skeleton.</p> <code>tracks</code> <code>list[Track]</code> <p>A list of <code>Track</code>s that are associated with this dataset.</p> <code>suggestions</code> <code>list[SuggestionFrame]</code> <p>A list of <code>SuggestionFrame</code>s that are associated with this dataset.</p> <code>provenance</code> <code>dict[str, Any]</code> <p>Dictionary of arbitrary metadata providing additional information about where the dataset came from.</p> Notes <p><code>Video</code>s in contain <code>LabeledFrame</code>s, and <code>Skeleton</code>s and <code>Track</code>s in contained <code>Instance</code>s are added to the respective lists automatically.</p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>@define\nclass Labels:\n    \"\"\"Pose data for a set of videos that have user labels and/or predictions.\n\n    Attributes:\n        labeled_frames: A list of `LabeledFrame`s that are associated with this dataset.\n        videos: A list of `Video`s that are associated with this dataset. Videos do not\n            need to have corresponding `LabeledFrame`s if they do not have any\n            labels or predictions yet.\n        skeletons: A list of `Skeleton`s that are associated with this dataset. This\n            should generally only contain a single skeleton.\n        tracks: A list of `Track`s that are associated with this dataset.\n        suggestions: A list of `SuggestionFrame`s that are associated with this dataset.\n        provenance: Dictionary of arbitrary metadata providing additional information\n            about where the dataset came from.\n\n    Notes:\n        `Video`s in contain `LabeledFrame`s, and `Skeleton`s and `Track`s in contained\n        `Instance`s are added to the respective lists automatically.\n    \"\"\"\n\n    labeled_frames: list[LabeledFrame] = field(factory=list)\n    videos: list[Video] = field(factory=list)\n    skeletons: list[Skeleton] = field(factory=list)\n    tracks: list[Track] = field(factory=list)\n    suggestions: list[SuggestionFrame] = field(factory=list)\n    provenance: dict[str, Any] = field(factory=dict)\n\n    def __attrs_post_init__(self):\n        \"\"\"Append videos, skeletons, and tracks seen in `labeled_frames` to `Labels`.\"\"\"\n        self.update()\n\n    def update(self):\n        \"\"\"Update data structures based on contents.\n\n        This function will update the list of skeletons, videos and tracks from the\n        labeled frames, instances and suggestions.\n        \"\"\"\n        for lf in self.labeled_frames:\n            if lf.video not in self.videos:\n                self.videos.append(lf.video)\n\n            for inst in lf:\n                if inst.skeleton not in self.skeletons:\n                    self.skeletons.append(inst.skeleton)\n\n                if inst.track is not None and inst.track not in self.tracks:\n                    self.tracks.append(inst.track)\n\n        for sf in self.suggestions:\n            if sf.video not in self.videos:\n                self.videos.append(sf.video)\n\n    def __getitem__(\n        self, key: int | slice | list[int] | np.ndarray | tuple[Video, int]\n    ) -&gt; list[LabeledFrame] | LabeledFrame:\n        \"\"\"Return one or more labeled frames based on indexing criteria.\"\"\"\n        if type(key) == int:\n            return self.labeled_frames[key]\n        elif type(key) == slice:\n            return [self.labeled_frames[i] for i in range(*key.indices(len(self)))]\n        elif type(key) == list:\n            return [self.labeled_frames[i] for i in key]\n        elif isinstance(key, np.ndarray):\n            return [self.labeled_frames[i] for i in key.tolist()]\n        elif type(key) == tuple and len(key) == 2:\n            video, frame_idx = key\n            res = self.find(video, frame_idx)\n            if len(res) == 1:\n                return res[0]\n            elif len(res) == 0:\n                raise IndexError(\n                    f\"No labeled frames found for video {video} and \"\n                    f\"frame index {frame_idx}.\"\n                )\n        elif type(key) == Video:\n            res = self.find(key)\n            if len(res) == 0:\n                raise IndexError(f\"No labeled frames found for video {key}.\")\n            return res\n        else:\n            raise IndexError(f\"Invalid indexing argument for labels: {key}\")\n\n    def __iter__(self):\n        \"\"\"Iterate over `labeled_frames` list when calling iter method on `Labels`.\"\"\"\n        return iter(self.labeled_frames)\n\n    def __len__(self) -&gt; int:\n        \"\"\"Return number of labeled frames.\"\"\"\n        return len(self.labeled_frames)\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return a readable representation of the labels.\"\"\"\n        return (\n            \"Labels(\"\n            f\"labeled_frames={len(self.labeled_frames)}, \"\n            f\"videos={len(self.videos)}, \"\n            f\"skeletons={len(self.skeletons)}, \"\n            f\"tracks={len(self.tracks)}, \"\n            f\"suggestions={len(self.suggestions)}\"\n            \")\"\n        )\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return a readable representation of the labels.\"\"\"\n        return self.__repr__()\n\n    def append(self, lf: LabeledFrame, update: bool = True):\n        \"\"\"Append a labeled frame to the labels.\n\n        Args:\n            lf: A labeled frame to add to the labels.\n            update: If `True` (the default), update list of videos, tracks and\n                skeletons from the contents.\n        \"\"\"\n        self.labeled_frames.append(lf)\n\n        if update:\n            if lf.video not in self.videos:\n                self.videos.append(lf.video)\n\n            for inst in lf:\n                if inst.skeleton not in self.skeletons:\n                    self.skeletons.append(inst.skeleton)\n\n                if inst.track is not None and inst.track not in self.tracks:\n                    self.tracks.append(inst.track)\n\n    def extend(self, lfs: list[LabeledFrame], update: bool = True):\n        \"\"\"Append a labeled frame to the labels.\n\n        Args:\n            lfs: A list of labeled frames to add to the labels.\n            update: If `True` (the default), update list of videos, tracks and\n                skeletons from the contents.\n        \"\"\"\n        self.labeled_frames.extend(lfs)\n\n        if update:\n            for lf in lfs:\n                if lf.video not in self.videos:\n                    self.videos.append(lf.video)\n\n                for inst in lf:\n                    if inst.skeleton not in self.skeletons:\n                        self.skeletons.append(inst.skeleton)\n\n                    if inst.track is not None and inst.track not in self.tracks:\n                        self.tracks.append(inst.track)\n\n    def numpy(\n        self,\n        video: Optional[Union[Video, int]] = None,\n        all_frames: bool = True,\n        untracked: bool = False,\n        return_confidence: bool = False,\n    ) -&gt; np.ndarray:\n        \"\"\"Construct a numpy array from instance points.\n\n        Args:\n            video: Video or video index to convert to numpy arrays. If `None` (the\n                default), uses the first video.\n            untracked: If `False` (the default), include only instances that have a\n                track assignment. If `True`, includes all instances in each frame in\n                arbitrary order.\n            return_confidence: If `False` (the default), only return points of nodes. If\n                `True`, return the points and scores of nodes.\n\n        Returns:\n            An array of tracks of shape `(n_frames, n_tracks, n_nodes, 2)` if\n            `return_confidence` is `False`. Otherwise returned shape is\n            `(n_frames, n_tracks, n_nodes, 3)` if `return_confidence` is `True`.\n\n            Missing data will be replaced with `np.nan`.\n\n            If this is a single instance project, a track does not need to be assigned.\n\n            Only predicted instances (NOT user instances) will be returned.\n\n        Notes:\n            This method assumes that instances have tracks assigned and is intended to\n            function primarily for single-video prediction results.\n        \"\"\"\n        # Get labeled frames for specified video.\n        if video is None:\n            video = 0\n        if type(video) == int:\n            video = self.videos[video]\n        lfs = [lf for lf in self.labeled_frames if lf.video == video]\n\n        # Figure out frame index range.\n        first_frame, last_frame = 0, 0\n        for lf in lfs:\n            first_frame = min(first_frame, lf.frame_idx)\n            last_frame = max(last_frame, lf.frame_idx)\n\n        # Figure out the number of tracks based on number of instances in each frame.\n        # First, let's check the max number of predicted instances (regardless of\n        # whether they're tracked.\n        n_preds = 0\n        for lf in lfs:\n            n_pred_instances = len(lf.predicted_instances)\n            n_preds = max(n_preds, n_pred_instances)\n\n        # Case 1: We don't care about order because there's only 1 instance per frame,\n        # or we're considering untracked instances.\n        untracked = untracked or n_preds == 1\n        if untracked:\n            n_tracks = n_preds\n        else:\n            # Case 2: We're considering only tracked instances.\n            n_tracks = len(self.tracks)\n\n        n_frames = int(last_frame - first_frame + 1)\n        skeleton = self.skeletons[-1]  # Assume project only uses last skeleton\n        n_nodes = len(skeleton.nodes)\n\n        if return_confidence:\n            tracks = np.full((n_frames, n_tracks, n_nodes, 3), np.nan, dtype=\"float32\")\n        else:\n            tracks = np.full((n_frames, n_tracks, n_nodes, 2), np.nan, dtype=\"float32\")\n        for lf in lfs:\n            i = int(lf.frame_idx - first_frame)\n            if untracked:\n                for j, inst in enumerate(lf.predicted_instances):\n                    tracks[i, j] = inst.numpy(scores=return_confidence)\n            else:\n                tracked_instances = [\n                    inst\n                    for inst in lf.instances\n                    if type(inst) == PredictedInstance and inst.track is not None\n                ]\n                for inst in tracked_instances:\n                    j = self.tracks.index(inst.track)  # type: ignore[arg-type]\n                    tracks[i, j] = inst.numpy(scores=return_confidence)\n\n        return tracks\n\n    @property\n    def video(self) -&gt; Video:\n        \"\"\"Return the video if there is only a single video in the labels.\"\"\"\n        if len(self.videos) == 0:\n            raise ValueError(\"There are no videos in the labels.\")\n        elif len(self.videos) == 1:\n            return self.videos[0]\n        else:\n            raise ValueError(\n                \"Labels.video can only be used when there is only a single video saved \"\n                \"in the labels. Use Labels.videos instead.\"\n            )\n\n    @property\n    def skeleton(self) -&gt; Skeleton:\n        \"\"\"Return the skeleton if there is only a single skeleton in the labels.\"\"\"\n        if len(self.skeletons) == 0:\n            raise ValueError(\"There are no skeletons in the labels.\")\n        elif len(self.skeletons) == 1:\n            return self.skeletons[0]\n        else:\n            raise ValueError(\n                \"Labels.skeleton can only be used when there is only a single skeleton \"\n                \"saved in the labels. Use Labels.skeletons instead.\"\n            )\n\n    def find(\n        self,\n        video: Video,\n        frame_idx: int | list[int] | None = None,\n        return_new: bool = False,\n    ) -&gt; list[LabeledFrame]:\n        \"\"\"Search for labeled frames given video and/or frame index.\n\n        Args:\n            video: A `Video` that is associated with the project.\n            frame_idx: The frame index (or indices) which we want to find in the video.\n                If a range is specified, we'll return all frames with indices in that\n                range. If not specific, then we'll return all labeled frames for video.\n            return_new: Whether to return singleton of new and empty `LabeledFrame` if\n                none are found in project.\n\n        Returns:\n            List of `LabeledFrame` objects that match the criteria.\n\n            The list will be empty if no matches found, unless return_new is True, in\n            which case it contains new (empty) `LabeledFrame` objects with `video` and\n            `frame_index` set.\n        \"\"\"\n        results = []\n\n        if frame_idx is None:\n            for lf in self.labeled_frames:\n                if lf.video == video:\n                    results.append(lf)\n            return results\n\n        if np.isscalar(frame_idx):\n            frame_idx = np.array(frame_idx).reshape(-1)\n\n        for frame_ind in frame_idx:\n            result = None\n            for lf in self.labeled_frames:\n                if lf.video == video and lf.frame_idx == frame_ind:\n                    result = lf\n                    results.append(result)\n                    break\n            if result is None and return_new:\n                results.append(LabeledFrame(video=video, frame_idx=frame_ind))\n\n        return results\n\n    def save(\n        self,\n        filename: str,\n        format: Optional[str] = None,\n        embed: bool | str | list[tuple[Video, int]] | None = None,\n        **kwargs,\n    ):\n        \"\"\"Save labels to file in specified format.\n\n        Args:\n            filename: Path to save labels to.\n            format: The format to save the labels in. If `None`, the format will be\n                inferred from the file extension. Available formats are `\"slp\"`,\n                `\"nwb\"`, `\"labelstudio\"`, and `\"jabs\"`.\n            embed: Frames to embed in the saved labels file. One of `None`, `True`,\n                `\"all\"`, `\"user\"`, `\"suggestions\"`, `\"user+suggestions\"`, `\"source\"` or\n                list of tuples of `(video, frame_idx)`.\n\n                If `None` is specified (the default) and the labels contains embedded\n                frames, those embedded frames will be re-saved to the new file.\n\n                If `True` or `\"all\"`, all labeled frames and suggested frames will be\n                embedded.\n\n                If `\"source\"` is specified, no images will be embedded and the source\n                video will be restored if available.\n\n                This argument is only valid for the SLP backend.\n        \"\"\"\n        from sleap_io import save_file\n\n        save_file(self, filename, format=format, embed=embed, **kwargs)\n\n    def clean(\n        self,\n        frames: bool = True,\n        empty_instances: bool = False,\n        skeletons: bool = True,\n        tracks: bool = True,\n        videos: bool = False,\n    ):\n        \"\"\"Remove empty frames, unused skeletons, tracks and videos.\n\n        Args:\n            frames: If `True` (the default), remove empty frames.\n            empty_instances: If `True` (NOT default), remove instances that have no\n                visible points.\n            skeletons: If `True` (the default), remove unused skeletons.\n            tracks: If `True` (the default), remove unused tracks.\n            videos: If `True` (NOT default), remove videos that have no labeled frames.\n        \"\"\"\n        used_skeletons = []\n        used_tracks = []\n        used_videos = []\n        kept_frames = []\n        for lf in self.labeled_frames:\n\n            if empty_instances:\n                lf.remove_empty_instances()\n\n            if frames and len(lf) == 0:\n                continue\n\n            if videos and lf.video not in used_videos:\n                used_videos.append(lf.video)\n\n            if skeletons or tracks:\n                for inst in lf:\n                    if skeletons and inst.skeleton not in used_skeletons:\n                        used_skeletons.append(inst.skeleton)\n                    if (\n                        tracks\n                        and inst.track is not None\n                        and inst.track not in used_tracks\n                    ):\n                        used_tracks.append(inst.track)\n\n            if frames:\n                kept_frames.append(lf)\n\n        if videos:\n            self.videos = [video for video in self.videos if video in used_videos]\n\n        if skeletons:\n            self.skeletons = [\n                skeleton for skeleton in self.skeletons if skeleton in used_skeletons\n            ]\n\n        if tracks:\n            self.tracks = [track for track in self.tracks if track in used_tracks]\n\n        if frames:\n            self.labeled_frames = kept_frames\n\n    def remove_predictions(self, clean: bool = True):\n        \"\"\"Remove all predicted instances from the labels.\n\n        Args:\n            clean: If `True` (the default), also remove any empty frames and unused\n                tracks and skeletons. It does NOT remove videos that have no labeled\n                frames or instances with no visible points.\n\n        See also: `Labels.clean`\n        \"\"\"\n        for lf in self.labeled_frames:\n            lf.remove_predictions()\n\n        if clean:\n            self.clean(\n                frames=True,\n                empty_instances=False,\n                skeletons=True,\n                tracks=True,\n                videos=False,\n            )\n\n    @property\n    def user_labeled_frames(self) -&gt; list[LabeledFrame]:\n        \"\"\"Return all labeled frames with user (non-predicted) instances.\"\"\"\n        return [lf for lf in self.labeled_frames if lf.has_user_instances]\n\n    def replace_videos(\n        self,\n        old_videos: list[Video] | None = None,\n        new_videos: list[Video] | None = None,\n        video_map: dict[Video, Video] | None = None,\n    ):\n        \"\"\"Replace videos and update all references.\n\n        Args:\n            old_videos: List of videos to be replaced.\n            new_videos: List of videos to replace with.\n            video_map: Alternative input of dictionary where keys are the old videos and\n                values are the new videos.\n        \"\"\"\n        if video_map is None:\n            video_map = {o: n for o, n in zip(old_videos, new_videos)}\n\n        # Update the labeled frames with the new videos.\n        for lf in self.labeled_frames:\n            if lf.video in video_map:\n                lf.video = video_map[lf.video]\n\n        # Update suggestions with the new videos.\n        for sf in self.suggestions:\n            if sf.video in video_map:\n                sf.video = video_map[sf.video]\n\n    def replace_filenames(\n        self,\n        new_filenames: list[str | Path] | None = None,\n        filename_map: dict[str | Path, str | Path] | None = None,\n        prefix_map: dict[str | Path, str | Path] | None = None,\n    ):\n        \"\"\"Replace video filenames.\n\n        Args:\n            new_filenames: List of new filenames. Must have the same length as the\n                number of videos in the labels.\n            filename_map: Dictionary mapping old filenames (keys) to new filenames\n                (values).\n            prefix_map: Dictonary mapping old prefixes (keys) to new prefixes (values).\n\n        Notes:\n            Only one of the argument types can be provided.\n        \"\"\"\n        n = 0\n        if new_filenames is not None:\n            n += 1\n        if filename_map is not None:\n            n += 1\n        if prefix_map is not None:\n            n += 1\n        if n != 1:\n            raise ValueError(\n                \"Exactly one input method must be provided to replace filenames.\"\n            )\n\n        if new_filenames is not None:\n            if len(self.videos) != len(new_filenames):\n                raise ValueError(\n                    f\"Number of new filenames ({len(new_filenames)}) does not match \"\n                    f\"the number of videos ({len(self.videos)}).\"\n                )\n\n            for video, new_filename in zip(self.videos, new_filenames):\n                video.replace_filename(new_filename)\n\n        elif filename_map is not None:\n            for video in self.videos:\n                for old_fn, new_fn in filename_map.items():\n                    if type(video.filename) == list:\n                        new_fns = []\n                        for fn in video.filename:\n                            if Path(fn) == Path(old_fn):\n                                new_fns.append(new_fn)\n                            else:\n                                new_fns.append(fn)\n                        video.replace_filename(new_fns)\n                    else:\n                        if Path(video.filename) == Path(old_fn):\n                            video.replace_filename(new_fn)\n\n        elif prefix_map is not None:\n            for video in self.videos:\n                for old_prefix, new_prefix in prefix_map.items():\n                    old_prefix, new_prefix = Path(old_prefix), Path(new_prefix)\n\n                    if type(video.filename) == list:\n                        new_fns = []\n                        for fn in video.filename:\n                            fn = Path(fn)\n                            if fn.as_posix().startswith(old_prefix.as_posix()):\n                                new_fns.append(new_prefix / fn.relative_to(old_prefix))\n                            else:\n                                new_fns.append(fn)\n                        video.replace_filename(new_fns)\n                    else:\n                        fn = Path(video.filename)\n                        if fn.as_posix().startswith(old_prefix.as_posix()):\n                            video.replace_filename(\n                                new_prefix / fn.relative_to(old_prefix)\n                            )\n\n    def split(self, n: int | float, seed: int | None = None) -&gt; tuple[Labels, Labels]:\n        \"\"\"Separate the labels into random splits.\n\n        Args:\n            n: Size of the first split. If integer &gt;= 1, assumes that this is the number\n                of labeled frames in the first split. If &lt; 1.0, this will be treated as\n                a fraction of the total labeled frames.\n            seed: Optional integer seed to use for reproducibility.\n\n        Returns:\n            A tuple of `split1, split2`.\n\n            If an integer was specified, `len(split1) == n`.\n\n            If a fraction was specified, `len(split1) == int(n * len(labels))`.\n\n            The second split contains the remainder, i.e.,\n            `len(split2) == len(labels) - len(split1)`.\n\n            If there are too few frames, a minimum of 1 frame will be kept in the second\n            split.\n\n            If there is exactly 1 labeled frame in the labels, the same frame will be\n            assigned to both splits.\n        \"\"\"\n        n0 = len(self)\n        if n0 == 0:\n            return self, self\n        n1 = n\n        if n &lt; 1.0:\n            n1 = max(int(n0 * float(n)), 1)\n        n2 = max(n0 - n1, 1)\n        n1, n2 = int(n1), int(n2)\n\n        rng = np.random.default_rng(seed=seed)\n        inds1 = rng.choice(n0, size=(n1,), replace=False)\n\n        if n0 == 1:\n            inds2 = np.array([0])\n        else:\n            inds2 = np.setdiff1d(np.arange(n0), inds1)\n\n        split1, split2 = self[inds1], self[inds2]\n        split1, split2 = deepcopy(split1), deepcopy(split2)\n        split1, split2 = Labels(split1), Labels(split2)\n\n        split1.provenance = self.provenance\n        split2.provenance = self.provenance\n        split1.provenance[\"source_labels\"] = self.provenance.get(\"filename\", None)\n        split2.provenance[\"source_labels\"] = self.provenance.get(\"filename\", None)\n\n        return split1, split2\n\n    def make_training_splits(\n        self,\n        n_train: int | float,\n        n_val: int | float | None = None,\n        n_test: int | float | None = None,\n        save_dir: str | Path | None = None,\n        seed: int | None = None,\n    ) -&gt; tuple[Labels, Labels] | tuple[Labels, Labels, Labels]:\n        \"\"\"Make splits for training with embedded images.\n\n        Args:\n            n_train: Size of the training split as integer or fraction.\n            n_val: Size of the validation split as integer or fraction. If `None`,\n                this will be inferred based on the values of `n_train` and `n_test`. If\n                `n_test` is `None`, this will be the remainder of the data after the\n                training split.\n            n_test: Size of the testing split as integer or fraction. If `None`, the\n                test split will not be saved.\n            save_dir: If specified, save splits to SLP files with embedded images.\n            seed: Optional integer seed to use for reproducibility.\n\n        Returns:\n            A tuple of `labels_train, labels_val` or\n            `labels_train, labels_val, labels_test` if `n_test` was specified.\n\n        Notes:\n            Predictions and suggestions will be removed before saving, leaving only\n            frames with user labeled data (the source labels are not affected).\n\n            Frames with user labeled data will be embedded in the resulting files.\n\n            If `save_dir` is specified, this will save the randomly sampled splits to:\n\n                - `{save_dir}/train.pkg.slp`\n                - `{save_dir}/val.pkg.slp`\n                - `{save_dir}/test.pkg.slp` (if `n_test` is specified)\n\n        See also: `Labels.split`\n        \"\"\"\n        # Clean up labels.\n        labels = deepcopy(self)\n        labels.remove_predictions()\n        labels.suggestions = []\n        labels.clean()\n\n        # Make splits.\n        labels_train, labels_rest = labels.split(n_train, seed=seed)\n        if n_test is not None:\n            if n_test &lt; 1:\n                n_test = (n_test * len(labels)) / len(labels_rest)\n            labels_test, labels_rest = labels_rest.split(n=n_test, seed=seed)\n        if n_val is not None:\n            if n_val &lt; 1:\n                n_val = (n_val * len(labels)) / len(labels_rest)\n            labels_val, _ = labels_rest.split(n=n_val, seed=seed)\n        else:\n            labels_val = labels_rest\n\n        # Save.\n        if save_dir is not None:\n            save_dir = Path(save_dir)\n            save_dir.mkdir(exist_ok=True, parents=True)\n\n            labels_train.save(save_dir / \"train.pkg.slp\", embed=\"user\")\n            labels_val.save(save_dir / \"val.pkg.slp\", embed=\"user\")\n            labels_test.save(save_dir / \"test.pkg.slp\", embed=\"user\")\n\n        if n_test is None:\n            return labels_train, labels_val\n        else:\n            return labels_train, labels_val, labels_test\n</code></pre>"},{"location":"model/#sleap_io.Labels.skeleton","title":"<code>skeleton: Skeleton</code>  <code>property</code>","text":"<p>Return the skeleton if there is only a single skeleton in the labels.</p>"},{"location":"model/#sleap_io.Labels.user_labeled_frames","title":"<code>user_labeled_frames: list[LabeledFrame]</code>  <code>property</code>","text":"<p>Return all labeled frames with user (non-predicted) instances.</p>"},{"location":"model/#sleap_io.Labels.video","title":"<code>video: Video</code>  <code>property</code>","text":"<p>Return the video if there is only a single video in the labels.</p>"},{"location":"model/#sleap_io.Labels.__attrs_post_init__","title":"<code>__attrs_post_init__()</code>","text":"<p>Append videos, skeletons, and tracks seen in <code>labeled_frames</code> to <code>Labels</code>.</p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def __attrs_post_init__(self):\n    \"\"\"Append videos, skeletons, and tracks seen in `labeled_frames` to `Labels`.\"\"\"\n    self.update()\n</code></pre>"},{"location":"model/#sleap_io.Labels.__getitem__","title":"<code>__getitem__(key)</code>","text":"<p>Return one or more labeled frames based on indexing criteria.</p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def __getitem__(\n    self, key: int | slice | list[int] | np.ndarray | tuple[Video, int]\n) -&gt; list[LabeledFrame] | LabeledFrame:\n    \"\"\"Return one or more labeled frames based on indexing criteria.\"\"\"\n    if type(key) == int:\n        return self.labeled_frames[key]\n    elif type(key) == slice:\n        return [self.labeled_frames[i] for i in range(*key.indices(len(self)))]\n    elif type(key) == list:\n        return [self.labeled_frames[i] for i in key]\n    elif isinstance(key, np.ndarray):\n        return [self.labeled_frames[i] for i in key.tolist()]\n    elif type(key) == tuple and len(key) == 2:\n        video, frame_idx = key\n        res = self.find(video, frame_idx)\n        if len(res) == 1:\n            return res[0]\n        elif len(res) == 0:\n            raise IndexError(\n                f\"No labeled frames found for video {video} and \"\n                f\"frame index {frame_idx}.\"\n            )\n    elif type(key) == Video:\n        res = self.find(key)\n        if len(res) == 0:\n            raise IndexError(f\"No labeled frames found for video {key}.\")\n        return res\n    else:\n        raise IndexError(f\"Invalid indexing argument for labels: {key}\")\n</code></pre>"},{"location":"model/#sleap_io.Labels.__iter__","title":"<code>__iter__()</code>","text":"<p>Iterate over <code>labeled_frames</code> list when calling iter method on <code>Labels</code>.</p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def __iter__(self):\n    \"\"\"Iterate over `labeled_frames` list when calling iter method on `Labels`.\"\"\"\n    return iter(self.labeled_frames)\n</code></pre>"},{"location":"model/#sleap_io.Labels.__len__","title":"<code>__len__()</code>","text":"<p>Return number of labeled frames.</p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"Return number of labeled frames.\"\"\"\n    return len(self.labeled_frames)\n</code></pre>"},{"location":"model/#sleap_io.Labels.__repr__","title":"<code>__repr__()</code>","text":"<p>Return a readable representation of the labels.</p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return a readable representation of the labels.\"\"\"\n    return (\n        \"Labels(\"\n        f\"labeled_frames={len(self.labeled_frames)}, \"\n        f\"videos={len(self.videos)}, \"\n        f\"skeletons={len(self.skeletons)}, \"\n        f\"tracks={len(self.tracks)}, \"\n        f\"suggestions={len(self.suggestions)}\"\n        \")\"\n    )\n</code></pre>"},{"location":"model/#sleap_io.Labels.__str__","title":"<code>__str__()</code>","text":"<p>Return a readable representation of the labels.</p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return a readable representation of the labels.\"\"\"\n    return self.__repr__()\n</code></pre>"},{"location":"model/#sleap_io.Labels.append","title":"<code>append(lf, update=True)</code>","text":"<p>Append a labeled frame to the labels.</p> <p>Parameters:</p> Name Type Description Default <code>lf</code> <code>LabeledFrame</code> <p>A labeled frame to add to the labels.</p> required <code>update</code> <code>bool</code> <p>If <code>True</code> (the default), update list of videos, tracks and skeletons from the contents.</p> <code>True</code> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def append(self, lf: LabeledFrame, update: bool = True):\n    \"\"\"Append a labeled frame to the labels.\n\n    Args:\n        lf: A labeled frame to add to the labels.\n        update: If `True` (the default), update list of videos, tracks and\n            skeletons from the contents.\n    \"\"\"\n    self.labeled_frames.append(lf)\n\n    if update:\n        if lf.video not in self.videos:\n            self.videos.append(lf.video)\n\n        for inst in lf:\n            if inst.skeleton not in self.skeletons:\n                self.skeletons.append(inst.skeleton)\n\n            if inst.track is not None and inst.track not in self.tracks:\n                self.tracks.append(inst.track)\n</code></pre>"},{"location":"model/#sleap_io.Labels.clean","title":"<code>clean(frames=True, empty_instances=False, skeletons=True, tracks=True, videos=False)</code>","text":"<p>Remove empty frames, unused skeletons, tracks and videos.</p> <p>Parameters:</p> Name Type Description Default <code>frames</code> <code>bool</code> <p>If <code>True</code> (the default), remove empty frames.</p> <code>True</code> <code>empty_instances</code> <code>bool</code> <p>If <code>True</code> (NOT default), remove instances that have no visible points.</p> <code>False</code> <code>skeletons</code> <code>bool</code> <p>If <code>True</code> (the default), remove unused skeletons.</p> <code>True</code> <code>tracks</code> <code>bool</code> <p>If <code>True</code> (the default), remove unused tracks.</p> <code>True</code> <code>videos</code> <code>bool</code> <p>If <code>True</code> (NOT default), remove videos that have no labeled frames.</p> <code>False</code> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def clean(\n    self,\n    frames: bool = True,\n    empty_instances: bool = False,\n    skeletons: bool = True,\n    tracks: bool = True,\n    videos: bool = False,\n):\n    \"\"\"Remove empty frames, unused skeletons, tracks and videos.\n\n    Args:\n        frames: If `True` (the default), remove empty frames.\n        empty_instances: If `True` (NOT default), remove instances that have no\n            visible points.\n        skeletons: If `True` (the default), remove unused skeletons.\n        tracks: If `True` (the default), remove unused tracks.\n        videos: If `True` (NOT default), remove videos that have no labeled frames.\n    \"\"\"\n    used_skeletons = []\n    used_tracks = []\n    used_videos = []\n    kept_frames = []\n    for lf in self.labeled_frames:\n\n        if empty_instances:\n            lf.remove_empty_instances()\n\n        if frames and len(lf) == 0:\n            continue\n\n        if videos and lf.video not in used_videos:\n            used_videos.append(lf.video)\n\n        if skeletons or tracks:\n            for inst in lf:\n                if skeletons and inst.skeleton not in used_skeletons:\n                    used_skeletons.append(inst.skeleton)\n                if (\n                    tracks\n                    and inst.track is not None\n                    and inst.track not in used_tracks\n                ):\n                    used_tracks.append(inst.track)\n\n        if frames:\n            kept_frames.append(lf)\n\n    if videos:\n        self.videos = [video for video in self.videos if video in used_videos]\n\n    if skeletons:\n        self.skeletons = [\n            skeleton for skeleton in self.skeletons if skeleton in used_skeletons\n        ]\n\n    if tracks:\n        self.tracks = [track for track in self.tracks if track in used_tracks]\n\n    if frames:\n        self.labeled_frames = kept_frames\n</code></pre>"},{"location":"model/#sleap_io.Labels.extend","title":"<code>extend(lfs, update=True)</code>","text":"<p>Append a labeled frame to the labels.</p> <p>Parameters:</p> Name Type Description Default <code>lfs</code> <code>list[LabeledFrame]</code> <p>A list of labeled frames to add to the labels.</p> required <code>update</code> <code>bool</code> <p>If <code>True</code> (the default), update list of videos, tracks and skeletons from the contents.</p> <code>True</code> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def extend(self, lfs: list[LabeledFrame], update: bool = True):\n    \"\"\"Append a labeled frame to the labels.\n\n    Args:\n        lfs: A list of labeled frames to add to the labels.\n        update: If `True` (the default), update list of videos, tracks and\n            skeletons from the contents.\n    \"\"\"\n    self.labeled_frames.extend(lfs)\n\n    if update:\n        for lf in lfs:\n            if lf.video not in self.videos:\n                self.videos.append(lf.video)\n\n            for inst in lf:\n                if inst.skeleton not in self.skeletons:\n                    self.skeletons.append(inst.skeleton)\n\n                if inst.track is not None and inst.track not in self.tracks:\n                    self.tracks.append(inst.track)\n</code></pre>"},{"location":"model/#sleap_io.Labels.find","title":"<code>find(video, frame_idx=None, return_new=False)</code>","text":"<p>Search for labeled frames given video and/or frame index.</p> <p>Parameters:</p> Name Type Description Default <code>video</code> <code>Video</code> <p>A <code>Video</code> that is associated with the project.</p> required <code>frame_idx</code> <code>int | list[int] | None</code> <p>The frame index (or indices) which we want to find in the video. If a range is specified, we'll return all frames with indices in that range. If not specific, then we'll return all labeled frames for video.</p> <code>None</code> <code>return_new</code> <code>bool</code> <p>Whether to return singleton of new and empty <code>LabeledFrame</code> if none are found in project.</p> <code>False</code> <p>Returns:</p> Type Description <code>list[LabeledFrame]</code> <p>List of <code>LabeledFrame</code> objects that match the criteria.</p> <p>The list will be empty if no matches found, unless return_new is True, in which case it contains new (empty) <code>LabeledFrame</code> objects with <code>video</code> and <code>frame_index</code> set.</p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def find(\n    self,\n    video: Video,\n    frame_idx: int | list[int] | None = None,\n    return_new: bool = False,\n) -&gt; list[LabeledFrame]:\n    \"\"\"Search for labeled frames given video and/or frame index.\n\n    Args:\n        video: A `Video` that is associated with the project.\n        frame_idx: The frame index (or indices) which we want to find in the video.\n            If a range is specified, we'll return all frames with indices in that\n            range. If not specific, then we'll return all labeled frames for video.\n        return_new: Whether to return singleton of new and empty `LabeledFrame` if\n            none are found in project.\n\n    Returns:\n        List of `LabeledFrame` objects that match the criteria.\n\n        The list will be empty if no matches found, unless return_new is True, in\n        which case it contains new (empty) `LabeledFrame` objects with `video` and\n        `frame_index` set.\n    \"\"\"\n    results = []\n\n    if frame_idx is None:\n        for lf in self.labeled_frames:\n            if lf.video == video:\n                results.append(lf)\n        return results\n\n    if np.isscalar(frame_idx):\n        frame_idx = np.array(frame_idx).reshape(-1)\n\n    for frame_ind in frame_idx:\n        result = None\n        for lf in self.labeled_frames:\n            if lf.video == video and lf.frame_idx == frame_ind:\n                result = lf\n                results.append(result)\n                break\n        if result is None and return_new:\n            results.append(LabeledFrame(video=video, frame_idx=frame_ind))\n\n    return results\n</code></pre>"},{"location":"model/#sleap_io.Labels.make_training_splits","title":"<code>make_training_splits(n_train, n_val=None, n_test=None, save_dir=None, seed=None)</code>","text":"<p>Make splits for training with embedded images.</p> <p>Parameters:</p> Name Type Description Default <code>n_train</code> <code>int | float</code> <p>Size of the training split as integer or fraction.</p> required <code>n_val</code> <code>int | float | None</code> <p>Size of the validation split as integer or fraction. If <code>None</code>, this will be inferred based on the values of <code>n_train</code> and <code>n_test</code>. If <code>n_test</code> is <code>None</code>, this will be the remainder of the data after the training split.</p> <code>None</code> <code>n_test</code> <code>int | float | None</code> <p>Size of the testing split as integer or fraction. If <code>None</code>, the test split will not be saved.</p> <code>None</code> <code>save_dir</code> <code>str | Path | None</code> <p>If specified, save splits to SLP files with embedded images.</p> <code>None</code> <code>seed</code> <code>int | None</code> <p>Optional integer seed to use for reproducibility.</p> <code>None</code> <p>Returns:</p> Type Description <code>tuple[Labels, Labels] | tuple[Labels, Labels, Labels]</code> <p>A tuple of <code>labels_train, labels_val</code> or <code>labels_train, labels_val, labels_test</code> if <code>n_test</code> was specified.</p> Notes <p>Predictions and suggestions will be removed before saving, leaving only frames with user labeled data (the source labels are not affected).</p> <p>Frames with user labeled data will be embedded in the resulting files.</p> <p>If <code>save_dir</code> is specified, this will save the randomly sampled splits to:</p> <pre><code>- `{save_dir}/train.pkg.slp`\n- `{save_dir}/val.pkg.slp`\n- `{save_dir}/test.pkg.slp` (if `n_test` is specified)\n</code></pre> <p>See also: <code>Labels.split</code></p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def make_training_splits(\n    self,\n    n_train: int | float,\n    n_val: int | float | None = None,\n    n_test: int | float | None = None,\n    save_dir: str | Path | None = None,\n    seed: int | None = None,\n) -&gt; tuple[Labels, Labels] | tuple[Labels, Labels, Labels]:\n    \"\"\"Make splits for training with embedded images.\n\n    Args:\n        n_train: Size of the training split as integer or fraction.\n        n_val: Size of the validation split as integer or fraction. If `None`,\n            this will be inferred based on the values of `n_train` and `n_test`. If\n            `n_test` is `None`, this will be the remainder of the data after the\n            training split.\n        n_test: Size of the testing split as integer or fraction. If `None`, the\n            test split will not be saved.\n        save_dir: If specified, save splits to SLP files with embedded images.\n        seed: Optional integer seed to use for reproducibility.\n\n    Returns:\n        A tuple of `labels_train, labels_val` or\n        `labels_train, labels_val, labels_test` if `n_test` was specified.\n\n    Notes:\n        Predictions and suggestions will be removed before saving, leaving only\n        frames with user labeled data (the source labels are not affected).\n\n        Frames with user labeled data will be embedded in the resulting files.\n\n        If `save_dir` is specified, this will save the randomly sampled splits to:\n\n            - `{save_dir}/train.pkg.slp`\n            - `{save_dir}/val.pkg.slp`\n            - `{save_dir}/test.pkg.slp` (if `n_test` is specified)\n\n    See also: `Labels.split`\n    \"\"\"\n    # Clean up labels.\n    labels = deepcopy(self)\n    labels.remove_predictions()\n    labels.suggestions = []\n    labels.clean()\n\n    # Make splits.\n    labels_train, labels_rest = labels.split(n_train, seed=seed)\n    if n_test is not None:\n        if n_test &lt; 1:\n            n_test = (n_test * len(labels)) / len(labels_rest)\n        labels_test, labels_rest = labels_rest.split(n=n_test, seed=seed)\n    if n_val is not None:\n        if n_val &lt; 1:\n            n_val = (n_val * len(labels)) / len(labels_rest)\n        labels_val, _ = labels_rest.split(n=n_val, seed=seed)\n    else:\n        labels_val = labels_rest\n\n    # Save.\n    if save_dir is not None:\n        save_dir = Path(save_dir)\n        save_dir.mkdir(exist_ok=True, parents=True)\n\n        labels_train.save(save_dir / \"train.pkg.slp\", embed=\"user\")\n        labels_val.save(save_dir / \"val.pkg.slp\", embed=\"user\")\n        labels_test.save(save_dir / \"test.pkg.slp\", embed=\"user\")\n\n    if n_test is None:\n        return labels_train, labels_val\n    else:\n        return labels_train, labels_val, labels_test\n</code></pre>"},{"location":"model/#sleap_io.Labels.numpy","title":"<code>numpy(video=None, all_frames=True, untracked=False, return_confidence=False)</code>","text":"<p>Construct a numpy array from instance points.</p> <p>Parameters:</p> Name Type Description Default <code>video</code> <code>Optional[Union[Video, int]]</code> <p>Video or video index to convert to numpy arrays. If <code>None</code> (the default), uses the first video.</p> <code>None</code> <code>untracked</code> <code>bool</code> <p>If <code>False</code> (the default), include only instances that have a track assignment. If <code>True</code>, includes all instances in each frame in arbitrary order.</p> <code>False</code> <code>return_confidence</code> <code>bool</code> <p>If <code>False</code> (the default), only return points of nodes. If <code>True</code>, return the points and scores of nodes.</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>An array of tracks of shape <code>(n_frames, n_tracks, n_nodes, 2)</code> if <code>return_confidence</code> is <code>False</code>. Otherwise returned shape is <code>(n_frames, n_tracks, n_nodes, 3)</code> if <code>return_confidence</code> is <code>True</code>.</p> <p>Missing data will be replaced with <code>np.nan</code>.</p> <p>If this is a single instance project, a track does not need to be assigned.</p> <p>Only predicted instances (NOT user instances) will be returned.</p> Notes <p>This method assumes that instances have tracks assigned and is intended to function primarily for single-video prediction results.</p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def numpy(\n    self,\n    video: Optional[Union[Video, int]] = None,\n    all_frames: bool = True,\n    untracked: bool = False,\n    return_confidence: bool = False,\n) -&gt; np.ndarray:\n    \"\"\"Construct a numpy array from instance points.\n\n    Args:\n        video: Video or video index to convert to numpy arrays. If `None` (the\n            default), uses the first video.\n        untracked: If `False` (the default), include only instances that have a\n            track assignment. If `True`, includes all instances in each frame in\n            arbitrary order.\n        return_confidence: If `False` (the default), only return points of nodes. If\n            `True`, return the points and scores of nodes.\n\n    Returns:\n        An array of tracks of shape `(n_frames, n_tracks, n_nodes, 2)` if\n        `return_confidence` is `False`. Otherwise returned shape is\n        `(n_frames, n_tracks, n_nodes, 3)` if `return_confidence` is `True`.\n\n        Missing data will be replaced with `np.nan`.\n\n        If this is a single instance project, a track does not need to be assigned.\n\n        Only predicted instances (NOT user instances) will be returned.\n\n    Notes:\n        This method assumes that instances have tracks assigned and is intended to\n        function primarily for single-video prediction results.\n    \"\"\"\n    # Get labeled frames for specified video.\n    if video is None:\n        video = 0\n    if type(video) == int:\n        video = self.videos[video]\n    lfs = [lf for lf in self.labeled_frames if lf.video == video]\n\n    # Figure out frame index range.\n    first_frame, last_frame = 0, 0\n    for lf in lfs:\n        first_frame = min(first_frame, lf.frame_idx)\n        last_frame = max(last_frame, lf.frame_idx)\n\n    # Figure out the number of tracks based on number of instances in each frame.\n    # First, let's check the max number of predicted instances (regardless of\n    # whether they're tracked.\n    n_preds = 0\n    for lf in lfs:\n        n_pred_instances = len(lf.predicted_instances)\n        n_preds = max(n_preds, n_pred_instances)\n\n    # Case 1: We don't care about order because there's only 1 instance per frame,\n    # or we're considering untracked instances.\n    untracked = untracked or n_preds == 1\n    if untracked:\n        n_tracks = n_preds\n    else:\n        # Case 2: We're considering only tracked instances.\n        n_tracks = len(self.tracks)\n\n    n_frames = int(last_frame - first_frame + 1)\n    skeleton = self.skeletons[-1]  # Assume project only uses last skeleton\n    n_nodes = len(skeleton.nodes)\n\n    if return_confidence:\n        tracks = np.full((n_frames, n_tracks, n_nodes, 3), np.nan, dtype=\"float32\")\n    else:\n        tracks = np.full((n_frames, n_tracks, n_nodes, 2), np.nan, dtype=\"float32\")\n    for lf in lfs:\n        i = int(lf.frame_idx - first_frame)\n        if untracked:\n            for j, inst in enumerate(lf.predicted_instances):\n                tracks[i, j] = inst.numpy(scores=return_confidence)\n        else:\n            tracked_instances = [\n                inst\n                for inst in lf.instances\n                if type(inst) == PredictedInstance and inst.track is not None\n            ]\n            for inst in tracked_instances:\n                j = self.tracks.index(inst.track)  # type: ignore[arg-type]\n                tracks[i, j] = inst.numpy(scores=return_confidence)\n\n    return tracks\n</code></pre>"},{"location":"model/#sleap_io.Labels.remove_predictions","title":"<code>remove_predictions(clean=True)</code>","text":"<p>Remove all predicted instances from the labels.</p> <p>Parameters:</p> Name Type Description Default <code>clean</code> <code>bool</code> <p>If <code>True</code> (the default), also remove any empty frames and unused tracks and skeletons. It does NOT remove videos that have no labeled frames or instances with no visible points.</p> <code>True</code> <p>See also: <code>Labels.clean</code></p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def remove_predictions(self, clean: bool = True):\n    \"\"\"Remove all predicted instances from the labels.\n\n    Args:\n        clean: If `True` (the default), also remove any empty frames and unused\n            tracks and skeletons. It does NOT remove videos that have no labeled\n            frames or instances with no visible points.\n\n    See also: `Labels.clean`\n    \"\"\"\n    for lf in self.labeled_frames:\n        lf.remove_predictions()\n\n    if clean:\n        self.clean(\n            frames=True,\n            empty_instances=False,\n            skeletons=True,\n            tracks=True,\n            videos=False,\n        )\n</code></pre>"},{"location":"model/#sleap_io.Labels.replace_filenames","title":"<code>replace_filenames(new_filenames=None, filename_map=None, prefix_map=None)</code>","text":"<p>Replace video filenames.</p> <p>Parameters:</p> Name Type Description Default <code>new_filenames</code> <code>list[str | Path] | None</code> <p>List of new filenames. Must have the same length as the number of videos in the labels.</p> <code>None</code> <code>filename_map</code> <code>dict[str | Path, str | Path] | None</code> <p>Dictionary mapping old filenames (keys) to new filenames (values).</p> <code>None</code> <code>prefix_map</code> <code>dict[str | Path, str | Path] | None</code> <p>Dictonary mapping old prefixes (keys) to new prefixes (values).</p> <code>None</code> Notes <p>Only one of the argument types can be provided.</p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def replace_filenames(\n    self,\n    new_filenames: list[str | Path] | None = None,\n    filename_map: dict[str | Path, str | Path] | None = None,\n    prefix_map: dict[str | Path, str | Path] | None = None,\n):\n    \"\"\"Replace video filenames.\n\n    Args:\n        new_filenames: List of new filenames. Must have the same length as the\n            number of videos in the labels.\n        filename_map: Dictionary mapping old filenames (keys) to new filenames\n            (values).\n        prefix_map: Dictonary mapping old prefixes (keys) to new prefixes (values).\n\n    Notes:\n        Only one of the argument types can be provided.\n    \"\"\"\n    n = 0\n    if new_filenames is not None:\n        n += 1\n    if filename_map is not None:\n        n += 1\n    if prefix_map is not None:\n        n += 1\n    if n != 1:\n        raise ValueError(\n            \"Exactly one input method must be provided to replace filenames.\"\n        )\n\n    if new_filenames is not None:\n        if len(self.videos) != len(new_filenames):\n            raise ValueError(\n                f\"Number of new filenames ({len(new_filenames)}) does not match \"\n                f\"the number of videos ({len(self.videos)}).\"\n            )\n\n        for video, new_filename in zip(self.videos, new_filenames):\n            video.replace_filename(new_filename)\n\n    elif filename_map is not None:\n        for video in self.videos:\n            for old_fn, new_fn in filename_map.items():\n                if type(video.filename) == list:\n                    new_fns = []\n                    for fn in video.filename:\n                        if Path(fn) == Path(old_fn):\n                            new_fns.append(new_fn)\n                        else:\n                            new_fns.append(fn)\n                    video.replace_filename(new_fns)\n                else:\n                    if Path(video.filename) == Path(old_fn):\n                        video.replace_filename(new_fn)\n\n    elif prefix_map is not None:\n        for video in self.videos:\n            for old_prefix, new_prefix in prefix_map.items():\n                old_prefix, new_prefix = Path(old_prefix), Path(new_prefix)\n\n                if type(video.filename) == list:\n                    new_fns = []\n                    for fn in video.filename:\n                        fn = Path(fn)\n                        if fn.as_posix().startswith(old_prefix.as_posix()):\n                            new_fns.append(new_prefix / fn.relative_to(old_prefix))\n                        else:\n                            new_fns.append(fn)\n                    video.replace_filename(new_fns)\n                else:\n                    fn = Path(video.filename)\n                    if fn.as_posix().startswith(old_prefix.as_posix()):\n                        video.replace_filename(\n                            new_prefix / fn.relative_to(old_prefix)\n                        )\n</code></pre>"},{"location":"model/#sleap_io.Labels.replace_videos","title":"<code>replace_videos(old_videos=None, new_videos=None, video_map=None)</code>","text":"<p>Replace videos and update all references.</p> <p>Parameters:</p> Name Type Description Default <code>old_videos</code> <code>list[Video] | None</code> <p>List of videos to be replaced.</p> <code>None</code> <code>new_videos</code> <code>list[Video] | None</code> <p>List of videos to replace with.</p> <code>None</code> <code>video_map</code> <code>dict[Video, Video] | None</code> <p>Alternative input of dictionary where keys are the old videos and values are the new videos.</p> <code>None</code> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def replace_videos(\n    self,\n    old_videos: list[Video] | None = None,\n    new_videos: list[Video] | None = None,\n    video_map: dict[Video, Video] | None = None,\n):\n    \"\"\"Replace videos and update all references.\n\n    Args:\n        old_videos: List of videos to be replaced.\n        new_videos: List of videos to replace with.\n        video_map: Alternative input of dictionary where keys are the old videos and\n            values are the new videos.\n    \"\"\"\n    if video_map is None:\n        video_map = {o: n for o, n in zip(old_videos, new_videos)}\n\n    # Update the labeled frames with the new videos.\n    for lf in self.labeled_frames:\n        if lf.video in video_map:\n            lf.video = video_map[lf.video]\n\n    # Update suggestions with the new videos.\n    for sf in self.suggestions:\n        if sf.video in video_map:\n            sf.video = video_map[sf.video]\n</code></pre>"},{"location":"model/#sleap_io.Labels.save","title":"<code>save(filename, format=None, embed=None, **kwargs)</code>","text":"<p>Save labels to file in specified format.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>Path to save labels to.</p> required <code>format</code> <code>Optional[str]</code> <p>The format to save the labels in. If <code>None</code>, the format will be inferred from the file extension. Available formats are <code>\"slp\"</code>, <code>\"nwb\"</code>, <code>\"labelstudio\"</code>, and <code>\"jabs\"</code>.</p> <code>None</code> <code>embed</code> <code>bool | str | list[tuple[Video, int]] | None</code> <p>Frames to embed in the saved labels file. One of <code>None</code>, <code>True</code>, <code>\"all\"</code>, <code>\"user\"</code>, <code>\"suggestions\"</code>, <code>\"user+suggestions\"</code>, <code>\"source\"</code> or list of tuples of <code>(video, frame_idx)</code>.</p> <p>If <code>None</code> is specified (the default) and the labels contains embedded frames, those embedded frames will be re-saved to the new file.</p> <p>If <code>True</code> or <code>\"all\"</code>, all labeled frames and suggested frames will be embedded.</p> <p>If <code>\"source\"</code> is specified, no images will be embedded and the source video will be restored if available.</p> <p>This argument is only valid for the SLP backend.</p> <code>None</code> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def save(\n    self,\n    filename: str,\n    format: Optional[str] = None,\n    embed: bool | str | list[tuple[Video, int]] | None = None,\n    **kwargs,\n):\n    \"\"\"Save labels to file in specified format.\n\n    Args:\n        filename: Path to save labels to.\n        format: The format to save the labels in. If `None`, the format will be\n            inferred from the file extension. Available formats are `\"slp\"`,\n            `\"nwb\"`, `\"labelstudio\"`, and `\"jabs\"`.\n        embed: Frames to embed in the saved labels file. One of `None`, `True`,\n            `\"all\"`, `\"user\"`, `\"suggestions\"`, `\"user+suggestions\"`, `\"source\"` or\n            list of tuples of `(video, frame_idx)`.\n\n            If `None` is specified (the default) and the labels contains embedded\n            frames, those embedded frames will be re-saved to the new file.\n\n            If `True` or `\"all\"`, all labeled frames and suggested frames will be\n            embedded.\n\n            If `\"source\"` is specified, no images will be embedded and the source\n            video will be restored if available.\n\n            This argument is only valid for the SLP backend.\n    \"\"\"\n    from sleap_io import save_file\n\n    save_file(self, filename, format=format, embed=embed, **kwargs)\n</code></pre>"},{"location":"model/#sleap_io.Labels.split","title":"<code>split(n, seed=None)</code>","text":"<p>Separate the labels into random splits.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int | float</code> <p>Size of the first split. If integer &gt;= 1, assumes that this is the number of labeled frames in the first split. If &lt; 1.0, this will be treated as a fraction of the total labeled frames.</p> required <code>seed</code> <code>int | None</code> <p>Optional integer seed to use for reproducibility.</p> <code>None</code> <p>Returns:</p> Type Description <code>tuple[Labels, Labels]</code> <p>A tuple of <code>split1, split2</code>.</p> <p>If an integer was specified, <code>len(split1) == n</code>.</p> <p>If a fraction was specified, <code>len(split1) == int(n * len(labels))</code>.</p> <p>The second split contains the remainder, i.e., <code>len(split2) == len(labels) - len(split1)</code>.</p> <p>If there are too few frames, a minimum of 1 frame will be kept in the second split.</p> <p>If there is exactly 1 labeled frame in the labels, the same frame will be assigned to both splits.</p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def split(self, n: int | float, seed: int | None = None) -&gt; tuple[Labels, Labels]:\n    \"\"\"Separate the labels into random splits.\n\n    Args:\n        n: Size of the first split. If integer &gt;= 1, assumes that this is the number\n            of labeled frames in the first split. If &lt; 1.0, this will be treated as\n            a fraction of the total labeled frames.\n        seed: Optional integer seed to use for reproducibility.\n\n    Returns:\n        A tuple of `split1, split2`.\n\n        If an integer was specified, `len(split1) == n`.\n\n        If a fraction was specified, `len(split1) == int(n * len(labels))`.\n\n        The second split contains the remainder, i.e.,\n        `len(split2) == len(labels) - len(split1)`.\n\n        If there are too few frames, a minimum of 1 frame will be kept in the second\n        split.\n\n        If there is exactly 1 labeled frame in the labels, the same frame will be\n        assigned to both splits.\n    \"\"\"\n    n0 = len(self)\n    if n0 == 0:\n        return self, self\n    n1 = n\n    if n &lt; 1.0:\n        n1 = max(int(n0 * float(n)), 1)\n    n2 = max(n0 - n1, 1)\n    n1, n2 = int(n1), int(n2)\n\n    rng = np.random.default_rng(seed=seed)\n    inds1 = rng.choice(n0, size=(n1,), replace=False)\n\n    if n0 == 1:\n        inds2 = np.array([0])\n    else:\n        inds2 = np.setdiff1d(np.arange(n0), inds1)\n\n    split1, split2 = self[inds1], self[inds2]\n    split1, split2 = deepcopy(split1), deepcopy(split2)\n    split1, split2 = Labels(split1), Labels(split2)\n\n    split1.provenance = self.provenance\n    split2.provenance = self.provenance\n    split1.provenance[\"source_labels\"] = self.provenance.get(\"filename\", None)\n    split2.provenance[\"source_labels\"] = self.provenance.get(\"filename\", None)\n\n    return split1, split2\n</code></pre>"},{"location":"model/#sleap_io.Labels.update","title":"<code>update()</code>","text":"<p>Update data structures based on contents.</p> <p>This function will update the list of skeletons, videos and tracks from the labeled frames, instances and suggestions.</p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def update(self):\n    \"\"\"Update data structures based on contents.\n\n    This function will update the list of skeletons, videos and tracks from the\n    labeled frames, instances and suggestions.\n    \"\"\"\n    for lf in self.labeled_frames:\n        if lf.video not in self.videos:\n            self.videos.append(lf.video)\n\n        for inst in lf:\n            if inst.skeleton not in self.skeletons:\n                self.skeletons.append(inst.skeleton)\n\n            if inst.track is not None and inst.track not in self.tracks:\n                self.tracks.append(inst.track)\n\n    for sf in self.suggestions:\n        if sf.video not in self.videos:\n            self.videos.append(sf.video)\n</code></pre>"},{"location":"model/#sleap_io.LabeledFrame","title":"<code>sleap_io.LabeledFrame</code>","text":"<p>Labeled data for a single frame of a video.</p> <p>Attributes:</p> Name Type Description <code>video</code> <code>Video</code> <p>The <code>Video</code> associated with this <code>LabeledFrame</code>.</p> <code>frame_idx</code> <code>int</code> <p>The index of the <code>LabeledFrame</code> in the <code>Video</code>.</p> <code>instances</code> <code>list[Union[Instance, PredictedInstance]]</code> <p>List of <code>Instance</code> objects associated with this <code>LabeledFrame</code>.</p> Notes <p>Instances of this class are hashed by identity, not by value. This means that two <code>LabeledFrame</code> instances with the same attributes will NOT be considered equal in a set or dict.</p> Source code in <code>sleap_io/model/labeled_frame.py</code> <pre><code>@define(eq=False)\nclass LabeledFrame:\n    \"\"\"Labeled data for a single frame of a video.\n\n    Attributes:\n        video: The `Video` associated with this `LabeledFrame`.\n        frame_idx: The index of the `LabeledFrame` in the `Video`.\n        instances: List of `Instance` objects associated with this `LabeledFrame`.\n\n    Notes:\n        Instances of this class are hashed by identity, not by value. This means that\n        two `LabeledFrame` instances with the same attributes will NOT be considered\n        equal in a set or dict.\n    \"\"\"\n\n    video: Video\n    frame_idx: int\n    instances: list[Union[Instance, PredictedInstance]] = field(factory=list)\n\n    def __len__(self) -&gt; int:\n        \"\"\"Return the number of instances in the frame.\"\"\"\n        return len(self.instances)\n\n    def __getitem__(self, key: int) -&gt; Union[Instance, PredictedInstance]:\n        \"\"\"Return the `Instance` at `key` index in the `instances` list.\"\"\"\n        return self.instances[key]\n\n    def __iter__(self):\n        \"\"\"Iterate over `Instance`s in `instances` list.\"\"\"\n        return iter(self.instances)\n\n    @property\n    def user_instances(self) -&gt; list[Instance]:\n        \"\"\"Frame instances that are user-labeled (`Instance` objects).\"\"\"\n        return [inst for inst in self.instances if type(inst) == Instance]\n\n    @property\n    def has_user_instances(self) -&gt; bool:\n        \"\"\"Return True if the frame has any user-labeled instances.\"\"\"\n        for inst in self.instances:\n            if type(inst) == Instance:\n                return True\n        return False\n\n    @property\n    def predicted_instances(self) -&gt; list[Instance]:\n        \"\"\"Frame instances that are predicted by a model (`PredictedInstance` objects).\"\"\"\n        return [inst for inst in self.instances if type(inst) == PredictedInstance]\n\n    @property\n    def has_predicted_instances(self) -&gt; bool:\n        \"\"\"Return True if the frame has any predicted instances.\"\"\"\n        for inst in self.instances:\n            if type(inst) == PredictedInstance:\n                return True\n        return False\n\n    def numpy(self) -&gt; np.ndarray:\n        \"\"\"Return all instances in the frame as a numpy array.\n\n        Returns:\n            Points as a numpy array of shape `(n_instances, n_nodes, 2)`.\n\n            Note that the order of the instances is arbitrary.\n        \"\"\"\n        n_instances = len(self.instances)\n        n_nodes = len(self.instances[0]) if n_instances &gt; 0 else 0\n        pts = np.full((n_instances, n_nodes, 2), np.nan)\n        for i, inst in enumerate(self.instances):\n            pts[i] = inst.numpy()[:, 0:2]\n        return pts\n\n    @property\n    def image(self) -&gt; np.ndarray:\n        \"\"\"Return the image of the frame as a numpy array.\"\"\"\n        return self.video[self.frame_idx]\n\n    @property\n    def unused_predictions(self) -&gt; list[Instance]:\n        \"\"\"Return a list of \"unused\" `PredictedInstance` objects in frame.\n\n        This is all of the `PredictedInstance` objects which do not have a corresponding\n        `Instance` in the same track in the same frame.\n        \"\"\"\n        unused_predictions = []\n        any_tracks = [inst.track for inst in self.instances if inst.track is not None]\n        if len(any_tracks):\n            # Use tracks to determine which predicted instances have been used\n            used_tracks = [\n                inst.track\n                for inst in self.instances\n                if type(inst) == Instance and inst.track is not None\n            ]\n            unused_predictions = [\n                inst\n                for inst in self.instances\n                if inst.track not in used_tracks and type(inst) == PredictedInstance\n            ]\n\n        else:\n            # Use from_predicted to determine which predicted instances have been used\n            # TODO: should we always do this instead of using tracks?\n            used_instances = [\n                inst.from_predicted\n                for inst in self.instances\n                if inst.from_predicted is not None\n            ]\n            unused_predictions = [\n                inst\n                for inst in self.instances\n                if type(inst) == PredictedInstance and inst not in used_instances\n            ]\n\n        return unused_predictions\n\n    def remove_predictions(self):\n        \"\"\"Remove all `PredictedInstance` objects from the frame.\"\"\"\n        self.instances = [inst for inst in self.instances if type(inst) == Instance]\n\n    def remove_empty_instances(self):\n        \"\"\"Remove all instances with no visible points.\"\"\"\n        self.instances = [inst for inst in self.instances if not inst.is_empty]\n</code></pre>"},{"location":"model/#sleap_io.LabeledFrame.has_predicted_instances","title":"<code>has_predicted_instances: bool</code>  <code>property</code>","text":"<p>Return True if the frame has any predicted instances.</p>"},{"location":"model/#sleap_io.LabeledFrame.has_user_instances","title":"<code>has_user_instances: bool</code>  <code>property</code>","text":"<p>Return True if the frame has any user-labeled instances.</p>"},{"location":"model/#sleap_io.LabeledFrame.image","title":"<code>image: np.ndarray</code>  <code>property</code>","text":"<p>Return the image of the frame as a numpy array.</p>"},{"location":"model/#sleap_io.LabeledFrame.predicted_instances","title":"<code>predicted_instances: list[Instance]</code>  <code>property</code>","text":"<p>Frame instances that are predicted by a model (<code>PredictedInstance</code> objects).</p>"},{"location":"model/#sleap_io.LabeledFrame.unused_predictions","title":"<code>unused_predictions: list[Instance]</code>  <code>property</code>","text":"<p>Return a list of \"unused\" <code>PredictedInstance</code> objects in frame.</p> <p>This is all of the <code>PredictedInstance</code> objects which do not have a corresponding <code>Instance</code> in the same track in the same frame.</p>"},{"location":"model/#sleap_io.LabeledFrame.user_instances","title":"<code>user_instances: list[Instance]</code>  <code>property</code>","text":"<p>Frame instances that are user-labeled (<code>Instance</code> objects).</p>"},{"location":"model/#sleap_io.LabeledFrame.__getitem__","title":"<code>__getitem__(key)</code>","text":"<p>Return the <code>Instance</code> at <code>key</code> index in the <code>instances</code> list.</p> Source code in <code>sleap_io/model/labeled_frame.py</code> <pre><code>def __getitem__(self, key: int) -&gt; Union[Instance, PredictedInstance]:\n    \"\"\"Return the `Instance` at `key` index in the `instances` list.\"\"\"\n    return self.instances[key]\n</code></pre>"},{"location":"model/#sleap_io.LabeledFrame.__iter__","title":"<code>__iter__()</code>","text":"<p>Iterate over <code>Instance</code>s in <code>instances</code> list.</p> Source code in <code>sleap_io/model/labeled_frame.py</code> <pre><code>def __iter__(self):\n    \"\"\"Iterate over `Instance`s in `instances` list.\"\"\"\n    return iter(self.instances)\n</code></pre>"},{"location":"model/#sleap_io.LabeledFrame.__len__","title":"<code>__len__()</code>","text":"<p>Return the number of instances in the frame.</p> Source code in <code>sleap_io/model/labeled_frame.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"Return the number of instances in the frame.\"\"\"\n    return len(self.instances)\n</code></pre>"},{"location":"model/#sleap_io.LabeledFrame.numpy","title":"<code>numpy()</code>","text":"<p>Return all instances in the frame as a numpy array.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>Points as a numpy array of shape <code>(n_instances, n_nodes, 2)</code>.</p> <p>Note that the order of the instances is arbitrary.</p> Source code in <code>sleap_io/model/labeled_frame.py</code> <pre><code>def numpy(self) -&gt; np.ndarray:\n    \"\"\"Return all instances in the frame as a numpy array.\n\n    Returns:\n        Points as a numpy array of shape `(n_instances, n_nodes, 2)`.\n\n        Note that the order of the instances is arbitrary.\n    \"\"\"\n    n_instances = len(self.instances)\n    n_nodes = len(self.instances[0]) if n_instances &gt; 0 else 0\n    pts = np.full((n_instances, n_nodes, 2), np.nan)\n    for i, inst in enumerate(self.instances):\n        pts[i] = inst.numpy()[:, 0:2]\n    return pts\n</code></pre>"},{"location":"model/#sleap_io.LabeledFrame.remove_empty_instances","title":"<code>remove_empty_instances()</code>","text":"<p>Remove all instances with no visible points.</p> Source code in <code>sleap_io/model/labeled_frame.py</code> <pre><code>def remove_empty_instances(self):\n    \"\"\"Remove all instances with no visible points.\"\"\"\n    self.instances = [inst for inst in self.instances if not inst.is_empty]\n</code></pre>"},{"location":"model/#sleap_io.LabeledFrame.remove_predictions","title":"<code>remove_predictions()</code>","text":"<p>Remove all <code>PredictedInstance</code> objects from the frame.</p> Source code in <code>sleap_io/model/labeled_frame.py</code> <pre><code>def remove_predictions(self):\n    \"\"\"Remove all `PredictedInstance` objects from the frame.\"\"\"\n    self.instances = [inst for inst in self.instances if type(inst) == Instance]\n</code></pre>"},{"location":"model/#sleap_io.Instance","title":"<code>sleap_io.Instance</code>","text":"<p>This class represents a ground truth instance such as an animal.</p> <p>An <code>Instance</code> has a set of landmarks (<code>Point</code>s) that correspond to the nodes defined in its <code>Skeleton</code>.</p> <p>It may also be associated with a <code>Track</code> which links multiple instances together across frames or videos.</p> <p>Attributes:</p> Name Type Description <code>points</code> <code>Union[dict[Node, Point], dict[Node, PredictedPoint]]</code> <p>A dictionary with keys as <code>Node</code>s and values as <code>Point</code>s containing all of the landmarks of the instance. This can also be specified as a dictionary with node names, a list of length <code>n_nodes</code>, or a numpy array of shape <code>(n_nodes, 2)</code>.</p> <code>skeleton</code> <code>Skeleton</code> <p>The <code>Skeleton</code> that describes the <code>Node</code>s and <code>Edge</code>s associated with this instance.</p> <code>track</code> <code>Optional[Track]</code> <p>An optional <code>Track</code> associated with a unique animal/object across frames or videos.</p> <code>from_predicted</code> <code>Optional[PredictedInstance]</code> <p>The <code>PredictedInstance</code> (if any) that this instance was initialized from. This is used with human-in-the-loop workflows.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>@define(auto_attribs=True, slots=True, eq=True)\nclass Instance:\n    \"\"\"This class represents a ground truth instance such as an animal.\n\n    An `Instance` has a set of landmarks (`Point`s) that correspond to the nodes defined\n    in its `Skeleton`.\n\n    It may also be associated with a `Track` which links multiple instances together\n    across frames or videos.\n\n    Attributes:\n        points: A dictionary with keys as `Node`s and values as `Point`s containing all\n            of the landmarks of the instance. This can also be specified as a dictionary\n            with node names, a list of length `n_nodes`, or a numpy array of shape\n            `(n_nodes, 2)`.\n        skeleton: The `Skeleton` that describes the `Node`s and `Edge`s associated with\n            this instance.\n        track: An optional `Track` associated with a unique animal/object across frames\n            or videos.\n        from_predicted: The `PredictedInstance` (if any) that this instance was\n            initialized from. This is used with human-in-the-loop workflows.\n    \"\"\"\n\n    _POINT_TYPE = Point\n\n    def _make_default_point(self, x, y):\n        return self._POINT_TYPE(x, y, visible=not (math.isnan(x) or math.isnan(y)))\n\n    def _convert_points(self, attr, points):\n        \"\"\"Maintain points mappings between nodes and points.\"\"\"\n        if type(points) == np.ndarray:\n            points = points.tolist()\n\n        if type(points) == list:\n            if len(points) != len(self.skeleton):\n                raise ValueError(\n                    \"If specifying points as a list, must provide as many points as \"\n                    \"nodes in the skeleton.\"\n                )\n            points = {node: pt for node, pt in zip(self.skeleton.nodes, points)}\n\n        if type(points) == dict:\n            keys = [\n                node if type(node) == Node else self.skeleton[node]\n                for node in points.keys()\n            ]\n            vals = [\n                (\n                    point\n                    if type(point) == self._POINT_TYPE\n                    else self._make_default_point(*point)\n                )\n                for point in points.values()\n            ]\n            points = {k: v for k, v in zip(keys, vals)}\n\n        missing_nodes = list(set(self.skeleton.nodes) - set(points.keys()))\n        for node in missing_nodes:\n            points[node] = self._make_default_point(x=np.nan, y=np.nan)\n\n        return points\n\n    points: Union[dict[Node, Point], dict[Node, PredictedPoint]] = field(\n        on_setattr=_convert_points, eq=cmp_using(eq=_compare_points)  # type: ignore\n    )\n    skeleton: Skeleton\n    track: Optional[Track] = None\n    from_predicted: Optional[PredictedInstance] = None\n\n    def __attrs_post_init__(self):\n        \"\"\"Maintain point mappings between node and points after initialization.\"\"\"\n        super().__setattr__(\"points\", self._convert_points(None, self.points))\n\n    def __getitem__(self, node: Union[int, str, Node]) -&gt; Optional[Point]:\n        \"\"\"Return the point associated with a node or `None` if not set.\"\"\"\n        if (type(node) == int) or (type(node) == str):\n            node = self.skeleton[node]\n        if isinstance(node, Node):\n            return self.points.get(node, None)\n        else:\n            raise IndexError(f\"Invalid indexing argument for instance: {node}\")\n\n    def __len__(self) -&gt; int:\n        \"\"\"Return the number of points in the instance.\"\"\"\n        return len(self.points)\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return a readable representation of the instance.\"\"\"\n        pts = self.numpy().tolist()\n        track = f'\"{self.track.name}\"' if self.track is not None else self.track\n\n        return f\"Instance(points={pts}, track={track})\"\n\n    @property\n    def n_visible(self) -&gt; int:\n        \"\"\"Return the number of visible points in the instance.\"\"\"\n        return sum(pt.visible for pt in self.points.values())\n\n    @property\n    def is_empty(self) -&gt; bool:\n        \"\"\"Return `True` if no points are visible on the instance.\"\"\"\n        return self.n_visible == 0\n\n    @classmethod\n    def from_numpy(\n        cls, points: np.ndarray, skeleton: Skeleton, track: Optional[Track] = None\n    ) -&gt; \"Instance\":\n        \"\"\"Create an instance object from a numpy array.\n\n        Args:\n            points: A numpy array of shape `(n_nodes, 2)` corresponding to the points of\n                the skeleton. Values of `np.nan` indicate \"missing\" nodes.\n            skeleton: The `Skeleton` that this `Instance` is associated with. It should\n                have `n_nodes` nodes.\n            track: An optional `Track` associated with a unique animal/object across\n                frames or videos.\n        \"\"\"\n        return cls(\n            points=points, skeleton=skeleton, track=track  # type: ignore[arg-type]\n        )\n\n    def numpy(self) -&gt; np.ndarray:\n        \"\"\"Return the instance points as a numpy array.\"\"\"\n        pts = np.full((len(self.skeleton), 2), np.nan)\n        for node, point in self.points.items():\n            if point.visible:\n                pts[self.skeleton.index(node)] = point.numpy()\n        return pts\n</code></pre>"},{"location":"model/#sleap_io.Instance.is_empty","title":"<code>is_empty: bool</code>  <code>property</code>","text":"<p>Return <code>True</code> if no points are visible on the instance.</p>"},{"location":"model/#sleap_io.Instance.n_visible","title":"<code>n_visible: int</code>  <code>property</code>","text":"<p>Return the number of visible points in the instance.</p>"},{"location":"model/#sleap_io.Instance.__attrs_post_init__","title":"<code>__attrs_post_init__()</code>","text":"<p>Maintain point mappings between node and points after initialization.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>def __attrs_post_init__(self):\n    \"\"\"Maintain point mappings between node and points after initialization.\"\"\"\n    super().__setattr__(\"points\", self._convert_points(None, self.points))\n</code></pre>"},{"location":"model/#sleap_io.Instance.__getitem__","title":"<code>__getitem__(node)</code>","text":"<p>Return the point associated with a node or <code>None</code> if not set.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>def __getitem__(self, node: Union[int, str, Node]) -&gt; Optional[Point]:\n    \"\"\"Return the point associated with a node or `None` if not set.\"\"\"\n    if (type(node) == int) or (type(node) == str):\n        node = self.skeleton[node]\n    if isinstance(node, Node):\n        return self.points.get(node, None)\n    else:\n        raise IndexError(f\"Invalid indexing argument for instance: {node}\")\n</code></pre>"},{"location":"model/#sleap_io.Instance.__len__","title":"<code>__len__()</code>","text":"<p>Return the number of points in the instance.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"Return the number of points in the instance.\"\"\"\n    return len(self.points)\n</code></pre>"},{"location":"model/#sleap_io.Instance.__repr__","title":"<code>__repr__()</code>","text":"<p>Return a readable representation of the instance.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return a readable representation of the instance.\"\"\"\n    pts = self.numpy().tolist()\n    track = f'\"{self.track.name}\"' if self.track is not None else self.track\n\n    return f\"Instance(points={pts}, track={track})\"\n</code></pre>"},{"location":"model/#sleap_io.Instance.from_numpy","title":"<code>from_numpy(points, skeleton, track=None)</code>  <code>classmethod</code>","text":"<p>Create an instance object from a numpy array.</p> <p>Parameters:</p> Name Type Description Default <code>points</code> <code>ndarray</code> <p>A numpy array of shape <code>(n_nodes, 2)</code> corresponding to the points of the skeleton. Values of <code>np.nan</code> indicate \"missing\" nodes.</p> required <code>skeleton</code> <code>Skeleton</code> <p>The <code>Skeleton</code> that this <code>Instance</code> is associated with. It should have <code>n_nodes</code> nodes.</p> required <code>track</code> <code>Optional[Track]</code> <p>An optional <code>Track</code> associated with a unique animal/object across frames or videos.</p> <code>None</code> Source code in <code>sleap_io/model/instance.py</code> <pre><code>@classmethod\ndef from_numpy(\n    cls, points: np.ndarray, skeleton: Skeleton, track: Optional[Track] = None\n) -&gt; \"Instance\":\n    \"\"\"Create an instance object from a numpy array.\n\n    Args:\n        points: A numpy array of shape `(n_nodes, 2)` corresponding to the points of\n            the skeleton. Values of `np.nan` indicate \"missing\" nodes.\n        skeleton: The `Skeleton` that this `Instance` is associated with. It should\n            have `n_nodes` nodes.\n        track: An optional `Track` associated with a unique animal/object across\n            frames or videos.\n    \"\"\"\n    return cls(\n        points=points, skeleton=skeleton, track=track  # type: ignore[arg-type]\n    )\n</code></pre>"},{"location":"model/#sleap_io.Instance.numpy","title":"<code>numpy()</code>","text":"<p>Return the instance points as a numpy array.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>def numpy(self) -&gt; np.ndarray:\n    \"\"\"Return the instance points as a numpy array.\"\"\"\n    pts = np.full((len(self.skeleton), 2), np.nan)\n    for node, point in self.points.items():\n        if point.visible:\n            pts[self.skeleton.index(node)] = point.numpy()\n    return pts\n</code></pre>"},{"location":"model/#sleap_io.PredictedInstance","title":"<code>sleap_io.PredictedInstance</code>","text":"<p>             Bases: <code>Instance</code></p> <p>A <code>PredictedInstance</code> is an <code>Instance</code> that was predicted using a model.</p> <p>Attributes:</p> Name Type Description <code>skeleton</code> <p>The <code>Skeleton</code> that this <code>Instance</code> is associated with.</p> <code>points</code> <p>A dictionary where keys are <code>Skeleton</code> nodes and values are <code>Point</code>s.</p> <code>track</code> <p>An optional <code>Track</code> associated with a unique animal/object across frames or videos.</p> <code>from_predicted</code> <code>Optional[PredictedInstance]</code> <p>Not applicable in <code>PredictedInstance</code>s (must be set to <code>None</code>).</p> <code>score</code> <code>float</code> <p>The instance detection or part grouping prediction score. This is a scalar that represents the confidence with which this entire instance was predicted. This may not always be applicable depending on the model type.</p> <code>tracking_score</code> <code>Optional[float]</code> <p>The score associated with the <code>Track</code> assignment. This is typically the value from the score matrix used in an identity assignment.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>@define\nclass PredictedInstance(Instance):\n    \"\"\"A `PredictedInstance` is an `Instance` that was predicted using a model.\n\n    Attributes:\n        skeleton: The `Skeleton` that this `Instance` is associated with.\n        points: A dictionary where keys are `Skeleton` nodes and values are `Point`s.\n        track: An optional `Track` associated with a unique animal/object across frames\n            or videos.\n        from_predicted: Not applicable in `PredictedInstance`s (must be set to `None`).\n        score: The instance detection or part grouping prediction score. This is a\n            scalar that represents the confidence with which this entire instance was\n            predicted. This may not always be applicable depending on the model type.\n        tracking_score: The score associated with the `Track` assignment. This is\n            typically the value from the score matrix used in an identity assignment.\n    \"\"\"\n\n    _POINT_TYPE = PredictedPoint\n\n    from_predicted: Optional[PredictedInstance] = field(\n        default=None, validator=validators.instance_of(type(None))\n    )\n    score: float = 0.0\n    tracking_score: Optional[float] = 0\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return a readable representation of the instance.\"\"\"\n        pts = self.numpy().tolist()\n        track = f'\"{self.track.name}\"' if self.track is not None else self.track\n\n        score = str(self.score) if self.score is None else f\"{self.score:.2f}\"\n        tracking_score = (\n            str(self.tracking_score)\n            if self.tracking_score is None\n            else f\"{self.tracking_score:.2f}\"\n        )\n        return (\n            f\"PredictedInstance(points={pts}, track={track}, \"\n            f\"score={score}, tracking_score={tracking_score})\"\n        )\n\n    @classmethod\n    def from_numpy(  # type: ignore[override]\n        cls,\n        points: np.ndarray,\n        point_scores: np.ndarray,\n        instance_score: float,\n        skeleton: Skeleton,\n        tracking_score: Optional[float] = None,\n        track: Optional[Track] = None,\n    ) -&gt; \"PredictedInstance\":\n        \"\"\"Create an instance object from a numpy array.\n\n        Args:\n            points: A numpy array of shape `(n_nodes, 2)` corresponding to the points of\n                the skeleton. Values of `np.nan` indicate \"missing\" nodes.\n            point_scores: The points-level prediction score. This is an array that\n                represents the confidence with which each point in the instance was\n                predicted. This may not always be applicable depending on the model\n                type.\n            instance_score: The instance detection or part grouping prediction score.\n                This is a scalar that represents the confidence with which this entire\n                instance was predicted. This may not always be applicable depending on\n                the model type.\n            skeleton: The `Skeleton` that this `Instance` is associated with. It should\n                have `n_nodes` nodes.\n            tracking_score: The score associated with the `Track` assignment. This is\n                typically the value from the score matrix used in an identity\n                assignment.\n            track: An optional `Track` associated with a unique animal/object across\n                frames or videos.\n        \"\"\"\n        node_points = {\n            node: PredictedPoint(pt[0], pt[1], score=score)\n            for node, pt, score in zip(skeleton.nodes, points, point_scores)\n        }\n        return cls(\n            points=node_points,\n            skeleton=skeleton,\n            score=instance_score,\n            tracking_score=tracking_score,\n            track=track,\n        )\n\n    def numpy(self, scores: bool = False) -&gt; np.ndarray:\n        \"\"\"Return the instance points as a numpy array.\"\"\"\n        pts = np.full((len(self.skeleton), 3), np.nan)\n        for node, point in self.points.items():\n            if point.visible:\n                pts[self.skeleton.index(node)] = point.numpy()\n        if not scores:\n            pts = pts[:, :2]\n        return pts\n</code></pre>"},{"location":"model/#sleap_io.PredictedInstance.__repr__","title":"<code>__repr__()</code>","text":"<p>Return a readable representation of the instance.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return a readable representation of the instance.\"\"\"\n    pts = self.numpy().tolist()\n    track = f'\"{self.track.name}\"' if self.track is not None else self.track\n\n    score = str(self.score) if self.score is None else f\"{self.score:.2f}\"\n    tracking_score = (\n        str(self.tracking_score)\n        if self.tracking_score is None\n        else f\"{self.tracking_score:.2f}\"\n    )\n    return (\n        f\"PredictedInstance(points={pts}, track={track}, \"\n        f\"score={score}, tracking_score={tracking_score})\"\n    )\n</code></pre>"},{"location":"model/#sleap_io.PredictedInstance.from_numpy","title":"<code>from_numpy(points, point_scores, instance_score, skeleton, tracking_score=None, track=None)</code>  <code>classmethod</code>","text":"<p>Create an instance object from a numpy array.</p> <p>Parameters:</p> Name Type Description Default <code>points</code> <code>ndarray</code> <p>A numpy array of shape <code>(n_nodes, 2)</code> corresponding to the points of the skeleton. Values of <code>np.nan</code> indicate \"missing\" nodes.</p> required <code>point_scores</code> <code>ndarray</code> <p>The points-level prediction score. This is an array that represents the confidence with which each point in the instance was predicted. This may not always be applicable depending on the model type.</p> required <code>instance_score</code> <code>float</code> <p>The instance detection or part grouping prediction score. This is a scalar that represents the confidence with which this entire instance was predicted. This may not always be applicable depending on the model type.</p> required <code>skeleton</code> <code>Skeleton</code> <p>The <code>Skeleton</code> that this <code>Instance</code> is associated with. It should have <code>n_nodes</code> nodes.</p> required <code>tracking_score</code> <code>Optional[float]</code> <p>The score associated with the <code>Track</code> assignment. This is typically the value from the score matrix used in an identity assignment.</p> <code>None</code> <code>track</code> <code>Optional[Track]</code> <p>An optional <code>Track</code> associated with a unique animal/object across frames or videos.</p> <code>None</code> Source code in <code>sleap_io/model/instance.py</code> <pre><code>@classmethod\ndef from_numpy(  # type: ignore[override]\n    cls,\n    points: np.ndarray,\n    point_scores: np.ndarray,\n    instance_score: float,\n    skeleton: Skeleton,\n    tracking_score: Optional[float] = None,\n    track: Optional[Track] = None,\n) -&gt; \"PredictedInstance\":\n    \"\"\"Create an instance object from a numpy array.\n\n    Args:\n        points: A numpy array of shape `(n_nodes, 2)` corresponding to the points of\n            the skeleton. Values of `np.nan` indicate \"missing\" nodes.\n        point_scores: The points-level prediction score. This is an array that\n            represents the confidence with which each point in the instance was\n            predicted. This may not always be applicable depending on the model\n            type.\n        instance_score: The instance detection or part grouping prediction score.\n            This is a scalar that represents the confidence with which this entire\n            instance was predicted. This may not always be applicable depending on\n            the model type.\n        skeleton: The `Skeleton` that this `Instance` is associated with. It should\n            have `n_nodes` nodes.\n        tracking_score: The score associated with the `Track` assignment. This is\n            typically the value from the score matrix used in an identity\n            assignment.\n        track: An optional `Track` associated with a unique animal/object across\n            frames or videos.\n    \"\"\"\n    node_points = {\n        node: PredictedPoint(pt[0], pt[1], score=score)\n        for node, pt, score in zip(skeleton.nodes, points, point_scores)\n    }\n    return cls(\n        points=node_points,\n        skeleton=skeleton,\n        score=instance_score,\n        tracking_score=tracking_score,\n        track=track,\n    )\n</code></pre>"},{"location":"model/#sleap_io.PredictedInstance.numpy","title":"<code>numpy(scores=False)</code>","text":"<p>Return the instance points as a numpy array.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>def numpy(self, scores: bool = False) -&gt; np.ndarray:\n    \"\"\"Return the instance points as a numpy array.\"\"\"\n    pts = np.full((len(self.skeleton), 3), np.nan)\n    for node, point in self.points.items():\n        if point.visible:\n            pts[self.skeleton.index(node)] = point.numpy()\n    if not scores:\n        pts = pts[:, :2]\n    return pts\n</code></pre>"},{"location":"model/#sleap_io.Point","title":"<code>sleap_io.Point</code>","text":"<p>A 2D spatial landmark and metadata associated with annotation.</p> <p>Attributes:</p> Name Type Description <code>x</code> <code>float</code> <p>The horizontal pixel location of point in image coordinates.</p> <code>y</code> <code>float</code> <p>The vertical pixel location of point in image coordinates.</p> <code>visible</code> <code>bool</code> <p>Whether point is visible in the image or not.</p> <code>complete</code> <code>bool</code> <p>Has the point been verified by the user labeler.</p> Class variables <p>eq_atol: Controls absolute tolerence allowed in <code>x</code> and <code>y</code> when comparing two     <code>Point</code>s for equality. eq_rtol: Controls relative tolerence allowed in <code>x</code> and <code>y</code> when comparing two     <code>Point</code>s for equality.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>@define\nclass Point:\n    \"\"\"A 2D spatial landmark and metadata associated with annotation.\n\n    Attributes:\n        x: The horizontal pixel location of point in image coordinates.\n        y: The vertical pixel location of point in image coordinates.\n        visible: Whether point is visible in the image or not.\n        complete: Has the point been verified by the user labeler.\n\n    Class variables:\n        eq_atol: Controls absolute tolerence allowed in `x` and `y` when comparing two\n            `Point`s for equality.\n        eq_rtol: Controls relative tolerence allowed in `x` and `y` when comparing two\n            `Point`s for equality.\n\n    \"\"\"\n\n    eq_atol: ClassVar[float] = 1e-08\n    eq_rtol: ClassVar[float] = 0\n\n    x: float\n    y: float\n    visible: bool = True\n    complete: bool = False\n\n    def __eq__(self, other: object) -&gt; bool:\n        \"\"\"Compare `self` and `other` for equality.\n\n        Precision error between the respective `x` and `y` properties of two\n        instances may be allowed or controlled via the `Point.eq_atol` and\n        `Point.eq_rtol` class variables. Set to zero to disable their effect.\n        Internally, `numpy.isclose()` is used for the comparison:\n        https://numpy.org/doc/stable/reference/generated/numpy.isclose.html\n\n        Args:\n            other: Instance of `Point` to compare to.\n\n        Returns:\n            Returns True if all attributes of `self` and `other` are the identical\n                (possibly allowing precision error for `x` and `y` attributes).\n        \"\"\"\n        # Check that other is a Point.\n        if type(other) is not type(self):\n            return False\n\n        # We know that we have some kind of point at this point.\n        other = cast(Point, other)\n\n        return bool(\n            np.all(\n                np.isclose(\n                    [self.x, self.y],\n                    [other.x, other.y],\n                    rtol=Point.eq_rtol,\n                    atol=Point.eq_atol,\n                    equal_nan=True,\n                )\n            )\n            and (self.visible == other.visible)\n            and (self.complete == other.complete)\n        )\n\n    def numpy(self) -&gt; np.ndarray:\n        \"\"\"Return the coordinates as a numpy array of shape `(2,)`.\"\"\"\n        return np.array([self.x, self.y]) if self.visible else np.full((2,), np.nan)\n</code></pre>"},{"location":"model/#sleap_io.Point.__eq__","title":"<code>__eq__(other)</code>","text":"<p>Compare <code>self</code> and <code>other</code> for equality.</p> <p>Precision error between the respective <code>x</code> and <code>y</code> properties of two instances may be allowed or controlled via the <code>Point.eq_atol</code> and <code>Point.eq_rtol</code> class variables. Set to zero to disable their effect. Internally, <code>numpy.isclose()</code> is used for the comparison: https://numpy.org/doc/stable/reference/generated/numpy.isclose.html</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>object</code> <p>Instance of <code>Point</code> to compare to.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>Returns True if all attributes of <code>self</code> and <code>other</code> are the identical     (possibly allowing precision error for <code>x</code> and <code>y</code> attributes).</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>def __eq__(self, other: object) -&gt; bool:\n    \"\"\"Compare `self` and `other` for equality.\n\n    Precision error between the respective `x` and `y` properties of two\n    instances may be allowed or controlled via the `Point.eq_atol` and\n    `Point.eq_rtol` class variables. Set to zero to disable their effect.\n    Internally, `numpy.isclose()` is used for the comparison:\n    https://numpy.org/doc/stable/reference/generated/numpy.isclose.html\n\n    Args:\n        other: Instance of `Point` to compare to.\n\n    Returns:\n        Returns True if all attributes of `self` and `other` are the identical\n            (possibly allowing precision error for `x` and `y` attributes).\n    \"\"\"\n    # Check that other is a Point.\n    if type(other) is not type(self):\n        return False\n\n    # We know that we have some kind of point at this point.\n    other = cast(Point, other)\n\n    return bool(\n        np.all(\n            np.isclose(\n                [self.x, self.y],\n                [other.x, other.y],\n                rtol=Point.eq_rtol,\n                atol=Point.eq_atol,\n                equal_nan=True,\n            )\n        )\n        and (self.visible == other.visible)\n        and (self.complete == other.complete)\n    )\n</code></pre>"},{"location":"model/#sleap_io.Point.numpy","title":"<code>numpy()</code>","text":"<p>Return the coordinates as a numpy array of shape <code>(2,)</code>.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>def numpy(self) -&gt; np.ndarray:\n    \"\"\"Return the coordinates as a numpy array of shape `(2,)`.\"\"\"\n    return np.array([self.x, self.y]) if self.visible else np.full((2,), np.nan)\n</code></pre>"},{"location":"model/#sleap_io.PredictedPoint","title":"<code>sleap_io.PredictedPoint</code>","text":"<p>             Bases: <code>Point</code></p> <p>A predicted point with associated score generated by a prediction model.</p> <p>It has all the properties of a labeled <code>Point</code>, plus a <code>score</code>.</p> <p>Attributes:</p> Name Type Description <code>x</code> <p>The horizontal pixel location of point within image frame.</p> <code>y</code> <p>The vertical pixel location of point within image frame.</p> <code>visible</code> <p>Whether point is visible in the image or not.</p> <code>complete</code> <p>Has the point been verified by the user labeler.</p> <code>score</code> <code>float</code> <p>The point-level prediction score. This is typically the confidence and set to a value between 0 and 1.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>@define\nclass PredictedPoint(Point):\n    \"\"\"A predicted point with associated score generated by a prediction model.\n\n    It has all the properties of a labeled `Point`, plus a `score`.\n\n    Attributes:\n        x: The horizontal pixel location of point within image frame.\n        y: The vertical pixel location of point within image frame.\n        visible: Whether point is visible in the image or not.\n        complete: Has the point been verified by the user labeler.\n        score: The point-level prediction score. This is typically the confidence and\n            set to a value between 0 and 1.\n    \"\"\"\n\n    score: float = 0.0\n\n    def numpy(self) -&gt; np.ndarray:\n        \"\"\"Return the coordinates and score as a numpy array of shape `(3,)`.\"\"\"\n        return (\n            np.array([self.x, self.y, self.score])\n            if self.visible\n            else np.full((3,), np.nan)\n        )\n\n    def __eq__(self, other: object) -&gt; bool:\n        \"\"\"Compare `self` and `other` for equality.\n\n        See `Point.__eq__()` for important notes about point equality semantics!\n\n        Args:\n            other: Instance of `PredictedPoint` to compare\n\n        Returns:\n            Returns True if all attributes of `self` and `other` are the identical\n                (possibly allowing precision error for `x` and `y` attributes).\n        \"\"\"\n        if not super().__eq__(other):\n            return False\n\n        # we know that we have a point at this point\n        other = cast(PredictedPoint, other)\n\n        return self.score == other.score\n</code></pre>"},{"location":"model/#sleap_io.PredictedPoint.__eq__","title":"<code>__eq__(other)</code>","text":"<p>Compare <code>self</code> and <code>other</code> for equality.</p> <p>See <code>Point.__eq__()</code> for important notes about point equality semantics!</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>object</code> <p>Instance of <code>PredictedPoint</code> to compare</p> required <p>Returns:</p> Type Description <code>bool</code> <p>Returns True if all attributes of <code>self</code> and <code>other</code> are the identical     (possibly allowing precision error for <code>x</code> and <code>y</code> attributes).</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>def __eq__(self, other: object) -&gt; bool:\n    \"\"\"Compare `self` and `other` for equality.\n\n    See `Point.__eq__()` for important notes about point equality semantics!\n\n    Args:\n        other: Instance of `PredictedPoint` to compare\n\n    Returns:\n        Returns True if all attributes of `self` and `other` are the identical\n            (possibly allowing precision error for `x` and `y` attributes).\n    \"\"\"\n    if not super().__eq__(other):\n        return False\n\n    # we know that we have a point at this point\n    other = cast(PredictedPoint, other)\n\n    return self.score == other.score\n</code></pre>"},{"location":"model/#sleap_io.PredictedPoint.numpy","title":"<code>numpy()</code>","text":"<p>Return the coordinates and score as a numpy array of shape <code>(3,)</code>.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>def numpy(self) -&gt; np.ndarray:\n    \"\"\"Return the coordinates and score as a numpy array of shape `(3,)`.\"\"\"\n    return (\n        np.array([self.x, self.y, self.score])\n        if self.visible\n        else np.full((3,), np.nan)\n    )\n</code></pre>"},{"location":"model/#sleap_io.Skeleton","title":"<code>sleap_io.Skeleton</code>","text":"<p>A description of a set of landmark types and connections between them.</p> <p>Skeletons are represented by a directed graph composed of a set of <code>Node</code>s (landmark types such as body parts) and <code>Edge</code>s (connections between parts).</p> <p>Attributes:</p> Name Type Description <code>nodes</code> <code>list[Node]</code> <p>A list of <code>Node</code>s. May be specified as a list of strings to create new nodes from their names.</p> <code>edges</code> <code>list[Edge]</code> <p>A list of <code>Edge</code>s. May be specified as a list of 2-tuples of string names or integer indices of <code>nodes</code>. Each edge corresponds to a pair of source and destination nodes forming a directed edge.</p> <code>symmetries</code> <code>list[Symmetry]</code> <p>A list of <code>Symmetry</code>s. Each symmetry corresponds to symmetric body parts, such as <code>\"left eye\", \"right eye\"</code>. This is used when applying flip (reflection) augmentation to images in order to appropriately swap the indices of symmetric landmarks.</p> <code>name</code> <code>Optional[str]</code> <p>A descriptive name for the <code>Skeleton</code>.</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>@define\nclass Skeleton:\n    \"\"\"A description of a set of landmark types and connections between them.\n\n    Skeletons are represented by a directed graph composed of a set of `Node`s (landmark\n    types such as body parts) and `Edge`s (connections between parts).\n\n    Attributes:\n        nodes: A list of `Node`s. May be specified as a list of strings to create new\n            nodes from their names.\n        edges: A list of `Edge`s. May be specified as a list of 2-tuples of string names\n            or integer indices of `nodes`. Each edge corresponds to a pair of source and\n            destination nodes forming a directed edge.\n        symmetries: A list of `Symmetry`s. Each symmetry corresponds to symmetric body\n            parts, such as `\"left eye\", \"right eye\"`. This is used when applying flip\n            (reflection) augmentation to images in order to appropriately swap the\n            indices of symmetric landmarks.\n        name: A descriptive name for the `Skeleton`.\n    \"\"\"\n\n    def _update_node_map(self, attr, nodes):\n        \"\"\"Callback for maintaining node name/index to `Node` map.\"\"\"\n        self._node_name_map = {node.name: node for node in nodes}\n        self._node_ind_map = {node: i for i, node in enumerate(nodes)}\n\n    nodes: list[Node] = field(factory=list, on_setattr=_update_node_map)\n    edges: list[Edge] = field(factory=list)\n    symmetries: list[Symmetry] = field(factory=list)\n    name: Optional[str] = None\n    _node_name_map: dict[str, Node] = field(init=False, repr=False, eq=False)\n    _node_ind_map: dict[Node, int] = field(init=False, repr=False, eq=False)\n\n    def __attrs_post_init__(self):\n        \"\"\"Ensure nodes are `Node`s, edges are `Edge`s, and `Node` map is updated.\"\"\"\n        self._convert_nodes()\n        self._convert_edges()\n        self._update_node_map(None, self.nodes)\n\n    def _convert_nodes(self):\n        \"\"\"Convert nodes to `Node` objects if needed.\"\"\"\n        if isinstance(self.nodes, np.ndarray):\n            object.__setattr__(self, \"nodes\", self.nodes.tolist())\n        for i, node in enumerate(self.nodes):\n            if type(node) == str:\n                self.nodes[i] = Node(node)\n\n    def _convert_edges(self):\n        \"\"\"Convert list of edge names or integers to `Edge` objects if needed.\"\"\"\n        if isinstance(self.edges, np.ndarray):\n            self.edges = self.edges.tolist()\n        node_names = self.node_names\n        for i, edge in enumerate(self.edges):\n            if type(edge) == Edge:\n                continue\n            src, dst = edge\n            if type(src) == str:\n                try:\n                    src = node_names.index(src)\n                except ValueError:\n                    raise ValueError(\n                        f\"Node '{src}' specified in the edge list is not in the nodes.\"\n                    )\n            if type(src) == int or (\n                np.isscalar(src) and np.issubdtype(src.dtype, np.integer)\n            ):\n                src = self.nodes[src]\n\n            if type(dst) == str:\n                try:\n                    dst = node_names.index(dst)\n                except ValueError:\n                    raise ValueError(\n                        f\"Node '{dst}' specified in the edge list is not in the nodes.\"\n                    )\n            if type(dst) == int or (\n                np.isscalar(dst) and np.issubdtype(dst.dtype, np.integer)\n            ):\n                dst = self.nodes[dst]\n\n            self.edges[i] = Edge(src, dst)\n\n    @property\n    def node_names(self) -&gt; list[str]:\n        \"\"\"Names of the nodes associated with this skeleton as a list of strings.\"\"\"\n        return [node.name for node in self.nodes]\n\n    @property\n    def edge_inds(self) -&gt; list[Tuple[int, int]]:\n        \"\"\"Edges indices as a list of 2-tuples.\"\"\"\n        return [\n            (self.nodes.index(edge.source), self.nodes.index(edge.destination))\n            for edge in self.edges\n        ]\n\n    @property\n    def edge_names(self) -&gt; list[str, str]:\n        \"\"\"Edge names as a list of 2-tuples with string node names.\"\"\"\n        return [(edge.source.name, edge.destination.name) for edge in self.edges]\n\n    @property\n    def flipped_node_inds(self) -&gt; list[int]:\n        \"\"\"Returns node indices that should be switched when horizontally flipping.\"\"\"\n        flip_idx = np.arange(len(self.nodes))\n        if len(self.symmetries) &gt; 0:\n            symmetry_inds = np.array(\n                [(self.index(a), self.index(b)) for a, b in self.symmetries]\n            )\n            flip_idx[symmetry_inds[:, 0]] = symmetry_inds[:, 1]\n            flip_idx[symmetry_inds[:, 1]] = symmetry_inds[:, 0]\n\n        flip_idx = flip_idx.tolist()\n        return flip_idx\n\n    def __len__(self) -&gt; int:\n        \"\"\"Return the number of nodes in the skeleton.\"\"\"\n        return len(self.nodes)\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return a readable representation of the skeleton.\"\"\"\n        nodes = \", \".join([f'\"{node}\"' for node in self.node_names])\n        return \"Skeleton(\" f\"nodes=[{nodes}], \" f\"edges={self.edge_inds}\" \")\"\n\n    def index(self, node: Node | str) -&gt; int:\n        \"\"\"Return the index of a node specified as a `Node` or string name.\"\"\"\n        if type(node) == str:\n            return self.index(self._node_name_map[node])\n        elif type(node) == Node:\n            return self._node_ind_map[node]\n        else:\n            raise IndexError(f\"Invalid indexing argument for skeleton: {node}\")\n\n    def __getitem__(self, idx: int | str) -&gt; Node:\n        \"\"\"Return a `Node` when indexing by name or integer.\"\"\"\n        if type(idx) == int:\n            return self.nodes[idx]\n        elif type(idx) == str:\n            return self._node_name_map[idx]\n        else:\n            raise IndexError(f\"Invalid indexing argument for skeleton: {idx}\")\n\n    def add_node(self, node: Node | str):\n        \"\"\"Add a `Node` to the skeleton.\n\n        Args:\n            node: A `Node` object or a string name to create a new node.\n        \"\"\"\n        if type(node) == str:\n            node = Node(node)\n        if node not in self.nodes:\n            self.nodes.append(node)\n            self._update_node_map(None, self.nodes)\n\n    def add_edge(self, src: Edge | Node | str = None, dst: Node | str = None):\n        \"\"\"Add an `Edge` to the skeleton.\n\n        Args:\n            src: The source `Node` or name of the source node.\n            dst: The destination `Node` or name of the destination node.\n        \"\"\"\n        if type(src) == Edge:\n            edge = src\n            if edge not in self.edges:\n                self.edges.append(edge)\n            if edge.source not in self.nodes:\n                self.add_node(edge.source)\n            if edge.destination not in self.nodes:\n                self.add_node(edge.destination)\n            return\n\n        if type(src) == str or type(src) == Node:\n            try:\n                src = self.index(src)\n            except KeyError:\n                self.add_node(src)\n                src = self.index(src)\n\n        if type(dst) == str or type(dst) == Node:\n            try:\n                dst = self.index(dst)\n            except KeyError:\n                self.add_node(dst)\n                dst = self.index(dst)\n\n        edge = Edge(self.nodes[src], self.nodes[dst])\n        if edge not in self.edges:\n            self.edges.append(edge)\n\n    def add_symmetry(\n        self, node1: Symmetry | Node | str = None, node2: Node | str = None\n    ):\n        \"\"\"Add a symmetry relationship to the skeleton.\n\n        Args:\n            node1: The first `Node` or name of the first node.\n            node2: The second `Node` or name of the second node.\n        \"\"\"\n        if type(node1) == Symmetry:\n            if node1 not in self.symmetries:\n                self.symmetries.append(node1)\n                for node in node1.nodes:\n                    if node not in self.nodes:\n                        self.add_node(node)\n            return\n\n        if type(node1) == str or type(node1) == Node:\n            try:\n                node1 = self.index(node1)\n            except KeyError:\n                self.add_node(node1)\n                node1 = self.index(node1)\n\n        if type(node2) == str or type(node2) == Node:\n            try:\n                node2 = self.index(node2)\n            except KeyError:\n                self.add_node(node2)\n                node2 = self.index(node2)\n\n        symmetry = Symmetry({self.nodes[node1], self.nodes[node2]})\n        if symmetry not in self.symmetries:\n            self.symmetries.append(symmetry)\n</code></pre>"},{"location":"model/#sleap_io.Skeleton.edge_inds","title":"<code>edge_inds: list[Tuple[int, int]]</code>  <code>property</code>","text":"<p>Edges indices as a list of 2-tuples.</p>"},{"location":"model/#sleap_io.Skeleton.edge_names","title":"<code>edge_names: list[str, str]</code>  <code>property</code>","text":"<p>Edge names as a list of 2-tuples with string node names.</p>"},{"location":"model/#sleap_io.Skeleton.flipped_node_inds","title":"<code>flipped_node_inds: list[int]</code>  <code>property</code>","text":"<p>Returns node indices that should be switched when horizontally flipping.</p>"},{"location":"model/#sleap_io.Skeleton.node_names","title":"<code>node_names: list[str]</code>  <code>property</code>","text":"<p>Names of the nodes associated with this skeleton as a list of strings.</p>"},{"location":"model/#sleap_io.Skeleton.__attrs_post_init__","title":"<code>__attrs_post_init__()</code>","text":"<p>Ensure nodes are <code>Node</code>s, edges are <code>Edge</code>s, and <code>Node</code> map is updated.</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def __attrs_post_init__(self):\n    \"\"\"Ensure nodes are `Node`s, edges are `Edge`s, and `Node` map is updated.\"\"\"\n    self._convert_nodes()\n    self._convert_edges()\n    self._update_node_map(None, self.nodes)\n</code></pre>"},{"location":"model/#sleap_io.Skeleton.__getitem__","title":"<code>__getitem__(idx)</code>","text":"<p>Return a <code>Node</code> when indexing by name or integer.</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def __getitem__(self, idx: int | str) -&gt; Node:\n    \"\"\"Return a `Node` when indexing by name or integer.\"\"\"\n    if type(idx) == int:\n        return self.nodes[idx]\n    elif type(idx) == str:\n        return self._node_name_map[idx]\n    else:\n        raise IndexError(f\"Invalid indexing argument for skeleton: {idx}\")\n</code></pre>"},{"location":"model/#sleap_io.Skeleton.__len__","title":"<code>__len__()</code>","text":"<p>Return the number of nodes in the skeleton.</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"Return the number of nodes in the skeleton.\"\"\"\n    return len(self.nodes)\n</code></pre>"},{"location":"model/#sleap_io.Skeleton.__repr__","title":"<code>__repr__()</code>","text":"<p>Return a readable representation of the skeleton.</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return a readable representation of the skeleton.\"\"\"\n    nodes = \", \".join([f'\"{node}\"' for node in self.node_names])\n    return \"Skeleton(\" f\"nodes=[{nodes}], \" f\"edges={self.edge_inds}\" \")\"\n</code></pre>"},{"location":"model/#sleap_io.Skeleton.add_edge","title":"<code>add_edge(src=None, dst=None)</code>","text":"<p>Add an <code>Edge</code> to the skeleton.</p> <p>Parameters:</p> Name Type Description Default <code>src</code> <code>Edge | Node | str</code> <p>The source <code>Node</code> or name of the source node.</p> <code>None</code> <code>dst</code> <code>Node | str</code> <p>The destination <code>Node</code> or name of the destination node.</p> <code>None</code> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def add_edge(self, src: Edge | Node | str = None, dst: Node | str = None):\n    \"\"\"Add an `Edge` to the skeleton.\n\n    Args:\n        src: The source `Node` or name of the source node.\n        dst: The destination `Node` or name of the destination node.\n    \"\"\"\n    if type(src) == Edge:\n        edge = src\n        if edge not in self.edges:\n            self.edges.append(edge)\n        if edge.source not in self.nodes:\n            self.add_node(edge.source)\n        if edge.destination not in self.nodes:\n            self.add_node(edge.destination)\n        return\n\n    if type(src) == str or type(src) == Node:\n        try:\n            src = self.index(src)\n        except KeyError:\n            self.add_node(src)\n            src = self.index(src)\n\n    if type(dst) == str or type(dst) == Node:\n        try:\n            dst = self.index(dst)\n        except KeyError:\n            self.add_node(dst)\n            dst = self.index(dst)\n\n    edge = Edge(self.nodes[src], self.nodes[dst])\n    if edge not in self.edges:\n        self.edges.append(edge)\n</code></pre>"},{"location":"model/#sleap_io.Skeleton.add_node","title":"<code>add_node(node)</code>","text":"<p>Add a <code>Node</code> to the skeleton.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>Node | str</code> <p>A <code>Node</code> object or a string name to create a new node.</p> required Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def add_node(self, node: Node | str):\n    \"\"\"Add a `Node` to the skeleton.\n\n    Args:\n        node: A `Node` object or a string name to create a new node.\n    \"\"\"\n    if type(node) == str:\n        node = Node(node)\n    if node not in self.nodes:\n        self.nodes.append(node)\n        self._update_node_map(None, self.nodes)\n</code></pre>"},{"location":"model/#sleap_io.Skeleton.add_symmetry","title":"<code>add_symmetry(node1=None, node2=None)</code>","text":"<p>Add a symmetry relationship to the skeleton.</p> <p>Parameters:</p> Name Type Description Default <code>node1</code> <code>Symmetry | Node | str</code> <p>The first <code>Node</code> or name of the first node.</p> <code>None</code> <code>node2</code> <code>Node | str</code> <p>The second <code>Node</code> or name of the second node.</p> <code>None</code> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def add_symmetry(\n    self, node1: Symmetry | Node | str = None, node2: Node | str = None\n):\n    \"\"\"Add a symmetry relationship to the skeleton.\n\n    Args:\n        node1: The first `Node` or name of the first node.\n        node2: The second `Node` or name of the second node.\n    \"\"\"\n    if type(node1) == Symmetry:\n        if node1 not in self.symmetries:\n            self.symmetries.append(node1)\n            for node in node1.nodes:\n                if node not in self.nodes:\n                    self.add_node(node)\n        return\n\n    if type(node1) == str or type(node1) == Node:\n        try:\n            node1 = self.index(node1)\n        except KeyError:\n            self.add_node(node1)\n            node1 = self.index(node1)\n\n    if type(node2) == str or type(node2) == Node:\n        try:\n            node2 = self.index(node2)\n        except KeyError:\n            self.add_node(node2)\n            node2 = self.index(node2)\n\n    symmetry = Symmetry({self.nodes[node1], self.nodes[node2]})\n    if symmetry not in self.symmetries:\n        self.symmetries.append(symmetry)\n</code></pre>"},{"location":"model/#sleap_io.Skeleton.index","title":"<code>index(node)</code>","text":"<p>Return the index of a node specified as a <code>Node</code> or string name.</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def index(self, node: Node | str) -&gt; int:\n    \"\"\"Return the index of a node specified as a `Node` or string name.\"\"\"\n    if type(node) == str:\n        return self.index(self._node_name_map[node])\n    elif type(node) == Node:\n        return self._node_ind_map[node]\n    else:\n        raise IndexError(f\"Invalid indexing argument for skeleton: {node}\")\n</code></pre>"},{"location":"model/#sleap_io.Node","title":"<code>sleap_io.Node</code>","text":"<p>A landmark type within a <code>Skeleton</code>.</p> <p>This typically corresponds to a unique landmark within a skeleton, such as the \"left eye\".</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>Descriptive label for the landmark.</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>@define(frozen=True, cache_hash=True)\nclass Node:\n    \"\"\"A landmark type within a `Skeleton`.\n\n    This typically corresponds to a unique landmark within a skeleton, such as the \"left\n    eye\".\n\n    Attributes:\n        name: Descriptive label for the landmark.\n    \"\"\"\n\n    name: str\n</code></pre>"},{"location":"model/#sleap_io.Edge","title":"<code>sleap_io.Edge</code>","text":"<p>A connection between two <code>Node</code> objects within a <code>Skeleton</code>.</p> <p>This is a directed edge, representing the ordering of <code>Node</code>s in the <code>Skeleton</code> tree.</p> <p>Attributes:</p> Name Type Description <code>source</code> <code>Node</code> <p>The origin <code>Node</code>.</p> <code>destination</code> <code>Node</code> <p>The destination <code>Node</code>.</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>@define(frozen=True)\nclass Edge:\n    \"\"\"A connection between two `Node` objects within a `Skeleton`.\n\n    This is a directed edge, representing the ordering of `Node`s in the `Skeleton`\n    tree.\n\n    Attributes:\n        source: The origin `Node`.\n        destination: The destination `Node`.\n    \"\"\"\n\n    source: Node\n    destination: Node\n\n    def __getitem__(self, idx) -&gt; Node:\n        \"\"\"Return the source `Node` (`idx` is 0) or destination `Node` (`idx` is 1).\"\"\"\n        if idx == 0:\n            return self.source\n        elif idx == 1:\n            return self.destination\n        else:\n            raise IndexError(\"Edge only has 2 nodes (source and destination).\")\n</code></pre>"},{"location":"model/#sleap_io.Edge.__getitem__","title":"<code>__getitem__(idx)</code>","text":"<p>Return the source <code>Node</code> (<code>idx</code> is 0) or destination <code>Node</code> (<code>idx</code> is 1).</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def __getitem__(self, idx) -&gt; Node:\n    \"\"\"Return the source `Node` (`idx` is 0) or destination `Node` (`idx` is 1).\"\"\"\n    if idx == 0:\n        return self.source\n    elif idx == 1:\n        return self.destination\n    else:\n        raise IndexError(\"Edge only has 2 nodes (source and destination).\")\n</code></pre>"},{"location":"model/#sleap_io.Symmetry","title":"<code>sleap_io.Symmetry</code>","text":"<p>A relationship between a pair of nodes denoting their left/right pairing.</p> <p>Attributes:</p> Name Type Description <code>nodes</code> <code>set[Node]</code> <p>A set of two <code>Node</code>s.</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>@define\nclass Symmetry:\n    \"\"\"A relationship between a pair of nodes denoting their left/right pairing.\n\n    Attributes:\n        nodes: A set of two `Node`s.\n    \"\"\"\n\n    nodes: set[Node] = field(converter=set, validator=lambda _, __, val: len(val) == 2)\n\n    def __iter__(self):\n        \"\"\"Iterate over the symmetric nodes.\"\"\"\n        return iter(self.nodes)\n\n    def __getitem__(self, idx) -&gt; Node:\n        \"\"\"Return the first node.\"\"\"\n        for i, node in enumerate(self.nodes):\n            if i == idx:\n                return node\n</code></pre>"},{"location":"model/#sleap_io.Symmetry.__getitem__","title":"<code>__getitem__(idx)</code>","text":"<p>Return the first node.</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def __getitem__(self, idx) -&gt; Node:\n    \"\"\"Return the first node.\"\"\"\n    for i, node in enumerate(self.nodes):\n        if i == idx:\n            return node\n</code></pre>"},{"location":"model/#sleap_io.Symmetry.__iter__","title":"<code>__iter__()</code>","text":"<p>Iterate over the symmetric nodes.</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def __iter__(self):\n    \"\"\"Iterate over the symmetric nodes.\"\"\"\n    return iter(self.nodes)\n</code></pre>"},{"location":"model/#sleap_io.Track","title":"<code>sleap_io.Track</code>","text":"<p>An object that represents the same animal/object across multiple detections.</p> <p>This allows tracking of unique entities in the video over time and space.</p> <p>A <code>Track</code> may also be used to refer to unique identity classes that span multiple videos, such as <code>\"female mouse\"</code>.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>A name given to this track for identification purposes.</p> Notes <p><code>Track</code>s are compared by identity. This means that unique track objects with the same name are considered to be different.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>@define(eq=False)\nclass Track:\n    \"\"\"An object that represents the same animal/object across multiple detections.\n\n    This allows tracking of unique entities in the video over time and space.\n\n    A `Track` may also be used to refer to unique identity classes that span multiple\n    videos, such as `\"female mouse\"`.\n\n    Attributes:\n        name: A name given to this track for identification purposes.\n\n    Notes:\n        `Track`s are compared by identity. This means that unique track objects with the\n        same name are considered to be different.\n    \"\"\"\n\n    name: str = \"\"\n</code></pre>"},{"location":"model/#sleap_io.Video","title":"<code>sleap_io.Video</code>","text":"<p><code>Video</code> class used by sleap to represent videos and data associated with them.</p> <p>This class is used to store information regarding a video and its components. It is used to store the video's <code>filename</code>, <code>shape</code>, and the video's <code>backend</code>.</p> <p>To create a <code>Video</code> object, use the <code>from_filename</code> method which will select the backend appropriately.</p> <p>Attributes:</p> Name Type Description <code>filename</code> <code>str | list[str]</code> <p>The filename(s) of the video. Supported extensions: \"mp4\", \"avi\", \"mov\", \"mj2\", \"mkv\", \"h5\", \"hdf5\", \"slp\", \"png\", \"jpg\", \"jpeg\", \"tif\", \"tiff\", \"bmp\". If the filename is a list, a list of image filenames are expected. If filename is a folder, it will be searched for images.</p> <code>backend</code> <code>Optional[VideoBackend]</code> <p>An object that implements the basic methods for reading and manipulating frames of a specific video type.</p> <code>backend_metadata</code> <code>dict[str, any]</code> <p>A dictionary of metadata specific to the backend. This is useful for storing metadata that requires an open backend (e.g., shape information) without having access to the video file itself.</p> <code>source_video</code> <code>Optional[Video]</code> <p>The source video object if this is a proxy video. This is present when the video contains an embedded subset of frames from another video.</p> Notes <p>Instances of this class are hashed by identity, not by value. This means that two <code>Video</code> instances with the same attributes will NOT be considered equal in a set or dict.</p> <p>See also: VideoBackend</p> Source code in <code>sleap_io/model/video.py</code> <pre><code>@attrs.define(eq=False)\nclass Video:\n    \"\"\"`Video` class used by sleap to represent videos and data associated with them.\n\n    This class is used to store information regarding a video and its components.\n    It is used to store the video's `filename`, `shape`, and the video's `backend`.\n\n    To create a `Video` object, use the `from_filename` method which will select the\n    backend appropriately.\n\n    Attributes:\n        filename: The filename(s) of the video. Supported extensions: \"mp4\", \"avi\",\n            \"mov\", \"mj2\", \"mkv\", \"h5\", \"hdf5\", \"slp\", \"png\", \"jpg\", \"jpeg\", \"tif\",\n            \"tiff\", \"bmp\". If the filename is a list, a list of image filenames are\n            expected. If filename is a folder, it will be searched for images.\n        backend: An object that implements the basic methods for reading and\n            manipulating frames of a specific video type.\n        backend_metadata: A dictionary of metadata specific to the backend. This is\n            useful for storing metadata that requires an open backend (e.g., shape\n            information) without having access to the video file itself.\n        source_video: The source video object if this is a proxy video. This is present\n            when the video contains an embedded subset of frames from another video.\n\n    Notes:\n        Instances of this class are hashed by identity, not by value. This means that\n        two `Video` instances with the same attributes will NOT be considered equal in a\n        set or dict.\n\n    See also: VideoBackend\n    \"\"\"\n\n    filename: str | list[str]\n    backend: Optional[VideoBackend] = None\n    backend_metadata: dict[str, any] = attrs.field(factory=dict)\n    source_video: Optional[Video] = None\n\n    EXTS = MediaVideo.EXTS + HDF5Video.EXTS + ImageVideo.EXTS\n\n    def __attrs_post_init__(self):\n        \"\"\"Post init syntactic sugar.\"\"\"\n        if self.backend is None and self.exists():\n            self.open()\n\n    @classmethod\n    def from_filename(\n        cls,\n        filename: str | list[str],\n        dataset: Optional[str] = None,\n        grayscale: Optional[bool] = None,\n        keep_open: bool = True,\n        source_video: Optional[Video] = None,\n        **kwargs,\n    ) -&gt; VideoBackend:\n        \"\"\"Create a Video from a filename.\n\n        Args:\n            filename: The filename(s) of the video. Supported extensions: \"mp4\", \"avi\",\n                \"mov\", \"mj2\", \"mkv\", \"h5\", \"hdf5\", \"slp\", \"png\", \"jpg\", \"jpeg\", \"tif\",\n                \"tiff\", \"bmp\". If the filename is a list, a list of image filenames are\n                expected. If filename is a folder, it will be searched for images.\n            dataset: Name of dataset in HDF5 file.\n            grayscale: Whether to force grayscale. If None, autodetect on first frame\n                load.\n            keep_open: Whether to keep the video reader open between calls to read\n                frames. If False, will close the reader after each call. If True (the\n                default), it will keep the reader open and cache it for subsequent calls\n                which may enhance the performance of reading multiple frames.\n            source_video: The source video object if this is a proxy video. This is\n                present when the video contains an embedded subset of frames from\n                another video.\n\n        Returns:\n            Video instance with the appropriate backend instantiated.\n        \"\"\"\n        return cls(\n            filename=filename,\n            backend=VideoBackend.from_filename(\n                filename,\n                dataset=dataset,\n                grayscale=grayscale,\n                keep_open=keep_open,\n                **kwargs,\n            ),\n            source_video=source_video,\n        )\n\n    @property\n    def shape(self) -&gt; Tuple[int, int, int, int] | None:\n        \"\"\"Return the shape of the video as (num_frames, height, width, channels).\n\n        If the video backend is not set or it cannot determine the shape of the video,\n        this will return None.\n        \"\"\"\n        return self._get_shape()\n\n    def _get_shape(self) -&gt; Tuple[int, int, int, int] | None:\n        \"\"\"Return the shape of the video as (num_frames, height, width, channels).\n\n        This suppresses errors related to querying the backend for the video shape, such\n        as when it has not been set or when the video file is not found.\n        \"\"\"\n        try:\n            return self.backend.shape\n        except:\n            if \"shape\" in self.backend_metadata:\n                return self.backend_metadata[\"shape\"]\n            return None\n\n    @property\n    def grayscale(self) -&gt; bool | None:\n        \"\"\"Return whether the video is grayscale.\n\n        If the video backend is not set or it cannot determine whether the video is\n        grayscale, this will return None.\n        \"\"\"\n        shape = self.shape\n        if shape is not None:\n            return shape[-1] == 1\n        else:\n            if \"grayscale\" in self.backend_metadata:\n                return self.backend_metadata[\"grayscale\"]\n            return None\n\n    def __len__(self) -&gt; int:\n        \"\"\"Return the length of the video as the number of frames.\"\"\"\n        shape = self.shape\n        return 0 if shape is None else shape[0]\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Informal string representation (for print or format).\"\"\"\n        dataset = (\n            f\"dataset={self.backend.dataset}, \"\n            if getattr(self.backend, \"dataset\", \"\")\n            else \"\"\n        )\n        return (\n            \"Video(\"\n            f'filename=\"{self.filename}\", '\n            f\"shape={self.shape}, \"\n            f\"{dataset}\"\n            f\"backend={type(self.backend).__name__}\"\n            \")\"\n        )\n\n    def __str__(self) -&gt; str:\n        \"\"\"Informal string representation (for print or format).\"\"\"\n        return self.__repr__()\n\n    def __getitem__(self, inds: int | list[int] | slice) -&gt; np.ndarray:\n        \"\"\"Return the frames of the video at the given indices.\n\n        Args:\n            inds: Index or list of indices of frames to read.\n\n        Returns:\n            Frame or frames as a numpy array of shape `(height, width, channels)` if a\n            scalar index is provided, or `(frames, height, width, channels)` if a list\n            of indices is provided.\n\n        See also: VideoBackend.get_frame, VideoBackend.get_frames\n        \"\"\"\n        if not self.is_open:\n            self.open()\n        return self.backend[inds]\n\n    def exists(self, check_all: bool = False) -&gt; bool:\n        \"\"\"Check if the video file exists.\n\n        Args:\n            check_all: If `True`, check that all filenames in a list exist. If `False`\n                (the default), check that the first filename exists.\n        \"\"\"\n        if isinstance(self.filename, list):\n            if check_all:\n                for f in self.filename:\n                    if not Path(f).exists():\n                        return False\n                return True\n            else:\n                return Path(self.filename[0]).exists()\n        return Path(self.filename).exists()\n\n    @property\n    def is_open(self) -&gt; bool:\n        \"\"\"Check if the video backend is open.\"\"\"\n        return self.exists() and self.backend is not None\n\n    def open(\n        self,\n        dataset: Optional[str] = None,\n        grayscale: Optional[str] = None,\n        keep_open: bool = True,\n    ):\n        \"\"\"Open the video backend for reading.\n\n        Args:\n            dataset: Name of dataset in HDF5 file.\n            grayscale: Whether to force grayscale. If None, autodetect on first frame\n                load.\n            keep_open: Whether to keep the video reader open between calls to read\n                frames. If False, will close the reader after each call. If True (the\n                default), it will keep the reader open and cache it for subsequent calls\n                which may enhance the performance of reading multiple frames.\n\n        Notes:\n            This is useful for opening the video backend to read frames and then closing\n            it after reading all the necessary frames.\n\n            If the backend was already open, it will be closed before opening a new one.\n            Values for the HDF5 dataset and grayscale will be remembered if not\n            specified.\n        \"\"\"\n        if not self.exists():\n            raise FileNotFoundError(f\"Video file not found: {self.filename}\")\n\n        # Try to remember values from previous backend if available and not specified.\n        if self.backend is not None:\n            if dataset is None:\n                dataset = getattr(self.backend, \"dataset\", None)\n            if grayscale is None:\n                grayscale = getattr(self.backend, \"grayscale\", None)\n\n        else:\n            if dataset is None and \"dataset\" in self.backend_metadata:\n                dataset = self.backend_metadata[\"dataset\"]\n            if grayscale is None and \"grayscale\" in self.backend_metadata:\n                grayscale = self.backend_metadata[\"grayscale\"]\n\n        # Close previous backend if open.\n        self.close()\n\n        # Create new backend.\n        self.backend = VideoBackend.from_filename(\n            self.filename,\n            dataset=dataset,\n            grayscale=grayscale,\n            keep_open=keep_open,\n        )\n\n    def close(self):\n        \"\"\"Close the video backend.\"\"\"\n        if self.backend is not None:\n            del self.backend\n            self.backend = None\n\n    def replace_filename(\n        self, new_filename: str | Path | list[str] | list[Path], open: bool = True\n    ):\n        \"\"\"Update the filename of the video, optionally opening the backend.\n\n        Args:\n            new_filename: New filename to set for the video.\n            open: If `True` (the default), open the backend with the new filename. If\n                the new filename does not exist, no error is raised.\n        \"\"\"\n        if isinstance(new_filename, Path):\n            new_filename = new_filename.as_posix()\n\n        if isinstance(new_filename, list):\n            new_filename = [\n                p.as_posix() if isinstance(p, Path) else p for p in new_filename\n            ]\n\n        self.filename = new_filename\n\n        if open:\n            if self.exists():\n                self.open()\n            else:\n                self.close()\n</code></pre>"},{"location":"model/#sleap_io.Video.grayscale","title":"<code>grayscale: bool | None</code>  <code>property</code>","text":"<p>Return whether the video is grayscale.</p> <p>If the video backend is not set or it cannot determine whether the video is grayscale, this will return None.</p>"},{"location":"model/#sleap_io.Video.is_open","title":"<code>is_open: bool</code>  <code>property</code>","text":"<p>Check if the video backend is open.</p>"},{"location":"model/#sleap_io.Video.shape","title":"<code>shape: Tuple[int, int, int, int] | None</code>  <code>property</code>","text":"<p>Return the shape of the video as (num_frames, height, width, channels).</p> <p>If the video backend is not set or it cannot determine the shape of the video, this will return None.</p>"},{"location":"model/#sleap_io.Video.__attrs_post_init__","title":"<code>__attrs_post_init__()</code>","text":"<p>Post init syntactic sugar.</p> Source code in <code>sleap_io/model/video.py</code> <pre><code>def __attrs_post_init__(self):\n    \"\"\"Post init syntactic sugar.\"\"\"\n    if self.backend is None and self.exists():\n        self.open()\n</code></pre>"},{"location":"model/#sleap_io.Video.__getitem__","title":"<code>__getitem__(inds)</code>","text":"<p>Return the frames of the video at the given indices.</p> <p>Parameters:</p> Name Type Description Default <code>inds</code> <code>int | list[int] | slice</code> <p>Index or list of indices of frames to read.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Frame or frames as a numpy array of shape <code>(height, width, channels)</code> if a scalar index is provided, or <code>(frames, height, width, channels)</code> if a list of indices is provided.</p> <p>See also: VideoBackend.get_frame, VideoBackend.get_frames</p> Source code in <code>sleap_io/model/video.py</code> <pre><code>def __getitem__(self, inds: int | list[int] | slice) -&gt; np.ndarray:\n    \"\"\"Return the frames of the video at the given indices.\n\n    Args:\n        inds: Index or list of indices of frames to read.\n\n    Returns:\n        Frame or frames as a numpy array of shape `(height, width, channels)` if a\n        scalar index is provided, or `(frames, height, width, channels)` if a list\n        of indices is provided.\n\n    See also: VideoBackend.get_frame, VideoBackend.get_frames\n    \"\"\"\n    if not self.is_open:\n        self.open()\n    return self.backend[inds]\n</code></pre>"},{"location":"model/#sleap_io.Video.__len__","title":"<code>__len__()</code>","text":"<p>Return the length of the video as the number of frames.</p> Source code in <code>sleap_io/model/video.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"Return the length of the video as the number of frames.\"\"\"\n    shape = self.shape\n    return 0 if shape is None else shape[0]\n</code></pre>"},{"location":"model/#sleap_io.Video.__repr__","title":"<code>__repr__()</code>","text":"<p>Informal string representation (for print or format).</p> Source code in <code>sleap_io/model/video.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Informal string representation (for print or format).\"\"\"\n    dataset = (\n        f\"dataset={self.backend.dataset}, \"\n        if getattr(self.backend, \"dataset\", \"\")\n        else \"\"\n    )\n    return (\n        \"Video(\"\n        f'filename=\"{self.filename}\", '\n        f\"shape={self.shape}, \"\n        f\"{dataset}\"\n        f\"backend={type(self.backend).__name__}\"\n        \")\"\n    )\n</code></pre>"},{"location":"model/#sleap_io.Video.__str__","title":"<code>__str__()</code>","text":"<p>Informal string representation (for print or format).</p> Source code in <code>sleap_io/model/video.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Informal string representation (for print or format).\"\"\"\n    return self.__repr__()\n</code></pre>"},{"location":"model/#sleap_io.Video.close","title":"<code>close()</code>","text":"<p>Close the video backend.</p> Source code in <code>sleap_io/model/video.py</code> <pre><code>def close(self):\n    \"\"\"Close the video backend.\"\"\"\n    if self.backend is not None:\n        del self.backend\n        self.backend = None\n</code></pre>"},{"location":"model/#sleap_io.Video.exists","title":"<code>exists(check_all=False)</code>","text":"<p>Check if the video file exists.</p> <p>Parameters:</p> Name Type Description Default <code>check_all</code> <code>bool</code> <p>If <code>True</code>, check that all filenames in a list exist. If <code>False</code> (the default), check that the first filename exists.</p> <code>False</code> Source code in <code>sleap_io/model/video.py</code> <pre><code>def exists(self, check_all: bool = False) -&gt; bool:\n    \"\"\"Check if the video file exists.\n\n    Args:\n        check_all: If `True`, check that all filenames in a list exist. If `False`\n            (the default), check that the first filename exists.\n    \"\"\"\n    if isinstance(self.filename, list):\n        if check_all:\n            for f in self.filename:\n                if not Path(f).exists():\n                    return False\n            return True\n        else:\n            return Path(self.filename[0]).exists()\n    return Path(self.filename).exists()\n</code></pre>"},{"location":"model/#sleap_io.Video.from_filename","title":"<code>from_filename(filename, dataset=None, grayscale=None, keep_open=True, source_video=None, **kwargs)</code>  <code>classmethod</code>","text":"<p>Create a Video from a filename.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str | list[str]</code> <p>The filename(s) of the video. Supported extensions: \"mp4\", \"avi\", \"mov\", \"mj2\", \"mkv\", \"h5\", \"hdf5\", \"slp\", \"png\", \"jpg\", \"jpeg\", \"tif\", \"tiff\", \"bmp\". If the filename is a list, a list of image filenames are expected. If filename is a folder, it will be searched for images.</p> required <code>dataset</code> <code>Optional[str]</code> <p>Name of dataset in HDF5 file.</p> <code>None</code> <code>grayscale</code> <code>Optional[bool]</code> <p>Whether to force grayscale. If None, autodetect on first frame load.</p> <code>None</code> <code>keep_open</code> <code>bool</code> <p>Whether to keep the video reader open between calls to read frames. If False, will close the reader after each call. If True (the default), it will keep the reader open and cache it for subsequent calls which may enhance the performance of reading multiple frames.</p> <code>True</code> <code>source_video</code> <code>Optional[Video]</code> <p>The source video object if this is a proxy video. This is present when the video contains an embedded subset of frames from another video.</p> <code>None</code> <p>Returns:</p> Type Description <code>VideoBackend</code> <p>Video instance with the appropriate backend instantiated.</p> Source code in <code>sleap_io/model/video.py</code> <pre><code>@classmethod\ndef from_filename(\n    cls,\n    filename: str | list[str],\n    dataset: Optional[str] = None,\n    grayscale: Optional[bool] = None,\n    keep_open: bool = True,\n    source_video: Optional[Video] = None,\n    **kwargs,\n) -&gt; VideoBackend:\n    \"\"\"Create a Video from a filename.\n\n    Args:\n        filename: The filename(s) of the video. Supported extensions: \"mp4\", \"avi\",\n            \"mov\", \"mj2\", \"mkv\", \"h5\", \"hdf5\", \"slp\", \"png\", \"jpg\", \"jpeg\", \"tif\",\n            \"tiff\", \"bmp\". If the filename is a list, a list of image filenames are\n            expected. If filename is a folder, it will be searched for images.\n        dataset: Name of dataset in HDF5 file.\n        grayscale: Whether to force grayscale. If None, autodetect on first frame\n            load.\n        keep_open: Whether to keep the video reader open between calls to read\n            frames. If False, will close the reader after each call. If True (the\n            default), it will keep the reader open and cache it for subsequent calls\n            which may enhance the performance of reading multiple frames.\n        source_video: The source video object if this is a proxy video. This is\n            present when the video contains an embedded subset of frames from\n            another video.\n\n    Returns:\n        Video instance with the appropriate backend instantiated.\n    \"\"\"\n    return cls(\n        filename=filename,\n        backend=VideoBackend.from_filename(\n            filename,\n            dataset=dataset,\n            grayscale=grayscale,\n            keep_open=keep_open,\n            **kwargs,\n        ),\n        source_video=source_video,\n    )\n</code></pre>"},{"location":"model/#sleap_io.Video.open","title":"<code>open(dataset=None, grayscale=None, keep_open=True)</code>","text":"<p>Open the video backend for reading.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>Optional[str]</code> <p>Name of dataset in HDF5 file.</p> <code>None</code> <code>grayscale</code> <code>Optional[str]</code> <p>Whether to force grayscale. If None, autodetect on first frame load.</p> <code>None</code> <code>keep_open</code> <code>bool</code> <p>Whether to keep the video reader open between calls to read frames. If False, will close the reader after each call. If True (the default), it will keep the reader open and cache it for subsequent calls which may enhance the performance of reading multiple frames.</p> <code>True</code> Notes <p>This is useful for opening the video backend to read frames and then closing it after reading all the necessary frames.</p> <p>If the backend was already open, it will be closed before opening a new one. Values for the HDF5 dataset and grayscale will be remembered if not specified.</p> Source code in <code>sleap_io/model/video.py</code> <pre><code>def open(\n    self,\n    dataset: Optional[str] = None,\n    grayscale: Optional[str] = None,\n    keep_open: bool = True,\n):\n    \"\"\"Open the video backend for reading.\n\n    Args:\n        dataset: Name of dataset in HDF5 file.\n        grayscale: Whether to force grayscale. If None, autodetect on first frame\n            load.\n        keep_open: Whether to keep the video reader open between calls to read\n            frames. If False, will close the reader after each call. If True (the\n            default), it will keep the reader open and cache it for subsequent calls\n            which may enhance the performance of reading multiple frames.\n\n    Notes:\n        This is useful for opening the video backend to read frames and then closing\n        it after reading all the necessary frames.\n\n        If the backend was already open, it will be closed before opening a new one.\n        Values for the HDF5 dataset and grayscale will be remembered if not\n        specified.\n    \"\"\"\n    if not self.exists():\n        raise FileNotFoundError(f\"Video file not found: {self.filename}\")\n\n    # Try to remember values from previous backend if available and not specified.\n    if self.backend is not None:\n        if dataset is None:\n            dataset = getattr(self.backend, \"dataset\", None)\n        if grayscale is None:\n            grayscale = getattr(self.backend, \"grayscale\", None)\n\n    else:\n        if dataset is None and \"dataset\" in self.backend_metadata:\n            dataset = self.backend_metadata[\"dataset\"]\n        if grayscale is None and \"grayscale\" in self.backend_metadata:\n            grayscale = self.backend_metadata[\"grayscale\"]\n\n    # Close previous backend if open.\n    self.close()\n\n    # Create new backend.\n    self.backend = VideoBackend.from_filename(\n        self.filename,\n        dataset=dataset,\n        grayscale=grayscale,\n        keep_open=keep_open,\n    )\n</code></pre>"},{"location":"model/#sleap_io.Video.replace_filename","title":"<code>replace_filename(new_filename, open=True)</code>","text":"<p>Update the filename of the video, optionally opening the backend.</p> <p>Parameters:</p> Name Type Description Default <code>new_filename</code> <code>str | Path | list[str] | list[Path]</code> <p>New filename to set for the video.</p> required <code>open</code> <code>bool</code> <p>If <code>True</code> (the default), open the backend with the new filename. If the new filename does not exist, no error is raised.</p> <code>True</code> Source code in <code>sleap_io/model/video.py</code> <pre><code>def replace_filename(\n    self, new_filename: str | Path | list[str] | list[Path], open: bool = True\n):\n    \"\"\"Update the filename of the video, optionally opening the backend.\n\n    Args:\n        new_filename: New filename to set for the video.\n        open: If `True` (the default), open the backend with the new filename. If\n            the new filename does not exist, no error is raised.\n    \"\"\"\n    if isinstance(new_filename, Path):\n        new_filename = new_filename.as_posix()\n\n    if isinstance(new_filename, list):\n        new_filename = [\n            p.as_posix() if isinstance(p, Path) else p for p in new_filename\n        ]\n\n    self.filename = new_filename\n\n    if open:\n        if self.exists():\n            self.open()\n        else:\n            self.close()\n</code></pre>"},{"location":"model/#sleap_io.SuggestionFrame","title":"<code>sleap_io.SuggestionFrame</code>","text":"<p>Data structure for a single frame of suggestions.</p> <p>Attributes:</p> Name Type Description <code>video</code> <code>Video</code> <p>The video associated with the frame.</p> <code>frame_idx</code> <code>int</code> <p>The index of the frame in the video.</p> Source code in <code>sleap_io/model/suggestions.py</code> <pre><code>@attrs.define(auto_attribs=True)\nclass SuggestionFrame:\n    \"\"\"Data structure for a single frame of suggestions.\n\n    Attributes:\n        video: The video associated with the frame.\n        frame_idx: The index of the frame in the video.\n    \"\"\"\n\n    video: Video\n    frame_idx: int\n</code></pre>"},{"location":"reference/SUMMARY/","title":"SUMMARY","text":"<ul> <li>sleap_io<ul> <li>io<ul> <li>jabs</li> <li>labelstudio</li> <li>main</li> <li>nwb</li> <li>slp</li> <li>utils</li> <li>video</li> </ul> </li> <li>model<ul> <li>instance</li> <li>labeled_frame</li> <li>labels</li> <li>skeleton</li> <li>suggestions</li> <li>video</li> </ul> </li> <li>version</li> </ul> </li> </ul>"},{"location":"reference/sleap_io/","title":"sleap_io","text":""},{"location":"reference/sleap_io/#sleap_io","title":"<code>sleap_io</code>","text":"<p>This module exposes all high level APIs for sleap-io.</p>"},{"location":"reference/sleap_io/version/","title":"version","text":""},{"location":"reference/sleap_io/version/#sleap_io.version","title":"<code>sleap_io.version</code>","text":"<p>This module defines the package version.</p>"},{"location":"reference/sleap_io/io/","title":"io","text":""},{"location":"reference/sleap_io/io/#sleap_io.io","title":"<code>sleap_io.io</code>","text":"<p>This sub-package contains I/O-related modules such as specific format backends.</p>"},{"location":"reference/sleap_io/io/jabs/","title":"jabs","text":""},{"location":"reference/sleap_io/io/jabs/#sleap_io.io.jabs","title":"<code>sleap_io.io.jabs</code>","text":"<p>This module handles direct I/O operations for working with JABS files.</p>"},{"location":"reference/sleap_io/io/jabs/#sleap_io.io.jabs.convert_labels","title":"<code>convert_labels(all_labels, video)</code>","text":"<p>Convert a <code>Labels</code> object into JABS-formatted annotations.</p> <p>Parameters:</p> Name Type Description Default <code>all_labels</code> <code>Labels</code> <p>SLEAP <code>Labels</code> to be converted to JABS format.</p> required <code>video</code> <code>Video</code> <p>name of video to be converted</p> required <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary of JABS data of the <code>Labels</code> data.</p> Source code in <code>sleap_io/io/jabs.py</code> <pre><code>def convert_labels(all_labels: Labels, video: Video) -&gt; dict:\n    \"\"\"Convert a `Labels` object into JABS-formatted annotations.\n\n    Args:\n        all_labels: SLEAP `Labels` to be converted to JABS format.\n        video: name of video to be converted\n\n    Returns:\n        Dictionary of JABS data of the `Labels` data.\n    \"\"\"\n    labels = all_labels.find(video=video)\n\n    # Determine shape of output\n    # Low estimate of last frame labeled\n    num_frames = max([x.frame_idx for x in labels]) + 1\n    # If there is metadata available for the video, use that\n    if video.shape:\n        num_frames = max(num_frames, video.shape[0])\n    num_keypoints = [len(x.nodes) for x in all_labels.skeletons if x.name == \"Mouse\"][0]\n    num_mice = get_max_ids_in_video(labels, key=\"Mouse\")\n    # Note that this 1-indexes identities\n    track_2_idx = {\n        key: val + 1\n        for key, val in zip(all_labels.tracks, range(len(all_labels.tracks)))\n    }\n    last_unassigned_id = num_mice\n\n    keypoint_mat = np.zeros([num_frames, num_mice, num_keypoints, 2], dtype=np.uint16)\n    confidence_mat = np.zeros([num_frames, num_mice, num_keypoints], dtype=np.float32)\n    identity_mat = np.zeros([num_frames, num_mice], dtype=np.uint32)\n    instance_vector = np.zeros([num_frames], dtype=np.uint8)\n    static_objects = {}\n\n    # Populate the matrices with data\n    for label in labels:\n        assigned_instances = 0\n        for instance_idx, instance in enumerate(label.instances):\n            # Static objects just get added to the object dict\n            # This will clobber data if more than one frame is annotated\n            if instance.skeleton.name != \"Mouse\":\n                static_objects[instance.skeleton.name] = instance.numpy()\n                continue\n            pose = instance.numpy()\n            if pose.shape[0] != len(JABS_DEFAULT_KEYPOINTS):\n                warnings.warn(\n                    f\"JABS format only supports 12 keypoints for mice. Skipping storage of instance on frame {label.frame_idx} with {len(instance.points)} keypoints.\"\n                )\n                continue\n            missing_points = np.isnan(pose[:, 0])\n            pose[np.isnan(pose)] = 0\n            # JABS stores y,x for poses\n            pose = np.flip(pose.astype(np.uint16), axis=-1)\n            keypoint_mat[label.frame_idx, instance_idx, :, :] = pose\n            confidence_mat[label.frame_idx, instance_idx, ~missing_points] = 1.0\n            if instance.track:\n                identity_mat[label.frame_idx, instance_idx] = track_2_idx[\n                    instance.track\n                ]\n            else:\n                warnings.warn(\n                    f\"Pose with unassigned track found on {label.video.filename} frame {label.frame_idx} instance {instance_idx}. Assigning ID {last_unassigned_id}.\"\n                )\n                identity_mat[label.frame_idx, instance_idx] = last_unassigned_id\n                last_unassigned_id += 1\n            assigned_instances += 1\n        instance_vector[label.frame_idx] = assigned_instances\n\n    # Return the data as a dict\n    return {\n        \"keypoints\": keypoint_mat.astype(np.uint16),\n        \"confidence\": confidence_mat.astype(np.float32),\n        \"identity\": identity_mat.astype(np.uint32),\n        \"num_identities\": instance_vector.astype(np.uint16),\n        \"static_objects\": static_objects,\n    }\n</code></pre>"},{"location":"reference/sleap_io/io/jabs/#sleap_io.io.jabs.get_max_ids_in_video","title":"<code>get_max_ids_in_video(labels, key='Mouse')</code>","text":"<p>Determine the maximum number of identities that exist at the same time.</p> <p>Parameters:</p> Name Type Description Default <code>labels</code> <code>List[Labels]</code> <p>SLEAP <code>Labels</code> to count</p> required <code>key</code> <code>str</code> <p>Name of the skeleton to select for identities</p> <code>'Mouse'</code> <p>Returns:</p> Type Description <code>int</code> <p>Count of the maximum concurrent identities in a single frame</p> Source code in <code>sleap_io/io/jabs.py</code> <pre><code>def get_max_ids_in_video(labels: List[Labels], key: str = \"Mouse\") -&gt; int:\n    \"\"\"Determine the maximum number of identities that exist at the same time.\n\n    Args:\n        labels: SLEAP `Labels` to count\n        key: Name of the skeleton to select for identities\n\n    Returns:\n        Count of the maximum concurrent identities in a single frame\n    \"\"\"\n    max_labels = 0\n    for label in labels:\n        n_labels = sum([x.skeleton.name == key for x in label.instances])\n        max_labels = max(max_labels, n_labels)\n\n    return max_labels\n</code></pre>"},{"location":"reference/sleap_io/io/jabs/#sleap_io.io.jabs.make_simple_skeleton","title":"<code>make_simple_skeleton(name, num_points)</code>","text":"<p>Create a <code>Skeleton</code> with a requested number of nodes attached in a line.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>name of the skeleton and prefix to nodes</p> required <code>num_points</code> <code>int</code> <p>number of points to use in the skeleton</p> required <p>Returns:</p> Type Description <code>Skeleton</code> <p>Generated <code>Skeleton</code>.</p> Source code in <code>sleap_io/io/jabs.py</code> <pre><code>def make_simple_skeleton(name: str, num_points: int) -&gt; Skeleton:\n    \"\"\"Create a `Skeleton` with a requested number of nodes attached in a line.\n\n    Args:\n        name: name of the skeleton and prefix to nodes\n        num_points: number of points to use in the skeleton\n\n    Returns:\n        Generated `Skeleton`.\n    \"\"\"\n    nodes = [Node(name + \"_kp\" + str(i)) for i in range(num_points)]\n    edges = [Edge(nodes[i], nodes[i + 1]) for i in range(num_points - 1)]\n    return Skeleton(nodes, edges, name=name)\n</code></pre>"},{"location":"reference/sleap_io/io/jabs/#sleap_io.io.jabs.prediction_to_instance","title":"<code>prediction_to_instance(data, confidence, skeleton, track=None)</code>","text":"<p>Create an <code>Instance</code> from prediction data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Union[ndarray[uint16], ndarray[float32]]</code> <p>keypoint locations</p> required <code>confidence</code> <code>ndarray[float32]</code> <p>confidence for keypoints</p> required <code>skeleton</code> <code>Skeleton</code> <p><code>Skeleton</code> to use for <code>Instance</code></p> required <code>track</code> <code>Track</code> <p><code>Track</code> to assign to <code>Instance</code></p> <code>None</code> <p>Returns:</p> Type Description <code>Instance</code> <p>Parsed <code>Instance</code>.</p> Source code in <code>sleap_io/io/jabs.py</code> <pre><code>def prediction_to_instance(\n    data: Union[np.ndarray[np.uint16], np.ndarray[np.float32]],\n    confidence: np.ndarray[np.float32],\n    skeleton: Skeleton,\n    track: Track = None,\n) -&gt; Instance:\n    \"\"\"Create an `Instance` from prediction data.\n\n    Args:\n        data: keypoint locations\n        confidence: confidence for keypoints\n        skeleton: `Skeleton` to use for `Instance`\n        track: `Track` to assign to `Instance`\n\n    Returns:\n        Parsed `Instance`.\n    \"\"\"\n    assert (\n        len(skeleton.nodes) == data.shape[0]\n    ), f\"Skeleton ({len(skeleton.nodes)}) does not match number of keypoints ({data.shape[0]})\"\n\n    points = {}\n    for i, cur_node in enumerate(skeleton.nodes):\n        # confidence of 0 indicates no keypoint predicted for instance\n        if confidence[i] &gt; 0:\n            points[cur_node] = Point(\n                data[i, 0],\n                data[i, 1],\n                visible=True,\n            )\n\n    if not points:\n        return None\n    else:\n        return Instance(points, skeleton=skeleton, track=track)\n</code></pre>"},{"location":"reference/sleap_io/io/jabs/#sleap_io.io.jabs.read_labels","title":"<code>read_labels(labels_path, skeleton=JABS_DEFAULT_SKELETON)</code>","text":"<p>Read JABS style pose from a file and return a <code>Labels</code> object.</p> <p>TODO: Attributes are ignored, including px_to_cm field. TODO: Segmentation data ignored in v6, but will read in pose. TODO: Lixit static objects currently stored as n_lixit,2 (eg 1 object). Should be converted to multiple objects</p> <p>Parameters:</p> Name Type Description Default <code>labels_path</code> <code>str</code> <p>Path to the JABS pose file.</p> required <code>skeleton</code> <code>Optional[Skeleton]</code> <p>An optional <code>Skeleton</code> object. Defaults to JABS pose version 2-6.</p> <code>JABS_DEFAULT_SKELETON</code> <p>Returns:</p> Type Description <code>Labels</code> <p>Parsed labels as a <code>Labels</code> instance.</p> Source code in <code>sleap_io/io/jabs.py</code> <pre><code>def read_labels(\n    labels_path: str, skeleton: Optional[Skeleton] = JABS_DEFAULT_SKELETON\n) -&gt; Labels:\n    \"\"\"Read JABS style pose from a file and return a `Labels` object.\n\n    TODO: Attributes are ignored, including px_to_cm field.\n    TODO: Segmentation data ignored in v6, but will read in pose.\n    TODO: Lixit static objects currently stored as n_lixit,2 (eg 1 object). Should be converted to multiple objects\n\n    Args:\n        labels_path: Path to the JABS pose file.\n        skeleton: An optional `Skeleton` object. Defaults to JABS pose version 2-6.\n\n    Returns:\n        Parsed labels as a `Labels` instance.\n    \"\"\"\n    frames: List[LabeledFrame] = []\n    # Video name is the pose file minus the suffix\n    video_name = re.sub(r\"(_pose_est_v[2-6])?\\.h5\", \".avi\", labels_path)\n    video = Video.from_filename(video_name)\n    if not skeleton:\n        skeleton = JABS_DEFAULT_SKELETON\n    tracks = {}\n\n    if not os.access(labels_path, os.F_OK):\n        raise FileNotFoundError(f\"{labels_path} doesn't exist.\")\n    if not os.access(labels_path, os.R_OK):\n        raise PermissionError(f\"{labels_path} cannot be accessed.\")\n\n    with h5py.File(labels_path, \"r\") as pose_file:\n        num_frames = pose_file[\"poseest/points\"].shape[0]\n        try:\n            pose_version = pose_file[\"poseest\"].attrs[\"version\"][0]\n        except (KeyError, IndexError):\n            pose_version = 2\n            data_shape = pose_file[\"poseest/points\"].shape\n            assert (\n                len(data_shape) == 3\n            ), f\"Pose version not present and shape does not match single mouse: shape of {data_shape} for {labels_path}\"\n        if pose_version == 2:\n            tracks[1] = Track(\"1\")\n        # Change field name for newer pose formats\n        if pose_version == 3:\n            id_key = \"instance_track_id\"\n        elif pose_version &gt; 3:\n            id_key = \"instance_embed_id\"\n            max_ids = pose_file[\"poseest/points\"].shape[1]\n\n        for frame_idx in range(num_frames):\n            instances = []\n            pose_data = pose_file[\"poseest/points\"][frame_idx, ...]\n            # JABS stores y,x for poses\n            pose_data = np.flip(pose_data, axis=-1)\n            pose_conf = pose_file[\"poseest/confidence\"][frame_idx, ...]\n            # single animal case\n            if pose_version == 2:\n                new_instance = prediction_to_instance(\n                    pose_data, pose_conf, skeleton, tracks[1]\n                )\n                instances.append(new_instance)\n            # multi-animal case\n            if pose_version &gt; 2:\n                pose_ids = pose_file[\"poseest/\" + id_key][frame_idx, ...]\n                # pose_v3 uses another field to describe the number of valid poses\n                if pose_version == 3:\n                    max_ids = pose_file[\"poseest/instance_count\"][frame_idx]\n                for cur_id in range(max_ids):\n                    # v4+ uses reserved values for invalid/unused poses\n                    # Note: ignores 'poseest/id_mask' to keep predictions that were not assigned an id\n                    if pose_version &gt; 3 and pose_ids[cur_id] &lt;= 0:\n                        continue\n                    if pose_ids[cur_id] not in tracks.keys():\n                        tracks[pose_ids[cur_id]] = Track(str(pose_ids[cur_id]))\n                    new_instance = prediction_to_instance(\n                        pose_data[cur_id],\n                        pose_conf[cur_id],\n                        skeleton,\n                        tracks[pose_ids[cur_id]],\n                    )\n                    if new_instance:\n                        instances.append(new_instance)\n            # Static objects\n            if (\n                frame_idx == 0\n                and pose_version &gt;= 5\n                and \"static_objects\" in pose_file.keys()\n            ):\n                present_objects = pose_file[\"static_objects\"].keys()\n                for cur_object in present_objects:\n                    object_keypoints = pose_file[\"static_objects/\" + cur_object][:]\n                    object_skeleton = make_simple_skeleton(\n                        cur_object, object_keypoints.shape[0]\n                    )\n                    new_instance = prediction_to_instance(\n                        object_keypoints,\n                        np.ones(object_keypoints.shape[:-1]),\n                        object_skeleton,\n                    )\n                    if new_instance:\n                        instances.append(new_instance)\n            frame_label = LabeledFrame(video, frame_idx, instances)\n            frames.append(frame_label)\n    labels = Labels(frames)\n    labels.provenance[\"filename\"] = labels_path\n    return labels\n</code></pre>"},{"location":"reference/sleap_io/io/jabs/#sleap_io.io.jabs.tracklets_to_v3","title":"<code>tracklets_to_v3(tracklet_matrix)</code>","text":"<p>Changes identity tracklets to the v3 format specifications.</p> v3 specifications require <p>(a) tracklets are 0-indexed (b) tracklets appear in ascending order \u00a9 tracklets exist for continuous blocks of time</p> <p>Parameters:</p> Name Type Description Default <code>tracklet_matrix</code> <code>ndarray</code> <p>Numpy array of shape (frame, n_animals) that contains identity values. Identities are assumed to be 1-indexed.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>A corrected numpy array of the same shape as input</p> Source code in <code>sleap_io/io/jabs.py</code> <pre><code>def tracklets_to_v3(tracklet_matrix: np.ndarray) -&gt; np.ndarray:\n    \"\"\"Changes identity tracklets to the v3 format specifications.\n\n    v3 specifications require:\n        (a) tracklets are 0-indexed\n        (b) tracklets appear in ascending order\n        (c) tracklets exist for continuous blocks of time\n\n    Args:\n        tracklet_matrix: Numpy array of shape (frame, n_animals) that contains identity values. Identities are assumed to be 1-indexed.\n\n    Returns:\n        A corrected numpy array of the same shape as input\n    \"\"\"\n    assert tracklet_matrix.ndim == 2\n\n    # Fragment the tracklets based on gaps\n    valid_ids = np.unique(tracklet_matrix)\n    valid_ids = valid_ids[valid_ids != 0]\n    track_fragments = {}\n    for cur_id in valid_ids:\n        frame_idx, column_idx = np.where(tracklet_matrix == cur_id)\n        gaps = np.nonzero(np.diff(frame_idx) - 1)[0]\n        for sliced_frame, sliced_column in zip(\n            np.split(frame_idx, gaps + 1), np.split(column_idx, gaps + 1)\n        ):\n            # The keys used here are (first frame, first column) such that sorting can be used for ascending order\n            track_fragments[sliced_frame[0], sliced_column[0]] = sliced_column\n\n    return_mat = np.zeros_like(tracklet_matrix)\n    for next_id, key in enumerate(sorted(track_fragments.keys())):\n        columns_to_assign = track_fragments[key]\n        return_mat[\n            range(key[0], key[0] + len(columns_to_assign)), columns_to_assign\n        ] = next_id\n\n    return return_mat\n</code></pre>"},{"location":"reference/sleap_io/io/jabs/#sleap_io.io.jabs.write_jabs_v2","title":"<code>write_jabs_v2(data, filename)</code>","text":"<p>Write JABS pose file v2 data to file.</p> <p>Writes single mouse pose data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>dict</code> <p>Dictionary of JABS data generated from convert_labels</p> required <code>filename</code> <code>str</code> <p>Filename to write data to</p> required Source code in <code>sleap_io/io/jabs.py</code> <pre><code>def write_jabs_v2(data: dict, filename: str):\n    \"\"\"Write JABS pose file v2 data to file.\n\n    Writes single mouse pose data.\n\n    Args:\n        data: Dictionary of JABS data generated from convert_labels\n        filename: Filename to write data to\n    \"\"\"\n    # Check that we're trying to write single mouse data\n    assert data[\"keypoints\"].shape[1] == 1\n    out_keypoints = np.squeeze(data[\"keypoints\"], axis=1)\n    out_confidences = np.squeeze(data[\"confidence\"], axis=1)\n\n    with h5py.File(filename, \"w\") as h5:\n        pose_grp = h5.require_group(\"poseest\")\n        pose_grp.attrs.update({\"version\": [2, 0]})\n        pose_grp.require_dataset(\n            \"points\", out_keypoints.shape, out_keypoints.dtype, data=out_keypoints\n        )\n        pose_grp.require_dataset(\n            \"confidence\",\n            out_confidences.shape,\n            out_confidences.dtype,\n            data=out_confidences,\n        )\n</code></pre>"},{"location":"reference/sleap_io/io/jabs/#sleap_io.io.jabs.write_jabs_v3","title":"<code>write_jabs_v3(data, filename)</code>","text":"<p>Write JABS pose file v3 data to file.</p> <p>Writes multi-mouse pose data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>dict</code> <p>Dictionary of JABS data generated from convert_labels</p> required <code>filename</code> <code>str</code> <p>Filename to write data to</p> required Source code in <code>sleap_io/io/jabs.py</code> <pre><code>def write_jabs_v3(data: dict, filename: str):\n    \"\"\"Write JABS pose file v3 data to file.\n\n    Writes multi-mouse pose data.\n\n    Args:\n        data: Dictionary of JABS data generated from convert_labels\n        filename: Filename to write data to\n    \"\"\"\n    v3_tracklets = tracklets_to_v3(data[\"identity\"])\n    with h5py.File(filename, \"w\") as h5:\n        pose_grp = h5.require_group(\"poseest\")\n        pose_grp.attrs.update({\"version\": [3, 0]})\n        # keypoint field\n        pose_grp.require_dataset(\n            \"points\",\n            data[\"keypoints\"].shape,\n            data[\"keypoints\"].dtype,\n            data=data[\"keypoints\"],\n        )\n        # confidence field\n        pose_grp.require_dataset(\n            \"confidence\",\n            data[\"confidence\"].shape,\n            data[\"confidence\"].dtype,\n            data=data[\"confidence\"],\n        )\n        # id field\n        pose_grp.require_dataset(\n            \"instance_track_id\",\n            v3_tracklets.shape,\n            v3_tracklets.dtype,\n            data=v3_tracklets,\n        )\n        # instance count field\n        pose_grp.require_dataset(\n            \"instance_count\",\n            data[\"num_identities\"].shape,\n            data[\"num_identities\"].dtype,\n            data=data[\"num_identities\"],\n        )\n        # extra field where we don't have data, so fill with default data\n        pose_grp.require_dataset(\n            \"instance_embedding\",\n            data[\"confidence\"].shape,\n            data[\"confidence\"].dtype,\n            data=np.zeros_like(data[\"confidence\"]),\n        )\n</code></pre>"},{"location":"reference/sleap_io/io/jabs/#sleap_io.io.jabs.write_jabs_v4","title":"<code>write_jabs_v4(data, filename)</code>","text":"<p>Write JABS pose file v4 data to file.</p> <p>Writes multi-mouse pose and longterm identity object data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>dict</code> <p>Dictionary of JABS data generated from convert_labels</p> required <code>filename</code> <code>str</code> <p>Filename to write data to</p> required Source code in <code>sleap_io/io/jabs.py</code> <pre><code>def write_jabs_v4(data: dict, filename: str):\n    \"\"\"Write JABS pose file v4 data to file.\n\n    Writes multi-mouse pose and longterm identity object data.\n\n    Args:\n        data: Dictionary of JABS data generated from convert_labels\n        filename: Filename to write data to\n    \"\"\"\n    # v4 extends v3\n    write_jabs_v3(data, filename)\n    with h5py.File(filename, \"a\") as h5:\n        pose_grp = h5.require_group(\"poseest\")\n        pose_grp.attrs.update({\"version\": [4, 0]})\n        # new fields on top of v4\n        identity_mask_mat = np.all(data[\"confidence\"] == 0, axis=-1).astype(bool)\n        pose_grp.require_dataset(\n            \"id_mask\",\n            identity_mask_mat.shape,\n            identity_mask_mat.dtype,\n            data=identity_mask_mat,\n        )\n        # No identity embedding data\n        # Note that since the identity information doesn't exist, this will break any functionality that relies on it\n        default_id_embeds = np.zeros(\n            list(identity_mask_mat.shape) + [0], dtype=np.float32\n        )\n        pose_grp.require_dataset(\n            \"identity_embeds\",\n            default_id_embeds.shape,\n            default_id_embeds.dtype,\n            data=default_id_embeds,\n        )\n        default_id_centers = np.zeros(default_id_embeds.shape[1:], dtype=np.float32)\n        pose_grp.require_dataset(\n            \"instance_id_center\",\n            default_id_centers.shape,\n            default_id_centers.dtype,\n            data=default_id_centers,\n        )\n        # v4 uses an id field that is 1-indexed\n        pose_grp.require_dataset(\n            \"instance_embed_id\",\n            data[\"identity\"].shape,\n            data[\"identity\"].dtype,\n            data=data[\"identity\"],\n        )\n</code></pre>"},{"location":"reference/sleap_io/io/jabs/#sleap_io.io.jabs.write_jabs_v5","title":"<code>write_jabs_v5(data, filename)</code>","text":"<p>Write JABS pose file v5 data to file.</p> <p>Writes multi-mouse pose, longterm identity, and static object data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>dict</code> <p>Dictionary of JABS data generated from convert_labels</p> required <code>filename</code> <code>str</code> <p>Filename to write data to</p> required Source code in <code>sleap_io/io/jabs.py</code> <pre><code>def write_jabs_v5(data: dict, filename: str):\n    \"\"\"Write JABS pose file v5 data to file.\n\n    Writes multi-mouse pose, longterm identity, and static object data.\n\n    Args:\n        data: Dictionary of JABS data generated from convert_labels\n        filename: Filename to write data to\n    \"\"\"\n    # v5 extends v4\n    write_jabs_v4(data, filename)\n    with h5py.File(filename, \"a\") as h5:\n        pose_grp = h5.require_group(\"poseest\")\n        pose_grp.attrs.update({\"version\": [5, 0]})\n        if \"static_objects\" in data.keys():\n            object_grp = h5.require_group(\"static_objects\")\n            for object_key, object_keypoints in data[\"static_objects\"].items():\n                object_grp.require_dataset(\n                    object_key,\n                    object_keypoints.shape,\n                    np.uint16,\n                    data=object_keypoints.astype(np.uint16),\n                )\n</code></pre>"},{"location":"reference/sleap_io/io/jabs/#sleap_io.io.jabs.write_labels","title":"<code>write_labels(labels, pose_version, root_folder)</code>","text":"<p>Convert and save a SLEAP <code>Labels</code> object to a JABS pose file.</p> <p>Only supports pose version 2 (single mouse) and 3-5 (multi mouse).</p> <p>Parameters:</p> Name Type Description Default <code>labels</code> <code>Labels</code> <p>SLEAP <code>Labels</code> to be converted to JABS pose format.</p> required <code>pose_version</code> <code>int</code> <p>JABS pose version to use when writing data.</p> required <code>root_folder</code> <code>str</code> <p>Root folder where the jabs files should be written</p> required Source code in <code>sleap_io/io/jabs.py</code> <pre><code>def write_labels(labels: Labels, pose_version: int, root_folder: str):\n    \"\"\"Convert and save a SLEAP `Labels` object to a JABS pose file.\n\n    Only supports pose version 2 (single mouse) and 3-5 (multi mouse).\n\n    Args:\n        labels: SLEAP `Labels` to be converted to JABS pose format.\n        pose_version: JABS pose version to use when writing data.\n        root_folder: Root folder where the jabs files should be written\n    \"\"\"\n    for video in labels.videos:\n        converted_labels = convert_labels(labels, video)\n        out_filename = (\n            os.path.splitext(video.filename)[0] + f\"_pose_est_v{pose_version}.h5\"\n        )\n        if root_folder:\n            out_filename = os.path.join(root_folder, out_filename)\n        os.makedirs(os.path.dirname(out_filename), exist_ok=True)\n        if os.path.exists(out_filename):\n            warnings.warn(f\"Skipping {out_filename} because it already exists.\")\n            continue\n        if pose_version == 2:\n            write_jabs_v2(converted_labels, out_filename)\n        elif pose_version == 3:\n            write_jabs_v3(converted_labels, out_filename)\n        elif pose_version == 4:\n            write_jabs_v4(converted_labels, out_filename)\n        elif pose_version == 5:\n            write_jabs_v5(converted_labels, out_filename)\n        else:\n            raise NotImplementedError(f\"Pose format {pose_version} not supported.\")\n</code></pre>"},{"location":"reference/sleap_io/io/labelstudio/","title":"labelstudio","text":""},{"location":"reference/sleap_io/io/labelstudio/#sleap_io.io.labelstudio","title":"<code>sleap_io.io.labelstudio</code>","text":"<p>This module handles direct I/O operations for working with Labelstudio files.</p> Some important nomenclature <ul> <li><code>tasks</code>: typically maps to a single frame of data to be annotated, closest   correspondance is to <code>LabeledFrame</code></li> <li><code>annotations</code>: collection of points, polygons, relations, etc. corresponds to   <code>Instance</code>s and <code>Point</code>s, but a flattened hierarchy</li> </ul>"},{"location":"reference/sleap_io/io/labelstudio/#sleap_io.io.labelstudio.build_relation_map","title":"<code>build_relation_map(annotations)</code>","text":"<p>Build a two-way relationship map between annotations.</p> <p>Parameters:</p> Name Type Description Default <code>annotations</code> <code>Iterable[dict]</code> <p>annotations, presumably, containing relation types</p> required <p>Returns:</p> Type Description <code>Dict[str, List[str]]</code> <p>A two way map of relations indexed by <code>from_id</code> and <code>to_id</code> fields.</p> Source code in <code>sleap_io/io/labelstudio.py</code> <pre><code>def build_relation_map(annotations: Iterable[dict]) -&gt; Dict[str, List[str]]:\n    \"\"\"Build a two-way relationship map between annotations.\n\n    Args:\n        annotations: annotations, presumably, containing relation types\n\n    Returns:\n        A two way map of relations indexed by `from_id` and `to_id` fields.\n    \"\"\"\n    relations = list(filter(lambda d: d[\"type\"] == \"relation\", annotations))\n    relmap: Dict[str, List[str]] = {}\n    for rel in relations:\n        if rel[\"from_id\"] not in relmap:\n            relmap[rel[\"from_id\"]] = []\n        relmap[rel[\"from_id\"]].append(rel[\"to_id\"])\n\n        if rel[\"to_id\"] not in relmap:\n            relmap[rel[\"to_id\"]] = []\n        relmap[rel[\"to_id\"]].append(rel[\"from_id\"])\n    return relmap\n</code></pre>"},{"location":"reference/sleap_io/io/labelstudio/#sleap_io.io.labelstudio.convert_labels","title":"<code>convert_labels(labels)</code>","text":"<p>Convert a <code>Labels</code> object into Label Studio-formatted annotations.</p> <p>Parameters:</p> Name Type Description Default <code>labels</code> <code>Labels</code> <p>SLEAP <code>Labels</code> to be converted to Label Studio task format.</p> required <p>Returns:</p> Type Description <code>List[dict]</code> <p>Label Studio dictionaries of the <code>Labels</code> data.</p> Source code in <code>sleap_io/io/labelstudio.py</code> <pre><code>def convert_labels(labels: Labels) -&gt; List[dict]:\n    \"\"\"Convert a `Labels` object into Label Studio-formatted annotations.\n\n    Args:\n        labels: SLEAP `Labels` to be converted to Label Studio task format.\n\n    Returns:\n        Label Studio dictionaries of the `Labels` data.\n    \"\"\"\n    out = []\n    for frame in labels.labeled_frames:\n        if frame.video.shape is not None:\n            height = frame.video.shape[1]\n            width = frame.video.shape[2]\n        else:\n            height = 100\n            width = 100\n\n        frame_annots = []\n\n        for instance in frame.instances:\n            inst_id = str(uuid.uuid4())\n            frame_annots.append(\n                {\n                    \"original_width\": width,\n                    \"original_height\": height,\n                    \"image_rotation\": 0,\n                    \"value\": {\n                        \"x\": 0,\n                        \"y\": 0,\n                        \"width\": width,\n                        \"height\": height,\n                        \"rotation\": 0,\n                        \"rectanglelabels\": [\n                            \"instance_class\"\n                        ],  # TODO: need to handle instance classes / identity\n                    },\n                    \"id\": inst_id,\n                    \"from_name\": \"individuals\",\n                    \"to_name\": \"image\",\n                    \"type\": \"rectanglelabels\",\n                }\n            )\n\n            for node, point in instance.points.items():\n                point_id = str(uuid.uuid4())\n\n                # add this point\n                frame_annots.append(\n                    {\n                        \"original_width\": width,\n                        \"original_height\": height,\n                        \"image_rotation\": 0,\n                        \"value\": {\n                            \"x\": point.x / width * 100,\n                            \"y\": point.y / height * 100,\n                            \"keypointlabels\": [node.name],\n                        },\n                        \"from_name\": \"keypoint-label\",\n                        \"to_name\": \"image\",\n                        \"type\": \"keypointlabels\",\n                        \"id\": point_id,\n                    }\n                )\n\n                # add relationship of point to individual\n                frame_annots.append(\n                    {\n                        \"from_id\": point_id,\n                        \"to_id\": inst_id,\n                        \"type\": \"relation\",\n                        \"direction\": \"right\",\n                    }\n                )\n\n        out.append(\n            {\n                \"data\": {\n                    # 'image': f\"/data/{up_deets['file']}\"\n                },\n                \"meta\": {\n                    \"video\": {\n                        \"filename\": frame.video.filename,\n                        \"frame_idx\": frame.frame_idx,\n                        \"shape\": frame.video.shape,\n                    }\n                },\n                \"annotations\": [\n                    {\n                        \"result\": frame_annots,\n                        \"was_cancelled\": False,\n                        \"ground_truth\": False,\n                        \"created_at\": datetime.datetime.utcnow().strftime(\n                            \"%Y-%m-%dT%H:%M:%S.%fZ\"\n                        ),\n                        \"updated_at\": datetime.datetime.utcnow().strftime(\n                            \"%Y-%m-%dT%H:%M:%S.%fZ\"\n                        ),\n                        \"lead_time\": 0,\n                        \"result_count\": 1,\n                        # \"completed_by\": user['id']\n                    }\n                ],\n            }\n        )\n\n    return out\n</code></pre>"},{"location":"reference/sleap_io/io/labelstudio/#sleap_io.io.labelstudio.filter_and_index","title":"<code>filter_and_index(annotations, annot_type)</code>","text":"<p>Filter annotations based on the type field and index them by ID.</p> <p>Parameters:</p> Name Type Description Default <code>annotations</code> <code>Iterable[dict]</code> <p>annotations to filter and index</p> required <code>annot_type</code> <code>str</code> <p>annotation type to filter e.x. 'keypointlabels' or 'rectanglelabels'</p> required <p>Returns:</p> Type Description <code>Dict[str, dict]</code> <p>Dict of ndexed and filtered annotations. Only annotations of type <code>annot_type</code> will survive, and annotations are indexed by ID.</p> Source code in <code>sleap_io/io/labelstudio.py</code> <pre><code>def filter_and_index(annotations: Iterable[dict], annot_type: str) -&gt; Dict[str, dict]:\n    \"\"\"Filter annotations based on the type field and index them by ID.\n\n    Args:\n        annotations: annotations to filter and index\n        annot_type: annotation type to filter e.x. 'keypointlabels' or 'rectanglelabels'\n\n    Returns:\n        Dict of ndexed and filtered annotations. Only annotations of type `annot_type`\n        will survive, and annotations are indexed by ID.\n    \"\"\"\n    filtered = list(filter(lambda d: d[\"type\"] == annot_type, annotations))\n    indexed = {item[\"id\"]: item for item in filtered}\n    return indexed\n</code></pre>"},{"location":"reference/sleap_io/io/labelstudio/#sleap_io.io.labelstudio.infer_nodes","title":"<code>infer_nodes(tasks)</code>","text":"<p>Parse the loaded JSON tasks to create a minimal skeleton.</p> <p>Parameters:</p> Name Type Description Default <code>tasks</code> <code>List[Dict]</code> <p>Collection of tasks loaded from Label Studio JSON.</p> required <p>Returns:</p> Type Description <code>Skeleton</code> <p>The inferred <code>Skeleton</code>.</p> Source code in <code>sleap_io/io/labelstudio.py</code> <pre><code>def infer_nodes(tasks: List[Dict]) -&gt; Skeleton:\n    \"\"\"Parse the loaded JSON tasks to create a minimal skeleton.\n\n    Args:\n        tasks: Collection of tasks loaded from Label Studio JSON.\n\n    Returns:\n        The inferred `Skeleton`.\n    \"\"\"\n    node_names = set()\n    for entry in tasks:\n        if \"annotations\" in entry:\n            key = \"annotations\"\n        elif \"completions\" in entry:\n            key = \"completions\"\n        else:\n            raise ValueError(\"Cannot find annotation data for entry!\")\n\n        for annotation in entry[key]:\n            for datum in annotation[\"result\"]:\n                if datum[\"type\"] == \"keypointlabels\":\n                    for node_name in datum[\"value\"][\"keypointlabels\"]:\n                        node_names.add(node_name)\n\n    skeleton = Skeleton(nodes=list(node_names))\n    return skeleton\n</code></pre>"},{"location":"reference/sleap_io/io/labelstudio/#sleap_io.io.labelstudio.parse_tasks","title":"<code>parse_tasks(tasks, skeleton)</code>","text":"<p>Read Label Studio style annotations from a file and return a <code>Labels</code> object.</p> <p>Parameters:</p> Name Type Description Default <code>tasks</code> <code>List[Dict]</code> <p>Collection of tasks to be converted to <code>Labels</code>.</p> required <code>skeleton</code> <code>Skeleton</code> <p><code>Skeleton</code> with the nodes and edges to be used.</p> required <p>Returns:</p> Type Description <code>Labels</code> <p>Parsed labels as a <code>Labels</code> instance.</p> Source code in <code>sleap_io/io/labelstudio.py</code> <pre><code>def parse_tasks(tasks: List[Dict], skeleton: Skeleton) -&gt; Labels:\n    \"\"\"Read Label Studio style annotations from a file and return a `Labels` object.\n\n    Args:\n        tasks: Collection of tasks to be converted to `Labels`.\n        skeleton: `Skeleton` with the nodes and edges to be used.\n\n    Returns:\n        Parsed labels as a `Labels` instance.\n    \"\"\"\n    frames: List[LabeledFrame] = []\n    for entry in tasks:\n        # depending version, we have seen keys `annotations` and `completions`\n        if \"annotations\" in entry:\n            key = \"annotations\"\n        elif \"completions\" in entry:\n            key = \"completions\"\n        else:\n            raise ValueError(\"Cannot find annotation data for entry!\")\n\n        frames.append(task_to_labeled_frame(entry, skeleton, key=key))\n\n    return Labels(frames)\n</code></pre>"},{"location":"reference/sleap_io/io/labelstudio/#sleap_io.io.labelstudio.read_labels","title":"<code>read_labels(labels_path, skeleton=None)</code>","text":"<p>Read Label Studio style annotations from a file and return a <code>Labels</code> object.</p> <p>Parameters:</p> Name Type Description Default <code>labels_path</code> <code>str</code> <p>Path to the Label Studio annotation file, in json format.</p> required <code>skeleton</code> <code>Optional[Union[Skeleton, List[str]]]</code> <p>An optional <code>Skeleton</code> object or list of node names. If not provided (the default), skeleton will be inferred from the data. It may be useful to provide this so the keypoint label types can be filtered to just the ones in the skeleton.</p> <code>None</code> <p>Returns:</p> Type Description <code>Labels</code> <p>Parsed labels as a <code>Labels</code> instance.</p> Source code in <code>sleap_io/io/labelstudio.py</code> <pre><code>def read_labels(\n    labels_path: str, skeleton: Optional[Union[Skeleton, List[str]]] = None\n) -&gt; Labels:\n    \"\"\"Read Label Studio style annotations from a file and return a `Labels` object.\n\n    Args:\n        labels_path: Path to the Label Studio annotation file, in json format.\n        skeleton: An optional `Skeleton` object or list of node names. If not provided\n            (the default), skeleton will be inferred from the data. It may be useful to\n            provide this so the keypoint label types can be filtered to just the ones in\n            the skeleton.\n\n    Returns:\n        Parsed labels as a `Labels` instance.\n    \"\"\"\n    with open(labels_path, \"r\") as task_file:\n        tasks = json.load(task_file)\n\n    if type(skeleton) == list:\n        skeleton = Skeleton(nodes=skeleton)  # type: ignore[arg-type]\n    elif skeleton is None:\n        skeleton = infer_nodes(tasks)\n    else:\n        assert isinstance(skeleton, Skeleton)\n\n    labels = parse_tasks(tasks, skeleton)\n    labels.provenance[\"filename\"] = labels_path\n    return labels\n</code></pre>"},{"location":"reference/sleap_io/io/labelstudio/#sleap_io.io.labelstudio.task_to_labeled_frame","title":"<code>task_to_labeled_frame(task, skeleton, key='annotations')</code>","text":"<p>Parse annotations from an entry.</p> <p>Parameters:</p> Name Type Description Default <code>task</code> <code>dict</code> <p>Label Studio task to be parsed.</p> required <code>skeleton</code> <code>Skeleton</code> <p>Skeleton to use for parsing.</p> required <code>key</code> <code>str</code> <p>Key to use for parsing annotations. Defaults to \"annotations\".</p> <code>'annotations'</code> <p>Returns:</p> Type Description <code>LabeledFrame</code> <p>Parsed <code>LabeledFrame</code> instance.</p> Source code in <code>sleap_io/io/labelstudio.py</code> <pre><code>def task_to_labeled_frame(\n    task: dict, skeleton: Skeleton, key: str = \"annotations\"\n) -&gt; LabeledFrame:\n    \"\"\"Parse annotations from an entry.\n\n    Args:\n        task: Label Studio task to be parsed.\n        skeleton: Skeleton to use for parsing.\n        key: Key to use for parsing annotations. Defaults to \"annotations\".\n\n    Returns:\n        Parsed `LabeledFrame` instance.\n    \"\"\"\n    if len(task[key]) &gt; 1:\n        warnings.warn(\n            f\"Task {task.get('id', '??')}: Multiple annotations found, \"\n            \"only taking the first!\"\n        )\n\n    # only parse the first entry result\n    to_parse = task[key][0][\"result\"]\n\n    individuals = filter_and_index(to_parse, \"rectanglelabels\")\n    keypoints = filter_and_index(to_parse, \"keypointlabels\")\n    relations = build_relation_map(to_parse)\n    instances = []\n\n    if len(individuals) &gt; 0:\n        # multi animal case:\n        for indv_id, indv in individuals.items():\n            points = {}\n            for rel in relations[indv_id]:\n                kpt = keypoints.pop(rel)\n                node = Node(kpt[\"value\"][\"keypointlabels\"][0])\n                x_pos = (kpt[\"value\"][\"x\"] * kpt[\"original_width\"]) / 100\n                y_pos = (kpt[\"value\"][\"y\"] * kpt[\"original_height\"]) / 100\n\n                # If the value is a NAN, the user did not mark this keypoint\n                if math.isnan(x_pos) or math.isnan(y_pos):\n                    continue\n\n                points[node] = Point(x_pos, y_pos)\n\n            if len(points) &gt; 0:\n                instances.append(Instance(points, skeleton))\n\n    # If this is multi-animal, any leftover keypoints should be unique bodyparts, and\n    # will be collected here if single-animal, we only have 'unique bodyparts' [in a\n    # way] and the process is identical\n    points = {}\n    for _, kpt in keypoints.items():\n        node = Node(kpt[\"value\"][\"keypointlabels\"][0])\n        points[node] = Point(\n            (kpt[\"value\"][\"x\"] * kpt[\"original_width\"]) / 100,\n            (kpt[\"value\"][\"y\"] * kpt[\"original_height\"]) / 100,\n            visible=True,\n        )\n    if len(points) &gt; 0:\n        instances.append(Instance(points, skeleton))\n\n    video, frame_idx = video_from_task(task)\n\n    return LabeledFrame(video, frame_idx, instances)\n</code></pre>"},{"location":"reference/sleap_io/io/labelstudio/#sleap_io.io.labelstudio.video_from_task","title":"<code>video_from_task(task)</code>","text":"<p>Given a Label Studio task, retrieve video information.</p> <p>Parameters:</p> Name Type Description Default <code>task</code> <code>dict</code> <p>Label Studio task</p> required <p>Returns:</p> Type Description <code>Tuple[Video, int]</code> <p>Video and frame index for this task</p> Source code in <code>sleap_io/io/labelstudio.py</code> <pre><code>def video_from_task(task: dict) -&gt; Tuple[Video, int]:\n    \"\"\"Given a Label Studio task, retrieve video information.\n\n    Args:\n        task: Label Studio task\n\n    Returns:\n        Video and frame index for this task\n    \"\"\"\n    if \"meta\" in task and \"video\" in task[\"meta\"]:\n        video = Video(task[\"meta\"][\"video\"][\"filename\"], task[\"meta\"][\"video\"][\"shape\"])\n        frame_idx = task[\"meta\"][\"video\"][\"frame_idx\"]\n        return video, frame_idx\n\n    else:\n        raise KeyError(\"Unable to locate video information for task!\", task)\n</code></pre>"},{"location":"reference/sleap_io/io/labelstudio/#sleap_io.io.labelstudio.write_labels","title":"<code>write_labels(labels, filename)</code>","text":"<p>Convert and save a SLEAP <code>Labels</code> object to a Label Studio <code>.json</code> file.</p> <p>Parameters:</p> Name Type Description Default <code>labels</code> <code>Labels</code> <p>SLEAP <code>Labels</code> to be converted to Label Studio task format.</p> required <code>filename</code> <code>str</code> <p>Path to save Label Studio annotations (<code>.json</code>).</p> required Source code in <code>sleap_io/io/labelstudio.py</code> <pre><code>def write_labels(labels: Labels, filename: str):\n    \"\"\"Convert and save a SLEAP `Labels` object to a Label Studio `.json` file.\n\n    Args:\n        labels: SLEAP `Labels` to be converted to Label Studio task format.\n        filename: Path to save Label Studio annotations (`.json`).\n    \"\"\"\n\n    def _encode(obj):\n        if type(obj).__name__ == \"uint64\":\n            return int(obj)\n\n    ls_dicts = convert_labels(labels)\n    with open(filename, \"w\") as f:\n        json.dump(ls_dicts, f, indent=4, default=_encode)\n</code></pre>"},{"location":"reference/sleap_io/io/main/","title":"main","text":""},{"location":"reference/sleap_io/io/main/#sleap_io.io.main","title":"<code>sleap_io.io.main</code>","text":"<p>This module contains high-level wrappers for utilizing different I/O backends.</p>"},{"location":"reference/sleap_io/io/main/#sleap_io.io.main.load_file","title":"<code>load_file(filename, format=None, **kwargs)</code>","text":"<p>Load a file and return the appropriate object.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str | Path</code> <p>Path to a file.</p> required <code>format</code> <code>Optional[str]</code> <p>Optional format to load as. If not provided, will be inferred from the file extension. Available formats are: \"slp\", \"nwb\", \"labelstudio\", \"jabs\" and \"video\".</p> <code>None</code> <p>Returns:</p> Type Description <code>Union[Labels, Video]</code> <p>A <code>Labels</code> or <code>Video</code> object.</p> Source code in <code>sleap_io/io/main.py</code> <pre><code>def load_file(\n    filename: str | Path, format: Optional[str] = None, **kwargs\n) -&gt; Union[Labels, Video]:\n    \"\"\"Load a file and return the appropriate object.\n\n    Args:\n        filename: Path to a file.\n        format: Optional format to load as. If not provided, will be inferred from the\n            file extension. Available formats are: \"slp\", \"nwb\", \"labelstudio\", \"jabs\"\n            and \"video\".\n\n    Returns:\n        A `Labels` or `Video` object.\n    \"\"\"\n    if isinstance(filename, Path):\n        filename = filename.as_posix()\n\n    if format is None:\n        if filename.endswith(\".slp\"):\n            format = \"slp\"\n        elif filename.endswith(\".nwb\"):\n            format = \"nwb\"\n        elif filename.endswith(\".json\"):\n            format = \"json\"\n        elif filename.endswith(\".h5\"):\n            format = \"jabs\"\n        else:\n            for vid_ext in Video.EXTS:\n                if filename.endswith(vid_ext):\n                    format = \"video\"\n                    break\n        if format is None:\n            raise ValueError(f\"Could not infer format from filename: '{filename}'.\")\n\n    if filename.endswith(\".slp\"):\n        return load_slp(filename, **kwargs)\n    elif filename.endswith(\".nwb\"):\n        return load_nwb(filename, **kwargs)\n    elif filename.endswith(\".json\"):\n        return load_labelstudio(filename, **kwargs)\n    elif filename.endswith(\".h5\"):\n        return load_jabs(filename, **kwargs)\n    elif format == \"video\":\n        return load_video(filename, **kwargs)\n</code></pre>"},{"location":"reference/sleap_io/io/main/#sleap_io.io.main.load_jabs","title":"<code>load_jabs(filename, skeleton=None)</code>","text":"<p>Read JABS-style predictions from a file and return a <code>Labels</code> object.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>Path to the jabs h5 pose file.</p> required <code>skeleton</code> <code>Optional[Skeleton]</code> <p>An optional <code>Skeleton</code> object.</p> <code>None</code> <p>Returns:</p> Type Description <code>Labels</code> <p>Parsed labels as a <code>Labels</code> instance.</p> Source code in <code>sleap_io/io/main.py</code> <pre><code>def load_jabs(filename: str, skeleton: Optional[Skeleton] = None) -&gt; Labels:\n    \"\"\"Read JABS-style predictions from a file and return a `Labels` object.\n\n    Args:\n        filename: Path to the jabs h5 pose file.\n        skeleton: An optional `Skeleton` object.\n\n    Returns:\n        Parsed labels as a `Labels` instance.\n    \"\"\"\n    return jabs.read_labels(filename, skeleton=skeleton)\n</code></pre>"},{"location":"reference/sleap_io/io/main/#sleap_io.io.main.load_labelstudio","title":"<code>load_labelstudio(filename, skeleton=None)</code>","text":"<p>Read Label Studio-style annotations from a file and return a <code>Labels</code> object.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>Path to the label-studio annotation file in JSON format.</p> required <code>skeleton</code> <code>Optional[Union[Skeleton, list[str]]]</code> <p>An optional <code>Skeleton</code> object or list of node names. If not provided (the default), skeleton will be inferred from the data. It may be useful to provide this so the keypoint label types can be filtered to just the ones in the skeleton.</p> <code>None</code> <p>Returns:</p> Type Description <code>Labels</code> <p>Parsed labels as a <code>Labels</code> instance.</p> Source code in <code>sleap_io/io/main.py</code> <pre><code>def load_labelstudio(\n    filename: str, skeleton: Optional[Union[Skeleton, list[str]]] = None\n) -&gt; Labels:\n    \"\"\"Read Label Studio-style annotations from a file and return a `Labels` object.\n\n    Args:\n        filename: Path to the label-studio annotation file in JSON format.\n        skeleton: An optional `Skeleton` object or list of node names. If not provided\n            (the default), skeleton will be inferred from the data. It may be useful to\n            provide this so the keypoint label types can be filtered to just the ones in\n            the skeleton.\n\n    Returns:\n        Parsed labels as a `Labels` instance.\n    \"\"\"\n    return labelstudio.read_labels(filename, skeleton=skeleton)\n</code></pre>"},{"location":"reference/sleap_io/io/main/#sleap_io.io.main.load_nwb","title":"<code>load_nwb(filename)</code>","text":"<p>Load an NWB dataset as a SLEAP <code>Labels</code> object.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>Path to a NWB file (<code>.nwb</code>).</p> required <p>Returns:</p> Type Description <code>Labels</code> <p>The dataset as a <code>Labels</code> object.</p> Source code in <code>sleap_io/io/main.py</code> <pre><code>def load_nwb(filename: str) -&gt; Labels:\n    \"\"\"Load an NWB dataset as a SLEAP `Labels` object.\n\n    Args:\n        filename: Path to a NWB file (`.nwb`).\n\n    Returns:\n        The dataset as a `Labels` object.\n    \"\"\"\n    return nwb.read_nwb(filename)\n</code></pre>"},{"location":"reference/sleap_io/io/main/#sleap_io.io.main.load_slp","title":"<code>load_slp(filename)</code>","text":"<p>Load a SLEAP dataset.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>Path to a SLEAP labels file (<code>.slp</code>).</p> required <p>Returns:</p> Type Description <code>Labels</code> <p>The dataset as a <code>Labels</code> object.</p> Source code in <code>sleap_io/io/main.py</code> <pre><code>def load_slp(filename: str) -&gt; Labels:\n    \"\"\"Load a SLEAP dataset.\n\n    Args:\n        filename: Path to a SLEAP labels file (`.slp`).\n\n    Returns:\n        The dataset as a `Labels` object.\n    \"\"\"\n    return slp.read_labels(filename)\n</code></pre>"},{"location":"reference/sleap_io/io/main/#sleap_io.io.main.load_video","title":"<code>load_video(filename, **kwargs)</code>","text":"<p>Load a video file.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>The filename(s) of the video. Supported extensions: \"mp4\", \"avi\", \"mov\", \"mj2\", \"mkv\", \"h5\", \"hdf5\", \"slp\", \"png\", \"jpg\", \"jpeg\", \"tif\", \"tiff\", \"bmp\". If the filename is a list, a list of image filenames are expected. If filename is a folder, it will be searched for images.</p> required <p>Returns:</p> Type Description <code>Video</code> <p>A <code>Video</code> object.</p> Source code in <code>sleap_io/io/main.py</code> <pre><code>def load_video(filename: str, **kwargs) -&gt; Video:\n    \"\"\"Load a video file.\n\n    Args:\n        filename: The filename(s) of the video. Supported extensions: \"mp4\", \"avi\",\n            \"mov\", \"mj2\", \"mkv\", \"h5\", \"hdf5\", \"slp\", \"png\", \"jpg\", \"jpeg\", \"tif\",\n            \"tiff\", \"bmp\". If the filename is a list, a list of image filenames are\n            expected. If filename is a folder, it will be searched for images.\n\n    Returns:\n        A `Video` object.\n    \"\"\"\n    return Video.from_filename(filename, **kwargs)\n</code></pre>"},{"location":"reference/sleap_io/io/main/#sleap_io.io.main.save_file","title":"<code>save_file(labels, filename, format=None, **kwargs)</code>","text":"<p>Save a file based on the extension.</p> <p>Parameters:</p> Name Type Description Default <code>labels</code> <code>Labels</code> <p>A SLEAP <code>Labels</code> object (see <code>load_slp</code>).</p> required <code>filename</code> <code>str | Path</code> <p>Path to save labels to.</p> required <code>format</code> <code>Optional[str]</code> <p>Optional format to save as. If not provided, will be inferred from the file extension. Available formats are: \"slp\", \"nwb\", \"labelstudio\" and \"jabs\".</p> <code>None</code> Source code in <code>sleap_io/io/main.py</code> <pre><code>def save_file(\n    labels: Labels, filename: str | Path, format: Optional[str] = None, **kwargs\n):\n    \"\"\"Save a file based on the extension.\n\n    Args:\n        labels: A SLEAP `Labels` object (see `load_slp`).\n        filename: Path to save labels to.\n        format: Optional format to save as. If not provided, will be inferred from the\n            file extension. Available formats are: \"slp\", \"nwb\", \"labelstudio\" and\n            \"jabs\".\n    \"\"\"\n    if isinstance(filename, Path):\n        filename = str(filename)\n\n    if format is None:\n        if filename.endswith(\".slp\"):\n            format = \"slp\"\n        elif filename.endswith(\".nwb\"):\n            format = \"nwb\"\n        elif filename.endswith(\".json\"):\n            format = \"labelstudio\"\n        elif \"pose_version\" in kwargs:\n            format = \"jabs\"\n\n    if format == \"slp\":\n        save_slp(labels, filename, **kwargs)\n    elif format == \"nwb\":\n        save_nwb(labels, filename, **kwargs)\n    elif format == \"labelstudio\":\n        save_labelstudio(labels, filename, **kwargs)\n    elif format == \"jabs\":\n        pose_version = kwargs.pop(\"pose_version\", 5)\n        save_jabs(labels, pose_version, filename, **kwargs)\n    else:\n        raise ValueError(f\"Unknown format '{format}' for filename: '{filename}'.\")\n</code></pre>"},{"location":"reference/sleap_io/io/main/#sleap_io.io.main.save_jabs","title":"<code>save_jabs(labels, pose_version, root_folder=None)</code>","text":"<p>Save a SLEAP dataset to JABS pose file format.</p> <p>Parameters:</p> Name Type Description Default <code>labels</code> <code>Labels</code> <p>SLEAP <code>Labels</code> object.</p> required <code>pose_version</code> <code>int</code> <p>The JABS pose version to write data out.</p> required <code>root_folder</code> <code>Optional[str]</code> <p>Optional root folder where the files should be saved.</p> <code>None</code> Note <p>Filenames for JABS poses are based on video filenames.</p> Source code in <code>sleap_io/io/main.py</code> <pre><code>def save_jabs(labels: Labels, pose_version: int, root_folder: Optional[str] = None):\n    \"\"\"Save a SLEAP dataset to JABS pose file format.\n\n    Args:\n        labels: SLEAP `Labels` object.\n        pose_version: The JABS pose version to write data out.\n        root_folder: Optional root folder where the files should be saved.\n\n    Note:\n        Filenames for JABS poses are based on video filenames.\n    \"\"\"\n    jabs.write_labels(labels, pose_version, root_folder)\n</code></pre>"},{"location":"reference/sleap_io/io/main/#sleap_io.io.main.save_labelstudio","title":"<code>save_labelstudio(labels, filename)</code>","text":"<p>Save a SLEAP dataset to Label Studio format.</p> <p>Parameters:</p> Name Type Description Default <code>labels</code> <code>Labels</code> <p>A SLEAP <code>Labels</code> object (see <code>load_slp</code>).</p> required <code>filename</code> <code>str</code> <p>Path to save labels to ending with <code>.json</code>.</p> required Source code in <code>sleap_io/io/main.py</code> <pre><code>def save_labelstudio(labels: Labels, filename: str):\n    \"\"\"Save a SLEAP dataset to Label Studio format.\n\n    Args:\n        labels: A SLEAP `Labels` object (see `load_slp`).\n        filename: Path to save labels to ending with `.json`.\n    \"\"\"\n    labelstudio.write_labels(labels, filename)\n</code></pre>"},{"location":"reference/sleap_io/io/main/#sleap_io.io.main.save_nwb","title":"<code>save_nwb(labels, filename, append=True)</code>","text":"<p>Save a SLEAP dataset to NWB format.</p> <p>Parameters:</p> Name Type Description Default <code>labels</code> <code>Labels</code> <p>A SLEAP <code>Labels</code> object (see <code>load_slp</code>).</p> required <code>filename</code> <code>str</code> <p>Path to NWB file to save to. Must end in <code>.nwb</code>.</p> required <code>append</code> <code>bool</code> <p>If <code>True</code> (the default), append to existing NWB file. File will be created if it does not exist.</p> <code>True</code> <p>See also: nwb.write_nwb, nwb.append_nwb</p> Source code in <code>sleap_io/io/main.py</code> <pre><code>def save_nwb(labels: Labels, filename: str, append: bool = True):\n    \"\"\"Save a SLEAP dataset to NWB format.\n\n    Args:\n        labels: A SLEAP `Labels` object (see `load_slp`).\n        filename: Path to NWB file to save to. Must end in `.nwb`.\n        append: If `True` (the default), append to existing NWB file. File will be\n            created if it does not exist.\n\n    See also: nwb.write_nwb, nwb.append_nwb\n    \"\"\"\n    if append and Path(filename).exists():\n        nwb.append_nwb(labels, filename)\n    else:\n        nwb.write_nwb(labels, filename)\n</code></pre>"},{"location":"reference/sleap_io/io/main/#sleap_io.io.main.save_slp","title":"<code>save_slp(labels, filename, embed=None)</code>","text":"<p>Save a SLEAP dataset to a <code>.slp</code> file.</p> <p>Parameters:</p> Name Type Description Default <code>labels</code> <code>Labels</code> <p>A SLEAP <code>Labels</code> object (see <code>load_slp</code>).</p> required <code>filename</code> <code>str</code> <p>Path to save labels to ending with <code>.slp</code>.</p> required <code>embed</code> <code>bool | str | list[tuple[Video, int]] | None</code> <p>Frames to embed in the saved labels file. One of <code>None</code>, <code>True</code>, <code>\"all\"</code>, <code>\"user\"</code>, <code>\"suggestions\"</code>, <code>\"user+suggestions\"</code>, <code>\"source\"</code> or list of tuples of <code>(video, frame_idx)</code>.</p> <p>If <code>None</code> is specified (the default) and the labels contains embedded frames, those embedded frames will be re-saved to the new file.</p> <p>If <code>True</code> or <code>\"all\"</code>, all labeled frames and suggested frames will be embedded.</p> <p>If <code>\"source\"</code> is specified, no images will be embedded and the source video will be restored if available.</p> <p>This argument is only valid for the SLP backend.</p> <code>None</code> Source code in <code>sleap_io/io/main.py</code> <pre><code>def save_slp(\n    labels: Labels,\n    filename: str,\n    embed: bool | str | list[tuple[Video, int]] | None = None,\n):\n    \"\"\"Save a SLEAP dataset to a `.slp` file.\n\n    Args:\n        labels: A SLEAP `Labels` object (see `load_slp`).\n        filename: Path to save labels to ending with `.slp`.\n        embed: Frames to embed in the saved labels file. One of `None`, `True`,\n            `\"all\"`, `\"user\"`, `\"suggestions\"`, `\"user+suggestions\"`, `\"source\"` or list\n            of tuples of `(video, frame_idx)`.\n\n            If `None` is specified (the default) and the labels contains embedded\n            frames, those embedded frames will be re-saved to the new file.\n\n            If `True` or `\"all\"`, all labeled frames and suggested frames will be\n            embedded.\n\n            If `\"source\"` is specified, no images will be embedded and the source video\n            will be restored if available.\n\n            This argument is only valid for the SLP backend.\n    \"\"\"\n    return slp.write_labels(filename, labels, embed=embed)\n</code></pre>"},{"location":"reference/sleap_io/io/nwb/","title":"nwb","text":""},{"location":"reference/sleap_io/io/nwb/#sleap_io.io.nwb","title":"<code>sleap_io.io.nwb</code>","text":"<p>Functions to write and read from the neurodata without borders (NWB) format.</p>"},{"location":"reference/sleap_io/io/nwb/#sleap_io.io.nwb.append_nwb","title":"<code>append_nwb(labels, filename, pose_estimation_metadata=None)</code>","text":"<p>Append a SLEAP <code>Labels</code> object to an existing NWB data file.</p> <p>Parameters:</p> Name Type Description Default <code>labels</code> <code>Labels</code> <p>A general <code>Labels</code> object.</p> required <code>filename</code> <code>str</code> <p>The path to the NWB file.</p> required <code>pose_estimation_metadata</code> <code>Optional[dict]</code> <p>Metadata for pose estimation. See <code>append_nwb_data</code> for details.</p> <code>None</code> <p>See also: append_nwb_data</p> Source code in <code>sleap_io/io/nwb.py</code> <pre><code>def append_nwb(\n    labels: Labels, filename: str, pose_estimation_metadata: Optional[dict] = None\n):\n    \"\"\"Append a SLEAP `Labels` object to an existing NWB data file.\n\n    Args:\n        labels: A general `Labels` object.\n        filename: The path to the NWB file.\n        pose_estimation_metadata: Metadata for pose estimation. See `append_nwb_data`\n            for details.\n\n    See also: append_nwb_data\n    \"\"\"\n    with NWBHDF5IO(filename, mode=\"a\", load_namespaces=True) as io:\n        nwb_file = io.read()\n        nwb_file = append_nwb_data(\n            labels, nwb_file, pose_estimation_metadata=pose_estimation_metadata\n        )\n        io.write(nwb_file)\n</code></pre>"},{"location":"reference/sleap_io/io/nwb/#sleap_io.io.nwb.append_nwb_data","title":"<code>append_nwb_data(labels, nwbfile, pose_estimation_metadata=None)</code>","text":"<p>Append data from a Labels object to an in-memory nwb file.</p> <p>Parameters:</p> Name Type Description Default <code>labels</code> <code>Labels</code> <p>A general labels object</p> required <code>nwbfile</code> <code>NWBFile</code> <p>And in-memory nwbfile where the data is to be appended.</p> required <code>pose_estimation_metadata</code> <code>Optional[dict]</code> <p>This argument has a dual purpose:</p> <p>1) It can be used to pass time information about the video which is necessary for synchronizing frames in pose estimation tracking to other modalities. Either the video timestamps can be passed to This can be used to pass the timestamps with the key <code>video_timestamps</code> or the sampling rate with key<code>video_sample_rate</code>.</p> <p>e.g. pose_estimation_metadata[\"video_timestamps\"] = np.array(timestamps) or   pose_estimation_metadata[\"video_sample_rate\"] = 15  # In Hz</p> <p>2) The other use of this dictionary is to ovewrite sleap-io default arguments for the PoseEstimation container. see https://github.com/rly/ndx-pose for a full list or arguments.</p> <code>None</code> <p>Returns:</p> Type Description <code>NWBFile</code> <p>An in-memory nwbfile with the data from the labels object appended.</p> Source code in <code>sleap_io/io/nwb.py</code> <pre><code>def append_nwb_data(\n    labels: Labels, nwbfile: NWBFile, pose_estimation_metadata: Optional[dict] = None\n) -&gt; NWBFile:\n    \"\"\"Append data from a Labels object to an in-memory nwb file.\n\n    Args:\n        labels: A general labels object\n        nwbfile: And in-memory nwbfile where the data is to be appended.\n        pose_estimation_metadata: This argument has a dual purpose:\n\n            1) It can be used to pass time information about the video which is\n            necessary for synchronizing frames in pose estimation tracking to other\n            modalities. Either the video timestamps can be passed to\n            This can be used to pass the timestamps with the key `video_timestamps`\n            or the sampling rate with key`video_sample_rate`.\n\n            e.g. pose_estimation_metadata[\"video_timestamps\"] = np.array(timestamps)\n            or   pose_estimation_metadata[\"video_sample_rate\"] = 15  # In Hz\n\n            2) The other use of this dictionary is to ovewrite sleap-io default\n            arguments for the PoseEstimation container.\n            see https://github.com/rly/ndx-pose for a full list or arguments.\n\n    Returns:\n        An in-memory nwbfile with the data from the labels object appended.\n    \"\"\"\n    pose_estimation_metadata = pose_estimation_metadata or dict()\n\n    # Extract default metadata\n    provenance = labels.provenance\n    default_metadata = dict(scorer=str(provenance))\n    sleap_version = provenance.get(\"sleap_version\", None)\n    default_metadata[\"source_software_version\"] = sleap_version\n\n    labels_data_df = convert_predictions_to_dataframe(labels)\n\n    # For every video create a processing module\n    for video_index, video in enumerate(labels.videos):\n        video_path = Path(video.filename)\n        processing_module_name = f\"SLEAP_VIDEO_{video_index:03}_{video_path.stem}\"\n        nwb_processing_module = get_processing_module_for_video(\n            processing_module_name, nwbfile\n        )\n\n        # Propagate video metadata\n        default_metadata[\"original_videos\"] = [f\"{video.filename}\"]  # type: ignore\n        default_metadata[\"labeled_videos\"] = [f\"{video.filename}\"]  # type: ignore\n\n        # Overwrite default with the user provided metadata\n        default_metadata.update(pose_estimation_metadata)\n\n        # For every track in that video create a PoseEstimation container\n        name_of_tracks_in_video = (\n            labels_data_df[video.filename]\n            .columns.get_level_values(\"track_name\")\n            .unique()\n        )\n\n        for track_index, track_name in enumerate(name_of_tracks_in_video):\n            pose_estimation_container = build_pose_estimation_container_for_track(\n                labels_data_df,\n                labels,\n                track_name,\n                video,\n                default_metadata,\n            )\n            nwb_processing_module.add(pose_estimation_container)\n\n    return nwbfile\n</code></pre>"},{"location":"reference/sleap_io/io/nwb/#sleap_io.io.nwb.build_pose_estimation_container_for_track","title":"<code>build_pose_estimation_container_for_track(labels_data_df, labels, track_name, video, pose_estimation_metadata)</code>","text":"<p>Create a PoseEstimation container for a track.</p> <p>Parameters:</p> Name Type Description Default <code>labels_data_df</code> <code>DataFrame</code> <p>A pandas object with the data corresponding to the predicted instances associated to this labels object.</p> required <code>labels</code> <code>Labels</code> <p>A general labels object</p> required <code>track_name</code> <code>str</code> <p>The name of the track in labels.tracks</p> required <code>video</code> <code>Video</code> <p>The video to which data belongs to</p> required <p>Returns:</p> Name Type Description <code>PoseEstimation</code> <code>PoseEstimation</code> <p>A PoseEstimation multicontainer where the time series of all the node trajectories in the track are stored. One time series per node.</p> Source code in <code>sleap_io/io/nwb.py</code> <pre><code>def build_pose_estimation_container_for_track(\n    labels_data_df: pd.DataFrame,\n    labels: Labels,\n    track_name: str,\n    video: Video,\n    pose_estimation_metadata: dict,\n) -&gt; PoseEstimation:\n    \"\"\"Create a PoseEstimation container for a track.\n\n    Args:\n        labels_data_df (pd.DataFrame): A pandas object with the data corresponding\n            to the predicted instances associated to this labels object.\n        labels (Labels): A general labels object\n        track_name (str): The name of the track in labels.tracks\n        video (Video): The video to which data belongs to\n\n    Returns:\n        PoseEstimation: A PoseEstimation multicontainer where the time series\n        of all the node trajectories in the track are stored. One time series per\n        node.\n    \"\"\"\n    # Copy metadata for local use and modification\n    pose_estimation_metadata_copy = deepcopy(pose_estimation_metadata)\n    video_path = Path(video.filename)\n\n    all_track_skeletons = (\n        labels_data_df[video.filename]\n        .columns.get_level_values(\"skeleton_name\")\n        .unique()\n    )\n\n    # Assuming only one skeleton per track\n    skeleton_name = all_track_skeletons[0]\n    skeleton = next(\n        skeleton for skeleton in labels.skeletons if skeleton.name == skeleton_name\n    )\n\n    track_data_df = labels_data_df[\n        video.filename,\n        skeleton.name,\n        track_name,\n    ]\n\n    # Combine each node's PoseEstimationSeries to create a PoseEstimation container\n    timestamps = pose_estimation_metadata_copy.pop(\"video_timestamps\", None)\n    sample_rate = pose_estimation_metadata_copy.pop(\"video_sample_rate\", 1.0)\n    if timestamps is None:\n        # Keeps backward compatbility.\n        timestamps = np.arange(track_data_df.shape[0]) * sample_rate\n    else:\n        timestamps = np.asarray(timestamps)\n\n    pose_estimation_series_list = build_track_pose_estimation_list(\n        track_data_df, timestamps\n    )\n\n    # Arrange and mix metadata\n    pose_estimation_container_kwargs = dict(\n        name=f\"track={track_name}\",\n        description=f\"Estimated positions of {skeleton.name} in video {video_path.name}\",\n        pose_estimation_series=pose_estimation_series_list,\n        nodes=skeleton.node_names,\n        edges=np.array(skeleton.edge_inds).astype(\"uint64\"),\n        source_software=\"SLEAP\",\n        # dimensions=np.array([[video.backend.height, video.backend.width]]),\n    )\n\n    pose_estimation_container_kwargs.update(**pose_estimation_metadata_copy)\n    pose_estimation_container = PoseEstimation(**pose_estimation_container_kwargs)\n\n    return pose_estimation_container\n</code></pre>"},{"location":"reference/sleap_io/io/nwb/#sleap_io.io.nwb.build_track_pose_estimation_list","title":"<code>build_track_pose_estimation_list(track_data_df, timestamps)</code>","text":"<p>Build a list of PoseEstimationSeries from tracks.</p> <p>Parameters:</p> Name Type Description Default <code>track_data_df</code> <code>DataFrame</code> <p>A pandas DataFrame object containing the trajectories for all the nodes associated with a specific track.</p> required <p>Returns:</p> Type Description <code>List[PoseEstimationSeries]</code> <p>List[PoseEstimationSeries]: The list of all the PoseEstimationSeries. One for each node.</p> Source code in <code>sleap_io/io/nwb.py</code> <pre><code>def build_track_pose_estimation_list(\n    track_data_df: pd.DataFrame, timestamps: ArrayLike\n) -&gt; List[PoseEstimationSeries]:\n    \"\"\"Build a list of PoseEstimationSeries from tracks.\n\n    Args:\n        track_data_df (pd.DataFrame): A pandas DataFrame object containing the\n            trajectories for all the nodes associated with a specific track.\n\n    Returns:\n        List[PoseEstimationSeries]: The list of all the PoseEstimationSeries.\n        One for each node.\n    \"\"\"\n    name_of_nodes_in_track = track_data_df.columns.get_level_values(\n        \"node_name\"\n    ).unique()\n\n    pose_estimation_series_list: List[PoseEstimationSeries] = []\n    for node_name in name_of_nodes_in_track:\n        # Drop data with missing values\n        data_for_node = track_data_df[node_name].dropna(axis=\"index\", how=\"any\")\n\n        node_trajectory = data_for_node[[\"x\", \"y\"]].to_numpy()\n        confidence = data_for_node[\"score\"].to_numpy()\n\n        reference_frame = (\n            \"The coordinates are in (x, y) relative to the top-left of the image. \"\n            \"Coordinates refer to the midpoint of the pixel. \"\n            \"That is, t the midpoint of the top-left pixel is at (0, 0), whereas \"\n            \"the top-left corner of that same pixel is at (-0.5, -0.5).\"\n        )\n\n        pose_estimation_kwargs = dict(\n            name=f\"{node_name}\",\n            description=f\"Sequential trajectory of {node_name}.\",\n            data=node_trajectory,\n            unit=\"pixels\",\n            reference_frame=reference_frame,\n            confidence=confidence,\n            confidence_definition=\"Point-wise confidence scores.\",\n        )\n\n        # Add timestamps or only rate if the timestamps are uniform\n        frames = data_for_node.index.values\n        timestamps_for_data = timestamps[frames]  # type: ignore[index]\n        sample_periods = np.diff(timestamps_for_data)\n        if sample_periods.size == 0:\n            rate = None  # This is the case with only one data point\n        else:\n            # Difference below 0.1 ms do not matter for behavior in videos\n            uniform_samples = np.unique(sample_periods.round(5)).size == 1\n            rate = 1 / sample_periods[0] if uniform_samples else None\n\n        if rate:\n            # Video sample rates are ints but nwb expect floats\n            rate = float(int(rate))\n            pose_estimation_kwargs.update(\n                rate=rate, starting_time=timestamps_for_data[0]\n            )\n        else:\n            pose_estimation_kwargs.update(timestamps=timestamps_for_data)\n\n        # Build the pose estimation object and attach it to the list\n        pose_estimation_series = PoseEstimationSeries(**pose_estimation_kwargs)\n        pose_estimation_series_list.append(pose_estimation_series)\n\n    return pose_estimation_series_list\n</code></pre>"},{"location":"reference/sleap_io/io/nwb/#sleap_io.io.nwb.get_processing_module_for_video","title":"<code>get_processing_module_for_video(processing_module_name, nwbfile)</code>","text":"<p>Auxiliary function to create a processing module.</p> <p>Checks for the processing module existence and creates if not available.</p> <p>Parameters:</p> Name Type Description Default <code>processing_module_name</code> <code>str</code> <p>The name of the processing module.</p> required <code>nwbfile</code> <code>NWBFile</code> <p>The nwbfile to attach the processing module to.</p> required <p>Returns:</p> Name Type Description <code>ProcessingModule</code> <code>ProcessingModule</code> <p>An nwb processing module with the desired name.</p> Source code in <code>sleap_io/io/nwb.py</code> <pre><code>def get_processing_module_for_video(\n    processing_module_name: str, nwbfile: NWBFile\n) -&gt; ProcessingModule:\n    \"\"\"Auxiliary function to create a processing module.\n\n    Checks for the processing module existence and creates if not available.\n\n    Args:\n        processing_module_name (str): The name of the processing module.\n        nwbfile (NWBFile): The nwbfile to attach the processing module to.\n\n    Returns:\n        ProcessingModule: An nwb processing module with the desired name.\n    \"\"\"\n    description = \"Processed SLEAP data\"\n    processing_module = (\n        nwbfile.processing[processing_module_name]\n        if processing_module_name in nwbfile.processing\n        else nwbfile.create_processing_module(\n            name=processing_module_name, description=description\n        )\n    )\n    return processing_module\n</code></pre>"},{"location":"reference/sleap_io/io/nwb/#sleap_io.io.nwb.get_timestamps","title":"<code>get_timestamps(series)</code>","text":"<p>Return a vector of timestamps for a <code>PoseEstimationSeries</code>.</p> Source code in <code>sleap_io/io/nwb.py</code> <pre><code>def get_timestamps(series: PoseEstimationSeries) -&gt; np.ndarray:\n    \"\"\"Return a vector of timestamps for a `PoseEstimationSeries`.\"\"\"\n    if series.timestamps is not None:\n        return np.asarray(series.timestamps)\n    else:\n        return np.arange(series.data.shape[0]) * series.rate + series.starting_time\n</code></pre>"},{"location":"reference/sleap_io/io/nwb/#sleap_io.io.nwb.read_nwb","title":"<code>read_nwb(path)</code>","text":"<p>Read an NWB formatted file to a SLEAP <code>Labels</code> object.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Path to an NWB file (<code>.nwb</code>).</p> required <p>Returns:</p> Type Description <code>Labels</code> <p>A <code>Labels</code> object.</p> Source code in <code>sleap_io/io/nwb.py</code> <pre><code>def read_nwb(path: str) -&gt; Labels:\n    \"\"\"Read an NWB formatted file to a SLEAP `Labels` object.\n\n    Args:\n        path: Path to an NWB file (`.nwb`).\n\n    Returns:\n        A `Labels` object.\n    \"\"\"\n    with NWBHDF5IO(path, mode=\"r\", load_namespaces=True) as io:\n        read_nwbfile = io.read()\n        nwb_file = read_nwbfile.processing\n\n        # Get list of videos\n        video_keys: List[str] = [key for key in nwb_file.keys() if \"SLEAP_VIDEO\" in key]\n        video_tracks = dict()\n\n        # Get track keys\n        test_processing_module: ProcessingModule = nwb_file[video_keys[0]]\n        track_keys: List[str] = list(test_processing_module.fields[\"data_interfaces\"])\n\n        # Get track\n        test_pose_estimation: PoseEstimation = test_processing_module[track_keys[0]]\n        node_names = test_pose_estimation.nodes[:]\n        edge_inds = test_pose_estimation.edges[:]\n\n        for processing_module in nwb_file.values():\n            # Get track keys\n            _track_keys: List[str] = list(processing_module.fields[\"data_interfaces\"])\n            is_tracked: bool = re.sub(\"[0-9]+\", \"\", _track_keys[0]) == \"track\"\n\n            # Figure out the max number of frames and the canonical timestamps\n            timestamps = np.empty(())\n            for track_key in _track_keys:\n                for node_name in node_names:\n                    pose_estimation_series = processing_module[track_key][node_name]\n                    timestamps = np.union1d(\n                        timestamps, get_timestamps(pose_estimation_series)\n                    )\n            timestamps = np.sort(timestamps)\n\n            # Recreate Labels numpy (same as output of Labels.numpy())\n            n_tracks = len(_track_keys)\n            n_frames = len(timestamps)\n            n_nodes = len(node_names)\n            tracks_numpy = np.full((n_frames, n_tracks, n_nodes, 2), np.nan, np.float32)\n            confidence = np.full((n_frames, n_tracks, n_nodes), np.nan, np.float32)\n            for track_idx, track_key in enumerate(_track_keys):\n                pose_estimation = processing_module[track_key]\n\n                for node_idx, node_name in enumerate(node_names):\n                    pose_estimation_series = pose_estimation[node_name]\n                    frame_inds = np.searchsorted(\n                        timestamps, get_timestamps(pose_estimation_series)\n                    )\n                    tracks_numpy[frame_inds, track_idx, node_idx, :] = (\n                        pose_estimation_series.data[:]\n                    )\n                    confidence[frame_inds, track_idx, node_idx] = (\n                        pose_estimation_series.confidence[:]\n                    )\n\n            video_tracks[Path(pose_estimation.original_videos[0]).as_posix()] = (\n                tracks_numpy,\n                confidence,\n                is_tracked,\n            )\n\n    # Create skeleton\n    skeleton = Skeleton(\n        nodes=node_names,\n        edges=edge_inds,\n    )\n\n    # Add instances to labeled frames\n    lfs = []\n    for video_fn, (tracks_numpy, confidence, is_tracked) in video_tracks.items():\n        video = Video(filename=video_fn)\n        n_frames, n_tracks, n_nodes, _ = tracks_numpy.shape\n        tracks = [Track(name=f\"track{track_idx}\") for track_idx in range(n_tracks)]\n        for frame_idx, (frame_pts, frame_confs) in enumerate(\n            zip(tracks_numpy, confidence)\n        ):\n            insts: List[Union[Instance, PredictedInstance]] = []\n            for track, (inst_pts, inst_confs) in zip(\n                tracks, zip(frame_pts, frame_confs)\n            ):\n                if np.isnan(inst_pts).all():\n                    continue\n                insts.append(\n                    PredictedInstance.from_numpy(\n                        points=inst_pts,  # (n_nodes, 2)\n                        point_scores=inst_confs,  # (n_nodes,)\n                        instance_score=inst_confs.mean(),  # ()\n                        skeleton=skeleton,\n                        track=track if is_tracked else None,\n                    )\n                )\n            if len(insts) &gt; 0:\n                lfs.append(\n                    LabeledFrame(video=video, frame_idx=frame_idx, instances=insts)\n                )\n    labels = Labels(lfs)\n    labels.provenance[\"filename\"] = path\n    return labels\n</code></pre>"},{"location":"reference/sleap_io/io/nwb/#sleap_io.io.nwb.write_nwb","title":"<code>write_nwb(labels, nwbfile_path, nwb_file_kwargs=None, pose_estimation_metadata=None)</code>","text":"<p>Write labels to an nwb file and save it to the nwbfile_path given.</p> <p>Parameters:</p> Name Type Description Default <code>labels</code> <code>Labels</code> <p>A general <code>Labels</code> object.</p> required <code>nwbfile_path</code> <code>str</code> <p>The path where the nwb file is to be written.</p> required <code>nwb_file_kwargs</code> <code>Optional[dict]</code> <p>A dict containing metadata to the nwbfile. Example: nwb_file_kwargs = {     'session_description: 'your_session_description',     'identifier': 'your session_identifier', } For a full list of possible values see: https://pynwb.readthedocs.io/en/stable/pynwb.file.html#pynwb.file.NWBFile</p> <p>Defaults to None and default values are used to generate the nwb file.</p> <code>None</code> <code>pose_estimation_metadata</code> <code>Optional[dict]</code> <p>This argument has a dual purpose:</p> <p>1) It can be used to pass time information about the video which is necessary for synchronizing frames in pose estimation tracking to other modalities. Either the video timestamps can be passed to This can be used to pass the timestamps with the key <code>video_timestamps</code> or the sampling rate with key<code>video_sample_rate</code>.</p> <p>e.g. pose_estimation_metadata[\"video_timestamps\"] = np.array(timestamps) or   pose_estimation_metadata[\"video_sample_rate] = 15  # In Hz</p> <p>2) The other use of this dictionary is to ovewrite sleap-io default arguments for the PoseEstimation container. see https://github.com/rly/ndx-pose for a full list or arguments.</p> <code>None</code> Source code in <code>sleap_io/io/nwb.py</code> <pre><code>def write_nwb(\n    labels: Labels,\n    nwbfile_path: str,\n    nwb_file_kwargs: Optional[dict] = None,\n    pose_estimation_metadata: Optional[dict] = None,\n):\n    \"\"\"Write labels to an nwb file and save it to the nwbfile_path given.\n\n    Args:\n        labels: A general `Labels` object.\n        nwbfile_path: The path where the nwb file is to be written.\n        nwb_file_kwargs: A dict containing metadata to the nwbfile. Example:\n            nwb_file_kwargs = {\n                'session_description: 'your_session_description',\n                'identifier': 'your session_identifier',\n            }\n            For a full list of possible values see:\n            https://pynwb.readthedocs.io/en/stable/pynwb.file.html#pynwb.file.NWBFile\n\n            Defaults to None and default values are used to generate the nwb file.\n\n        pose_estimation_metadata: This argument has a dual purpose:\n\n            1) It can be used to pass time information about the video which is\n            necessary for synchronizing frames in pose estimation tracking to other\n            modalities. Either the video timestamps can be passed to\n            This can be used to pass the timestamps with the key `video_timestamps`\n            or the sampling rate with key`video_sample_rate`.\n\n            e.g. pose_estimation_metadata[\"video_timestamps\"] = np.array(timestamps)\n            or   pose_estimation_metadata[\"video_sample_rate] = 15  # In Hz\n\n            2) The other use of this dictionary is to ovewrite sleap-io default\n            arguments for the PoseEstimation container.\n            see https://github.com/rly/ndx-pose for a full list or arguments.\n    \"\"\"\n    nwb_file_kwargs = nwb_file_kwargs or dict()\n\n    # Add required values for nwbfile if not present\n    session_description = nwb_file_kwargs.get(\n        \"session_description\", \"Processed SLEAP pose data\"\n    )\n    session_start_time = nwb_file_kwargs.get(\n        \"session_start_time\", datetime.datetime.now(datetime.timezone.utc)\n    )\n    identifier = nwb_file_kwargs.get(\"identifier\", str(uuid.uuid1()))\n\n    nwb_file_kwargs.update(\n        session_description=session_description,\n        session_start_time=session_start_time,\n        identifier=identifier,\n    )\n\n    nwbfile = NWBFile(**nwb_file_kwargs)\n    nwbfile = append_nwb_data(labels, nwbfile, pose_estimation_metadata)\n\n    with NWBHDF5IO(str(nwbfile_path), \"w\") as io:\n        io.write(nwbfile)\n</code></pre>"},{"location":"reference/sleap_io/io/slp/","title":"slp","text":""},{"location":"reference/sleap_io/io/slp/#sleap_io.io.slp","title":"<code>sleap_io.io.slp</code>","text":"<p>This module handles direct I/O operations for working with .slp files.</p>"},{"location":"reference/sleap_io/io/slp/#sleap_io.io.slp.InstanceType","title":"<code>InstanceType</code>","text":"<p>             Bases: <code>IntEnum</code></p> <p>Enumeration of instance types to integers.</p> Source code in <code>sleap_io/io/slp.py</code> <pre><code>class InstanceType(IntEnum):\n    \"\"\"Enumeration of instance types to integers.\"\"\"\n\n    USER = 0\n    PREDICTED = 1\n</code></pre>"},{"location":"reference/sleap_io/io/slp/#sleap_io.io.slp.embed_frames","title":"<code>embed_frames(labels_path, labels, embed, image_format='png')</code>","text":"<p>Embed frames in a SLEAP labels file.</p> <p>Parameters:</p> Name Type Description Default <code>labels_path</code> <code>str</code> <p>A string path to the SLEAP labels file.</p> required <code>labels</code> <code>Labels</code> <p>A <code>Labels</code> object to embed in the labels file.</p> required <code>embed</code> <code>list[tuple[Video, int]]</code> <p>A list of tuples of <code>(video, frame_idx)</code> specifying the frames to embed.</p> required <code>image_format</code> <code>str</code> <p>The image format to use for embedding. Valid formats are \"png\" (the default), \"jpg\" or \"hdf5\".</p> <code>'png'</code> Notes <p>This function will embed the frames in the labels file and update the <code>Videos</code> and <code>Labels</code> objects in place.</p> Source code in <code>sleap_io/io/slp.py</code> <pre><code>def embed_frames(\n    labels_path: str,\n    labels: Labels,\n    embed: list[tuple[Video, int]],\n    image_format: str = \"png\",\n):\n    \"\"\"Embed frames in a SLEAP labels file.\n\n    Args:\n        labels_path: A string path to the SLEAP labels file.\n        labels: A `Labels` object to embed in the labels file.\n        embed: A list of tuples of `(video, frame_idx)` specifying the frames to embed.\n        image_format: The image format to use for embedding. Valid formats are \"png\"\n            (the default), \"jpg\" or \"hdf5\".\n\n    Notes:\n        This function will embed the frames in the labels file and update the `Videos`\n        and `Labels` objects in place.\n    \"\"\"\n    to_embed_by_video = {}\n    for video, frame_idx in embed:\n        if video not in to_embed_by_video:\n            to_embed_by_video[video] = []\n        to_embed_by_video[video].append(frame_idx)\n\n    for video in to_embed_by_video:\n        to_embed_by_video[video] = np.unique(to_embed_by_video[video])\n\n    replaced_videos = {}\n    for video, frame_inds in to_embed_by_video.items():\n        video_ind = labels.videos.index(video)\n        embedded_video = embed_video(\n            labels_path,\n            video,\n            group=f\"video{video_ind}\",\n            frame_inds=frame_inds,\n            image_format=image_format,\n        )\n\n        labels.videos[video_ind] = embedded_video\n        replaced_videos[video] = embedded_video\n\n    if len(replaced_videos) &gt; 0:\n        labels.replace_videos(video_map=replaced_videos)\n</code></pre>"},{"location":"reference/sleap_io/io/slp/#sleap_io.io.slp.embed_video","title":"<code>embed_video(labels_path, video, group, frame_inds, image_format='png', fixed_length=True)</code>","text":"<p>Embed frames of a video in a SLEAP labels file.</p> <p>Parameters:</p> Name Type Description Default <code>labels_path</code> <code>str</code> <p>A string path to the SLEAP labels file.</p> required <code>video</code> <code>Video</code> <p>A <code>Video</code> object to embed in the labels file.</p> required <code>group</code> <code>str</code> <p>The name of the group to store the embedded video in. Image data will be stored in a dataset named <code>{group}/video</code>. Frame indices will be stored in a data set named <code>{group}/frame_numbers</code>.</p> required <code>frame_inds</code> <code>list[int]</code> <p>A list of frame indices to embed.</p> required <code>image_format</code> <code>str</code> <p>The image format to use for embedding. Valid formats are \"png\" (the default), \"jpg\" or \"hdf5\".</p> <code>'png'</code> <code>fixed_length</code> <code>bool</code> <p>If <code>True</code> (the default), the embedded images will be padded to the length of the largest image. If <code>False</code>, the images will be stored as variable length, which is smaller but may not be supported by all readers.</p> <code>True</code> <p>Returns:</p> Type Description <code>Video</code> <p>An embedded <code>Video</code> object.</p> <p>If the video is already embedded, the original video will be returned. If not, a new <code>Video</code> object will be created with the embedded data.</p> Source code in <code>sleap_io/io/slp.py</code> <pre><code>def embed_video(\n    labels_path: str,\n    video: Video,\n    group: str,\n    frame_inds: list[int],\n    image_format: str = \"png\",\n    fixed_length: bool = True,\n) -&gt; Video:\n    \"\"\"Embed frames of a video in a SLEAP labels file.\n\n    Args:\n        labels_path: A string path to the SLEAP labels file.\n        video: A `Video` object to embed in the labels file.\n        group: The name of the group to store the embedded video in. Image data will be\n            stored in a dataset named `{group}/video`. Frame indices will be stored\n            in a data set named `{group}/frame_numbers`.\n        frame_inds: A list of frame indices to embed.\n        image_format: The image format to use for embedding. Valid formats are \"png\"\n            (the default), \"jpg\" or \"hdf5\".\n        fixed_length: If `True` (the default), the embedded images will be padded to the\n            length of the largest image. If `False`, the images will be stored as\n            variable length, which is smaller but may not be supported by all readers.\n\n    Returns:\n        An embedded `Video` object.\n\n        If the video is already embedded, the original video will be returned. If not,\n        a new `Video` object will be created with the embedded data.\n    \"\"\"\n    # Load the image data and optionally encode it.\n    imgs_data = []\n    for frame_idx in frame_inds:\n        frame = video[frame_idx]\n\n        if image_format == \"hdf5\":\n            img_data = frame\n        else:\n            if \"cv2\" in sys.modules:\n                img_data = np.squeeze(\n                    cv2.imencode(\".\" + image_format, frame)[1]\n                ).astype(\"int8\")\n            else:\n                img_data = np.frombuffer(\n                    iio.imwrite(\n                        \"&lt;bytes&gt;\", frame.squeeze(axis=-1), extension=\".\" + image_format\n                    ),\n                    dtype=\"int8\",\n                )\n\n        imgs_data.append(img_data)\n\n    # Write the image data to the labels file.\n    with h5py.File(labels_path, \"a\") as f:\n        if image_format == \"hdf5\":\n            f.create_dataset(\n                f\"{group}/video\", data=imgs_data, compression=\"gzip\", chunks=True\n            )\n        else:\n            if fixed_length:\n                ds = f.create_dataset(\n                    f\"{group}/video\",\n                    shape=(len(imgs_data), max(len(img) for img in imgs_data)),\n                    dtype=\"int8\",\n                    compression=\"gzip\",\n                )\n                for i, img in enumerate(imgs_data):\n                    ds[i, : len(img)] = img\n            else:\n                ds = f.create_dataset(\n                    f\"{group}/video\",\n                    shape=(len(imgs_data),),\n                    dtype=h5py.special_dtype(vlen=np.dtype(\"int8\")),\n                )\n                for i, img in enumerate(imgs_data):\n                    ds[i] = img\n\n        # Store metadata.\n        ds.attrs[\"format\"] = image_format\n        (\n            ds.attrs[\"frames\"],\n            ds.attrs[\"height\"],\n            ds.attrs[\"width\"],\n            ds.attrs[\"channels\"],\n        ) = video.shape\n\n        # Store frame indices.\n        f.create_dataset(f\"{group}/frame_numbers\", data=frame_inds)\n\n        # Store source video.\n        if video.source_video is not None:\n            # If this is already an embedded dataset, retain the previous source video.\n            source_video = video.source_video\n            embedded_video = video\n            video.replace_filename(labels_path, open=False)\n        else:\n            source_video = video\n            embedded_video = Video(\n                filename=labels_path,\n                backend=VideoBackend.from_filename(\n                    labels_path,\n                    dataset=f\"{group}/video\",\n                    grayscale=video.grayscale,\n                    keep_open=False,\n                ),\n                source_video=source_video,\n            )\n\n        grp = f.require_group(f\"{group}/source_video\")\n        grp.attrs[\"json\"] = json.dumps(\n            video_to_dict(source_video), separators=(\",\", \":\")\n        )\n\n    return embedded_video\n</code></pre>"},{"location":"reference/sleap_io/io/slp/#sleap_io.io.slp.embed_videos","title":"<code>embed_videos(labels_path, labels, embed)</code>","text":"<p>Embed videos in a SLEAP labels file.</p> <p>Parameters:</p> Name Type Description Default <code>labels_path</code> <code>str</code> <p>A string path to the SLEAP labels file to save.</p> required <code>labels</code> <code>Labels</code> <p>A <code>Labels</code> object to save.</p> required <code>embed</code> <code>bool | str | list[tuple[Video, int]]</code> <p>Frames to embed in the saved labels file. One of <code>None</code>, <code>True</code>, <code>\"all\"</code>, <code>\"user\"</code>, <code>\"suggestions\"</code>, <code>\"user+suggestions\"</code>, <code>\"source\"</code> or list of tuples of <code>(video, frame_idx)</code>.</p> <p>If <code>None</code> is specified (the default) and the labels contains embedded frames, those embedded frames will be re-saved to the new file.</p> <p>If <code>True</code> or <code>\"all\"</code>, all labeled frames and suggested frames will be embedded.</p> <p>If <code>\"source\"</code> is specified, no images will be embedded and the source video will be restored if available.</p> <p>This argument is only valid for the SLP backend.</p> required Source code in <code>sleap_io/io/slp.py</code> <pre><code>def embed_videos(\n    labels_path: str, labels: Labels, embed: bool | str | list[tuple[Video, int]]\n):\n    \"\"\"Embed videos in a SLEAP labels file.\n\n    Args:\n        labels_path: A string path to the SLEAP labels file to save.\n        labels: A `Labels` object to save.\n        embed: Frames to embed in the saved labels file. One of `None`, `True`,\n            `\"all\"`, `\"user\"`, `\"suggestions\"`, `\"user+suggestions\"`, `\"source\"` or list\n            of tuples of `(video, frame_idx)`.\n\n            If `None` is specified (the default) and the labels contains embedded\n            frames, those embedded frames will be re-saved to the new file.\n\n            If `True` or `\"all\"`, all labeled frames and suggested frames will be\n            embedded.\n\n            If `\"source\"` is specified, no images will be embedded and the source video\n            will be restored if available.\n\n            This argument is only valid for the SLP backend.\n    \"\"\"\n    if embed == True:\n        embed = \"all\"\n    if embed == \"user\":\n        embed = [(lf.video, lf.frame_idx) for lf in labels.user_labeled_frames]\n    elif embed == \"suggestions\":\n        embed = [(sf.video, sf.frame_idx) for sf in labels.suggestions]\n    elif embed == \"user+suggestions\":\n        embed = [(lf.video, lf.frame_idx) for lf in labels.user_labeled_frames]\n        embed += [(sf.video, sf.frame_idx) for sf in labels.suggestions]\n    elif embed == \"all\":\n        embed = [(lf.video, lf.frame_idx) for lf in labels]\n        embed += [(sf.video, sf.frame_idx) for sf in labels.suggestions]\n    elif embed == \"source\":\n        embed = []\n    elif isinstance(embed, list):\n        embed = embed\n    else:\n        raise ValueError(f\"Invalid value for embed: {embed}\")\n\n    embed_frames(labels_path, labels, embed)\n</code></pre>"},{"location":"reference/sleap_io/io/slp/#sleap_io.io.slp.make_video","title":"<code>make_video(labels_path, video_json, video_ind=None)</code>","text":"<p>Create a <code>Video</code> object from a JSON dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>labels_path</code> <code>str</code> <p>A string path to the SLEAP labels file.</p> required <code>video_json</code> <code>dict</code> <p>A dictionary containing the video metadata.</p> required <code>video_ind</code> <code>int | None</code> <p>The index of the video in the labels file. This is used to try to recover the source video for embedded videos. This is skipped if <code>None</code>.</p> <code>None</code> Source code in <code>sleap_io/io/slp.py</code> <pre><code>def make_video(\n    labels_path: str, video_json: dict, video_ind: int | None = None\n) -&gt; Video:\n    \"\"\"Create a `Video` object from a JSON dictionary.\n\n    Args:\n        labels_path: A string path to the SLEAP labels file.\n        video_json: A dictionary containing the video metadata.\n        video_ind: The index of the video in the labels file. This is used to try to\n            recover the source video for embedded videos. This is skipped if `None`.\n    \"\"\"\n    backend_metadata = video_json[\"backend\"]\n    video_path = backend_metadata[\"filename\"]\n\n    # Marker for embedded videos.\n    source_video = None\n    is_embedded = False\n    if video_path == \".\":\n        video_path = labels_path\n        is_embedded = True\n\n    # Basic path resolution.\n    video_path = Path(video_path)\n    if not video_path.exists():\n        # Check for the same filename in the same directory as the labels file.\n        video_path_ = Path(labels_path).parent / video_path.name\n        if video_path_.exists():\n            video_path = video_path_\n        else:\n            # TODO (TP): Expand capabilities of path resolution to support more\n            # complex path finding strategies.\n            pass\n\n    # Convert video path to string.\n    video_path = video_path.as_posix()\n\n    if is_embedded:\n        # Try to recover the source video.\n        with h5py.File(labels_path, \"r\") as f:\n            if f\"video{video_ind}\" in f:\n                source_video_json = json.loads(\n                    f[f\"video{video_ind}/source_video\"].attrs[\"json\"]\n                )\n                source_video = make_video(\n                    labels_path, source_video_json, video_ind=None\n                )\n\n    if \"filenames\" in backend_metadata:\n        # This is an ImageVideo.\n        # TODO: Path resolution.\n        video_path = backend_metadata[\"filenames\"]\n\n    try:\n        backend = VideoBackend.from_filename(\n            video_path,\n            dataset=backend_metadata.get(\"dataset\", None),\n            grayscale=backend_metadata.get(\"grayscale\", None),\n            input_format=backend_metadata.get(\"input_format\", None),\n        )\n    except ValueError:\n        backend = None\n\n    return Video(\n        filename=video_path,\n        backend=backend,\n        backend_metadata=backend_metadata,\n        source_video=source_video,\n    )\n</code></pre>"},{"location":"reference/sleap_io/io/slp/#sleap_io.io.slp.read_instances","title":"<code>read_instances(labels_path, skeletons, tracks, points, pred_points, format_id)</code>","text":"<p>Read <code>Instance</code> dataset in a SLEAP labels file.</p> <p>Parameters:</p> Name Type Description Default <code>labels_path</code> <code>str</code> <p>A string path to the SLEAP labels file.</p> required <code>skeletons</code> <code>list[Skeleton]</code> <p>A list of <code>Skeleton</code> objects (see <code>read_skeletons</code>).</p> required <code>tracks</code> <code>list[Track]</code> <p>A list of <code>Track</code> objects (see <code>read_tracks</code>).</p> required <code>points</code> <code>list[Point]</code> <p>A list of <code>Point</code> objects (see <code>read_points</code>).</p> required <code>pred_points</code> <code>list[PredictedPoint]</code> <p>A list of <code>PredictedPoint</code> objects (see <code>read_pred_points</code>).</p> required <code>format_id</code> <code>float</code> <p>The format version identifier used to specify the format of the input file.</p> required <p>Returns:</p> Type Description <code>list[Union[Instance, PredictedInstance]]</code> <p>A list of <code>Instance</code> and/or <code>PredictedInstance</code> objects.</p> Source code in <code>sleap_io/io/slp.py</code> <pre><code>def read_instances(\n    labels_path: str,\n    skeletons: list[Skeleton],\n    tracks: list[Track],\n    points: list[Point],\n    pred_points: list[PredictedPoint],\n    format_id: float,\n) -&gt; list[Union[Instance, PredictedInstance]]:\n    \"\"\"Read `Instance` dataset in a SLEAP labels file.\n\n    Args:\n        labels_path: A string path to the SLEAP labels file.\n        skeletons: A list of `Skeleton` objects (see `read_skeletons`).\n        tracks: A list of `Track` objects (see `read_tracks`).\n        points: A list of `Point` objects (see `read_points`).\n        pred_points: A list of `PredictedPoint` objects (see `read_pred_points`).\n        format_id: The format version identifier used to specify the format of the input\n            file.\n\n    Returns:\n        A list of `Instance` and/or `PredictedInstance` objects.\n    \"\"\"\n    instances_data = read_hdf5_dataset(labels_path, \"instances\")\n\n    instances = {}\n    from_predicted_pairs = []\n    for instance_data in instances_data:\n        if format_id &lt; 1.2:\n            (\n                instance_id,\n                instance_type,\n                frame_id,\n                skeleton_id,\n                track_id,\n                from_predicted,\n                instance_score,\n                point_id_start,\n                point_id_end,\n            ) = instance_data\n            tracking_score = np.zeros_like(instance_score)\n        else:\n            (\n                instance_id,\n                instance_type,\n                frame_id,\n                skeleton_id,\n                track_id,\n                from_predicted,\n                instance_score,\n                point_id_start,\n                point_id_end,\n                tracking_score,\n            ) = instance_data\n\n        if instance_type == InstanceType.USER:\n            instances[instance_id] = Instance(\n                points=points[point_id_start:point_id_end],  # type: ignore[arg-type]\n                skeleton=skeletons[skeleton_id],\n                track=tracks[track_id] if track_id &gt;= 0 else None,\n            )\n            if from_predicted &gt;= 0:\n                from_predicted_pairs.append((instance_id, from_predicted))\n        elif instance_type == InstanceType.PREDICTED:\n            instances[instance_id] = PredictedInstance(\n                points=pred_points[point_id_start:point_id_end],  # type: ignore[arg-type]\n                skeleton=skeletons[skeleton_id],\n                track=tracks[track_id] if track_id &gt;= 0 else None,\n                score=instance_score,\n                tracking_score=tracking_score,\n            )\n\n    # Link instances based on from_predicted field.\n    for instance_id, from_predicted in from_predicted_pairs:\n        instances[instance_id].from_predicted = instances[from_predicted]\n\n    # Convert instances back to list.\n    instances = list(instances.values())\n\n    return instances\n</code></pre>"},{"location":"reference/sleap_io/io/slp/#sleap_io.io.slp.read_labels","title":"<code>read_labels(labels_path)</code>","text":"<p>Read a SLEAP labels file.</p> <p>Parameters:</p> Name Type Description Default <code>labels_path</code> <code>str</code> <p>A string path to the SLEAP labels file.</p> required <p>Returns:</p> Type Description <code>Labels</code> <p>The processed <code>Labels</code> object.</p> Source code in <code>sleap_io/io/slp.py</code> <pre><code>def read_labels(labels_path: str) -&gt; Labels:\n    \"\"\"Read a SLEAP labels file.\n\n    Args:\n        labels_path: A string path to the SLEAP labels file.\n\n    Returns:\n        The processed `Labels` object.\n    \"\"\"\n    tracks = read_tracks(labels_path)\n    videos = read_videos(labels_path)\n    skeletons = read_skeletons(labels_path)\n    points = read_points(labels_path)\n    pred_points = read_pred_points(labels_path)\n    format_id = read_hdf5_attrs(labels_path, \"metadata\", \"format_id\")\n    instances = read_instances(\n        labels_path, skeletons, tracks, points, pred_points, format_id\n    )\n    suggestions = read_suggestions(labels_path, videos)\n    metadata = read_metadata(labels_path)\n    provenance = metadata.get(\"provenance\", dict())\n\n    frames = read_hdf5_dataset(labels_path, \"frames\")\n    labeled_frames = []\n    for _, video_id, frame_idx, instance_id_start, instance_id_end in frames:\n        labeled_frames.append(\n            LabeledFrame(\n                video=videos[video_id],\n                frame_idx=frame_idx,\n                instances=instances[instance_id_start:instance_id_end],\n            )\n        )\n\n    labels = Labels(\n        labeled_frames=labeled_frames,\n        videos=videos,\n        skeletons=skeletons,\n        tracks=tracks,\n        suggestions=suggestions,\n        provenance=provenance,\n    )\n    labels.provenance[\"filename\"] = labels_path\n\n    return labels\n</code></pre>"},{"location":"reference/sleap_io/io/slp/#sleap_io.io.slp.read_metadata","title":"<code>read_metadata(labels_path)</code>","text":"<p>Read metadata from a SLEAP labels file.</p> <p>Parameters:</p> Name Type Description Default <code>labels_path</code> <code>str</code> <p>A string path to the SLEAP labels file.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>A dict containing the metadata from a SLEAP labels file.</p> Source code in <code>sleap_io/io/slp.py</code> <pre><code>def read_metadata(labels_path: str) -&gt; dict:\n    \"\"\"Read metadata from a SLEAP labels file.\n\n    Args:\n        labels_path: A string path to the SLEAP labels file.\n\n    Returns:\n        A dict containing the metadata from a SLEAP labels file.\n    \"\"\"\n    md = read_hdf5_attrs(labels_path, \"metadata\", \"json\")\n    return json.loads(md.decode())\n</code></pre>"},{"location":"reference/sleap_io/io/slp/#sleap_io.io.slp.read_points","title":"<code>read_points(labels_path)</code>","text":"<p>Read <code>Point</code> dataset from a SLEAP labels file.</p> <p>Parameters:</p> Name Type Description Default <code>labels_path</code> <code>str</code> <p>A string path to the SLEAP labels file.</p> required <p>Returns:</p> Type Description <code>list[Point]</code> <p>A list of <code>Point</code> objects.</p> Source code in <code>sleap_io/io/slp.py</code> <pre><code>def read_points(labels_path: str) -&gt; list[Point]:\n    \"\"\"Read `Point` dataset from a SLEAP labels file.\n\n    Args:\n        labels_path: A string path to the SLEAP labels file.\n\n    Returns:\n        A list of `Point` objects.\n    \"\"\"\n    pts = read_hdf5_dataset(labels_path, \"points\")\n    return [\n        Point(x=x, y=y, visible=visible, complete=complete)\n        for x, y, visible, complete in pts\n    ]\n</code></pre>"},{"location":"reference/sleap_io/io/slp/#sleap_io.io.slp.read_pred_points","title":"<code>read_pred_points(labels_path)</code>","text":"<p>Read <code>PredictedPoint</code> dataset from a SLEAP labels file.</p> <p>Parameters:</p> Name Type Description Default <code>labels_path</code> <code>str</code> <p>A string path to the SLEAP labels file.</p> required <p>Returns:</p> Type Description <code>list[PredictedPoint]</code> <p>A list of <code>PredictedPoint</code> objects.</p> Source code in <code>sleap_io/io/slp.py</code> <pre><code>def read_pred_points(labels_path: str) -&gt; list[PredictedPoint]:\n    \"\"\"Read `PredictedPoint` dataset from a SLEAP labels file.\n\n    Args:\n        labels_path: A string path to the SLEAP labels file.\n\n    Returns:\n        A list of `PredictedPoint` objects.\n    \"\"\"\n    pred_pts = read_hdf5_dataset(labels_path, \"pred_points\")\n    return [\n        PredictedPoint(x=x, y=y, visible=visible, complete=complete, score=score)\n        for x, y, visible, complete, score in pred_pts\n    ]\n</code></pre>"},{"location":"reference/sleap_io/io/slp/#sleap_io.io.slp.read_skeletons","title":"<code>read_skeletons(labels_path)</code>","text":"<p>Read <code>Skeleton</code> dataset from a SLEAP labels file.</p> <p>Parameters:</p> Name Type Description Default <code>labels_path</code> <code>str</code> <p>A string that contains the path to the labels file.</p> required <p>Returns:</p> Type Description <code>list[Skeleton]</code> <p>A list of <code>Skeleton</code> objects.</p> Source code in <code>sleap_io/io/slp.py</code> <pre><code>def read_skeletons(labels_path: str) -&gt; list[Skeleton]:\n    \"\"\"Read `Skeleton` dataset from a SLEAP labels file.\n\n    Args:\n        labels_path: A string that contains the path to the labels file.\n\n    Returns:\n        A list of `Skeleton` objects.\n    \"\"\"\n    metadata = read_metadata(labels_path)\n\n    # Get node names. This is a superset of all nodes across all skeletons. Note that\n    # node ordering is specific to each skeleton, so we'll need to fix this afterwards.\n    node_names = [x[\"name\"] for x in metadata[\"nodes\"]]\n\n    skeleton_objects = []\n    for skel in metadata[\"skeletons\"]:\n        # Parse out the cattr-based serialization stuff from the skeleton links.\n        edge_inds, symmetry_inds = [], []\n        for link in skel[\"links\"]:\n            if \"py/reduce\" in link[\"type\"]:\n                edge_type = link[\"type\"][\"py/reduce\"][1][\"py/tuple\"][0]\n            else:\n                edge_type = link[\"type\"][\"py/id\"]\n\n            if edge_type == 1:  # 1 -&gt; real edge, 2 -&gt; symmetry edge\n                edge_inds.append((link[\"source\"], link[\"target\"]))\n\n            elif edge_type == 2:\n                symmetry_inds.append((link[\"source\"], link[\"target\"]))\n\n        # Re-index correctly.\n        skeleton_node_inds = [node[\"id\"] for node in skel[\"nodes\"]]\n        sorted_node_names = [node_names[i] for i in skeleton_node_inds]\n\n        # Create nodes.\n        nodes = []\n        for name in sorted_node_names:\n            nodes.append(Node(name=name))\n\n        # Create edges.\n        edge_inds = [\n            (skeleton_node_inds.index(s), skeleton_node_inds.index(d))\n            for s, d in edge_inds\n        ]\n        edges = []\n        for edge in edge_inds:\n            edges.append(Edge(source=nodes[edge[0]], destination=nodes[edge[1]]))\n\n        # Create symmetries.\n        symmetry_inds = [\n            (skeleton_node_inds.index(s), skeleton_node_inds.index(d))\n            for s, d in symmetry_inds\n        ]\n        symmetries = []\n        for symmetry in symmetry_inds:\n            symmetries.append(Symmetry([nodes[symmetry[0]], nodes[symmetry[1]]]))\n\n        # Create the full skeleton.\n        skel = Skeleton(\n            nodes=nodes, edges=edges, symmetries=symmetries, name=skel[\"graph\"][\"name\"]\n        )\n        skeleton_objects.append(skel)\n    return skeleton_objects\n</code></pre>"},{"location":"reference/sleap_io/io/slp/#sleap_io.io.slp.read_suggestions","title":"<code>read_suggestions(labels_path, videos)</code>","text":"<p>Read <code>SuggestionFrame</code> dataset in a SLEAP labels file.</p> <p>Parameters:</p> Name Type Description Default <code>labels_path</code> <code>str</code> <p>A string path to the SLEAP labels file.</p> required <code>videos</code> <code>list[Video]</code> <p>A list of <code>Video</code> objects.</p> required <p>Returns:</p> Type Description <code>list[SuggestionFrame]</code> <p>A list of <code>SuggestionFrame</code> objects.</p> Source code in <code>sleap_io/io/slp.py</code> <pre><code>def read_suggestions(labels_path: str, videos: list[Video]) -&gt; list[SuggestionFrame]:\n    \"\"\"Read `SuggestionFrame` dataset in a SLEAP labels file.\n\n    Args:\n        labels_path: A string path to the SLEAP labels file.\n        videos: A list of `Video` objects.\n\n    Returns:\n        A list of `SuggestionFrame` objects.\n    \"\"\"\n    try:\n        suggestions = read_hdf5_dataset(labels_path, \"suggestions_json\")\n    except KeyError:\n        return []\n    suggestions = [json.loads(x) for x in suggestions]\n    suggestions_objects = []\n    for suggestion in suggestions:\n        suggestions_objects.append(\n            SuggestionFrame(\n                video=videos[int(suggestion[\"video\"])],\n                frame_idx=suggestion[\"frame_idx\"],\n            )\n        )\n    return suggestions_objects\n</code></pre>"},{"location":"reference/sleap_io/io/slp/#sleap_io.io.slp.read_tracks","title":"<code>read_tracks(labels_path)</code>","text":"<p>Read <code>Track</code> dataset in a SLEAP labels file.</p> <p>Parameters:</p> Name Type Description Default <code>labels_path</code> <code>str</code> <p>A string path to the SLEAP labels file.</p> required <p>Returns:</p> Type Description <code>list[Track]</code> <p>A list of <code>Track</code> objects.</p> Source code in <code>sleap_io/io/slp.py</code> <pre><code>def read_tracks(labels_path: str) -&gt; list[Track]:\n    \"\"\"Read `Track` dataset in a SLEAP labels file.\n\n    Args:\n        labels_path: A string path to the SLEAP labels file.\n\n    Returns:\n        A list of `Track` objects.\n    \"\"\"\n    tracks = [json.loads(x) for x in read_hdf5_dataset(labels_path, \"tracks_json\")]\n    track_objects = []\n    for track in tracks:\n        track_objects.append(Track(name=track[1]))\n    return track_objects\n</code></pre>"},{"location":"reference/sleap_io/io/slp/#sleap_io.io.slp.read_videos","title":"<code>read_videos(labels_path)</code>","text":"<p>Read <code>Video</code> dataset in a SLEAP labels file.</p> <p>Parameters:</p> Name Type Description Default <code>labels_path</code> <code>str</code> <p>A string path to the SLEAP labels file.</p> required <p>Returns:</p> Type Description <code>list[Video]</code> <p>A list of <code>Video</code> objects.</p> Source code in <code>sleap_io/io/slp.py</code> <pre><code>def read_videos(labels_path: str) -&gt; list[Video]:\n    \"\"\"Read `Video` dataset in a SLEAP labels file.\n\n    Args:\n        labels_path: A string path to the SLEAP labels file.\n\n    Returns:\n        A list of `Video` objects.\n    \"\"\"\n    videos = []\n    for video_ind, video_data in enumerate(\n        read_hdf5_dataset(labels_path, \"videos_json\")\n    ):\n        video_json = json.loads(video_data)\n        video = make_video(labels_path, video_json, video_ind=video_ind)\n        videos.append(video)\n    return videos\n</code></pre>"},{"location":"reference/sleap_io/io/slp/#sleap_io.io.slp.serialize_skeletons","title":"<code>serialize_skeletons(skeletons)</code>","text":"<p>Serialize a list of <code>Skeleton</code> objects to JSON-compatible dicts.</p> <p>Parameters:</p> Name Type Description Default <code>skeletons</code> <code>list[Skeleton]</code> <p>A list of <code>Skeleton</code> objects.</p> required <p>Returns:</p> Type Description <code>tuple[list[dict], list[dict]]</code> <p>A tuple of <code>nodes_dicts, skeletons_dicts</code>.</p> <p><code>nodes_dicts</code> is a list of dicts containing the nodes in all the skeletons.</p> <p><code>skeletons_dicts</code> is a list of dicts containing the skeletons.</p> Notes <p>This function attempts to replicate the serialization of skeletons in legacy SLEAP which relies on a combination of networkx's graph serialization and our own metadata used to store nodes and edges independent of the graph structure.</p> <p>However, because sleap-io does not currently load in the legacy metadata, this function will not produce byte-level compatible serialization with legacy formats, even though the ordering and all attributes of nodes and edges should match up.</p> Source code in <code>sleap_io/io/slp.py</code> <pre><code>def serialize_skeletons(skeletons: list[Skeleton]) -&gt; tuple[list[dict], list[dict]]:\n    \"\"\"Serialize a list of `Skeleton` objects to JSON-compatible dicts.\n\n    Args:\n        skeletons: A list of `Skeleton` objects.\n\n    Returns:\n        A tuple of `nodes_dicts, skeletons_dicts`.\n\n        `nodes_dicts` is a list of dicts containing the nodes in all the skeletons.\n\n        `skeletons_dicts` is a list of dicts containing the skeletons.\n\n    Notes:\n        This function attempts to replicate the serialization of skeletons in legacy\n        SLEAP which relies on a combination of networkx's graph serialization and our\n        own metadata used to store nodes and edges independent of the graph structure.\n\n        However, because sleap-io does not currently load in the legacy metadata, this\n        function will not produce byte-level compatible serialization with legacy\n        formats, even though the ordering and all attributes of nodes and edges should\n        match up.\n    \"\"\"\n    # Create global list of nodes with all nodes from all skeletons.\n    nodes_dicts = []\n    node_to_id = {}\n    for skeleton in skeletons:\n        for node in skeleton.nodes:\n            if node not in node_to_id:\n                # Note: This ID is not the same as the node index in the skeleton in\n                # legacy SLEAP, but we do not retain this information in the labels, so\n                # IDs will be different.\n                #\n                # The weight is also kept fixed here, but technically this is not\n                # modified or used in legacy SLEAP either.\n                #\n                # TODO: Store legacy metadata in labels to get byte-level compatibility?\n                node_to_id[node] = len(node_to_id)\n                nodes_dicts.append({\"name\": node.name, \"weight\": 1.0})\n\n    skeletons_dicts = []\n    for skeleton in skeletons:\n        # Build links dicts for normal edges.\n        edges_dicts = []\n        for edge_ind, edge in enumerate(skeleton.edges):\n            if edge_ind == 0:\n                edge_type = {\n                    \"py/reduce\": [\n                        {\"py/type\": \"sleap.skeleton.EdgeType\"},\n                        {\"py/tuple\": [1]},  # 1 = real edge, 2 = symmetry edge\n                    ]\n                }\n            else:\n                edge_type = {\"py/id\": 1}\n\n            edges_dicts.append(\n                {\n                    # Note: Insert idx is not the same as the edge index in the skeleton\n                    # in legacy SLEAP.\n                    \"edge_insert_idx\": edge_ind,\n                    \"key\": 0,  # Always 0.\n                    \"source\": node_to_id[edge.source],\n                    \"target\": node_to_id[edge.destination],\n                    \"type\": edge_type,\n                }\n            )\n\n        # Build links dicts for symmetry edges.\n        for symmetry_ind, symmetry in enumerate(skeleton.symmetries):\n            if symmetry_ind == 0:\n                edge_type = {\n                    \"py/reduce\": [\n                        {\"py/type\": \"sleap.skeleton.EdgeType\"},\n                        {\"py/tuple\": [2]},  # 1 = real edge, 2 = symmetry edge\n                    ]\n                }\n            else:\n                edge_type = {\"py/id\": 2}\n\n            src, dst = tuple(symmetry.nodes)\n            edges_dicts.append(\n                {\n                    \"key\": 0,\n                    \"source\": node_to_id[src],\n                    \"target\": node_to_id[dst],\n                    \"type\": edge_type,\n                }\n            )\n\n        # Create skeleton dict.\n        skeletons_dicts.append(\n            {\n                \"directed\": True,\n                \"graph\": {\n                    \"name\": skeleton.name,\n                    \"num_edges_inserted\": len(skeleton.edges),\n                },\n                \"links\": edges_dicts,\n                \"multigraph\": True,\n                # In the order in Skeleton.nodes and must match up with nodes_dicts.\n                \"nodes\": [{\"id\": node_to_id[node]} for node in skeleton.nodes],\n            }\n        )\n\n    return skeletons_dicts, nodes_dicts\n</code></pre>"},{"location":"reference/sleap_io/io/slp/#sleap_io.io.slp.video_to_dict","title":"<code>video_to_dict(video)</code>","text":"<p>Convert a <code>Video</code> object to a JSON-compatible dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>video</code> <code>Video</code> <p>A <code>Video</code> object to convert.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>A dictionary containing the video metadata.</p> Source code in <code>sleap_io/io/slp.py</code> <pre><code>def video_to_dict(video: Video) -&gt; dict:\n    \"\"\"Convert a `Video` object to a JSON-compatible dictionary.\n\n    Args:\n        video: A `Video` object to convert.\n\n    Returns:\n        A dictionary containing the video metadata.\n    \"\"\"\n    if video.backend is None:\n        return {\"filename\": video.filename, \"backend\": video.backend_metadata}\n\n    if type(video.backend) == MediaVideo:\n        return {\n            \"filename\": video.filename,\n            \"backend\": {\n                \"type\": \"MediaVideo\",\n                \"shape\": video.shape,\n                \"filename\": video.filename,\n                \"grayscale\": video.grayscale,\n                \"bgr\": True,\n                \"dataset\": \"\",\n                \"input_format\": \"\",\n            },\n        }\n\n    elif type(video.backend) == HDF5Video:\n        return {\n            \"filename\": video.filename,\n            \"backend\": {\n                \"type\": \"HDF5Video\",\n                \"shape\": video.shape,\n                \"filename\": (\n                    \".\" if video.backend.has_embedded_images else video.filename\n                ),\n                \"dataset\": video.backend.dataset,\n                \"input_format\": video.backend.input_format,\n                \"convert_range\": False,\n                \"has_embedded_images\": video.backend.has_embedded_images,\n            },\n        }\n\n    elif type(video.backend) == ImageVideo:\n        return {\n            \"filename\": video.filename,\n            \"backend\": {\n                \"type\": \"ImageVideo\",\n                \"shape\": video.shape,\n                \"filename\": video.backend.filename[0],\n                \"filenames\": video.backend.filename,\n                \"dataset\": video.backend_metadata.get(\"dataset\", None),\n                \"grayscale\": video.grayscale,\n                \"input_format\": video.backend_metadata.get(\"input_format\", None),\n            },\n        }\n</code></pre>"},{"location":"reference/sleap_io/io/slp/#sleap_io.io.slp.write_labels","title":"<code>write_labels(labels_path, labels, embed=None)</code>","text":"<p>Write a SLEAP labels file.</p> <p>Parameters:</p> Name Type Description Default <code>labels_path</code> <code>str</code> <p>A string path to the SLEAP labels file to save.</p> required <code>labels</code> <code>Labels</code> <p>A <code>Labels</code> object to save.</p> required <code>embed</code> <code>bool | str | list[tuple[Video, int]] | None</code> <p>Frames to embed in the saved labels file. One of <code>None</code>, <code>True</code>, <code>\"all\"</code>, <code>\"user\"</code>, <code>\"suggestions\"</code>, <code>\"user+suggestions\"</code>, <code>\"source\"</code> or list of tuples of <code>(video, frame_idx)</code>.</p> <p>If <code>None</code> is specified (the default) and the labels contains embedded frames, those embedded frames will be re-saved to the new file.</p> <p>If <code>True</code> or <code>\"all\"</code>, all labeled frames and suggested frames will be embedded.</p> <p>If <code>\"source\"</code> is specified, no images will be embedded and the source video will be restored if available.</p> <p>This argument is only valid for the SLP backend.</p> <code>None</code> Source code in <code>sleap_io/io/slp.py</code> <pre><code>def write_labels(\n    labels_path: str,\n    labels: Labels,\n    embed: bool | str | list[tuple[Video, int]] | None = None,\n):\n    \"\"\"Write a SLEAP labels file.\n\n    Args:\n        labels_path: A string path to the SLEAP labels file to save.\n        labels: A `Labels` object to save.\n        embed: Frames to embed in the saved labels file. One of `None`, `True`,\n            `\"all\"`, `\"user\"`, `\"suggestions\"`, `\"user+suggestions\"`, `\"source\"` or list\n            of tuples of `(video, frame_idx)`.\n\n            If `None` is specified (the default) and the labels contains embedded\n            frames, those embedded frames will be re-saved to the new file.\n\n            If `True` or `\"all\"`, all labeled frames and suggested frames will be\n            embedded.\n\n            If `\"source\"` is specified, no images will be embedded and the source video\n            will be restored if available.\n\n            This argument is only valid for the SLP backend.\n    \"\"\"\n    if Path(labels_path).exists():\n        Path(labels_path).unlink()\n    if embed is not None:\n        embed_videos(labels_path, labels, embed)\n    write_videos(labels_path, labels.videos, restore_source=(embed == \"source\"))\n    write_tracks(labels_path, labels.tracks)\n    write_suggestions(labels_path, labels.suggestions, labels.videos)\n    write_metadata(labels_path, labels)\n    write_lfs(labels_path, labels)\n</code></pre>"},{"location":"reference/sleap_io/io/slp/#sleap_io.io.slp.write_lfs","title":"<code>write_lfs(labels_path, labels)</code>","text":"<p>Write labeled frames, instances and points to a SLEAP labels file.</p> <p>Parameters:</p> Name Type Description Default <code>labels_path</code> <code>str</code> <p>A string path to the SLEAP labels file.</p> required <code>labels</code> <code>Labels</code> <p>A <code>Labels</code> object to store the metadata for.</p> required Source code in <code>sleap_io/io/slp.py</code> <pre><code>def write_lfs(labels_path: str, labels: Labels):\n    \"\"\"Write labeled frames, instances and points to a SLEAP labels file.\n\n    Args:\n        labels_path: A string path to the SLEAP labels file.\n        labels: A `Labels` object to store the metadata for.\n    \"\"\"\n    # We store the data in structured arrays for performance, so we first define the\n    # dtype fields.\n    instance_dtype = np.dtype(\n        [\n            (\"instance_id\", \"i8\"),\n            (\"instance_type\", \"u1\"),\n            (\"frame_id\", \"u8\"),\n            (\"skeleton\", \"u4\"),\n            (\"track\", \"i4\"),\n            (\"from_predicted\", \"i8\"),\n            (\"score\", \"f4\"),\n            (\"point_id_start\", \"u8\"),\n            (\"point_id_end\", \"u8\"),\n            (\"tracking_score\", \"f4\"),  # FORMAT_ID &gt;= 1.2\n        ]\n    )\n    frame_dtype = np.dtype(\n        [\n            (\"frame_id\", \"u8\"),\n            (\"video\", \"u4\"),\n            (\"frame_idx\", \"u8\"),\n            (\"instance_id_start\", \"u8\"),\n            (\"instance_id_end\", \"u8\"),\n        ]\n    )\n    point_dtype = np.dtype(\n        [(\"x\", \"f8\"), (\"y\", \"f8\"), (\"visible\", \"?\"), (\"complete\", \"?\")]\n    )\n    predicted_point_dtype = np.dtype(\n        [(\"x\", \"f8\"), (\"y\", \"f8\"), (\"visible\", \"?\"), (\"complete\", \"?\"), (\"score\", \"f8\")]\n    )\n\n    # Next, we extract the data from the labels object into lists with the same fields.\n    frames, instances, points, predicted_points, to_link = [], [], [], [], []\n    inst_to_id = {}\n    for lf in labels:\n        frame_id = len(frames)\n        instance_id_start = len(instances)\n        for inst in lf:\n            instance_id = len(instances)\n            inst_to_id[id(inst)] = instance_id\n            skeleton_id = labels.skeletons.index(inst.skeleton)\n            track = labels.tracks.index(inst.track) if inst.track else -1\n            from_predicted = -1\n            if inst.from_predicted:\n                to_link.append((instance_id, inst.from_predicted))\n\n            if type(inst) == Instance:\n                instance_type = InstanceType.USER\n                score = np.nan\n                tracking_score = np.nan\n                point_id_start = len(points)\n\n                for node in inst.skeleton.nodes:\n                    pt = inst.points[node]\n                    points.append([pt.x, pt.y, pt.visible, pt.complete])\n\n                point_id_end = len(points)\n\n            elif type(inst) == PredictedInstance:\n                instance_type = InstanceType.PREDICTED\n                score = inst.score\n                tracking_score = inst.tracking_score\n                point_id_start = len(predicted_points)\n\n                for node in inst.skeleton.nodes:\n                    pt = inst.points[node]\n                    predicted_points.append(\n                        [pt.x, pt.y, pt.visible, pt.complete, pt.score]\n                    )\n\n                point_id_end = len(predicted_points)\n\n            else:\n                raise ValueError(f\"Unknown instance type: {type(inst)}\")\n\n            instances.append(\n                [\n                    instance_id,\n                    int(instance_type),\n                    frame_id,\n                    skeleton_id,\n                    track,\n                    from_predicted,\n                    score,\n                    point_id_start,\n                    point_id_end,\n                    tracking_score,\n                ]\n            )\n\n        instance_id_end = len(instances)\n\n        frames.append(\n            [\n                frame_id,\n                labels.videos.index(lf.video),\n                lf.frame_idx,\n                instance_id_start,\n                instance_id_end,\n            ]\n        )\n\n    # Link instances based on from_predicted field.\n    for instance_id, from_predicted in to_link:\n        if id(from_predicted) in inst_to_id:\n            instances[instance_id][5] = inst_to_id[id(from_predicted)]\n        else:\n            # Source instance may be missing if predictions were removed from the\n            # labels, in which case, remove the link.\n            instances[instance_id][5] = -1\n\n    # Create structured arrays.\n    points = np.array([tuple(x) for x in points], dtype=point_dtype)\n    predicted_points = np.array(\n        [tuple(x) for x in predicted_points], dtype=predicted_point_dtype\n    )\n    instances = np.array([tuple(x) for x in instances], dtype=instance_dtype)\n    frames = np.array([tuple(x) for x in frames], dtype=frame_dtype)\n\n    # Write to file.\n    with h5py.File(labels_path, \"a\") as f:\n        f.create_dataset(\"points\", data=points, dtype=points.dtype)\n        f.create_dataset(\n            \"pred_points\",\n            data=predicted_points,\n            dtype=predicted_points.dtype,\n        )\n        f.create_dataset(\n            \"instances\",\n            data=instances,\n            dtype=instances.dtype,\n        )\n        f.create_dataset(\n            \"frames\",\n            data=frames,\n            dtype=frames.dtype,\n        )\n</code></pre>"},{"location":"reference/sleap_io/io/slp/#sleap_io.io.slp.write_metadata","title":"<code>write_metadata(labels_path, labels)</code>","text":"<p>Write metadata to a SLEAP labels file.</p> <p>This function will write the skeletons and provenance for the labels.</p> <p>Parameters:</p> Name Type Description Default <code>labels_path</code> <code>str</code> <p>A string path to the SLEAP labels file.</p> required <code>labels</code> <code>Labels</code> <p>A <code>Labels</code> object to store the metadata for.</p> required <p>See also: serialize_skeletons</p> Source code in <code>sleap_io/io/slp.py</code> <pre><code>def write_metadata(labels_path: str, labels: Labels):\n    \"\"\"Write metadata to a SLEAP labels file.\n\n    This function will write the skeletons and provenance for the labels.\n\n    Args:\n        labels_path: A string path to the SLEAP labels file.\n        labels: A `Labels` object to store the metadata for.\n\n    See also: serialize_skeletons\n    \"\"\"\n    skeletons_dicts, nodes_dicts = serialize_skeletons(labels.skeletons)\n\n    md = {\n        \"version\": \"2.0.0\",\n        \"skeletons\": skeletons_dicts,\n        \"nodes\": nodes_dicts,\n        \"videos\": [],\n        \"tracks\": [],\n        \"suggestions\": [],  # TODO: Handle suggestions metadata.\n        \"negative_anchors\": {},\n        \"provenance\": labels.provenance,\n    }\n\n    # Custom encoding.\n    for k in md[\"provenance\"]:\n        if isinstance(md[\"provenance\"][k], Path):\n            # Path -&gt; str\n            md[\"provenance\"][k] = md[\"provenance\"][k].as_posix()\n\n    with h5py.File(labels_path, \"a\") as f:\n        grp = f.require_group(\"metadata\")\n        grp.attrs[\"format_id\"] = 1.2\n        grp.attrs[\"json\"] = np.string_(json.dumps(md, separators=(\",\", \":\")))\n</code></pre>"},{"location":"reference/sleap_io/io/slp/#sleap_io.io.slp.write_suggestions","title":"<code>write_suggestions(labels_path, suggestions, videos)</code>","text":"<p>Write track metadata to a SLEAP labels file.</p> <p>Parameters:</p> Name Type Description Default <code>labels_path</code> <code>str</code> <p>A string path to the SLEAP labels file.</p> required <code>suggestions</code> <code>list[SuggestionFrame]</code> <p>A list of <code>SuggestionFrame</code> objects to store the metadata for.</p> required <code>videos</code> <code>list[Video]</code> <p>A list of <code>Video</code> objects.</p> required Source code in <code>sleap_io/io/slp.py</code> <pre><code>def write_suggestions(\n    labels_path: str, suggestions: list[SuggestionFrame], videos: list[Video]\n):\n    \"\"\"Write track metadata to a SLEAP labels file.\n\n    Args:\n        labels_path: A string path to the SLEAP labels file.\n        suggestions: A list of `SuggestionFrame` objects to store the metadata for.\n        videos: A list of `Video` objects.\n    \"\"\"\n    GROUP = 0  # TODO: Handle storing extraneous metadata.\n    suggestions_json = []\n    for suggestion in suggestions:\n        suggestion_dict = {\n            \"video\": str(videos.index(suggestion.video)),\n            \"frame_idx\": suggestion.frame_idx,\n            \"group\": GROUP,\n        }\n        suggestion_json = np.string_(json.dumps(suggestion_dict, separators=(\",\", \":\")))\n        suggestions_json.append(suggestion_json)\n\n    with h5py.File(labels_path, \"a\") as f:\n        f.create_dataset(\"suggestions_json\", data=suggestions_json, maxshape=(None,))\n</code></pre>"},{"location":"reference/sleap_io/io/slp/#sleap_io.io.slp.write_tracks","title":"<code>write_tracks(labels_path, tracks)</code>","text":"<p>Write track metadata to a SLEAP labels file.</p> <p>Parameters:</p> Name Type Description Default <code>labels_path</code> <code>str</code> <p>A string path to the SLEAP labels file.</p> required <code>tracks</code> <code>list[Track]</code> <p>A list of <code>Track</code> objects to store the metadata for.</p> required Source code in <code>sleap_io/io/slp.py</code> <pre><code>def write_tracks(labels_path: str, tracks: list[Track]):\n    \"\"\"Write track metadata to a SLEAP labels file.\n\n    Args:\n        labels_path: A string path to the SLEAP labels file.\n        tracks: A list of `Track` objects to store the metadata for.\n    \"\"\"\n    # TODO: Add support for track metadata like spawned on frame.\n    SPAWNED_ON = 0\n    tracks_json = [\n        np.string_(json.dumps([SPAWNED_ON, track.name], separators=(\",\", \":\")))\n        for track in tracks\n    ]\n    with h5py.File(labels_path, \"a\") as f:\n        f.create_dataset(\"tracks_json\", data=tracks_json, maxshape=(None,))\n</code></pre>"},{"location":"reference/sleap_io/io/slp/#sleap_io.io.slp.write_videos","title":"<code>write_videos(labels_path, videos, restore_source=False)</code>","text":"<p>Write video metadata to a SLEAP labels file.</p> <p>Parameters:</p> Name Type Description Default <code>labels_path</code> <code>str</code> <p>A string path to the SLEAP labels file.</p> required <code>videos</code> <code>list[Video]</code> <p>A list of <code>Video</code> objects to store the metadata for.</p> required <code>restore_source</code> <code>bool</code> <p>If <code>True</code>, restore source videos if available and will not re-embed the embedded images. If <code>False</code> (the default), will re-embed images that were previously embedded.</p> <code>False</code> Source code in <code>sleap_io/io/slp.py</code> <pre><code>def write_videos(labels_path: str, videos: list[Video], restore_source: bool = False):\n    \"\"\"Write video metadata to a SLEAP labels file.\n\n    Args:\n        labels_path: A string path to the SLEAP labels file.\n        videos: A list of `Video` objects to store the metadata for.\n        restore_source: If `True`, restore source videos if available and will not\n            re-embed the embedded images. If `False` (the default), will re-embed images\n            that were previously embedded.\n    \"\"\"\n    video_jsons = []\n    for video_ind, video in enumerate(videos):\n\n        if type(video.backend) == HDF5Video and video.backend.has_embedded_images:\n            if restore_source:\n                video = video.source_video\n            else:\n                # If the video has embedded images, embed them images again if we haven't\n                # already.\n                already_embedded = False\n                if Path(labels_path).exists():\n                    with h5py.File(labels_path, \"r\") as f:\n                        already_embedded = f\"video{video_ind}/video\" in f\n\n                if not already_embedded:\n                    video = embed_video(\n                        labels_path,\n                        video,\n                        group=f\"video{video_ind}\",\n                        frame_inds=video.backend.source_inds,\n                        image_format=video.backend.image_format,\n                    )\n\n        video_json = video_to_dict(video)\n\n        video_jsons.append(np.string_(json.dumps(video_json, separators=(\",\", \":\"))))\n\n    with h5py.File(labels_path, \"a\") as f:\n        f.create_dataset(\"videos_json\", data=video_jsons, maxshape=(None,))\n</code></pre>"},{"location":"reference/sleap_io/io/utils/","title":"utils","text":""},{"location":"reference/sleap_io/io/utils/#sleap_io.io.utils","title":"<code>sleap_io.io.utils</code>","text":"<p>Miscellaneous utilities for working with different I/O formats.</p>"},{"location":"reference/sleap_io/io/utils/#sleap_io.io.utils.convert_predictions_to_dataframe","title":"<code>convert_predictions_to_dataframe(labels)</code>","text":"<p>Convert predictions data to a Pandas dataframe.</p> <p>Parameters:</p> Name Type Description Default <code>labels</code> <code>Labels</code> <p>A general label object.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: A pandas data frame with the structured data with hierarchical columns. The column hierarchy is:         \"video_path\",         \"skeleton_name\",         \"track_name\",         \"node_name\", And it is indexed by the frames.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If no frames in the label objects contain predicted instances.</p> Source code in <code>sleap_io/io/utils.py</code> <pre><code>def convert_predictions_to_dataframe(labels: Labels) -&gt; pd.DataFrame:\n    \"\"\"Convert predictions data to a Pandas dataframe.\n\n    Args:\n        labels: A general label object.\n\n    Returns:\n        pd.DataFrame: A pandas data frame with the structured data with\n        hierarchical columns. The column hierarchy is:\n                \"video_path\",\n                \"skeleton_name\",\n                \"track_name\",\n                \"node_name\",\n        And it is indexed by the frames.\n\n    Raises:\n        ValueError: If no frames in the label objects contain predicted instances.\n    \"\"\"\n    # Form pairs of labeled_frames and predicted instances\n    labeled_frames = labels.labeled_frames\n    all_frame_instance_tuples: Generator[\n        tuple[LabeledFrame, PredictedInstance], None, None\n    ] = (\n        (label_frame, instance)  # type: ignore\n        for label_frame in labeled_frames\n        for instance in label_frame.predicted_instances\n    )\n\n    # Extract the data\n    data_list = list()\n    for labeled_frame, instance in all_frame_instance_tuples:\n        # Traverse the nodes of the instances's skeleton\n        skeleton = instance.skeleton\n        for node in skeleton.nodes:\n            row_dict = dict(\n                frame_idx=labeled_frame.frame_idx,\n                x=instance.points[node].x,\n                y=instance.points[node].y,\n                score=instance.points[node].score,  # type: ignore[attr-defined]\n                node_name=node.name,\n                skeleton_name=skeleton.name,\n                track_name=instance.track.name if instance.track else \"untracked\",\n                video_path=labeled_frame.video.filename,\n            )\n            data_list.append(row_dict)\n\n    if not data_list:\n        raise ValueError(\"No predicted instances found in labels object\")\n\n    labels_df = pd.DataFrame(data_list)\n\n    # Reformat the data with columns for dict-like hierarchical data access.\n    index = [\n        \"skeleton_name\",\n        \"track_name\",\n        \"node_name\",\n        \"video_path\",\n        \"frame_idx\",\n    ]\n\n    labels_tidy_df = (\n        labels_df.set_index(index)\n        .unstack(level=[0, 1, 2, 3])\n        .swaplevel(0, -1, axis=1)  # video_path on top while x, y score on bottom\n        .sort_index(axis=1)  # Better format for columns\n        .sort_index(axis=0)  # Sorts by frames\n    )\n\n    return labels_tidy_df\n</code></pre>"},{"location":"reference/sleap_io/io/utils/#sleap_io.io.utils.read_hdf5_attrs","title":"<code>read_hdf5_attrs(filename, dataset='/', attribute=None)</code>","text":"<p>Read attributes from an HDF5 dataset.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>Path to an HDF5 file.</p> required <code>dataset</code> <code>str</code> <p>Path to a dataset or group from which attributes will be read.</p> <code>'/'</code> <code>attribute</code> <code>Optional[str]</code> <p>If specified, the attribute name to read. If <code>None</code> (the default), all attributes for the dataset will be returned.</p> <code>None</code> <p>Returns:</p> Type Description <code>Union[Any, dict[str, Any]]</code> <p>The attributes in a dictionary, or the attribute field if <code>attribute</code> was provided.</p> Source code in <code>sleap_io/io/utils.py</code> <pre><code>def read_hdf5_attrs(\n    filename: str, dataset: str = \"/\", attribute: Optional[str] = None\n) -&gt; Union[Any, dict[str, Any]]:\n    \"\"\"Read attributes from an HDF5 dataset.\n\n    Args:\n        filename: Path to an HDF5 file.\n        dataset: Path to a dataset or group from which attributes will be read.\n        attribute: If specified, the attribute name to read. If `None` (the default),\n            all attributes for the dataset will be returned.\n\n    Returns:\n        The attributes in a dictionary, or the attribute field if `attribute` was\n        provided.\n    \"\"\"\n    with h5py.File(filename, \"r\") as f:\n        ds = f[dataset]\n        if attribute is None:\n            data = dict(ds.attrs)\n        else:\n            data = ds.attrs[attribute]\n    return data\n</code></pre>"},{"location":"reference/sleap_io/io/utils/#sleap_io.io.utils.read_hdf5_dataset","title":"<code>read_hdf5_dataset(filename, dataset)</code>","text":"<p>Read data from an HDF5 file.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>Path to an HDF5 file.</p> required <code>dataset</code> <code>str</code> <p>Path to a dataset.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>The data as an array.</p> Source code in <code>sleap_io/io/utils.py</code> <pre><code>def read_hdf5_dataset(filename: str, dataset: str) -&gt; np.ndarray:\n    \"\"\"Read data from an HDF5 file.\n\n    Args:\n        filename: Path to an HDF5 file.\n        dataset: Path to a dataset.\n\n    Returns:\n        The data as an array.\n    \"\"\"\n    with h5py.File(filename, \"r\") as f:\n        data = f[dataset][()]\n    return data\n</code></pre>"},{"location":"reference/sleap_io/io/utils/#sleap_io.io.utils.read_hdf5_group","title":"<code>read_hdf5_group(filename, group='/')</code>","text":"<p>Read an entire group from an HDF5 file.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>Path an HDF5 file.</p> required <code>group</code> <code>str</code> <p>Path to a group within the HDF5 file. Defaults to \"/\" (read the entire file).</p> <code>'/'</code> <p>Returns:</p> Type Description <code>dict[str, ndarray]</code> <p>A flat dictionary with keys corresponding to dataset paths and values corresponding to the datasets as arrays.</p> Source code in <code>sleap_io/io/utils.py</code> <pre><code>def read_hdf5_group(filename: str, group: str = \"/\") -&gt; dict[str, np.ndarray]:\n    \"\"\"Read an entire group from an HDF5 file.\n\n    Args:\n        filename: Path an HDF5 file.\n        group: Path to a group within the HDF5 file. Defaults to \"/\" (read the entire\n            file).\n\n    Returns:\n        A flat dictionary with keys corresponding to dataset paths and values\n        corresponding to the datasets as arrays.\n    \"\"\"\n    data = {}\n\n    def read_datasets(k, v):\n        if type(v) == h5py.Dataset:\n            data[v.name] = v[()]\n\n    with h5py.File(filename, \"r\") as f:\n        f[group].visititems(read_datasets)\n\n    return data\n</code></pre>"},{"location":"reference/sleap_io/io/utils/#sleap_io.io.utils.write_hdf5_attrs","title":"<code>write_hdf5_attrs(filename, dataset, attributes)</code>","text":"<p>Write attributes to an HDF5 dataset.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>Path to an HDF5 file.</p> required <code>dataset</code> <code>str</code> <p>Path to a dataset or group to which attributes will be written.</p> required <code>attributes</code> <code>dict[str, Any]</code> <p>The attributes in a dictionary with the keys as the attribute names.</p> required Source code in <code>sleap_io/io/utils.py</code> <pre><code>def write_hdf5_attrs(filename: str, dataset: str, attributes: dict[str, Any]):\n    \"\"\"Write attributes to an HDF5 dataset.\n\n    Args:\n        filename: Path to an HDF5 file.\n        dataset: Path to a dataset or group to which attributes will be written.\n        attributes: The attributes in a dictionary with the keys as the attribute names.\n    \"\"\"\n\n    def _overwrite_hdf5_attr(\n        group_or_dataset: Union[h5py.Group, h5py.Dataset], attr_name: str, data: Any\n    ):\n        \"\"\"Overwrite attribute for group or dataset in HDF5 file.\n\n        Args:\n            group_or_dataset: Path to group or dataset in HDF5 file.\n            attr_name: Name of attribute.\n            data: Data to write to attribute.\n        \"\"\"\n        try:\n            del group_or_dataset.attrs[attr_name]\n        except KeyError:\n            pass\n        group_or_dataset.attrs.create(attr_name, data)\n\n    with h5py.File(filename, \"a\") as f:  # \"a\": read/write if exists, create otherwise\n        ds = f[dataset]\n        for attr_name, attr_value in attributes.items():\n            _overwrite_hdf5_attr(ds, attr_name, attr_value)\n</code></pre>"},{"location":"reference/sleap_io/io/utils/#sleap_io.io.utils.write_hdf5_dataset","title":"<code>write_hdf5_dataset(filename, dataset, data)</code>","text":"<p>Write data to an HDF5 file.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>Path to an HDF5 file.</p> required <code>dataset</code> <code>str</code> <p>Path to a dataset.</p> required <code>data</code> <code>ndarray</code> <p>Data to write to dataset.</p> required Source code in <code>sleap_io/io/utils.py</code> <pre><code>def write_hdf5_dataset(filename: str, dataset: str, data: np.ndarray):\n    \"\"\"Write data to an HDF5 file.\n\n    Args:\n        filename: Path to an HDF5 file.\n        dataset: Path to a dataset.\n        data: Data to write to dataset.\n    \"\"\"\n    with h5py.File(filename, \"a\") as f:  # \"a\": read/write if exists, create otherwise\n        _overwrite_hdf5_dataset(f, dataset, data)\n</code></pre>"},{"location":"reference/sleap_io/io/utils/#sleap_io.io.utils.write_hdf5_group","title":"<code>write_hdf5_group(filename, data)</code>","text":"<p>Write an entire group to an HDF5 file.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>Path an HDF5 file.</p> required <code>data</code> <code>dict[str, ndarray]</code> <p>A dictionary with keys corresponding to dataset/group paths and values corresponding to either sub group paths or the datasets as arrays.</p> required Source code in <code>sleap_io/io/utils.py</code> <pre><code>def write_hdf5_group(filename: str, data: dict[str, np.ndarray]):\n    \"\"\"Write an entire group to an HDF5 file.\n\n    Args:\n        filename: Path an HDF5 file.\n        data: A dictionary with keys corresponding to dataset/group paths and values\n            corresponding to either sub group paths or the datasets as arrays.\n    \"\"\"\n\n    def overwrite_hdf5_group(\n        file_or_group: Union[h5py.File, h5py.Group], group_name: str\n    ) -&gt; h5py.Group:\n        \"\"\"Overwrite group in HDF5 file.\n\n        Args:\n            file_or_group: Path to an HDF5 file or parent group.\n            group_name: Path to a group.\n\n        Return:\n            group: (Sub-)group under specified file or parent group.\n        \"\"\"\n        try:\n            del file_or_group[group_name]\n        except KeyError:\n            pass\n        group = file_or_group.create_group(group_name)\n        return group\n\n    def write_group(parent_group, data_to_write):\n        for name, dataset_or_group in data_to_write.items():\n            if isinstance(dataset_or_group, dict):\n                # Create (sub-)group under parent group (top level being the file)\n                group = overwrite_hdf5_group(parent_group, name)\n                write_group(group, dataset_or_group)  # Recall with new parent\n            else:\n                # Create dataset if dataset_or_group is a dataset\n                _overwrite_hdf5_dataset(\n                    f=parent_group, dataset=name, data=dataset_or_group\n                )\n\n    with h5py.File(filename, \"a\") as f:  # \"a\": read/write if exists, create otherwise\n        write_group(f, data)\n</code></pre>"},{"location":"reference/sleap_io/io/video/","title":"video","text":""},{"location":"reference/sleap_io/io/video/#sleap_io.io.video","title":"<code>sleap_io.io.video</code>","text":"<p>Backends for reading and writing videos.</p>"},{"location":"reference/sleap_io/io/video/#sleap_io.io.video.HDF5Video","title":"<code>HDF5Video</code>","text":"<p>             Bases: <code>VideoBackend</code></p> <p>Video backend for reading videos stored in HDF5 files.</p> <p>This backend supports reading videos stored in HDF5 files, both in rank-4 datasets as well as in datasets with lists of binary-encoded images.</p> <p>Embedded image datasets are used in SLEAP when exporting package files (<code>.pkg.slp</code>) with videos embedded in them. This is useful for bundling training or inference data without having to worry about the videos (or frame images) being moved or deleted. It is expected that these types of datasets will be in a <code>Group</code> with a <code>int8</code> variable length dataset called <code>\"video\"</code>. This dataset must also contain an attribute called \"format\" with a string describing the image format (e.g., \"png\" or \"jpg\") which will be used to decode it appropriately.</p> <p>If a <code>frame_numbers</code> dataset is present in the group, it will be used to map from source video frames to the frames in the dataset. This is useful to preserve frame indexing when exporting a subset of frames in the video. It will also be used to populate <code>frame_map</code> and <code>source_inds</code> attributes.</p> <p>Attributes:</p> Name Type Description <code>filename</code> <p>Path to HDF5 file (.h5, .hdf5 or .slp).</p> <code>grayscale</code> <p>Whether to force grayscale. If None, autodetect on first frame load.</p> <code>keep_open</code> <p>Whether to keep the video reader open between calls to read frames. If False, will close the reader after each call. If True (the default), it will keep the reader open and cache it for subsequent calls which may enhance the performance of reading multiple frames.</p> <code>dataset</code> <code>Optional[str]</code> <p>Name of dataset to read from. If <code>None</code>, will try to find a rank-4 dataset by iterating through datasets in the file. If specifying an embedded dataset, this can be the group containing a \"video\" dataset or the dataset itself (e.g., \"video0\" or \"video0/video\").</p> <code>input_format</code> <code>str</code> <p>Format of the data in the dataset. One of \"channels_last\" (the default) in <code>(frames, height, width, channels)</code> order or \"channels_first\" in <code>(frames, channels, width, height)</code> order. Embedded datasets should use the \"channels_last\" format.</p> <code>frame_map</code> <code>dict[int, int]</code> <p>Mapping from frame indices to indices in the dataset. This is used to translate between the frame indices of the images within their source video and the indices of the images in the dataset. This is only used when reading embedded image datasets.</p> <code>source_filename</code> <code>Optional[str]</code> <p>Path to the source video file. This is metadata and only used when reading embedded image datasets.</p> <code>source_inds</code> <code>Optional[ndarray]</code> <p>Indices of the frames in the source video file. This is metadata and only used when reading embedded image datasets.</p> <code>image_format</code> <code>str</code> <p>Format of the images in the embedded dataset. This is metadata and only used when reading embedded image datasets.</p> Source code in <code>sleap_io/io/video.py</code> <pre><code>@attrs.define\nclass HDF5Video(VideoBackend):\n    \"\"\"Video backend for reading videos stored in HDF5 files.\n\n    This backend supports reading videos stored in HDF5 files, both in rank-4 datasets\n    as well as in datasets with lists of binary-encoded images.\n\n    Embedded image datasets are used in SLEAP when exporting package files (`.pkg.slp`)\n    with videos embedded in them. This is useful for bundling training or inference data\n    without having to worry about the videos (or frame images) being moved or deleted.\n    It is expected that these types of datasets will be in a `Group` with a `int8`\n    variable length dataset called `\"video\"`. This dataset must also contain an\n    attribute called \"format\" with a string describing the image format (e.g., \"png\" or\n    \"jpg\") which will be used to decode it appropriately.\n\n    If a `frame_numbers` dataset is present in the group, it will be used to map from\n    source video frames to the frames in the dataset. This is useful to preserve frame\n    indexing when exporting a subset of frames in the video. It will also be used to\n    populate `frame_map` and `source_inds` attributes.\n\n    Attributes:\n        filename: Path to HDF5 file (.h5, .hdf5 or .slp).\n        grayscale: Whether to force grayscale. If None, autodetect on first frame load.\n        keep_open: Whether to keep the video reader open between calls to read frames.\n            If False, will close the reader after each call. If True (the default), it\n            will keep the reader open and cache it for subsequent calls which may\n            enhance the performance of reading multiple frames.\n        dataset: Name of dataset to read from. If `None`, will try to find a rank-4\n            dataset by iterating through datasets in the file. If specifying an embedded\n            dataset, this can be the group containing a \"video\" dataset or the dataset\n            itself (e.g., \"video0\" or \"video0/video\").\n        input_format: Format of the data in the dataset. One of \"channels_last\" (the\n            default) in `(frames, height, width, channels)` order or \"channels_first\" in\n            `(frames, channels, width, height)` order. Embedded datasets should use the\n            \"channels_last\" format.\n        frame_map: Mapping from frame indices to indices in the dataset. This is used to\n            translate between the frame indices of the images within their source video\n            and the indices of the images in the dataset. This is only used when reading\n            embedded image datasets.\n        source_filename: Path to the source video file. This is metadata and only used\n            when reading embedded image datasets.\n        source_inds: Indices of the frames in the source video file. This is metadata\n            and only used when reading embedded image datasets.\n        image_format: Format of the images in the embedded dataset. This is metadata and\n            only used when reading embedded image datasets.\n    \"\"\"\n\n    dataset: Optional[str] = None\n    input_format: str = attrs.field(\n        default=\"channels_last\",\n        validator=attrs.validators.in_([\"channels_last\", \"channels_first\"]),\n    )\n    frame_map: dict[int, int] = attrs.field(init=False, default=attrs.Factory(dict))\n    source_filename: Optional[str] = None\n    source_inds: Optional[np.ndarray] = None\n    image_format: str = \"hdf5\"\n\n    EXTS = (\"h5\", \"hdf5\", \"slp\")\n\n    def __attrs_post_init__(self):\n        \"\"\"Auto-detect dataset and frame map heuristically.\"\"\"\n        # Check if the file accessible before applying heuristics.\n        try:\n            f = h5py.File(self.filename, \"r\")\n        except OSError:\n            return\n\n        if self.dataset is None:\n            # Iterate through datasets to find a rank 4 array.\n            def find_movies(name, obj):\n                if isinstance(obj, h5py.Dataset) and obj.ndim == 4:\n                    self.dataset = name\n                    return True\n\n            f.visititems(find_movies)\n\n        if self.dataset is None:\n            # Iterate through datasets to find an embedded video dataset.\n            def find_embedded(name, obj):\n                if isinstance(obj, h5py.Dataset) and name.endswith(\"/video\"):\n                    self.dataset = name\n                    return True\n\n            f.visititems(find_embedded)\n\n        if self.dataset is None:\n            # Couldn't find video datasets.\n            return\n\n        if isinstance(f[self.dataset], h5py.Group):\n            # If this is a group, assume it's an embedded video dataset.\n            if \"video\" in f[self.dataset]:\n                self.dataset = f\"{self.dataset}/video\"\n\n        if self.dataset.split(\"/\")[-1] == \"video\":\n            # This may be an embedded video dataset. Check for frame map.\n            ds = f[self.dataset]\n\n            if \"format\" in ds.attrs:\n                self.image_format = ds.attrs[\"format\"]\n\n            if \"frame_numbers\" in ds.parent:\n                frame_numbers = ds.parent[\"frame_numbers\"][:].astype(int)\n                self.frame_map = {frame: idx for idx, frame in enumerate(frame_numbers)}\n                self.source_inds = frame_numbers\n\n            if \"source_video\" in ds.parent:\n                self.source_filename = json.loads(\n                    ds.parent[\"source_video\"].attrs[\"json\"]\n                )[\"backend\"][\"filename\"]\n\n        f.close()\n\n    @property\n    def num_frames(self) -&gt; int:\n        \"\"\"Number of frames in the video.\"\"\"\n        with h5py.File(self.filename, \"r\") as f:\n            return f[self.dataset].shape[0]\n\n    @property\n    def img_shape(self) -&gt; Tuple[int, int, int]:\n        \"\"\"Shape of a single frame in the video as `(height, width, channels)`.\"\"\"\n        with h5py.File(self.filename, \"r\") as f:\n            ds = f[self.dataset]\n            if \"height\" in ds.attrs:\n                img_shape = (\n                    ds.attrs[\"height\"],\n                    ds.attrs[\"width\"],\n                    ds.attrs[\"channels\"],\n                )\n            else:\n                img_shape = ds.shape[1:]\n        if self.input_format == \"channels_first\":\n            img_shape = img_shape[::-1]\n        return int(img_shape[0]), int(img_shape[1]), int(img_shape[2])\n\n    def read_test_frame(self) -&gt; np.ndarray:\n        \"\"\"Read a single frame from the video to test for grayscale.\"\"\"\n        if self.frame_map:\n            frame_idx = list(self.frame_map.keys())[0]\n        else:\n            frame_idx = 0\n        return self.read_frame(frame_idx)\n\n    @property\n    def has_embedded_images(self) -&gt; bool:\n        \"\"\"Return True if the dataset contains embedded images.\"\"\"\n        return self.image_format is not None and self.image_format != \"hdf5\"\n\n    @property\n    def embedded_frame_inds(self) -&gt; list[int]:\n        \"\"\"Return the frame indices of the embedded images.\"\"\"\n        return list(self.frame_map.keys())\n\n    def decode_embedded(self, img_string: np.ndarray) -&gt; np.ndarray:\n        \"\"\"Decode an embedded image string into a numpy array.\n\n        Args:\n            img_string: Binary string of the image as a `int8` numpy vector with the\n                bytes as values corresponding to the format-encoded image.\n\n        Returns:\n            The decoded image as a numpy array of shape `(height, width, channels)`. If\n            a rank-2 image is decoded, it will be expanded such that channels will be 1.\n\n            This method does not apply grayscale conversion as per the `grayscale`\n            attribute. Use the `get_frame` or `get_frames` methods of the `VideoBackend`\n            to apply grayscale conversion rather than calling this function directly.\n        \"\"\"\n        if \"cv2\" in sys.modules:\n            img = cv2.imdecode(img_string, cv2.IMREAD_UNCHANGED)\n        else:\n            img = iio.imread(BytesIO(img_string), extension=f\".{self.image_format}\")\n\n        if img.ndim == 2:\n            img = np.expand_dims(img, axis=-1)\n        return img\n\n    def _read_frame(self, frame_idx: int) -&gt; np.ndarray:\n        \"\"\"Read a single frame from the video.\n\n        Args:\n            frame_idx: Index of frame to read.\n\n        Returns:\n            The frame as a numpy array of shape `(height, width, channels)`.\n\n        Notes:\n            This does not apply grayscale conversion. It is recommended to use the\n            `get_frame` method of the `VideoBackend` class instead.\n        \"\"\"\n        if self.keep_open:\n            if self._open_reader is None:\n                self._open_reader = h5py.File(self.filename, \"r\")\n            f = self._open_reader\n        else:\n            f = h5py.File(self.filename, \"r\")\n\n        ds = f[self.dataset]\n\n        if self.frame_map:\n            frame_idx = self.frame_map[frame_idx]\n\n        img = ds[frame_idx]\n\n        if self.has_embedded_images:\n            img = self.decode_embedded(img)\n\n        if self.input_format == \"channels_first\":\n            img = np.transpose(img, (2, 1, 0))\n\n        if not self.keep_open:\n            f.close()\n        return img\n\n    def _read_frames(self, frame_inds: list) -&gt; np.ndarray:\n        \"\"\"Read a list of frames from the video.\n\n        Args:\n            frame_inds: List of indices of frames to read.\n\n        Returns:\n            The frame as a numpy array of shape `(frames, height, width, channels)`.\n\n        Notes:\n            This does not apply grayscale conversion. It is recommended to use the\n            `get_frames` method of the `VideoBackend` class instead.\n        \"\"\"\n        if self.keep_open:\n            if self._open_reader is None:\n                self._open_reader = h5py.File(self.filename, \"r\")\n            f = self._open_reader\n        else:\n            f = h5py.File(self.filename, \"r\")\n\n        if self.frame_map:\n            frame_inds = [self.frame_map[idx] for idx in frame_inds]\n\n        ds = f[self.dataset]\n        imgs = ds[frame_inds]\n\n        if \"format\" in ds.attrs:\n            imgs = np.stack(\n                [self.decode_embedded(img) for img in imgs],\n                axis=0,\n            )\n\n        if self.input_format == \"channels_first\":\n            imgs = np.transpose(imgs, (0, 3, 2, 1))\n\n        if not self.keep_open:\n            f.close()\n\n        return imgs\n</code></pre>"},{"location":"reference/sleap_io/io/video/#sleap_io.io.video.HDF5Video.embedded_frame_inds","title":"<code>embedded_frame_inds: list[int]</code>  <code>property</code>","text":"<p>Return the frame indices of the embedded images.</p>"},{"location":"reference/sleap_io/io/video/#sleap_io.io.video.HDF5Video.has_embedded_images","title":"<code>has_embedded_images: bool</code>  <code>property</code>","text":"<p>Return True if the dataset contains embedded images.</p>"},{"location":"reference/sleap_io/io/video/#sleap_io.io.video.HDF5Video.img_shape","title":"<code>img_shape: Tuple[int, int, int]</code>  <code>property</code>","text":"<p>Shape of a single frame in the video as <code>(height, width, channels)</code>.</p>"},{"location":"reference/sleap_io/io/video/#sleap_io.io.video.HDF5Video.num_frames","title":"<code>num_frames: int</code>  <code>property</code>","text":"<p>Number of frames in the video.</p>"},{"location":"reference/sleap_io/io/video/#sleap_io.io.video.HDF5Video.__attrs_post_init__","title":"<code>__attrs_post_init__()</code>","text":"<p>Auto-detect dataset and frame map heuristically.</p> Source code in <code>sleap_io/io/video.py</code> <pre><code>def __attrs_post_init__(self):\n    \"\"\"Auto-detect dataset and frame map heuristically.\"\"\"\n    # Check if the file accessible before applying heuristics.\n    try:\n        f = h5py.File(self.filename, \"r\")\n    except OSError:\n        return\n\n    if self.dataset is None:\n        # Iterate through datasets to find a rank 4 array.\n        def find_movies(name, obj):\n            if isinstance(obj, h5py.Dataset) and obj.ndim == 4:\n                self.dataset = name\n                return True\n\n        f.visititems(find_movies)\n\n    if self.dataset is None:\n        # Iterate through datasets to find an embedded video dataset.\n        def find_embedded(name, obj):\n            if isinstance(obj, h5py.Dataset) and name.endswith(\"/video\"):\n                self.dataset = name\n                return True\n\n        f.visititems(find_embedded)\n\n    if self.dataset is None:\n        # Couldn't find video datasets.\n        return\n\n    if isinstance(f[self.dataset], h5py.Group):\n        # If this is a group, assume it's an embedded video dataset.\n        if \"video\" in f[self.dataset]:\n            self.dataset = f\"{self.dataset}/video\"\n\n    if self.dataset.split(\"/\")[-1] == \"video\":\n        # This may be an embedded video dataset. Check for frame map.\n        ds = f[self.dataset]\n\n        if \"format\" in ds.attrs:\n            self.image_format = ds.attrs[\"format\"]\n\n        if \"frame_numbers\" in ds.parent:\n            frame_numbers = ds.parent[\"frame_numbers\"][:].astype(int)\n            self.frame_map = {frame: idx for idx, frame in enumerate(frame_numbers)}\n            self.source_inds = frame_numbers\n\n        if \"source_video\" in ds.parent:\n            self.source_filename = json.loads(\n                ds.parent[\"source_video\"].attrs[\"json\"]\n            )[\"backend\"][\"filename\"]\n\n    f.close()\n</code></pre>"},{"location":"reference/sleap_io/io/video/#sleap_io.io.video.HDF5Video.decode_embedded","title":"<code>decode_embedded(img_string)</code>","text":"<p>Decode an embedded image string into a numpy array.</p> <p>Parameters:</p> Name Type Description Default <code>img_string</code> <code>ndarray</code> <p>Binary string of the image as a <code>int8</code> numpy vector with the bytes as values corresponding to the format-encoded image.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>The decoded image as a numpy array of shape <code>(height, width, channels)</code>. If a rank-2 image is decoded, it will be expanded such that channels will be 1.</p> <p>This method does not apply grayscale conversion as per the <code>grayscale</code> attribute. Use the <code>get_frame</code> or <code>get_frames</code> methods of the <code>VideoBackend</code> to apply grayscale conversion rather than calling this function directly.</p> Source code in <code>sleap_io/io/video.py</code> <pre><code>def decode_embedded(self, img_string: np.ndarray) -&gt; np.ndarray:\n    \"\"\"Decode an embedded image string into a numpy array.\n\n    Args:\n        img_string: Binary string of the image as a `int8` numpy vector with the\n            bytes as values corresponding to the format-encoded image.\n\n    Returns:\n        The decoded image as a numpy array of shape `(height, width, channels)`. If\n        a rank-2 image is decoded, it will be expanded such that channels will be 1.\n\n        This method does not apply grayscale conversion as per the `grayscale`\n        attribute. Use the `get_frame` or `get_frames` methods of the `VideoBackend`\n        to apply grayscale conversion rather than calling this function directly.\n    \"\"\"\n    if \"cv2\" in sys.modules:\n        img = cv2.imdecode(img_string, cv2.IMREAD_UNCHANGED)\n    else:\n        img = iio.imread(BytesIO(img_string), extension=f\".{self.image_format}\")\n\n    if img.ndim == 2:\n        img = np.expand_dims(img, axis=-1)\n    return img\n</code></pre>"},{"location":"reference/sleap_io/io/video/#sleap_io.io.video.HDF5Video.read_test_frame","title":"<code>read_test_frame()</code>","text":"<p>Read a single frame from the video to test for grayscale.</p> Source code in <code>sleap_io/io/video.py</code> <pre><code>def read_test_frame(self) -&gt; np.ndarray:\n    \"\"\"Read a single frame from the video to test for grayscale.\"\"\"\n    if self.frame_map:\n        frame_idx = list(self.frame_map.keys())[0]\n    else:\n        frame_idx = 0\n    return self.read_frame(frame_idx)\n</code></pre>"},{"location":"reference/sleap_io/io/video/#sleap_io.io.video.ImageVideo","title":"<code>ImageVideo</code>","text":"<p>             Bases: <code>VideoBackend</code></p> <p>Video backend for reading videos stored as image files.</p> <p>This backend supports reading videos stored as a list of images.</p> <p>Attributes:</p> Name Type Description <code>filename</code> <p>Path to video files.</p> <code>grayscale</code> <p>Whether to force grayscale. If None, autodetect on first frame load.</p> Source code in <code>sleap_io/io/video.py</code> <pre><code>@attrs.define\nclass ImageVideo(VideoBackend):\n    \"\"\"Video backend for reading videos stored as image files.\n\n    This backend supports reading videos stored as a list of images.\n\n    Attributes:\n        filename: Path to video files.\n        grayscale: Whether to force grayscale. If None, autodetect on first frame load.\n    \"\"\"\n\n    EXTS = (\"png\", \"jpg\", \"jpeg\", \"tif\", \"tiff\", \"bmp\")\n\n    @staticmethod\n    def find_images(folder: str) -&gt; list[str]:\n        \"\"\"Find images in a folder and return a list of filenames.\"\"\"\n        folder = Path(folder)\n        return sorted(\n            [f.as_posix() for f in folder.glob(\"*\") if f.suffix[1:] in ImageVideo.EXTS]\n        )\n\n    @property\n    def num_frames(self) -&gt; int:\n        \"\"\"Number of frames in the video.\"\"\"\n        return len(self.filename)\n\n    def _read_frame(self, frame_idx: int) -&gt; np.ndarray:\n        \"\"\"Read a single frame from the video.\n\n        Args:\n            frame_idx: Index of frame to read.\n\n        Returns:\n            The frame as a numpy array of shape `(height, width, channels)`.\n\n        Notes:\n            This does not apply grayscale conversion. It is recommended to use the\n            `get_frame` method of the `VideoBackend` class instead.\n        \"\"\"\n        img = iio.imread(self.filename[frame_idx])\n        if img.ndim == 2:\n            img = np.expand_dims(img, axis=-1)\n        return img\n</code></pre>"},{"location":"reference/sleap_io/io/video/#sleap_io.io.video.ImageVideo.num_frames","title":"<code>num_frames: int</code>  <code>property</code>","text":"<p>Number of frames in the video.</p>"},{"location":"reference/sleap_io/io/video/#sleap_io.io.video.ImageVideo.find_images","title":"<code>find_images(folder)</code>  <code>staticmethod</code>","text":"<p>Find images in a folder and return a list of filenames.</p> Source code in <code>sleap_io/io/video.py</code> <pre><code>@staticmethod\ndef find_images(folder: str) -&gt; list[str]:\n    \"\"\"Find images in a folder and return a list of filenames.\"\"\"\n    folder = Path(folder)\n    return sorted(\n        [f.as_posix() for f in folder.glob(\"*\") if f.suffix[1:] in ImageVideo.EXTS]\n    )\n</code></pre>"},{"location":"reference/sleap_io/io/video/#sleap_io.io.video.MediaVideo","title":"<code>MediaVideo</code>","text":"<p>             Bases: <code>VideoBackend</code></p> <p>Video backend for reading videos stored as common media files.</p> <p>This backend supports reading through FFMPEG (the default), pyav, or OpenCV. Here are their trade-offs:</p> <pre><code>- \"opencv\": Fastest video reader, but only supports a limited number of codecs\n    and may not be able to read some videos. It requires `opencv-python` to be\n    installed. It is the fastest because it uses the OpenCV C++ library to read\n    videos, but is limited by the version of FFMPEG that was linked into it at\n    build time as well as the OpenCV version used.\n- \"FFMPEG\": Slowest, but most reliable. This is the default backend. It requires\n    `imageio-ffmpeg` and a `ffmpeg` executable on the system path (which can be\n    installed via conda). The `imageio` plugin for FFMPEG reads frames into raw\n    bytes which are communicated to Python through STDOUT on a subprocess pipe,\n    which can be slow. However, it is the most reliable and feature-complete. If\n    you install the conda-forge version of ffmpeg, it will be compiled with\n    support for many codecs, including GPU-accelerated codecs like NVDEC for\n    H264 and others.\n- \"pyav\": Supports most codecs that FFMPEG does, but not as complete or reliable\n    of an implementation in `imageio` as FFMPEG for some video types. It is\n    faster than FFMPEG because it uses the `av` package to read frames directly\n    into numpy arrays in memory without the need for a subprocess pipe. These\n    are Python bindings for the C library libav, which is the same library that\n    FFMPEG uses under the hood.\n</code></pre> <p>Attributes:</p> Name Type Description <code>filename</code> <p>Path to video file.</p> <code>grayscale</code> <p>Whether to force grayscale. If None, autodetect on first frame load.</p> <code>keep_open</code> <p>Whether to keep the video reader open between calls to read frames. If False, will close the reader after each call. If True (the default), it will keep the reader open and cache it for subsequent calls which may enhance the performance of reading multiple frames.</p> <code>plugin</code> <code>str</code> <p>Video plugin to use. One of \"opencv\", \"FFMPEG\", or \"pyav\". If <code>None</code>, will use the first available plugin in the order listed above.</p> Source code in <code>sleap_io/io/video.py</code> <pre><code>@attrs.define\nclass MediaVideo(VideoBackend):\n    \"\"\"Video backend for reading videos stored as common media files.\n\n    This backend supports reading through FFMPEG (the default), pyav, or OpenCV. Here\n    are their trade-offs:\n\n        - \"opencv\": Fastest video reader, but only supports a limited number of codecs\n            and may not be able to read some videos. It requires `opencv-python` to be\n            installed. It is the fastest because it uses the OpenCV C++ library to read\n            videos, but is limited by the version of FFMPEG that was linked into it at\n            build time as well as the OpenCV version used.\n        - \"FFMPEG\": Slowest, but most reliable. This is the default backend. It requires\n            `imageio-ffmpeg` and a `ffmpeg` executable on the system path (which can be\n            installed via conda). The `imageio` plugin for FFMPEG reads frames into raw\n            bytes which are communicated to Python through STDOUT on a subprocess pipe,\n            which can be slow. However, it is the most reliable and feature-complete. If\n            you install the conda-forge version of ffmpeg, it will be compiled with\n            support for many codecs, including GPU-accelerated codecs like NVDEC for\n            H264 and others.\n        - \"pyav\": Supports most codecs that FFMPEG does, but not as complete or reliable\n            of an implementation in `imageio` as FFMPEG for some video types. It is\n            faster than FFMPEG because it uses the `av` package to read frames directly\n            into numpy arrays in memory without the need for a subprocess pipe. These\n            are Python bindings for the C library libav, which is the same library that\n            FFMPEG uses under the hood.\n\n    Attributes:\n        filename: Path to video file.\n        grayscale: Whether to force grayscale. If None, autodetect on first frame load.\n        keep_open: Whether to keep the video reader open between calls to read frames.\n            If False, will close the reader after each call. If True (the default), it\n            will keep the reader open and cache it for subsequent calls which may\n            enhance the performance of reading multiple frames.\n        plugin: Video plugin to use. One of \"opencv\", \"FFMPEG\", or \"pyav\". If `None`,\n            will use the first available plugin in the order listed above.\n    \"\"\"\n\n    plugin: str = attrs.field(\n        validator=attrs.validators.in_([\"opencv\", \"FFMPEG\", \"pyav\"])\n    )\n\n    EXTS = (\"mp4\", \"avi\", \"mov\", \"mj2\", \"mkv\")\n\n    @plugin.default\n    def _default_plugin(self) -&gt; str:\n        if \"cv2\" in sys.modules:\n            return \"opencv\"\n        elif \"imageio_ffmpeg\" in sys.modules:\n            return \"FFMPEG\"\n        elif \"av\" in sys.modules:\n            return \"pyav\"\n        else:\n            raise ImportError(\n                \"No video plugins found. Install opencv-python, imageio-ffmpeg, or av.\"\n            )\n\n    @property\n    def reader(self) -&gt; object:\n        \"\"\"Return the reader object for the video, caching if necessary.\"\"\"\n        if self.keep_open:\n            if self._open_reader is None:\n                if self.plugin == \"opencv\":\n                    self._open_reader = cv2.VideoCapture(self.filename)\n                elif self.plugin == \"pyav\" or self.plugin == \"FFMPEG\":\n                    self._open_reader = iio.imopen(\n                        self.filename, \"r\", plugin=self.plugin\n                    )\n            return self._open_reader\n        else:\n            if self.plugin == \"opencv\":\n                return cv2.VideoCapture(self.filename)\n            elif self.plugin == \"pyav\" or self.plugin == \"FFMPEG\":\n                return iio.imopen(self.filename, \"r\", plugin=self.plugin)\n\n    @property\n    def num_frames(self) -&gt; int:\n        \"\"\"Number of frames in the video.\"\"\"\n        if self.plugin == \"opencv\":\n            return int(self.reader.get(cv2.CAP_PROP_FRAME_COUNT))\n        else:\n            props = iio.improps(self.filename, plugin=self.plugin)\n            n_frames = props.n_images\n            if np.isinf(n_frames):\n                legacy_reader = self.reader.legacy_get_reader()\n                # Note: This might be super slow for some videos, so maybe we should\n                # defer evaluation of this or give the user control over it.\n                n_frames = legacy_reader.count_frames()\n            return n_frames\n\n    def _read_frame(self, frame_idx: int) -&gt; np.ndarray:\n        \"\"\"Read a single frame from the video.\n\n        Args:\n            frame_idx: Index of frame to read.\n\n        Returns:\n            The frame as a numpy array of shape `(height, width, channels)`.\n\n        Notes:\n            This does not apply grayscale conversion. It is recommended to use the\n            `get_frame` method of the `VideoBackend` class instead.\n        \"\"\"\n        if self.plugin == \"opencv\":\n            if self.reader.get(cv2.CAP_PROP_POS_FRAMES) != frame_idx:\n                self.reader.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n            _, img = self.reader.read()\n        elif self.plugin == \"pyav\" or self.plugin == \"FFMPEG\":\n            if self.keep_open:\n                img = self.reader.read(index=frame_idx)\n            else:\n                with iio.imopen(self.filename, \"r\", plugin=self.plugin) as reader:\n                    img = reader.read(index=frame_idx)\n        return img\n\n    def _read_frames(self, frame_inds: list) -&gt; np.ndarray:\n        \"\"\"Read a list of frames from the video.\n\n        Args:\n            frame_inds: List of indices of frames to read.\n\n        Returns:\n            The frame as a numpy array of shape `(frames, height, width, channels)`.\n\n        Notes:\n            This does not apply grayscale conversion. It is recommended to use the\n            `get_frames` method of the `VideoBackend` class instead.\n        \"\"\"\n        if self.plugin == \"opencv\":\n            if self.keep_open:\n                if self._open_reader is None:\n                    self._open_reader = cv2.VideoCapture(self.filename)\n                reader = self._open_reader\n            else:\n                reader = cv2.VideoCapture(self.filename)\n\n            reader.set(cv2.CAP_PROP_POS_FRAMES, frame_inds[0])\n            imgs = []\n            for idx in frame_inds:\n                if reader.get(cv2.CAP_PROP_POS_FRAMES) != idx:\n                    reader.set(cv2.CAP_PROP_POS_FRAMES, idx)\n                _, img = reader.read()\n                img = img[..., ::-1]  # BGR -&gt; RGB\n                imgs.append(img)\n            imgs = np.stack(imgs, axis=0)\n\n        elif self.plugin == \"pyav\" or self.plugin == \"FFMPEG\":\n            if self.keep_open:\n                if self._open_reader is None:\n                    self._open_reader = iio.imopen(\n                        self.filename, \"r\", plugin=self.plugin\n                    )\n                reader = self._open_reader\n                imgs = np.stack([reader.read(index=idx) for idx in frame_inds], axis=0)\n            else:\n                with iio.imopen(self.filename, \"r\", plugin=self.plugin) as reader:\n                    imgs = np.stack(\n                        [reader.read(index=idx) for idx in frame_inds], axis=0\n                    )\n        return imgs\n</code></pre>"},{"location":"reference/sleap_io/io/video/#sleap_io.io.video.MediaVideo.num_frames","title":"<code>num_frames: int</code>  <code>property</code>","text":"<p>Number of frames in the video.</p>"},{"location":"reference/sleap_io/io/video/#sleap_io.io.video.MediaVideo.reader","title":"<code>reader: object</code>  <code>property</code>","text":"<p>Return the reader object for the video, caching if necessary.</p>"},{"location":"reference/sleap_io/io/video/#sleap_io.io.video.VideoBackend","title":"<code>VideoBackend</code>","text":"<p>Base class for video backends.</p> <p>This class is not meant to be used directly. Instead, use the <code>from_filename</code> constructor to create a backend instance.</p> <p>Attributes:</p> Name Type Description <code>filename</code> <code>str | Path | list[str] | list[Path]</code> <p>Path to video file(s).</p> <code>grayscale</code> <code>Optional[bool]</code> <p>Whether to force grayscale. If None, autodetect on first frame load.</p> <code>keep_open</code> <code>bool</code> <p>Whether to keep the video reader open between calls to read frames. If False, will close the reader after each call. If True (the default), it will keep the reader open and cache it for subsequent calls which may enhance the performance of reading multiple frames.</p> Source code in <code>sleap_io/io/video.py</code> <pre><code>@attrs.define\nclass VideoBackend:\n    \"\"\"Base class for video backends.\n\n    This class is not meant to be used directly. Instead, use the `from_filename`\n    constructor to create a backend instance.\n\n    Attributes:\n        filename: Path to video file(s).\n        grayscale: Whether to force grayscale. If None, autodetect on first frame load.\n        keep_open: Whether to keep the video reader open between calls to read frames.\n            If False, will close the reader after each call. If True (the default), it\n            will keep the reader open and cache it for subsequent calls which may\n            enhance the performance of reading multiple frames.\n    \"\"\"\n\n    filename: str | Path | list[str] | list[Path]\n    grayscale: Optional[bool] = None\n    keep_open: bool = True\n    _cached_shape: Optional[Tuple[int, int, int, int]] = None\n    _open_reader: Optional[object] = None\n\n    @classmethod\n    def from_filename(\n        cls,\n        filename: str | list[str],\n        dataset: Optional[str] = None,\n        grayscale: Optional[bool] = None,\n        keep_open: bool = True,\n        **kwargs,\n    ) -&gt; VideoBackend:\n        \"\"\"Create a VideoBackend from a filename.\n\n        Args:\n            filename: Path to video file(s).\n            dataset: Name of dataset in HDF5 file.\n            grayscale: Whether to force grayscale. If None, autodetect on first frame\n                load.\n            keep_open: Whether to keep the video reader open between calls to read\n                frames. If False, will close the reader after each call. If True (the\n                default), it will keep the reader open and cache it for subsequent calls\n                which may enhance the performance of reading multiple frames.\n\n        Returns:\n            VideoBackend subclass instance.\n        \"\"\"\n        if isinstance(filename, Path):\n            filename = filename.as_posix()\n\n        if type(filename) == str and Path(filename).is_dir():\n            filename = ImageVideo.find_images(filename)\n\n        if type(filename) == list:\n            filename = [Path(f).as_posix() for f in filename]\n            return ImageVideo(\n                filename, grayscale=grayscale, **_get_valid_kwargs(ImageVideo, kwargs)\n            )\n        elif filename.endswith(ImageVideo.EXTS):\n            return ImageVideo(\n                [filename], grayscale=grayscale, **_get_valid_kwargs(ImageVideo, kwargs)\n            )\n        elif filename.endswith(MediaVideo.EXTS):\n            return MediaVideo(\n                filename,\n                grayscale=grayscale,\n                keep_open=keep_open,\n                **_get_valid_kwargs(MediaVideo, kwargs),\n            )\n        elif filename.endswith(HDF5Video.EXTS):\n            return HDF5Video(\n                filename,\n                dataset=dataset,\n                grayscale=grayscale,\n                keep_open=keep_open,\n                **_get_valid_kwargs(HDF5Video, kwargs),\n            )\n        else:\n            raise ValueError(f\"Unknown video file type: {filename}\")\n\n    def _read_frame(self, frame_idx: int) -&gt; np.ndarray:\n        \"\"\"Read a single frame from the video. Must be implemented in subclasses.\"\"\"\n        raise NotImplementedError\n\n    def _read_frames(self, frame_inds: list) -&gt; np.ndarray:\n        \"\"\"Read a list of frames from the video.\"\"\"\n        return np.stack([self.get_frame(i) for i in frame_inds], axis=0)\n\n    def read_test_frame(self) -&gt; np.ndarray:\n        \"\"\"Read a single frame from the video to test for grayscale.\n\n        Note:\n            This reads the frame at index 0. This may not be appropriate if the first\n            frame is not available in a given backend.\n        \"\"\"\n        return self._read_frame(0)\n\n    def detect_grayscale(self, test_img: np.ndarray | None = None) -&gt; bool:\n        \"\"\"Detect whether the video is grayscale.\n\n        This works by reading in a test frame and comparing the first and last channel\n        for equality. It may fail in cases where, due to compression, the first and\n        last channels are not exactly the same.\n\n        Args:\n            test_img: Optional test image to use. If not provided, a test image will be\n                loaded via the `read_test_frame` method.\n\n        Returns:\n            Whether the video is grayscale. This value is also cached in the `grayscale`\n            attribute of the class.\n        \"\"\"\n        if test_img is None:\n            test_img = self.read_test_frame()\n        is_grayscale = bool(np.all(test_img[..., 0] == test_img[..., -1]))\n        self.grayscale = is_grayscale\n        return is_grayscale\n\n    @property\n    def num_frames(self) -&gt; int:\n        \"\"\"Number of frames in the video. Must be implemented in subclasses.\"\"\"\n        raise NotImplementedError\n\n    @property\n    def img_shape(self) -&gt; Tuple[int, int, int]:\n        \"\"\"Shape of a single frame in the video.\"\"\"\n        height, width, channels = self.get_frame(0).shape\n        return int(height), int(width), int(channels)\n\n    @property\n    def shape(self) -&gt; Tuple[int, int, int, int]:\n        \"\"\"Shape of the video as a tuple of `(frames, height, width, channels)`.\n\n        On first call, this will defer to `num_frames` and `img_shape` to determine the\n        full shape. This call may be expensive for some subclasses, so the result is\n        cached and returned on subsequent calls.\n        \"\"\"\n        if self._cached_shape is not None:\n            return self._cached_shape\n        else:\n            shape = (self.num_frames,) + self.img_shape\n            self._cached_shape = shape\n            return shape\n\n    @property\n    def frames(self) -&gt; int:\n        \"\"\"Number of frames in the video.\"\"\"\n        return self.shape[0]\n\n    def __len__(self) -&gt; int:\n        \"\"\"Return number of frames in the video.\"\"\"\n        return self.shape[0]\n\n    def get_frame(self, frame_idx: int) -&gt; np.ndarray:\n        \"\"\"Read a single frame from the video.\n\n        Args:\n            frame_idx: Index of frame to read.\n\n        Returns:\n            Frame as a numpy array of shape `(height, width, channels)` where the\n            `channels` dimension is 1 for grayscale videos and 3 for color videos.\n\n        Notes:\n            If the `grayscale` attribute is set to `True`, the `channels` dimension will\n            be reduced to 1 if an RGB frame is loaded from the backend.\n\n            If the `grayscale` attribute is set to `None`, the `grayscale` attribute\n            will be automatically set based on the first frame read.\n\n        See also: `get_frames`\n        \"\"\"\n        img = self._read_frame(frame_idx)\n\n        if self.grayscale is None:\n            self.detect_grayscale(img)\n\n        if self.grayscale:\n            img = img[..., [0]]\n\n        return img\n\n    def get_frames(self, frame_inds: list[int]) -&gt; np.ndarray:\n        \"\"\"Read a list of frames from the video.\n\n        Depending on the backend implementation, this may be faster than reading frames\n        individually using `get_frame`.\n\n        Args:\n            frame_inds: List of frame indices to read.\n\n        Returns:\n            Frames as a numpy array of shape `(frames, height, width, channels)` where\n            `channels` dimension is 1 for grayscale videos and 3 for color videos.\n\n        Notes:\n            If the `grayscale` attribute is set to `True`, the `channels` dimension will\n            be reduced to 1 if an RGB frame is loaded from the backend.\n\n            If the `grayscale` attribute is set to `None`, the `grayscale` attribute\n            will be automatically set based on the first frame read.\n\n        See also: `get_frame`\n        \"\"\"\n        imgs = self._read_frames(frame_inds)\n\n        if self.grayscale is None:\n            self.detect_grayscale(imgs[0])\n\n        if self.grayscale:\n            imgs = imgs[..., [0]]\n\n        return imgs\n\n    def __getitem__(self, ind: int | list[int] | slice) -&gt; np.ndarray:\n        \"\"\"Return a single frame or a list of frames from the video.\n\n        Args:\n            ind: Index or list of indices of frames to read.\n\n        Returns:\n            Frame or frames as a numpy array of shape `(height, width, channels)` if a\n            scalar index is provided, or `(frames, height, width, channels)` if a list\n            of indices is provided.\n\n        See also: get_frame, get_frames\n        \"\"\"\n        if np.isscalar(ind):\n            return self.get_frame(ind)\n        else:\n            if type(ind) is slice:\n                start = (ind.start or 0) % len(self)\n                stop = ind.stop or len(self)\n                if stop &lt; 0:\n                    stop = len(self) + stop\n                step = ind.step or 1\n                ind = range(start, stop, step)\n            return self.get_frames(ind)\n</code></pre>"},{"location":"reference/sleap_io/io/video/#sleap_io.io.video.VideoBackend.frames","title":"<code>frames: int</code>  <code>property</code>","text":"<p>Number of frames in the video.</p>"},{"location":"reference/sleap_io/io/video/#sleap_io.io.video.VideoBackend.img_shape","title":"<code>img_shape: Tuple[int, int, int]</code>  <code>property</code>","text":"<p>Shape of a single frame in the video.</p>"},{"location":"reference/sleap_io/io/video/#sleap_io.io.video.VideoBackend.num_frames","title":"<code>num_frames: int</code>  <code>property</code>","text":"<p>Number of frames in the video. Must be implemented in subclasses.</p>"},{"location":"reference/sleap_io/io/video/#sleap_io.io.video.VideoBackend.shape","title":"<code>shape: Tuple[int, int, int, int]</code>  <code>property</code>","text":"<p>Shape of the video as a tuple of <code>(frames, height, width, channels)</code>.</p> <p>On first call, this will defer to <code>num_frames</code> and <code>img_shape</code> to determine the full shape. This call may be expensive for some subclasses, so the result is cached and returned on subsequent calls.</p>"},{"location":"reference/sleap_io/io/video/#sleap_io.io.video.VideoBackend.__getitem__","title":"<code>__getitem__(ind)</code>","text":"<p>Return a single frame or a list of frames from the video.</p> <p>Parameters:</p> Name Type Description Default <code>ind</code> <code>int | list[int] | slice</code> <p>Index or list of indices of frames to read.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Frame or frames as a numpy array of shape <code>(height, width, channels)</code> if a scalar index is provided, or <code>(frames, height, width, channels)</code> if a list of indices is provided.</p> <p>See also: get_frame, get_frames</p> Source code in <code>sleap_io/io/video.py</code> <pre><code>def __getitem__(self, ind: int | list[int] | slice) -&gt; np.ndarray:\n    \"\"\"Return a single frame or a list of frames from the video.\n\n    Args:\n        ind: Index or list of indices of frames to read.\n\n    Returns:\n        Frame or frames as a numpy array of shape `(height, width, channels)` if a\n        scalar index is provided, or `(frames, height, width, channels)` if a list\n        of indices is provided.\n\n    See also: get_frame, get_frames\n    \"\"\"\n    if np.isscalar(ind):\n        return self.get_frame(ind)\n    else:\n        if type(ind) is slice:\n            start = (ind.start or 0) % len(self)\n            stop = ind.stop or len(self)\n            if stop &lt; 0:\n                stop = len(self) + stop\n            step = ind.step or 1\n            ind = range(start, stop, step)\n        return self.get_frames(ind)\n</code></pre>"},{"location":"reference/sleap_io/io/video/#sleap_io.io.video.VideoBackend.__len__","title":"<code>__len__()</code>","text":"<p>Return number of frames in the video.</p> Source code in <code>sleap_io/io/video.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"Return number of frames in the video.\"\"\"\n    return self.shape[0]\n</code></pre>"},{"location":"reference/sleap_io/io/video/#sleap_io.io.video.VideoBackend.detect_grayscale","title":"<code>detect_grayscale(test_img=None)</code>","text":"<p>Detect whether the video is grayscale.</p> <p>This works by reading in a test frame and comparing the first and last channel for equality. It may fail in cases where, due to compression, the first and last channels are not exactly the same.</p> <p>Parameters:</p> Name Type Description Default <code>test_img</code> <code>ndarray | None</code> <p>Optional test image to use. If not provided, a test image will be loaded via the <code>read_test_frame</code> method.</p> <code>None</code> <p>Returns:</p> Type Description <code>bool</code> <p>Whether the video is grayscale. This value is also cached in the <code>grayscale</code> attribute of the class.</p> Source code in <code>sleap_io/io/video.py</code> <pre><code>def detect_grayscale(self, test_img: np.ndarray | None = None) -&gt; bool:\n    \"\"\"Detect whether the video is grayscale.\n\n    This works by reading in a test frame and comparing the first and last channel\n    for equality. It may fail in cases where, due to compression, the first and\n    last channels are not exactly the same.\n\n    Args:\n        test_img: Optional test image to use. If not provided, a test image will be\n            loaded via the `read_test_frame` method.\n\n    Returns:\n        Whether the video is grayscale. This value is also cached in the `grayscale`\n        attribute of the class.\n    \"\"\"\n    if test_img is None:\n        test_img = self.read_test_frame()\n    is_grayscale = bool(np.all(test_img[..., 0] == test_img[..., -1]))\n    self.grayscale = is_grayscale\n    return is_grayscale\n</code></pre>"},{"location":"reference/sleap_io/io/video/#sleap_io.io.video.VideoBackend.from_filename","title":"<code>from_filename(filename, dataset=None, grayscale=None, keep_open=True, **kwargs)</code>  <code>classmethod</code>","text":"<p>Create a VideoBackend from a filename.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str | list[str]</code> <p>Path to video file(s).</p> required <code>dataset</code> <code>Optional[str]</code> <p>Name of dataset in HDF5 file.</p> <code>None</code> <code>grayscale</code> <code>Optional[bool]</code> <p>Whether to force grayscale. If None, autodetect on first frame load.</p> <code>None</code> <code>keep_open</code> <code>bool</code> <p>Whether to keep the video reader open between calls to read frames. If False, will close the reader after each call. If True (the default), it will keep the reader open and cache it for subsequent calls which may enhance the performance of reading multiple frames.</p> <code>True</code> <p>Returns:</p> Type Description <code>VideoBackend</code> <p>VideoBackend subclass instance.</p> Source code in <code>sleap_io/io/video.py</code> <pre><code>@classmethod\ndef from_filename(\n    cls,\n    filename: str | list[str],\n    dataset: Optional[str] = None,\n    grayscale: Optional[bool] = None,\n    keep_open: bool = True,\n    **kwargs,\n) -&gt; VideoBackend:\n    \"\"\"Create a VideoBackend from a filename.\n\n    Args:\n        filename: Path to video file(s).\n        dataset: Name of dataset in HDF5 file.\n        grayscale: Whether to force grayscale. If None, autodetect on first frame\n            load.\n        keep_open: Whether to keep the video reader open between calls to read\n            frames. If False, will close the reader after each call. If True (the\n            default), it will keep the reader open and cache it for subsequent calls\n            which may enhance the performance of reading multiple frames.\n\n    Returns:\n        VideoBackend subclass instance.\n    \"\"\"\n    if isinstance(filename, Path):\n        filename = filename.as_posix()\n\n    if type(filename) == str and Path(filename).is_dir():\n        filename = ImageVideo.find_images(filename)\n\n    if type(filename) == list:\n        filename = [Path(f).as_posix() for f in filename]\n        return ImageVideo(\n            filename, grayscale=grayscale, **_get_valid_kwargs(ImageVideo, kwargs)\n        )\n    elif filename.endswith(ImageVideo.EXTS):\n        return ImageVideo(\n            [filename], grayscale=grayscale, **_get_valid_kwargs(ImageVideo, kwargs)\n        )\n    elif filename.endswith(MediaVideo.EXTS):\n        return MediaVideo(\n            filename,\n            grayscale=grayscale,\n            keep_open=keep_open,\n            **_get_valid_kwargs(MediaVideo, kwargs),\n        )\n    elif filename.endswith(HDF5Video.EXTS):\n        return HDF5Video(\n            filename,\n            dataset=dataset,\n            grayscale=grayscale,\n            keep_open=keep_open,\n            **_get_valid_kwargs(HDF5Video, kwargs),\n        )\n    else:\n        raise ValueError(f\"Unknown video file type: {filename}\")\n</code></pre>"},{"location":"reference/sleap_io/io/video/#sleap_io.io.video.VideoBackend.get_frame","title":"<code>get_frame(frame_idx)</code>","text":"<p>Read a single frame from the video.</p> <p>Parameters:</p> Name Type Description Default <code>frame_idx</code> <code>int</code> <p>Index of frame to read.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Frame as a numpy array of shape <code>(height, width, channels)</code> where the <code>channels</code> dimension is 1 for grayscale videos and 3 for color videos.</p> Notes <p>If the <code>grayscale</code> attribute is set to <code>True</code>, the <code>channels</code> dimension will be reduced to 1 if an RGB frame is loaded from the backend.</p> <p>If the <code>grayscale</code> attribute is set to <code>None</code>, the <code>grayscale</code> attribute will be automatically set based on the first frame read.</p> <p>See also: <code>get_frames</code></p> Source code in <code>sleap_io/io/video.py</code> <pre><code>def get_frame(self, frame_idx: int) -&gt; np.ndarray:\n    \"\"\"Read a single frame from the video.\n\n    Args:\n        frame_idx: Index of frame to read.\n\n    Returns:\n        Frame as a numpy array of shape `(height, width, channels)` where the\n        `channels` dimension is 1 for grayscale videos and 3 for color videos.\n\n    Notes:\n        If the `grayscale` attribute is set to `True`, the `channels` dimension will\n        be reduced to 1 if an RGB frame is loaded from the backend.\n\n        If the `grayscale` attribute is set to `None`, the `grayscale` attribute\n        will be automatically set based on the first frame read.\n\n    See also: `get_frames`\n    \"\"\"\n    img = self._read_frame(frame_idx)\n\n    if self.grayscale is None:\n        self.detect_grayscale(img)\n\n    if self.grayscale:\n        img = img[..., [0]]\n\n    return img\n</code></pre>"},{"location":"reference/sleap_io/io/video/#sleap_io.io.video.VideoBackend.get_frames","title":"<code>get_frames(frame_inds)</code>","text":"<p>Read a list of frames from the video.</p> <p>Depending on the backend implementation, this may be faster than reading frames individually using <code>get_frame</code>.</p> <p>Parameters:</p> Name Type Description Default <code>frame_inds</code> <code>list[int]</code> <p>List of frame indices to read.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Frames as a numpy array of shape <code>(frames, height, width, channels)</code> where <code>channels</code> dimension is 1 for grayscale videos and 3 for color videos.</p> Notes <p>If the <code>grayscale</code> attribute is set to <code>True</code>, the <code>channels</code> dimension will be reduced to 1 if an RGB frame is loaded from the backend.</p> <p>If the <code>grayscale</code> attribute is set to <code>None</code>, the <code>grayscale</code> attribute will be automatically set based on the first frame read.</p> <p>See also: <code>get_frame</code></p> Source code in <code>sleap_io/io/video.py</code> <pre><code>def get_frames(self, frame_inds: list[int]) -&gt; np.ndarray:\n    \"\"\"Read a list of frames from the video.\n\n    Depending on the backend implementation, this may be faster than reading frames\n    individually using `get_frame`.\n\n    Args:\n        frame_inds: List of frame indices to read.\n\n    Returns:\n        Frames as a numpy array of shape `(frames, height, width, channels)` where\n        `channels` dimension is 1 for grayscale videos and 3 for color videos.\n\n    Notes:\n        If the `grayscale` attribute is set to `True`, the `channels` dimension will\n        be reduced to 1 if an RGB frame is loaded from the backend.\n\n        If the `grayscale` attribute is set to `None`, the `grayscale` attribute\n        will be automatically set based on the first frame read.\n\n    See also: `get_frame`\n    \"\"\"\n    imgs = self._read_frames(frame_inds)\n\n    if self.grayscale is None:\n        self.detect_grayscale(imgs[0])\n\n    if self.grayscale:\n        imgs = imgs[..., [0]]\n\n    return imgs\n</code></pre>"},{"location":"reference/sleap_io/io/video/#sleap_io.io.video.VideoBackend.read_test_frame","title":"<code>read_test_frame()</code>","text":"<p>Read a single frame from the video to test for grayscale.</p> Note <p>This reads the frame at index 0. This may not be appropriate if the first frame is not available in a given backend.</p> Source code in <code>sleap_io/io/video.py</code> <pre><code>def read_test_frame(self) -&gt; np.ndarray:\n    \"\"\"Read a single frame from the video to test for grayscale.\n\n    Note:\n        This reads the frame at index 0. This may not be appropriate if the first\n        frame is not available in a given backend.\n    \"\"\"\n    return self._read_frame(0)\n</code></pre>"},{"location":"reference/sleap_io/model/","title":"model","text":""},{"location":"reference/sleap_io/model/#sleap_io.model","title":"<code>sleap_io.model</code>","text":"<p>This subpackage contains data model interfaces.</p>"},{"location":"reference/sleap_io/model/instance/","title":"instance","text":""},{"location":"reference/sleap_io/model/instance/#sleap_io.model.instance","title":"<code>sleap_io.model.instance</code>","text":"<p>Data structures for data associated with a single instance such as an animal.</p> <p>The <code>Instance</code> class is a SLEAP data structure that contains a collection of <code>Point</code>s that correspond to landmarks within a <code>Skeleton</code>.</p> <p><code>PredictedInstance</code> additionally contains metadata associated with how the instance was estimated, such as confidence scores.</p>"},{"location":"reference/sleap_io/model/instance/#sleap_io.model.instance.Instance","title":"<code>Instance</code>","text":"<p>This class represents a ground truth instance such as an animal.</p> <p>An <code>Instance</code> has a set of landmarks (<code>Point</code>s) that correspond to the nodes defined in its <code>Skeleton</code>.</p> <p>It may also be associated with a <code>Track</code> which links multiple instances together across frames or videos.</p> <p>Attributes:</p> Name Type Description <code>points</code> <code>Union[dict[Node, Point], dict[Node, PredictedPoint]]</code> <p>A dictionary with keys as <code>Node</code>s and values as <code>Point</code>s containing all of the landmarks of the instance. This can also be specified as a dictionary with node names, a list of length <code>n_nodes</code>, or a numpy array of shape <code>(n_nodes, 2)</code>.</p> <code>skeleton</code> <code>Skeleton</code> <p>The <code>Skeleton</code> that describes the <code>Node</code>s and <code>Edge</code>s associated with this instance.</p> <code>track</code> <code>Optional[Track]</code> <p>An optional <code>Track</code> associated with a unique animal/object across frames or videos.</p> <code>from_predicted</code> <code>Optional[PredictedInstance]</code> <p>The <code>PredictedInstance</code> (if any) that this instance was initialized from. This is used with human-in-the-loop workflows.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>@define(auto_attribs=True, slots=True, eq=True)\nclass Instance:\n    \"\"\"This class represents a ground truth instance such as an animal.\n\n    An `Instance` has a set of landmarks (`Point`s) that correspond to the nodes defined\n    in its `Skeleton`.\n\n    It may also be associated with a `Track` which links multiple instances together\n    across frames or videos.\n\n    Attributes:\n        points: A dictionary with keys as `Node`s and values as `Point`s containing all\n            of the landmarks of the instance. This can also be specified as a dictionary\n            with node names, a list of length `n_nodes`, or a numpy array of shape\n            `(n_nodes, 2)`.\n        skeleton: The `Skeleton` that describes the `Node`s and `Edge`s associated with\n            this instance.\n        track: An optional `Track` associated with a unique animal/object across frames\n            or videos.\n        from_predicted: The `PredictedInstance` (if any) that this instance was\n            initialized from. This is used with human-in-the-loop workflows.\n    \"\"\"\n\n    _POINT_TYPE = Point\n\n    def _make_default_point(self, x, y):\n        return self._POINT_TYPE(x, y, visible=not (math.isnan(x) or math.isnan(y)))\n\n    def _convert_points(self, attr, points):\n        \"\"\"Maintain points mappings between nodes and points.\"\"\"\n        if type(points) == np.ndarray:\n            points = points.tolist()\n\n        if type(points) == list:\n            if len(points) != len(self.skeleton):\n                raise ValueError(\n                    \"If specifying points as a list, must provide as many points as \"\n                    \"nodes in the skeleton.\"\n                )\n            points = {node: pt for node, pt in zip(self.skeleton.nodes, points)}\n\n        if type(points) == dict:\n            keys = [\n                node if type(node) == Node else self.skeleton[node]\n                for node in points.keys()\n            ]\n            vals = [\n                (\n                    point\n                    if type(point) == self._POINT_TYPE\n                    else self._make_default_point(*point)\n                )\n                for point in points.values()\n            ]\n            points = {k: v for k, v in zip(keys, vals)}\n\n        missing_nodes = list(set(self.skeleton.nodes) - set(points.keys()))\n        for node in missing_nodes:\n            points[node] = self._make_default_point(x=np.nan, y=np.nan)\n\n        return points\n\n    points: Union[dict[Node, Point], dict[Node, PredictedPoint]] = field(\n        on_setattr=_convert_points, eq=cmp_using(eq=_compare_points)  # type: ignore\n    )\n    skeleton: Skeleton\n    track: Optional[Track] = None\n    from_predicted: Optional[PredictedInstance] = None\n\n    def __attrs_post_init__(self):\n        \"\"\"Maintain point mappings between node and points after initialization.\"\"\"\n        super().__setattr__(\"points\", self._convert_points(None, self.points))\n\n    def __getitem__(self, node: Union[int, str, Node]) -&gt; Optional[Point]:\n        \"\"\"Return the point associated with a node or `None` if not set.\"\"\"\n        if (type(node) == int) or (type(node) == str):\n            node = self.skeleton[node]\n        if isinstance(node, Node):\n            return self.points.get(node, None)\n        else:\n            raise IndexError(f\"Invalid indexing argument for instance: {node}\")\n\n    def __len__(self) -&gt; int:\n        \"\"\"Return the number of points in the instance.\"\"\"\n        return len(self.points)\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return a readable representation of the instance.\"\"\"\n        pts = self.numpy().tolist()\n        track = f'\"{self.track.name}\"' if self.track is not None else self.track\n\n        return f\"Instance(points={pts}, track={track})\"\n\n    @property\n    def n_visible(self) -&gt; int:\n        \"\"\"Return the number of visible points in the instance.\"\"\"\n        return sum(pt.visible for pt in self.points.values())\n\n    @property\n    def is_empty(self) -&gt; bool:\n        \"\"\"Return `True` if no points are visible on the instance.\"\"\"\n        return self.n_visible == 0\n\n    @classmethod\n    def from_numpy(\n        cls, points: np.ndarray, skeleton: Skeleton, track: Optional[Track] = None\n    ) -&gt; \"Instance\":\n        \"\"\"Create an instance object from a numpy array.\n\n        Args:\n            points: A numpy array of shape `(n_nodes, 2)` corresponding to the points of\n                the skeleton. Values of `np.nan` indicate \"missing\" nodes.\n            skeleton: The `Skeleton` that this `Instance` is associated with. It should\n                have `n_nodes` nodes.\n            track: An optional `Track` associated with a unique animal/object across\n                frames or videos.\n        \"\"\"\n        return cls(\n            points=points, skeleton=skeleton, track=track  # type: ignore[arg-type]\n        )\n\n    def numpy(self) -&gt; np.ndarray:\n        \"\"\"Return the instance points as a numpy array.\"\"\"\n        pts = np.full((len(self.skeleton), 2), np.nan)\n        for node, point in self.points.items():\n            if point.visible:\n                pts[self.skeleton.index(node)] = point.numpy()\n        return pts\n</code></pre>"},{"location":"reference/sleap_io/model/instance/#sleap_io.model.instance.Instance.is_empty","title":"<code>is_empty: bool</code>  <code>property</code>","text":"<p>Return <code>True</code> if no points are visible on the instance.</p>"},{"location":"reference/sleap_io/model/instance/#sleap_io.model.instance.Instance.n_visible","title":"<code>n_visible: int</code>  <code>property</code>","text":"<p>Return the number of visible points in the instance.</p>"},{"location":"reference/sleap_io/model/instance/#sleap_io.model.instance.Instance.__attrs_post_init__","title":"<code>__attrs_post_init__()</code>","text":"<p>Maintain point mappings between node and points after initialization.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>def __attrs_post_init__(self):\n    \"\"\"Maintain point mappings between node and points after initialization.\"\"\"\n    super().__setattr__(\"points\", self._convert_points(None, self.points))\n</code></pre>"},{"location":"reference/sleap_io/model/instance/#sleap_io.model.instance.Instance.__getitem__","title":"<code>__getitem__(node)</code>","text":"<p>Return the point associated with a node or <code>None</code> if not set.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>def __getitem__(self, node: Union[int, str, Node]) -&gt; Optional[Point]:\n    \"\"\"Return the point associated with a node or `None` if not set.\"\"\"\n    if (type(node) == int) or (type(node) == str):\n        node = self.skeleton[node]\n    if isinstance(node, Node):\n        return self.points.get(node, None)\n    else:\n        raise IndexError(f\"Invalid indexing argument for instance: {node}\")\n</code></pre>"},{"location":"reference/sleap_io/model/instance/#sleap_io.model.instance.Instance.__len__","title":"<code>__len__()</code>","text":"<p>Return the number of points in the instance.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"Return the number of points in the instance.\"\"\"\n    return len(self.points)\n</code></pre>"},{"location":"reference/sleap_io/model/instance/#sleap_io.model.instance.Instance.__repr__","title":"<code>__repr__()</code>","text":"<p>Return a readable representation of the instance.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return a readable representation of the instance.\"\"\"\n    pts = self.numpy().tolist()\n    track = f'\"{self.track.name}\"' if self.track is not None else self.track\n\n    return f\"Instance(points={pts}, track={track})\"\n</code></pre>"},{"location":"reference/sleap_io/model/instance/#sleap_io.model.instance.Instance.from_numpy","title":"<code>from_numpy(points, skeleton, track=None)</code>  <code>classmethod</code>","text":"<p>Create an instance object from a numpy array.</p> <p>Parameters:</p> Name Type Description Default <code>points</code> <code>ndarray</code> <p>A numpy array of shape <code>(n_nodes, 2)</code> corresponding to the points of the skeleton. Values of <code>np.nan</code> indicate \"missing\" nodes.</p> required <code>skeleton</code> <code>Skeleton</code> <p>The <code>Skeleton</code> that this <code>Instance</code> is associated with. It should have <code>n_nodes</code> nodes.</p> required <code>track</code> <code>Optional[Track]</code> <p>An optional <code>Track</code> associated with a unique animal/object across frames or videos.</p> <code>None</code> Source code in <code>sleap_io/model/instance.py</code> <pre><code>@classmethod\ndef from_numpy(\n    cls, points: np.ndarray, skeleton: Skeleton, track: Optional[Track] = None\n) -&gt; \"Instance\":\n    \"\"\"Create an instance object from a numpy array.\n\n    Args:\n        points: A numpy array of shape `(n_nodes, 2)` corresponding to the points of\n            the skeleton. Values of `np.nan` indicate \"missing\" nodes.\n        skeleton: The `Skeleton` that this `Instance` is associated with. It should\n            have `n_nodes` nodes.\n        track: An optional `Track` associated with a unique animal/object across\n            frames or videos.\n    \"\"\"\n    return cls(\n        points=points, skeleton=skeleton, track=track  # type: ignore[arg-type]\n    )\n</code></pre>"},{"location":"reference/sleap_io/model/instance/#sleap_io.model.instance.Instance.numpy","title":"<code>numpy()</code>","text":"<p>Return the instance points as a numpy array.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>def numpy(self) -&gt; np.ndarray:\n    \"\"\"Return the instance points as a numpy array.\"\"\"\n    pts = np.full((len(self.skeleton), 2), np.nan)\n    for node, point in self.points.items():\n        if point.visible:\n            pts[self.skeleton.index(node)] = point.numpy()\n    return pts\n</code></pre>"},{"location":"reference/sleap_io/model/instance/#sleap_io.model.instance.Point","title":"<code>Point</code>","text":"<p>A 2D spatial landmark and metadata associated with annotation.</p> <p>Attributes:</p> Name Type Description <code>x</code> <code>float</code> <p>The horizontal pixel location of point in image coordinates.</p> <code>y</code> <code>float</code> <p>The vertical pixel location of point in image coordinates.</p> <code>visible</code> <code>bool</code> <p>Whether point is visible in the image or not.</p> <code>complete</code> <code>bool</code> <p>Has the point been verified by the user labeler.</p> Class variables <p>eq_atol: Controls absolute tolerence allowed in <code>x</code> and <code>y</code> when comparing two     <code>Point</code>s for equality. eq_rtol: Controls relative tolerence allowed in <code>x</code> and <code>y</code> when comparing two     <code>Point</code>s for equality.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>@define\nclass Point:\n    \"\"\"A 2D spatial landmark and metadata associated with annotation.\n\n    Attributes:\n        x: The horizontal pixel location of point in image coordinates.\n        y: The vertical pixel location of point in image coordinates.\n        visible: Whether point is visible in the image or not.\n        complete: Has the point been verified by the user labeler.\n\n    Class variables:\n        eq_atol: Controls absolute tolerence allowed in `x` and `y` when comparing two\n            `Point`s for equality.\n        eq_rtol: Controls relative tolerence allowed in `x` and `y` when comparing two\n            `Point`s for equality.\n\n    \"\"\"\n\n    eq_atol: ClassVar[float] = 1e-08\n    eq_rtol: ClassVar[float] = 0\n\n    x: float\n    y: float\n    visible: bool = True\n    complete: bool = False\n\n    def __eq__(self, other: object) -&gt; bool:\n        \"\"\"Compare `self` and `other` for equality.\n\n        Precision error between the respective `x` and `y` properties of two\n        instances may be allowed or controlled via the `Point.eq_atol` and\n        `Point.eq_rtol` class variables. Set to zero to disable their effect.\n        Internally, `numpy.isclose()` is used for the comparison:\n        https://numpy.org/doc/stable/reference/generated/numpy.isclose.html\n\n        Args:\n            other: Instance of `Point` to compare to.\n\n        Returns:\n            Returns True if all attributes of `self` and `other` are the identical\n                (possibly allowing precision error for `x` and `y` attributes).\n        \"\"\"\n        # Check that other is a Point.\n        if type(other) is not type(self):\n            return False\n\n        # We know that we have some kind of point at this point.\n        other = cast(Point, other)\n\n        return bool(\n            np.all(\n                np.isclose(\n                    [self.x, self.y],\n                    [other.x, other.y],\n                    rtol=Point.eq_rtol,\n                    atol=Point.eq_atol,\n                    equal_nan=True,\n                )\n            )\n            and (self.visible == other.visible)\n            and (self.complete == other.complete)\n        )\n\n    def numpy(self) -&gt; np.ndarray:\n        \"\"\"Return the coordinates as a numpy array of shape `(2,)`.\"\"\"\n        return np.array([self.x, self.y]) if self.visible else np.full((2,), np.nan)\n</code></pre>"},{"location":"reference/sleap_io/model/instance/#sleap_io.model.instance.Point.__eq__","title":"<code>__eq__(other)</code>","text":"<p>Compare <code>self</code> and <code>other</code> for equality.</p> <p>Precision error between the respective <code>x</code> and <code>y</code> properties of two instances may be allowed or controlled via the <code>Point.eq_atol</code> and <code>Point.eq_rtol</code> class variables. Set to zero to disable their effect. Internally, <code>numpy.isclose()</code> is used for the comparison: https://numpy.org/doc/stable/reference/generated/numpy.isclose.html</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>object</code> <p>Instance of <code>Point</code> to compare to.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>Returns True if all attributes of <code>self</code> and <code>other</code> are the identical     (possibly allowing precision error for <code>x</code> and <code>y</code> attributes).</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>def __eq__(self, other: object) -&gt; bool:\n    \"\"\"Compare `self` and `other` for equality.\n\n    Precision error between the respective `x` and `y` properties of two\n    instances may be allowed or controlled via the `Point.eq_atol` and\n    `Point.eq_rtol` class variables. Set to zero to disable their effect.\n    Internally, `numpy.isclose()` is used for the comparison:\n    https://numpy.org/doc/stable/reference/generated/numpy.isclose.html\n\n    Args:\n        other: Instance of `Point` to compare to.\n\n    Returns:\n        Returns True if all attributes of `self` and `other` are the identical\n            (possibly allowing precision error for `x` and `y` attributes).\n    \"\"\"\n    # Check that other is a Point.\n    if type(other) is not type(self):\n        return False\n\n    # We know that we have some kind of point at this point.\n    other = cast(Point, other)\n\n    return bool(\n        np.all(\n            np.isclose(\n                [self.x, self.y],\n                [other.x, other.y],\n                rtol=Point.eq_rtol,\n                atol=Point.eq_atol,\n                equal_nan=True,\n            )\n        )\n        and (self.visible == other.visible)\n        and (self.complete == other.complete)\n    )\n</code></pre>"},{"location":"reference/sleap_io/model/instance/#sleap_io.model.instance.Point.numpy","title":"<code>numpy()</code>","text":"<p>Return the coordinates as a numpy array of shape <code>(2,)</code>.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>def numpy(self) -&gt; np.ndarray:\n    \"\"\"Return the coordinates as a numpy array of shape `(2,)`.\"\"\"\n    return np.array([self.x, self.y]) if self.visible else np.full((2,), np.nan)\n</code></pre>"},{"location":"reference/sleap_io/model/instance/#sleap_io.model.instance.PredictedInstance","title":"<code>PredictedInstance</code>","text":"<p>             Bases: <code>Instance</code></p> <p>A <code>PredictedInstance</code> is an <code>Instance</code> that was predicted using a model.</p> <p>Attributes:</p> Name Type Description <code>skeleton</code> <p>The <code>Skeleton</code> that this <code>Instance</code> is associated with.</p> <code>points</code> <p>A dictionary where keys are <code>Skeleton</code> nodes and values are <code>Point</code>s.</p> <code>track</code> <p>An optional <code>Track</code> associated with a unique animal/object across frames or videos.</p> <code>from_predicted</code> <code>Optional[PredictedInstance]</code> <p>Not applicable in <code>PredictedInstance</code>s (must be set to <code>None</code>).</p> <code>score</code> <code>float</code> <p>The instance detection or part grouping prediction score. This is a scalar that represents the confidence with which this entire instance was predicted. This may not always be applicable depending on the model type.</p> <code>tracking_score</code> <code>Optional[float]</code> <p>The score associated with the <code>Track</code> assignment. This is typically the value from the score matrix used in an identity assignment.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>@define\nclass PredictedInstance(Instance):\n    \"\"\"A `PredictedInstance` is an `Instance` that was predicted using a model.\n\n    Attributes:\n        skeleton: The `Skeleton` that this `Instance` is associated with.\n        points: A dictionary where keys are `Skeleton` nodes and values are `Point`s.\n        track: An optional `Track` associated with a unique animal/object across frames\n            or videos.\n        from_predicted: Not applicable in `PredictedInstance`s (must be set to `None`).\n        score: The instance detection or part grouping prediction score. This is a\n            scalar that represents the confidence with which this entire instance was\n            predicted. This may not always be applicable depending on the model type.\n        tracking_score: The score associated with the `Track` assignment. This is\n            typically the value from the score matrix used in an identity assignment.\n    \"\"\"\n\n    _POINT_TYPE = PredictedPoint\n\n    from_predicted: Optional[PredictedInstance] = field(\n        default=None, validator=validators.instance_of(type(None))\n    )\n    score: float = 0.0\n    tracking_score: Optional[float] = 0\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return a readable representation of the instance.\"\"\"\n        pts = self.numpy().tolist()\n        track = f'\"{self.track.name}\"' if self.track is not None else self.track\n\n        score = str(self.score) if self.score is None else f\"{self.score:.2f}\"\n        tracking_score = (\n            str(self.tracking_score)\n            if self.tracking_score is None\n            else f\"{self.tracking_score:.2f}\"\n        )\n        return (\n            f\"PredictedInstance(points={pts}, track={track}, \"\n            f\"score={score}, tracking_score={tracking_score})\"\n        )\n\n    @classmethod\n    def from_numpy(  # type: ignore[override]\n        cls,\n        points: np.ndarray,\n        point_scores: np.ndarray,\n        instance_score: float,\n        skeleton: Skeleton,\n        tracking_score: Optional[float] = None,\n        track: Optional[Track] = None,\n    ) -&gt; \"PredictedInstance\":\n        \"\"\"Create an instance object from a numpy array.\n\n        Args:\n            points: A numpy array of shape `(n_nodes, 2)` corresponding to the points of\n                the skeleton. Values of `np.nan` indicate \"missing\" nodes.\n            point_scores: The points-level prediction score. This is an array that\n                represents the confidence with which each point in the instance was\n                predicted. This may not always be applicable depending on the model\n                type.\n            instance_score: The instance detection or part grouping prediction score.\n                This is a scalar that represents the confidence with which this entire\n                instance was predicted. This may not always be applicable depending on\n                the model type.\n            skeleton: The `Skeleton` that this `Instance` is associated with. It should\n                have `n_nodes` nodes.\n            tracking_score: The score associated with the `Track` assignment. This is\n                typically the value from the score matrix used in an identity\n                assignment.\n            track: An optional `Track` associated with a unique animal/object across\n                frames or videos.\n        \"\"\"\n        node_points = {\n            node: PredictedPoint(pt[0], pt[1], score=score)\n            for node, pt, score in zip(skeleton.nodes, points, point_scores)\n        }\n        return cls(\n            points=node_points,\n            skeleton=skeleton,\n            score=instance_score,\n            tracking_score=tracking_score,\n            track=track,\n        )\n\n    def numpy(self, scores: bool = False) -&gt; np.ndarray:\n        \"\"\"Return the instance points as a numpy array.\"\"\"\n        pts = np.full((len(self.skeleton), 3), np.nan)\n        for node, point in self.points.items():\n            if point.visible:\n                pts[self.skeleton.index(node)] = point.numpy()\n        if not scores:\n            pts = pts[:, :2]\n        return pts\n</code></pre>"},{"location":"reference/sleap_io/model/instance/#sleap_io.model.instance.PredictedInstance.__repr__","title":"<code>__repr__()</code>","text":"<p>Return a readable representation of the instance.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return a readable representation of the instance.\"\"\"\n    pts = self.numpy().tolist()\n    track = f'\"{self.track.name}\"' if self.track is not None else self.track\n\n    score = str(self.score) if self.score is None else f\"{self.score:.2f}\"\n    tracking_score = (\n        str(self.tracking_score)\n        if self.tracking_score is None\n        else f\"{self.tracking_score:.2f}\"\n    )\n    return (\n        f\"PredictedInstance(points={pts}, track={track}, \"\n        f\"score={score}, tracking_score={tracking_score})\"\n    )\n</code></pre>"},{"location":"reference/sleap_io/model/instance/#sleap_io.model.instance.PredictedInstance.from_numpy","title":"<code>from_numpy(points, point_scores, instance_score, skeleton, tracking_score=None, track=None)</code>  <code>classmethod</code>","text":"<p>Create an instance object from a numpy array.</p> <p>Parameters:</p> Name Type Description Default <code>points</code> <code>ndarray</code> <p>A numpy array of shape <code>(n_nodes, 2)</code> corresponding to the points of the skeleton. Values of <code>np.nan</code> indicate \"missing\" nodes.</p> required <code>point_scores</code> <code>ndarray</code> <p>The points-level prediction score. This is an array that represents the confidence with which each point in the instance was predicted. This may not always be applicable depending on the model type.</p> required <code>instance_score</code> <code>float</code> <p>The instance detection or part grouping prediction score. This is a scalar that represents the confidence with which this entire instance was predicted. This may not always be applicable depending on the model type.</p> required <code>skeleton</code> <code>Skeleton</code> <p>The <code>Skeleton</code> that this <code>Instance</code> is associated with. It should have <code>n_nodes</code> nodes.</p> required <code>tracking_score</code> <code>Optional[float]</code> <p>The score associated with the <code>Track</code> assignment. This is typically the value from the score matrix used in an identity assignment.</p> <code>None</code> <code>track</code> <code>Optional[Track]</code> <p>An optional <code>Track</code> associated with a unique animal/object across frames or videos.</p> <code>None</code> Source code in <code>sleap_io/model/instance.py</code> <pre><code>@classmethod\ndef from_numpy(  # type: ignore[override]\n    cls,\n    points: np.ndarray,\n    point_scores: np.ndarray,\n    instance_score: float,\n    skeleton: Skeleton,\n    tracking_score: Optional[float] = None,\n    track: Optional[Track] = None,\n) -&gt; \"PredictedInstance\":\n    \"\"\"Create an instance object from a numpy array.\n\n    Args:\n        points: A numpy array of shape `(n_nodes, 2)` corresponding to the points of\n            the skeleton. Values of `np.nan` indicate \"missing\" nodes.\n        point_scores: The points-level prediction score. This is an array that\n            represents the confidence with which each point in the instance was\n            predicted. This may not always be applicable depending on the model\n            type.\n        instance_score: The instance detection or part grouping prediction score.\n            This is a scalar that represents the confidence with which this entire\n            instance was predicted. This may not always be applicable depending on\n            the model type.\n        skeleton: The `Skeleton` that this `Instance` is associated with. It should\n            have `n_nodes` nodes.\n        tracking_score: The score associated with the `Track` assignment. This is\n            typically the value from the score matrix used in an identity\n            assignment.\n        track: An optional `Track` associated with a unique animal/object across\n            frames or videos.\n    \"\"\"\n    node_points = {\n        node: PredictedPoint(pt[0], pt[1], score=score)\n        for node, pt, score in zip(skeleton.nodes, points, point_scores)\n    }\n    return cls(\n        points=node_points,\n        skeleton=skeleton,\n        score=instance_score,\n        tracking_score=tracking_score,\n        track=track,\n    )\n</code></pre>"},{"location":"reference/sleap_io/model/instance/#sleap_io.model.instance.PredictedInstance.numpy","title":"<code>numpy(scores=False)</code>","text":"<p>Return the instance points as a numpy array.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>def numpy(self, scores: bool = False) -&gt; np.ndarray:\n    \"\"\"Return the instance points as a numpy array.\"\"\"\n    pts = np.full((len(self.skeleton), 3), np.nan)\n    for node, point in self.points.items():\n        if point.visible:\n            pts[self.skeleton.index(node)] = point.numpy()\n    if not scores:\n        pts = pts[:, :2]\n    return pts\n</code></pre>"},{"location":"reference/sleap_io/model/instance/#sleap_io.model.instance.PredictedPoint","title":"<code>PredictedPoint</code>","text":"<p>             Bases: <code>Point</code></p> <p>A predicted point with associated score generated by a prediction model.</p> <p>It has all the properties of a labeled <code>Point</code>, plus a <code>score</code>.</p> <p>Attributes:</p> Name Type Description <code>x</code> <p>The horizontal pixel location of point within image frame.</p> <code>y</code> <p>The vertical pixel location of point within image frame.</p> <code>visible</code> <p>Whether point is visible in the image or not.</p> <code>complete</code> <p>Has the point been verified by the user labeler.</p> <code>score</code> <code>float</code> <p>The point-level prediction score. This is typically the confidence and set to a value between 0 and 1.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>@define\nclass PredictedPoint(Point):\n    \"\"\"A predicted point with associated score generated by a prediction model.\n\n    It has all the properties of a labeled `Point`, plus a `score`.\n\n    Attributes:\n        x: The horizontal pixel location of point within image frame.\n        y: The vertical pixel location of point within image frame.\n        visible: Whether point is visible in the image or not.\n        complete: Has the point been verified by the user labeler.\n        score: The point-level prediction score. This is typically the confidence and\n            set to a value between 0 and 1.\n    \"\"\"\n\n    score: float = 0.0\n\n    def numpy(self) -&gt; np.ndarray:\n        \"\"\"Return the coordinates and score as a numpy array of shape `(3,)`.\"\"\"\n        return (\n            np.array([self.x, self.y, self.score])\n            if self.visible\n            else np.full((3,), np.nan)\n        )\n\n    def __eq__(self, other: object) -&gt; bool:\n        \"\"\"Compare `self` and `other` for equality.\n\n        See `Point.__eq__()` for important notes about point equality semantics!\n\n        Args:\n            other: Instance of `PredictedPoint` to compare\n\n        Returns:\n            Returns True if all attributes of `self` and `other` are the identical\n                (possibly allowing precision error for `x` and `y` attributes).\n        \"\"\"\n        if not super().__eq__(other):\n            return False\n\n        # we know that we have a point at this point\n        other = cast(PredictedPoint, other)\n\n        return self.score == other.score\n</code></pre>"},{"location":"reference/sleap_io/model/instance/#sleap_io.model.instance.PredictedPoint.__eq__","title":"<code>__eq__(other)</code>","text":"<p>Compare <code>self</code> and <code>other</code> for equality.</p> <p>See <code>Point.__eq__()</code> for important notes about point equality semantics!</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>object</code> <p>Instance of <code>PredictedPoint</code> to compare</p> required <p>Returns:</p> Type Description <code>bool</code> <p>Returns True if all attributes of <code>self</code> and <code>other</code> are the identical     (possibly allowing precision error for <code>x</code> and <code>y</code> attributes).</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>def __eq__(self, other: object) -&gt; bool:\n    \"\"\"Compare `self` and `other` for equality.\n\n    See `Point.__eq__()` for important notes about point equality semantics!\n\n    Args:\n        other: Instance of `PredictedPoint` to compare\n\n    Returns:\n        Returns True if all attributes of `self` and `other` are the identical\n            (possibly allowing precision error for `x` and `y` attributes).\n    \"\"\"\n    if not super().__eq__(other):\n        return False\n\n    # we know that we have a point at this point\n    other = cast(PredictedPoint, other)\n\n    return self.score == other.score\n</code></pre>"},{"location":"reference/sleap_io/model/instance/#sleap_io.model.instance.PredictedPoint.numpy","title":"<code>numpy()</code>","text":"<p>Return the coordinates and score as a numpy array of shape <code>(3,)</code>.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>def numpy(self) -&gt; np.ndarray:\n    \"\"\"Return the coordinates and score as a numpy array of shape `(3,)`.\"\"\"\n    return (\n        np.array([self.x, self.y, self.score])\n        if self.visible\n        else np.full((3,), np.nan)\n    )\n</code></pre>"},{"location":"reference/sleap_io/model/instance/#sleap_io.model.instance.Track","title":"<code>Track</code>","text":"<p>An object that represents the same animal/object across multiple detections.</p> <p>This allows tracking of unique entities in the video over time and space.</p> <p>A <code>Track</code> may also be used to refer to unique identity classes that span multiple videos, such as <code>\"female mouse\"</code>.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>A name given to this track for identification purposes.</p> Notes <p><code>Track</code>s are compared by identity. This means that unique track objects with the same name are considered to be different.</p> Source code in <code>sleap_io/model/instance.py</code> <pre><code>@define(eq=False)\nclass Track:\n    \"\"\"An object that represents the same animal/object across multiple detections.\n\n    This allows tracking of unique entities in the video over time and space.\n\n    A `Track` may also be used to refer to unique identity classes that span multiple\n    videos, such as `\"female mouse\"`.\n\n    Attributes:\n        name: A name given to this track for identification purposes.\n\n    Notes:\n        `Track`s are compared by identity. This means that unique track objects with the\n        same name are considered to be different.\n    \"\"\"\n\n    name: str = \"\"\n</code></pre>"},{"location":"reference/sleap_io/model/labeled_frame/","title":"labeled_frame","text":""},{"location":"reference/sleap_io/model/labeled_frame/#sleap_io.model.labeled_frame","title":"<code>sleap_io.model.labeled_frame</code>","text":"<p>Data structures for data contained within a single video frame.</p> <p>The <code>LabeledFrame</code> class is a data structure that contains <code>Instance</code>s and <code>PredictedInstance</code>s that are associated with a single frame within a video.</p>"},{"location":"reference/sleap_io/model/labeled_frame/#sleap_io.model.labeled_frame.LabeledFrame","title":"<code>LabeledFrame</code>","text":"<p>Labeled data for a single frame of a video.</p> <p>Attributes:</p> Name Type Description <code>video</code> <code>Video</code> <p>The <code>Video</code> associated with this <code>LabeledFrame</code>.</p> <code>frame_idx</code> <code>int</code> <p>The index of the <code>LabeledFrame</code> in the <code>Video</code>.</p> <code>instances</code> <code>list[Union[Instance, PredictedInstance]]</code> <p>List of <code>Instance</code> objects associated with this <code>LabeledFrame</code>.</p> Notes <p>Instances of this class are hashed by identity, not by value. This means that two <code>LabeledFrame</code> instances with the same attributes will NOT be considered equal in a set or dict.</p> Source code in <code>sleap_io/model/labeled_frame.py</code> <pre><code>@define(eq=False)\nclass LabeledFrame:\n    \"\"\"Labeled data for a single frame of a video.\n\n    Attributes:\n        video: The `Video` associated with this `LabeledFrame`.\n        frame_idx: The index of the `LabeledFrame` in the `Video`.\n        instances: List of `Instance` objects associated with this `LabeledFrame`.\n\n    Notes:\n        Instances of this class are hashed by identity, not by value. This means that\n        two `LabeledFrame` instances with the same attributes will NOT be considered\n        equal in a set or dict.\n    \"\"\"\n\n    video: Video\n    frame_idx: int\n    instances: list[Union[Instance, PredictedInstance]] = field(factory=list)\n\n    def __len__(self) -&gt; int:\n        \"\"\"Return the number of instances in the frame.\"\"\"\n        return len(self.instances)\n\n    def __getitem__(self, key: int) -&gt; Union[Instance, PredictedInstance]:\n        \"\"\"Return the `Instance` at `key` index in the `instances` list.\"\"\"\n        return self.instances[key]\n\n    def __iter__(self):\n        \"\"\"Iterate over `Instance`s in `instances` list.\"\"\"\n        return iter(self.instances)\n\n    @property\n    def user_instances(self) -&gt; list[Instance]:\n        \"\"\"Frame instances that are user-labeled (`Instance` objects).\"\"\"\n        return [inst for inst in self.instances if type(inst) == Instance]\n\n    @property\n    def has_user_instances(self) -&gt; bool:\n        \"\"\"Return True if the frame has any user-labeled instances.\"\"\"\n        for inst in self.instances:\n            if type(inst) == Instance:\n                return True\n        return False\n\n    @property\n    def predicted_instances(self) -&gt; list[Instance]:\n        \"\"\"Frame instances that are predicted by a model (`PredictedInstance` objects).\"\"\"\n        return [inst for inst in self.instances if type(inst) == PredictedInstance]\n\n    @property\n    def has_predicted_instances(self) -&gt; bool:\n        \"\"\"Return True if the frame has any predicted instances.\"\"\"\n        for inst in self.instances:\n            if type(inst) == PredictedInstance:\n                return True\n        return False\n\n    def numpy(self) -&gt; np.ndarray:\n        \"\"\"Return all instances in the frame as a numpy array.\n\n        Returns:\n            Points as a numpy array of shape `(n_instances, n_nodes, 2)`.\n\n            Note that the order of the instances is arbitrary.\n        \"\"\"\n        n_instances = len(self.instances)\n        n_nodes = len(self.instances[0]) if n_instances &gt; 0 else 0\n        pts = np.full((n_instances, n_nodes, 2), np.nan)\n        for i, inst in enumerate(self.instances):\n            pts[i] = inst.numpy()[:, 0:2]\n        return pts\n\n    @property\n    def image(self) -&gt; np.ndarray:\n        \"\"\"Return the image of the frame as a numpy array.\"\"\"\n        return self.video[self.frame_idx]\n\n    @property\n    def unused_predictions(self) -&gt; list[Instance]:\n        \"\"\"Return a list of \"unused\" `PredictedInstance` objects in frame.\n\n        This is all of the `PredictedInstance` objects which do not have a corresponding\n        `Instance` in the same track in the same frame.\n        \"\"\"\n        unused_predictions = []\n        any_tracks = [inst.track for inst in self.instances if inst.track is not None]\n        if len(any_tracks):\n            # Use tracks to determine which predicted instances have been used\n            used_tracks = [\n                inst.track\n                for inst in self.instances\n                if type(inst) == Instance and inst.track is not None\n            ]\n            unused_predictions = [\n                inst\n                for inst in self.instances\n                if inst.track not in used_tracks and type(inst) == PredictedInstance\n            ]\n\n        else:\n            # Use from_predicted to determine which predicted instances have been used\n            # TODO: should we always do this instead of using tracks?\n            used_instances = [\n                inst.from_predicted\n                for inst in self.instances\n                if inst.from_predicted is not None\n            ]\n            unused_predictions = [\n                inst\n                for inst in self.instances\n                if type(inst) == PredictedInstance and inst not in used_instances\n            ]\n\n        return unused_predictions\n\n    def remove_predictions(self):\n        \"\"\"Remove all `PredictedInstance` objects from the frame.\"\"\"\n        self.instances = [inst for inst in self.instances if type(inst) == Instance]\n\n    def remove_empty_instances(self):\n        \"\"\"Remove all instances with no visible points.\"\"\"\n        self.instances = [inst for inst in self.instances if not inst.is_empty]\n</code></pre>"},{"location":"reference/sleap_io/model/labeled_frame/#sleap_io.model.labeled_frame.LabeledFrame.has_predicted_instances","title":"<code>has_predicted_instances: bool</code>  <code>property</code>","text":"<p>Return True if the frame has any predicted instances.</p>"},{"location":"reference/sleap_io/model/labeled_frame/#sleap_io.model.labeled_frame.LabeledFrame.has_user_instances","title":"<code>has_user_instances: bool</code>  <code>property</code>","text":"<p>Return True if the frame has any user-labeled instances.</p>"},{"location":"reference/sleap_io/model/labeled_frame/#sleap_io.model.labeled_frame.LabeledFrame.image","title":"<code>image: np.ndarray</code>  <code>property</code>","text":"<p>Return the image of the frame as a numpy array.</p>"},{"location":"reference/sleap_io/model/labeled_frame/#sleap_io.model.labeled_frame.LabeledFrame.predicted_instances","title":"<code>predicted_instances: list[Instance]</code>  <code>property</code>","text":"<p>Frame instances that are predicted by a model (<code>PredictedInstance</code> objects).</p>"},{"location":"reference/sleap_io/model/labeled_frame/#sleap_io.model.labeled_frame.LabeledFrame.unused_predictions","title":"<code>unused_predictions: list[Instance]</code>  <code>property</code>","text":"<p>Return a list of \"unused\" <code>PredictedInstance</code> objects in frame.</p> <p>This is all of the <code>PredictedInstance</code> objects which do not have a corresponding <code>Instance</code> in the same track in the same frame.</p>"},{"location":"reference/sleap_io/model/labeled_frame/#sleap_io.model.labeled_frame.LabeledFrame.user_instances","title":"<code>user_instances: list[Instance]</code>  <code>property</code>","text":"<p>Frame instances that are user-labeled (<code>Instance</code> objects).</p>"},{"location":"reference/sleap_io/model/labeled_frame/#sleap_io.model.labeled_frame.LabeledFrame.__getitem__","title":"<code>__getitem__(key)</code>","text":"<p>Return the <code>Instance</code> at <code>key</code> index in the <code>instances</code> list.</p> Source code in <code>sleap_io/model/labeled_frame.py</code> <pre><code>def __getitem__(self, key: int) -&gt; Union[Instance, PredictedInstance]:\n    \"\"\"Return the `Instance` at `key` index in the `instances` list.\"\"\"\n    return self.instances[key]\n</code></pre>"},{"location":"reference/sleap_io/model/labeled_frame/#sleap_io.model.labeled_frame.LabeledFrame.__iter__","title":"<code>__iter__()</code>","text":"<p>Iterate over <code>Instance</code>s in <code>instances</code> list.</p> Source code in <code>sleap_io/model/labeled_frame.py</code> <pre><code>def __iter__(self):\n    \"\"\"Iterate over `Instance`s in `instances` list.\"\"\"\n    return iter(self.instances)\n</code></pre>"},{"location":"reference/sleap_io/model/labeled_frame/#sleap_io.model.labeled_frame.LabeledFrame.__len__","title":"<code>__len__()</code>","text":"<p>Return the number of instances in the frame.</p> Source code in <code>sleap_io/model/labeled_frame.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"Return the number of instances in the frame.\"\"\"\n    return len(self.instances)\n</code></pre>"},{"location":"reference/sleap_io/model/labeled_frame/#sleap_io.model.labeled_frame.LabeledFrame.numpy","title":"<code>numpy()</code>","text":"<p>Return all instances in the frame as a numpy array.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>Points as a numpy array of shape <code>(n_instances, n_nodes, 2)</code>.</p> <p>Note that the order of the instances is arbitrary.</p> Source code in <code>sleap_io/model/labeled_frame.py</code> <pre><code>def numpy(self) -&gt; np.ndarray:\n    \"\"\"Return all instances in the frame as a numpy array.\n\n    Returns:\n        Points as a numpy array of shape `(n_instances, n_nodes, 2)`.\n\n        Note that the order of the instances is arbitrary.\n    \"\"\"\n    n_instances = len(self.instances)\n    n_nodes = len(self.instances[0]) if n_instances &gt; 0 else 0\n    pts = np.full((n_instances, n_nodes, 2), np.nan)\n    for i, inst in enumerate(self.instances):\n        pts[i] = inst.numpy()[:, 0:2]\n    return pts\n</code></pre>"},{"location":"reference/sleap_io/model/labeled_frame/#sleap_io.model.labeled_frame.LabeledFrame.remove_empty_instances","title":"<code>remove_empty_instances()</code>","text":"<p>Remove all instances with no visible points.</p> Source code in <code>sleap_io/model/labeled_frame.py</code> <pre><code>def remove_empty_instances(self):\n    \"\"\"Remove all instances with no visible points.\"\"\"\n    self.instances = [inst for inst in self.instances if not inst.is_empty]\n</code></pre>"},{"location":"reference/sleap_io/model/labeled_frame/#sleap_io.model.labeled_frame.LabeledFrame.remove_predictions","title":"<code>remove_predictions()</code>","text":"<p>Remove all <code>PredictedInstance</code> objects from the frame.</p> Source code in <code>sleap_io/model/labeled_frame.py</code> <pre><code>def remove_predictions(self):\n    \"\"\"Remove all `PredictedInstance` objects from the frame.\"\"\"\n    self.instances = [inst for inst in self.instances if type(inst) == Instance]\n</code></pre>"},{"location":"reference/sleap_io/model/labels/","title":"labels","text":""},{"location":"reference/sleap_io/model/labels/#sleap_io.model.labels","title":"<code>sleap_io.model.labels</code>","text":"<p>Data structure for the labels, a top-level container for pose data.</p> <p><code>Label</code>s contain <code>LabeledFrame</code>s, which in turn contain <code>Instance</code>s, which contain <code>Point</code>s.</p> <p>This structure also maintains metadata that is common across all child objects such as <code>Track</code>s, <code>Video</code>s, <code>Skeleton</code>s and others.</p> <p>It is intended to be the entrypoint for deserialization and main container that should be used for serialization. It is designed to support both labeled data (used for training models) and predictions (inference results).</p>"},{"location":"reference/sleap_io/model/labels/#sleap_io.model.labels.Labels","title":"<code>Labels</code>","text":"<p>Pose data for a set of videos that have user labels and/or predictions.</p> <p>Attributes:</p> Name Type Description <code>labeled_frames</code> <code>list[LabeledFrame]</code> <p>A list of <code>LabeledFrame</code>s that are associated with this dataset.</p> <code>videos</code> <code>list[Video]</code> <p>A list of <code>Video</code>s that are associated with this dataset. Videos do not need to have corresponding <code>LabeledFrame</code>s if they do not have any labels or predictions yet.</p> <code>skeletons</code> <code>list[Skeleton]</code> <p>A list of <code>Skeleton</code>s that are associated with this dataset. This should generally only contain a single skeleton.</p> <code>tracks</code> <code>list[Track]</code> <p>A list of <code>Track</code>s that are associated with this dataset.</p> <code>suggestions</code> <code>list[SuggestionFrame]</code> <p>A list of <code>SuggestionFrame</code>s that are associated with this dataset.</p> <code>provenance</code> <code>dict[str, Any]</code> <p>Dictionary of arbitrary metadata providing additional information about where the dataset came from.</p> Notes <p><code>Video</code>s in contain <code>LabeledFrame</code>s, and <code>Skeleton</code>s and <code>Track</code>s in contained <code>Instance</code>s are added to the respective lists automatically.</p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>@define\nclass Labels:\n    \"\"\"Pose data for a set of videos that have user labels and/or predictions.\n\n    Attributes:\n        labeled_frames: A list of `LabeledFrame`s that are associated with this dataset.\n        videos: A list of `Video`s that are associated with this dataset. Videos do not\n            need to have corresponding `LabeledFrame`s if they do not have any\n            labels or predictions yet.\n        skeletons: A list of `Skeleton`s that are associated with this dataset. This\n            should generally only contain a single skeleton.\n        tracks: A list of `Track`s that are associated with this dataset.\n        suggestions: A list of `SuggestionFrame`s that are associated with this dataset.\n        provenance: Dictionary of arbitrary metadata providing additional information\n            about where the dataset came from.\n\n    Notes:\n        `Video`s in contain `LabeledFrame`s, and `Skeleton`s and `Track`s in contained\n        `Instance`s are added to the respective lists automatically.\n    \"\"\"\n\n    labeled_frames: list[LabeledFrame] = field(factory=list)\n    videos: list[Video] = field(factory=list)\n    skeletons: list[Skeleton] = field(factory=list)\n    tracks: list[Track] = field(factory=list)\n    suggestions: list[SuggestionFrame] = field(factory=list)\n    provenance: dict[str, Any] = field(factory=dict)\n\n    def __attrs_post_init__(self):\n        \"\"\"Append videos, skeletons, and tracks seen in `labeled_frames` to `Labels`.\"\"\"\n        self.update()\n\n    def update(self):\n        \"\"\"Update data structures based on contents.\n\n        This function will update the list of skeletons, videos and tracks from the\n        labeled frames, instances and suggestions.\n        \"\"\"\n        for lf in self.labeled_frames:\n            if lf.video not in self.videos:\n                self.videos.append(lf.video)\n\n            for inst in lf:\n                if inst.skeleton not in self.skeletons:\n                    self.skeletons.append(inst.skeleton)\n\n                if inst.track is not None and inst.track not in self.tracks:\n                    self.tracks.append(inst.track)\n\n        for sf in self.suggestions:\n            if sf.video not in self.videos:\n                self.videos.append(sf.video)\n\n    def __getitem__(\n        self, key: int | slice | list[int] | np.ndarray | tuple[Video, int]\n    ) -&gt; list[LabeledFrame] | LabeledFrame:\n        \"\"\"Return one or more labeled frames based on indexing criteria.\"\"\"\n        if type(key) == int:\n            return self.labeled_frames[key]\n        elif type(key) == slice:\n            return [self.labeled_frames[i] for i in range(*key.indices(len(self)))]\n        elif type(key) == list:\n            return [self.labeled_frames[i] for i in key]\n        elif isinstance(key, np.ndarray):\n            return [self.labeled_frames[i] for i in key.tolist()]\n        elif type(key) == tuple and len(key) == 2:\n            video, frame_idx = key\n            res = self.find(video, frame_idx)\n            if len(res) == 1:\n                return res[0]\n            elif len(res) == 0:\n                raise IndexError(\n                    f\"No labeled frames found for video {video} and \"\n                    f\"frame index {frame_idx}.\"\n                )\n        elif type(key) == Video:\n            res = self.find(key)\n            if len(res) == 0:\n                raise IndexError(f\"No labeled frames found for video {key}.\")\n            return res\n        else:\n            raise IndexError(f\"Invalid indexing argument for labels: {key}\")\n\n    def __iter__(self):\n        \"\"\"Iterate over `labeled_frames` list when calling iter method on `Labels`.\"\"\"\n        return iter(self.labeled_frames)\n\n    def __len__(self) -&gt; int:\n        \"\"\"Return number of labeled frames.\"\"\"\n        return len(self.labeled_frames)\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return a readable representation of the labels.\"\"\"\n        return (\n            \"Labels(\"\n            f\"labeled_frames={len(self.labeled_frames)}, \"\n            f\"videos={len(self.videos)}, \"\n            f\"skeletons={len(self.skeletons)}, \"\n            f\"tracks={len(self.tracks)}, \"\n            f\"suggestions={len(self.suggestions)}\"\n            \")\"\n        )\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return a readable representation of the labels.\"\"\"\n        return self.__repr__()\n\n    def append(self, lf: LabeledFrame, update: bool = True):\n        \"\"\"Append a labeled frame to the labels.\n\n        Args:\n            lf: A labeled frame to add to the labels.\n            update: If `True` (the default), update list of videos, tracks and\n                skeletons from the contents.\n        \"\"\"\n        self.labeled_frames.append(lf)\n\n        if update:\n            if lf.video not in self.videos:\n                self.videos.append(lf.video)\n\n            for inst in lf:\n                if inst.skeleton not in self.skeletons:\n                    self.skeletons.append(inst.skeleton)\n\n                if inst.track is not None and inst.track not in self.tracks:\n                    self.tracks.append(inst.track)\n\n    def extend(self, lfs: list[LabeledFrame], update: bool = True):\n        \"\"\"Append a labeled frame to the labels.\n\n        Args:\n            lfs: A list of labeled frames to add to the labels.\n            update: If `True` (the default), update list of videos, tracks and\n                skeletons from the contents.\n        \"\"\"\n        self.labeled_frames.extend(lfs)\n\n        if update:\n            for lf in lfs:\n                if lf.video not in self.videos:\n                    self.videos.append(lf.video)\n\n                for inst in lf:\n                    if inst.skeleton not in self.skeletons:\n                        self.skeletons.append(inst.skeleton)\n\n                    if inst.track is not None and inst.track not in self.tracks:\n                        self.tracks.append(inst.track)\n\n    def numpy(\n        self,\n        video: Optional[Union[Video, int]] = None,\n        all_frames: bool = True,\n        untracked: bool = False,\n        return_confidence: bool = False,\n    ) -&gt; np.ndarray:\n        \"\"\"Construct a numpy array from instance points.\n\n        Args:\n            video: Video or video index to convert to numpy arrays. If `None` (the\n                default), uses the first video.\n            untracked: If `False` (the default), include only instances that have a\n                track assignment. If `True`, includes all instances in each frame in\n                arbitrary order.\n            return_confidence: If `False` (the default), only return points of nodes. If\n                `True`, return the points and scores of nodes.\n\n        Returns:\n            An array of tracks of shape `(n_frames, n_tracks, n_nodes, 2)` if\n            `return_confidence` is `False`. Otherwise returned shape is\n            `(n_frames, n_tracks, n_nodes, 3)` if `return_confidence` is `True`.\n\n            Missing data will be replaced with `np.nan`.\n\n            If this is a single instance project, a track does not need to be assigned.\n\n            Only predicted instances (NOT user instances) will be returned.\n\n        Notes:\n            This method assumes that instances have tracks assigned and is intended to\n            function primarily for single-video prediction results.\n        \"\"\"\n        # Get labeled frames for specified video.\n        if video is None:\n            video = 0\n        if type(video) == int:\n            video = self.videos[video]\n        lfs = [lf for lf in self.labeled_frames if lf.video == video]\n\n        # Figure out frame index range.\n        first_frame, last_frame = 0, 0\n        for lf in lfs:\n            first_frame = min(first_frame, lf.frame_idx)\n            last_frame = max(last_frame, lf.frame_idx)\n\n        # Figure out the number of tracks based on number of instances in each frame.\n        # First, let's check the max number of predicted instances (regardless of\n        # whether they're tracked.\n        n_preds = 0\n        for lf in lfs:\n            n_pred_instances = len(lf.predicted_instances)\n            n_preds = max(n_preds, n_pred_instances)\n\n        # Case 1: We don't care about order because there's only 1 instance per frame,\n        # or we're considering untracked instances.\n        untracked = untracked or n_preds == 1\n        if untracked:\n            n_tracks = n_preds\n        else:\n            # Case 2: We're considering only tracked instances.\n            n_tracks = len(self.tracks)\n\n        n_frames = int(last_frame - first_frame + 1)\n        skeleton = self.skeletons[-1]  # Assume project only uses last skeleton\n        n_nodes = len(skeleton.nodes)\n\n        if return_confidence:\n            tracks = np.full((n_frames, n_tracks, n_nodes, 3), np.nan, dtype=\"float32\")\n        else:\n            tracks = np.full((n_frames, n_tracks, n_nodes, 2), np.nan, dtype=\"float32\")\n        for lf in lfs:\n            i = int(lf.frame_idx - first_frame)\n            if untracked:\n                for j, inst in enumerate(lf.predicted_instances):\n                    tracks[i, j] = inst.numpy(scores=return_confidence)\n            else:\n                tracked_instances = [\n                    inst\n                    for inst in lf.instances\n                    if type(inst) == PredictedInstance and inst.track is not None\n                ]\n                for inst in tracked_instances:\n                    j = self.tracks.index(inst.track)  # type: ignore[arg-type]\n                    tracks[i, j] = inst.numpy(scores=return_confidence)\n\n        return tracks\n\n    @property\n    def video(self) -&gt; Video:\n        \"\"\"Return the video if there is only a single video in the labels.\"\"\"\n        if len(self.videos) == 0:\n            raise ValueError(\"There are no videos in the labels.\")\n        elif len(self.videos) == 1:\n            return self.videos[0]\n        else:\n            raise ValueError(\n                \"Labels.video can only be used when there is only a single video saved \"\n                \"in the labels. Use Labels.videos instead.\"\n            )\n\n    @property\n    def skeleton(self) -&gt; Skeleton:\n        \"\"\"Return the skeleton if there is only a single skeleton in the labels.\"\"\"\n        if len(self.skeletons) == 0:\n            raise ValueError(\"There are no skeletons in the labels.\")\n        elif len(self.skeletons) == 1:\n            return self.skeletons[0]\n        else:\n            raise ValueError(\n                \"Labels.skeleton can only be used when there is only a single skeleton \"\n                \"saved in the labels. Use Labels.skeletons instead.\"\n            )\n\n    def find(\n        self,\n        video: Video,\n        frame_idx: int | list[int] | None = None,\n        return_new: bool = False,\n    ) -&gt; list[LabeledFrame]:\n        \"\"\"Search for labeled frames given video and/or frame index.\n\n        Args:\n            video: A `Video` that is associated with the project.\n            frame_idx: The frame index (or indices) which we want to find in the video.\n                If a range is specified, we'll return all frames with indices in that\n                range. If not specific, then we'll return all labeled frames for video.\n            return_new: Whether to return singleton of new and empty `LabeledFrame` if\n                none are found in project.\n\n        Returns:\n            List of `LabeledFrame` objects that match the criteria.\n\n            The list will be empty if no matches found, unless return_new is True, in\n            which case it contains new (empty) `LabeledFrame` objects with `video` and\n            `frame_index` set.\n        \"\"\"\n        results = []\n\n        if frame_idx is None:\n            for lf in self.labeled_frames:\n                if lf.video == video:\n                    results.append(lf)\n            return results\n\n        if np.isscalar(frame_idx):\n            frame_idx = np.array(frame_idx).reshape(-1)\n\n        for frame_ind in frame_idx:\n            result = None\n            for lf in self.labeled_frames:\n                if lf.video == video and lf.frame_idx == frame_ind:\n                    result = lf\n                    results.append(result)\n                    break\n            if result is None and return_new:\n                results.append(LabeledFrame(video=video, frame_idx=frame_ind))\n\n        return results\n\n    def save(\n        self,\n        filename: str,\n        format: Optional[str] = None,\n        embed: bool | str | list[tuple[Video, int]] | None = None,\n        **kwargs,\n    ):\n        \"\"\"Save labels to file in specified format.\n\n        Args:\n            filename: Path to save labels to.\n            format: The format to save the labels in. If `None`, the format will be\n                inferred from the file extension. Available formats are `\"slp\"`,\n                `\"nwb\"`, `\"labelstudio\"`, and `\"jabs\"`.\n            embed: Frames to embed in the saved labels file. One of `None`, `True`,\n                `\"all\"`, `\"user\"`, `\"suggestions\"`, `\"user+suggestions\"`, `\"source\"` or\n                list of tuples of `(video, frame_idx)`.\n\n                If `None` is specified (the default) and the labels contains embedded\n                frames, those embedded frames will be re-saved to the new file.\n\n                If `True` or `\"all\"`, all labeled frames and suggested frames will be\n                embedded.\n\n                If `\"source\"` is specified, no images will be embedded and the source\n                video will be restored if available.\n\n                This argument is only valid for the SLP backend.\n        \"\"\"\n        from sleap_io import save_file\n\n        save_file(self, filename, format=format, embed=embed, **kwargs)\n\n    def clean(\n        self,\n        frames: bool = True,\n        empty_instances: bool = False,\n        skeletons: bool = True,\n        tracks: bool = True,\n        videos: bool = False,\n    ):\n        \"\"\"Remove empty frames, unused skeletons, tracks and videos.\n\n        Args:\n            frames: If `True` (the default), remove empty frames.\n            empty_instances: If `True` (NOT default), remove instances that have no\n                visible points.\n            skeletons: If `True` (the default), remove unused skeletons.\n            tracks: If `True` (the default), remove unused tracks.\n            videos: If `True` (NOT default), remove videos that have no labeled frames.\n        \"\"\"\n        used_skeletons = []\n        used_tracks = []\n        used_videos = []\n        kept_frames = []\n        for lf in self.labeled_frames:\n\n            if empty_instances:\n                lf.remove_empty_instances()\n\n            if frames and len(lf) == 0:\n                continue\n\n            if videos and lf.video not in used_videos:\n                used_videos.append(lf.video)\n\n            if skeletons or tracks:\n                for inst in lf:\n                    if skeletons and inst.skeleton not in used_skeletons:\n                        used_skeletons.append(inst.skeleton)\n                    if (\n                        tracks\n                        and inst.track is not None\n                        and inst.track not in used_tracks\n                    ):\n                        used_tracks.append(inst.track)\n\n            if frames:\n                kept_frames.append(lf)\n\n        if videos:\n            self.videos = [video for video in self.videos if video in used_videos]\n\n        if skeletons:\n            self.skeletons = [\n                skeleton for skeleton in self.skeletons if skeleton in used_skeletons\n            ]\n\n        if tracks:\n            self.tracks = [track for track in self.tracks if track in used_tracks]\n\n        if frames:\n            self.labeled_frames = kept_frames\n\n    def remove_predictions(self, clean: bool = True):\n        \"\"\"Remove all predicted instances from the labels.\n\n        Args:\n            clean: If `True` (the default), also remove any empty frames and unused\n                tracks and skeletons. It does NOT remove videos that have no labeled\n                frames or instances with no visible points.\n\n        See also: `Labels.clean`\n        \"\"\"\n        for lf in self.labeled_frames:\n            lf.remove_predictions()\n\n        if clean:\n            self.clean(\n                frames=True,\n                empty_instances=False,\n                skeletons=True,\n                tracks=True,\n                videos=False,\n            )\n\n    @property\n    def user_labeled_frames(self) -&gt; list[LabeledFrame]:\n        \"\"\"Return all labeled frames with user (non-predicted) instances.\"\"\"\n        return [lf for lf in self.labeled_frames if lf.has_user_instances]\n\n    def replace_videos(\n        self,\n        old_videos: list[Video] | None = None,\n        new_videos: list[Video] | None = None,\n        video_map: dict[Video, Video] | None = None,\n    ):\n        \"\"\"Replace videos and update all references.\n\n        Args:\n            old_videos: List of videos to be replaced.\n            new_videos: List of videos to replace with.\n            video_map: Alternative input of dictionary where keys are the old videos and\n                values are the new videos.\n        \"\"\"\n        if video_map is None:\n            video_map = {o: n for o, n in zip(old_videos, new_videos)}\n\n        # Update the labeled frames with the new videos.\n        for lf in self.labeled_frames:\n            if lf.video in video_map:\n                lf.video = video_map[lf.video]\n\n        # Update suggestions with the new videos.\n        for sf in self.suggestions:\n            if sf.video in video_map:\n                sf.video = video_map[sf.video]\n\n    def replace_filenames(\n        self,\n        new_filenames: list[str | Path] | None = None,\n        filename_map: dict[str | Path, str | Path] | None = None,\n        prefix_map: dict[str | Path, str | Path] | None = None,\n    ):\n        \"\"\"Replace video filenames.\n\n        Args:\n            new_filenames: List of new filenames. Must have the same length as the\n                number of videos in the labels.\n            filename_map: Dictionary mapping old filenames (keys) to new filenames\n                (values).\n            prefix_map: Dictonary mapping old prefixes (keys) to new prefixes (values).\n\n        Notes:\n            Only one of the argument types can be provided.\n        \"\"\"\n        n = 0\n        if new_filenames is not None:\n            n += 1\n        if filename_map is not None:\n            n += 1\n        if prefix_map is not None:\n            n += 1\n        if n != 1:\n            raise ValueError(\n                \"Exactly one input method must be provided to replace filenames.\"\n            )\n\n        if new_filenames is not None:\n            if len(self.videos) != len(new_filenames):\n                raise ValueError(\n                    f\"Number of new filenames ({len(new_filenames)}) does not match \"\n                    f\"the number of videos ({len(self.videos)}).\"\n                )\n\n            for video, new_filename in zip(self.videos, new_filenames):\n                video.replace_filename(new_filename)\n\n        elif filename_map is not None:\n            for video in self.videos:\n                for old_fn, new_fn in filename_map.items():\n                    if type(video.filename) == list:\n                        new_fns = []\n                        for fn in video.filename:\n                            if Path(fn) == Path(old_fn):\n                                new_fns.append(new_fn)\n                            else:\n                                new_fns.append(fn)\n                        video.replace_filename(new_fns)\n                    else:\n                        if Path(video.filename) == Path(old_fn):\n                            video.replace_filename(new_fn)\n\n        elif prefix_map is not None:\n            for video in self.videos:\n                for old_prefix, new_prefix in prefix_map.items():\n                    old_prefix, new_prefix = Path(old_prefix), Path(new_prefix)\n\n                    if type(video.filename) == list:\n                        new_fns = []\n                        for fn in video.filename:\n                            fn = Path(fn)\n                            if fn.as_posix().startswith(old_prefix.as_posix()):\n                                new_fns.append(new_prefix / fn.relative_to(old_prefix))\n                            else:\n                                new_fns.append(fn)\n                        video.replace_filename(new_fns)\n                    else:\n                        fn = Path(video.filename)\n                        if fn.as_posix().startswith(old_prefix.as_posix()):\n                            video.replace_filename(\n                                new_prefix / fn.relative_to(old_prefix)\n                            )\n\n    def split(self, n: int | float, seed: int | None = None) -&gt; tuple[Labels, Labels]:\n        \"\"\"Separate the labels into random splits.\n\n        Args:\n            n: Size of the first split. If integer &gt;= 1, assumes that this is the number\n                of labeled frames in the first split. If &lt; 1.0, this will be treated as\n                a fraction of the total labeled frames.\n            seed: Optional integer seed to use for reproducibility.\n\n        Returns:\n            A tuple of `split1, split2`.\n\n            If an integer was specified, `len(split1) == n`.\n\n            If a fraction was specified, `len(split1) == int(n * len(labels))`.\n\n            The second split contains the remainder, i.e.,\n            `len(split2) == len(labels) - len(split1)`.\n\n            If there are too few frames, a minimum of 1 frame will be kept in the second\n            split.\n\n            If there is exactly 1 labeled frame in the labels, the same frame will be\n            assigned to both splits.\n        \"\"\"\n        n0 = len(self)\n        if n0 == 0:\n            return self, self\n        n1 = n\n        if n &lt; 1.0:\n            n1 = max(int(n0 * float(n)), 1)\n        n2 = max(n0 - n1, 1)\n        n1, n2 = int(n1), int(n2)\n\n        rng = np.random.default_rng(seed=seed)\n        inds1 = rng.choice(n0, size=(n1,), replace=False)\n\n        if n0 == 1:\n            inds2 = np.array([0])\n        else:\n            inds2 = np.setdiff1d(np.arange(n0), inds1)\n\n        split1, split2 = self[inds1], self[inds2]\n        split1, split2 = deepcopy(split1), deepcopy(split2)\n        split1, split2 = Labels(split1), Labels(split2)\n\n        split1.provenance = self.provenance\n        split2.provenance = self.provenance\n        split1.provenance[\"source_labels\"] = self.provenance.get(\"filename\", None)\n        split2.provenance[\"source_labels\"] = self.provenance.get(\"filename\", None)\n\n        return split1, split2\n\n    def make_training_splits(\n        self,\n        n_train: int | float,\n        n_val: int | float | None = None,\n        n_test: int | float | None = None,\n        save_dir: str | Path | None = None,\n        seed: int | None = None,\n    ) -&gt; tuple[Labels, Labels] | tuple[Labels, Labels, Labels]:\n        \"\"\"Make splits for training with embedded images.\n\n        Args:\n            n_train: Size of the training split as integer or fraction.\n            n_val: Size of the validation split as integer or fraction. If `None`,\n                this will be inferred based on the values of `n_train` and `n_test`. If\n                `n_test` is `None`, this will be the remainder of the data after the\n                training split.\n            n_test: Size of the testing split as integer or fraction. If `None`, the\n                test split will not be saved.\n            save_dir: If specified, save splits to SLP files with embedded images.\n            seed: Optional integer seed to use for reproducibility.\n\n        Returns:\n            A tuple of `labels_train, labels_val` or\n            `labels_train, labels_val, labels_test` if `n_test` was specified.\n\n        Notes:\n            Predictions and suggestions will be removed before saving, leaving only\n            frames with user labeled data (the source labels are not affected).\n\n            Frames with user labeled data will be embedded in the resulting files.\n\n            If `save_dir` is specified, this will save the randomly sampled splits to:\n\n                - `{save_dir}/train.pkg.slp`\n                - `{save_dir}/val.pkg.slp`\n                - `{save_dir}/test.pkg.slp` (if `n_test` is specified)\n\n        See also: `Labels.split`\n        \"\"\"\n        # Clean up labels.\n        labels = deepcopy(self)\n        labels.remove_predictions()\n        labels.suggestions = []\n        labels.clean()\n\n        # Make splits.\n        labels_train, labels_rest = labels.split(n_train, seed=seed)\n        if n_test is not None:\n            if n_test &lt; 1:\n                n_test = (n_test * len(labels)) / len(labels_rest)\n            labels_test, labels_rest = labels_rest.split(n=n_test, seed=seed)\n        if n_val is not None:\n            if n_val &lt; 1:\n                n_val = (n_val * len(labels)) / len(labels_rest)\n            labels_val, _ = labels_rest.split(n=n_val, seed=seed)\n        else:\n            labels_val = labels_rest\n\n        # Save.\n        if save_dir is not None:\n            save_dir = Path(save_dir)\n            save_dir.mkdir(exist_ok=True, parents=True)\n\n            labels_train.save(save_dir / \"train.pkg.slp\", embed=\"user\")\n            labels_val.save(save_dir / \"val.pkg.slp\", embed=\"user\")\n            labels_test.save(save_dir / \"test.pkg.slp\", embed=\"user\")\n\n        if n_test is None:\n            return labels_train, labels_val\n        else:\n            return labels_train, labels_val, labels_test\n</code></pre>"},{"location":"reference/sleap_io/model/labels/#sleap_io.model.labels.Labels.skeleton","title":"<code>skeleton: Skeleton</code>  <code>property</code>","text":"<p>Return the skeleton if there is only a single skeleton in the labels.</p>"},{"location":"reference/sleap_io/model/labels/#sleap_io.model.labels.Labels.user_labeled_frames","title":"<code>user_labeled_frames: list[LabeledFrame]</code>  <code>property</code>","text":"<p>Return all labeled frames with user (non-predicted) instances.</p>"},{"location":"reference/sleap_io/model/labels/#sleap_io.model.labels.Labels.video","title":"<code>video: Video</code>  <code>property</code>","text":"<p>Return the video if there is only a single video in the labels.</p>"},{"location":"reference/sleap_io/model/labels/#sleap_io.model.labels.Labels.__attrs_post_init__","title":"<code>__attrs_post_init__()</code>","text":"<p>Append videos, skeletons, and tracks seen in <code>labeled_frames</code> to <code>Labels</code>.</p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def __attrs_post_init__(self):\n    \"\"\"Append videos, skeletons, and tracks seen in `labeled_frames` to `Labels`.\"\"\"\n    self.update()\n</code></pre>"},{"location":"reference/sleap_io/model/labels/#sleap_io.model.labels.Labels.__getitem__","title":"<code>__getitem__(key)</code>","text":"<p>Return one or more labeled frames based on indexing criteria.</p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def __getitem__(\n    self, key: int | slice | list[int] | np.ndarray | tuple[Video, int]\n) -&gt; list[LabeledFrame] | LabeledFrame:\n    \"\"\"Return one or more labeled frames based on indexing criteria.\"\"\"\n    if type(key) == int:\n        return self.labeled_frames[key]\n    elif type(key) == slice:\n        return [self.labeled_frames[i] for i in range(*key.indices(len(self)))]\n    elif type(key) == list:\n        return [self.labeled_frames[i] for i in key]\n    elif isinstance(key, np.ndarray):\n        return [self.labeled_frames[i] for i in key.tolist()]\n    elif type(key) == tuple and len(key) == 2:\n        video, frame_idx = key\n        res = self.find(video, frame_idx)\n        if len(res) == 1:\n            return res[0]\n        elif len(res) == 0:\n            raise IndexError(\n                f\"No labeled frames found for video {video} and \"\n                f\"frame index {frame_idx}.\"\n            )\n    elif type(key) == Video:\n        res = self.find(key)\n        if len(res) == 0:\n            raise IndexError(f\"No labeled frames found for video {key}.\")\n        return res\n    else:\n        raise IndexError(f\"Invalid indexing argument for labels: {key}\")\n</code></pre>"},{"location":"reference/sleap_io/model/labels/#sleap_io.model.labels.Labels.__iter__","title":"<code>__iter__()</code>","text":"<p>Iterate over <code>labeled_frames</code> list when calling iter method on <code>Labels</code>.</p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def __iter__(self):\n    \"\"\"Iterate over `labeled_frames` list when calling iter method on `Labels`.\"\"\"\n    return iter(self.labeled_frames)\n</code></pre>"},{"location":"reference/sleap_io/model/labels/#sleap_io.model.labels.Labels.__len__","title":"<code>__len__()</code>","text":"<p>Return number of labeled frames.</p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"Return number of labeled frames.\"\"\"\n    return len(self.labeled_frames)\n</code></pre>"},{"location":"reference/sleap_io/model/labels/#sleap_io.model.labels.Labels.__repr__","title":"<code>__repr__()</code>","text":"<p>Return a readable representation of the labels.</p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return a readable representation of the labels.\"\"\"\n    return (\n        \"Labels(\"\n        f\"labeled_frames={len(self.labeled_frames)}, \"\n        f\"videos={len(self.videos)}, \"\n        f\"skeletons={len(self.skeletons)}, \"\n        f\"tracks={len(self.tracks)}, \"\n        f\"suggestions={len(self.suggestions)}\"\n        \")\"\n    )\n</code></pre>"},{"location":"reference/sleap_io/model/labels/#sleap_io.model.labels.Labels.__str__","title":"<code>__str__()</code>","text":"<p>Return a readable representation of the labels.</p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return a readable representation of the labels.\"\"\"\n    return self.__repr__()\n</code></pre>"},{"location":"reference/sleap_io/model/labels/#sleap_io.model.labels.Labels.append","title":"<code>append(lf, update=True)</code>","text":"<p>Append a labeled frame to the labels.</p> <p>Parameters:</p> Name Type Description Default <code>lf</code> <code>LabeledFrame</code> <p>A labeled frame to add to the labels.</p> required <code>update</code> <code>bool</code> <p>If <code>True</code> (the default), update list of videos, tracks and skeletons from the contents.</p> <code>True</code> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def append(self, lf: LabeledFrame, update: bool = True):\n    \"\"\"Append a labeled frame to the labels.\n\n    Args:\n        lf: A labeled frame to add to the labels.\n        update: If `True` (the default), update list of videos, tracks and\n            skeletons from the contents.\n    \"\"\"\n    self.labeled_frames.append(lf)\n\n    if update:\n        if lf.video not in self.videos:\n            self.videos.append(lf.video)\n\n        for inst in lf:\n            if inst.skeleton not in self.skeletons:\n                self.skeletons.append(inst.skeleton)\n\n            if inst.track is not None and inst.track not in self.tracks:\n                self.tracks.append(inst.track)\n</code></pre>"},{"location":"reference/sleap_io/model/labels/#sleap_io.model.labels.Labels.clean","title":"<code>clean(frames=True, empty_instances=False, skeletons=True, tracks=True, videos=False)</code>","text":"<p>Remove empty frames, unused skeletons, tracks and videos.</p> <p>Parameters:</p> Name Type Description Default <code>frames</code> <code>bool</code> <p>If <code>True</code> (the default), remove empty frames.</p> <code>True</code> <code>empty_instances</code> <code>bool</code> <p>If <code>True</code> (NOT default), remove instances that have no visible points.</p> <code>False</code> <code>skeletons</code> <code>bool</code> <p>If <code>True</code> (the default), remove unused skeletons.</p> <code>True</code> <code>tracks</code> <code>bool</code> <p>If <code>True</code> (the default), remove unused tracks.</p> <code>True</code> <code>videos</code> <code>bool</code> <p>If <code>True</code> (NOT default), remove videos that have no labeled frames.</p> <code>False</code> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def clean(\n    self,\n    frames: bool = True,\n    empty_instances: bool = False,\n    skeletons: bool = True,\n    tracks: bool = True,\n    videos: bool = False,\n):\n    \"\"\"Remove empty frames, unused skeletons, tracks and videos.\n\n    Args:\n        frames: If `True` (the default), remove empty frames.\n        empty_instances: If `True` (NOT default), remove instances that have no\n            visible points.\n        skeletons: If `True` (the default), remove unused skeletons.\n        tracks: If `True` (the default), remove unused tracks.\n        videos: If `True` (NOT default), remove videos that have no labeled frames.\n    \"\"\"\n    used_skeletons = []\n    used_tracks = []\n    used_videos = []\n    kept_frames = []\n    for lf in self.labeled_frames:\n\n        if empty_instances:\n            lf.remove_empty_instances()\n\n        if frames and len(lf) == 0:\n            continue\n\n        if videos and lf.video not in used_videos:\n            used_videos.append(lf.video)\n\n        if skeletons or tracks:\n            for inst in lf:\n                if skeletons and inst.skeleton not in used_skeletons:\n                    used_skeletons.append(inst.skeleton)\n                if (\n                    tracks\n                    and inst.track is not None\n                    and inst.track not in used_tracks\n                ):\n                    used_tracks.append(inst.track)\n\n        if frames:\n            kept_frames.append(lf)\n\n    if videos:\n        self.videos = [video for video in self.videos if video in used_videos]\n\n    if skeletons:\n        self.skeletons = [\n            skeleton for skeleton in self.skeletons if skeleton in used_skeletons\n        ]\n\n    if tracks:\n        self.tracks = [track for track in self.tracks if track in used_tracks]\n\n    if frames:\n        self.labeled_frames = kept_frames\n</code></pre>"},{"location":"reference/sleap_io/model/labels/#sleap_io.model.labels.Labels.extend","title":"<code>extend(lfs, update=True)</code>","text":"<p>Append a labeled frame to the labels.</p> <p>Parameters:</p> Name Type Description Default <code>lfs</code> <code>list[LabeledFrame]</code> <p>A list of labeled frames to add to the labels.</p> required <code>update</code> <code>bool</code> <p>If <code>True</code> (the default), update list of videos, tracks and skeletons from the contents.</p> <code>True</code> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def extend(self, lfs: list[LabeledFrame], update: bool = True):\n    \"\"\"Append a labeled frame to the labels.\n\n    Args:\n        lfs: A list of labeled frames to add to the labels.\n        update: If `True` (the default), update list of videos, tracks and\n            skeletons from the contents.\n    \"\"\"\n    self.labeled_frames.extend(lfs)\n\n    if update:\n        for lf in lfs:\n            if lf.video not in self.videos:\n                self.videos.append(lf.video)\n\n            for inst in lf:\n                if inst.skeleton not in self.skeletons:\n                    self.skeletons.append(inst.skeleton)\n\n                if inst.track is not None and inst.track not in self.tracks:\n                    self.tracks.append(inst.track)\n</code></pre>"},{"location":"reference/sleap_io/model/labels/#sleap_io.model.labels.Labels.find","title":"<code>find(video, frame_idx=None, return_new=False)</code>","text":"<p>Search for labeled frames given video and/or frame index.</p> <p>Parameters:</p> Name Type Description Default <code>video</code> <code>Video</code> <p>A <code>Video</code> that is associated with the project.</p> required <code>frame_idx</code> <code>int | list[int] | None</code> <p>The frame index (or indices) which we want to find in the video. If a range is specified, we'll return all frames with indices in that range. If not specific, then we'll return all labeled frames for video.</p> <code>None</code> <code>return_new</code> <code>bool</code> <p>Whether to return singleton of new and empty <code>LabeledFrame</code> if none are found in project.</p> <code>False</code> <p>Returns:</p> Type Description <code>list[LabeledFrame]</code> <p>List of <code>LabeledFrame</code> objects that match the criteria.</p> <p>The list will be empty if no matches found, unless return_new is True, in which case it contains new (empty) <code>LabeledFrame</code> objects with <code>video</code> and <code>frame_index</code> set.</p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def find(\n    self,\n    video: Video,\n    frame_idx: int | list[int] | None = None,\n    return_new: bool = False,\n) -&gt; list[LabeledFrame]:\n    \"\"\"Search for labeled frames given video and/or frame index.\n\n    Args:\n        video: A `Video` that is associated with the project.\n        frame_idx: The frame index (or indices) which we want to find in the video.\n            If a range is specified, we'll return all frames with indices in that\n            range. If not specific, then we'll return all labeled frames for video.\n        return_new: Whether to return singleton of new and empty `LabeledFrame` if\n            none are found in project.\n\n    Returns:\n        List of `LabeledFrame` objects that match the criteria.\n\n        The list will be empty if no matches found, unless return_new is True, in\n        which case it contains new (empty) `LabeledFrame` objects with `video` and\n        `frame_index` set.\n    \"\"\"\n    results = []\n\n    if frame_idx is None:\n        for lf in self.labeled_frames:\n            if lf.video == video:\n                results.append(lf)\n        return results\n\n    if np.isscalar(frame_idx):\n        frame_idx = np.array(frame_idx).reshape(-1)\n\n    for frame_ind in frame_idx:\n        result = None\n        for lf in self.labeled_frames:\n            if lf.video == video and lf.frame_idx == frame_ind:\n                result = lf\n                results.append(result)\n                break\n        if result is None and return_new:\n            results.append(LabeledFrame(video=video, frame_idx=frame_ind))\n\n    return results\n</code></pre>"},{"location":"reference/sleap_io/model/labels/#sleap_io.model.labels.Labels.make_training_splits","title":"<code>make_training_splits(n_train, n_val=None, n_test=None, save_dir=None, seed=None)</code>","text":"<p>Make splits for training with embedded images.</p> <p>Parameters:</p> Name Type Description Default <code>n_train</code> <code>int | float</code> <p>Size of the training split as integer or fraction.</p> required <code>n_val</code> <code>int | float | None</code> <p>Size of the validation split as integer or fraction. If <code>None</code>, this will be inferred based on the values of <code>n_train</code> and <code>n_test</code>. If <code>n_test</code> is <code>None</code>, this will be the remainder of the data after the training split.</p> <code>None</code> <code>n_test</code> <code>int | float | None</code> <p>Size of the testing split as integer or fraction. If <code>None</code>, the test split will not be saved.</p> <code>None</code> <code>save_dir</code> <code>str | Path | None</code> <p>If specified, save splits to SLP files with embedded images.</p> <code>None</code> <code>seed</code> <code>int | None</code> <p>Optional integer seed to use for reproducibility.</p> <code>None</code> <p>Returns:</p> Type Description <code>tuple[Labels, Labels] | tuple[Labels, Labels, Labels]</code> <p>A tuple of <code>labels_train, labels_val</code> or <code>labels_train, labels_val, labels_test</code> if <code>n_test</code> was specified.</p> Notes <p>Predictions and suggestions will be removed before saving, leaving only frames with user labeled data (the source labels are not affected).</p> <p>Frames with user labeled data will be embedded in the resulting files.</p> <p>If <code>save_dir</code> is specified, this will save the randomly sampled splits to:</p> <pre><code>- `{save_dir}/train.pkg.slp`\n- `{save_dir}/val.pkg.slp`\n- `{save_dir}/test.pkg.slp` (if `n_test` is specified)\n</code></pre> <p>See also: <code>Labels.split</code></p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def make_training_splits(\n    self,\n    n_train: int | float,\n    n_val: int | float | None = None,\n    n_test: int | float | None = None,\n    save_dir: str | Path | None = None,\n    seed: int | None = None,\n) -&gt; tuple[Labels, Labels] | tuple[Labels, Labels, Labels]:\n    \"\"\"Make splits for training with embedded images.\n\n    Args:\n        n_train: Size of the training split as integer or fraction.\n        n_val: Size of the validation split as integer or fraction. If `None`,\n            this will be inferred based on the values of `n_train` and `n_test`. If\n            `n_test` is `None`, this will be the remainder of the data after the\n            training split.\n        n_test: Size of the testing split as integer or fraction. If `None`, the\n            test split will not be saved.\n        save_dir: If specified, save splits to SLP files with embedded images.\n        seed: Optional integer seed to use for reproducibility.\n\n    Returns:\n        A tuple of `labels_train, labels_val` or\n        `labels_train, labels_val, labels_test` if `n_test` was specified.\n\n    Notes:\n        Predictions and suggestions will be removed before saving, leaving only\n        frames with user labeled data (the source labels are not affected).\n\n        Frames with user labeled data will be embedded in the resulting files.\n\n        If `save_dir` is specified, this will save the randomly sampled splits to:\n\n            - `{save_dir}/train.pkg.slp`\n            - `{save_dir}/val.pkg.slp`\n            - `{save_dir}/test.pkg.slp` (if `n_test` is specified)\n\n    See also: `Labels.split`\n    \"\"\"\n    # Clean up labels.\n    labels = deepcopy(self)\n    labels.remove_predictions()\n    labels.suggestions = []\n    labels.clean()\n\n    # Make splits.\n    labels_train, labels_rest = labels.split(n_train, seed=seed)\n    if n_test is not None:\n        if n_test &lt; 1:\n            n_test = (n_test * len(labels)) / len(labels_rest)\n        labels_test, labels_rest = labels_rest.split(n=n_test, seed=seed)\n    if n_val is not None:\n        if n_val &lt; 1:\n            n_val = (n_val * len(labels)) / len(labels_rest)\n        labels_val, _ = labels_rest.split(n=n_val, seed=seed)\n    else:\n        labels_val = labels_rest\n\n    # Save.\n    if save_dir is not None:\n        save_dir = Path(save_dir)\n        save_dir.mkdir(exist_ok=True, parents=True)\n\n        labels_train.save(save_dir / \"train.pkg.slp\", embed=\"user\")\n        labels_val.save(save_dir / \"val.pkg.slp\", embed=\"user\")\n        labels_test.save(save_dir / \"test.pkg.slp\", embed=\"user\")\n\n    if n_test is None:\n        return labels_train, labels_val\n    else:\n        return labels_train, labels_val, labels_test\n</code></pre>"},{"location":"reference/sleap_io/model/labels/#sleap_io.model.labels.Labels.numpy","title":"<code>numpy(video=None, all_frames=True, untracked=False, return_confidence=False)</code>","text":"<p>Construct a numpy array from instance points.</p> <p>Parameters:</p> Name Type Description Default <code>video</code> <code>Optional[Union[Video, int]]</code> <p>Video or video index to convert to numpy arrays. If <code>None</code> (the default), uses the first video.</p> <code>None</code> <code>untracked</code> <code>bool</code> <p>If <code>False</code> (the default), include only instances that have a track assignment. If <code>True</code>, includes all instances in each frame in arbitrary order.</p> <code>False</code> <code>return_confidence</code> <code>bool</code> <p>If <code>False</code> (the default), only return points of nodes. If <code>True</code>, return the points and scores of nodes.</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>An array of tracks of shape <code>(n_frames, n_tracks, n_nodes, 2)</code> if <code>return_confidence</code> is <code>False</code>. Otherwise returned shape is <code>(n_frames, n_tracks, n_nodes, 3)</code> if <code>return_confidence</code> is <code>True</code>.</p> <p>Missing data will be replaced with <code>np.nan</code>.</p> <p>If this is a single instance project, a track does not need to be assigned.</p> <p>Only predicted instances (NOT user instances) will be returned.</p> Notes <p>This method assumes that instances have tracks assigned and is intended to function primarily for single-video prediction results.</p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def numpy(\n    self,\n    video: Optional[Union[Video, int]] = None,\n    all_frames: bool = True,\n    untracked: bool = False,\n    return_confidence: bool = False,\n) -&gt; np.ndarray:\n    \"\"\"Construct a numpy array from instance points.\n\n    Args:\n        video: Video or video index to convert to numpy arrays. If `None` (the\n            default), uses the first video.\n        untracked: If `False` (the default), include only instances that have a\n            track assignment. If `True`, includes all instances in each frame in\n            arbitrary order.\n        return_confidence: If `False` (the default), only return points of nodes. If\n            `True`, return the points and scores of nodes.\n\n    Returns:\n        An array of tracks of shape `(n_frames, n_tracks, n_nodes, 2)` if\n        `return_confidence` is `False`. Otherwise returned shape is\n        `(n_frames, n_tracks, n_nodes, 3)` if `return_confidence` is `True`.\n\n        Missing data will be replaced with `np.nan`.\n\n        If this is a single instance project, a track does not need to be assigned.\n\n        Only predicted instances (NOT user instances) will be returned.\n\n    Notes:\n        This method assumes that instances have tracks assigned and is intended to\n        function primarily for single-video prediction results.\n    \"\"\"\n    # Get labeled frames for specified video.\n    if video is None:\n        video = 0\n    if type(video) == int:\n        video = self.videos[video]\n    lfs = [lf for lf in self.labeled_frames if lf.video == video]\n\n    # Figure out frame index range.\n    first_frame, last_frame = 0, 0\n    for lf in lfs:\n        first_frame = min(first_frame, lf.frame_idx)\n        last_frame = max(last_frame, lf.frame_idx)\n\n    # Figure out the number of tracks based on number of instances in each frame.\n    # First, let's check the max number of predicted instances (regardless of\n    # whether they're tracked.\n    n_preds = 0\n    for lf in lfs:\n        n_pred_instances = len(lf.predicted_instances)\n        n_preds = max(n_preds, n_pred_instances)\n\n    # Case 1: We don't care about order because there's only 1 instance per frame,\n    # or we're considering untracked instances.\n    untracked = untracked or n_preds == 1\n    if untracked:\n        n_tracks = n_preds\n    else:\n        # Case 2: We're considering only tracked instances.\n        n_tracks = len(self.tracks)\n\n    n_frames = int(last_frame - first_frame + 1)\n    skeleton = self.skeletons[-1]  # Assume project only uses last skeleton\n    n_nodes = len(skeleton.nodes)\n\n    if return_confidence:\n        tracks = np.full((n_frames, n_tracks, n_nodes, 3), np.nan, dtype=\"float32\")\n    else:\n        tracks = np.full((n_frames, n_tracks, n_nodes, 2), np.nan, dtype=\"float32\")\n    for lf in lfs:\n        i = int(lf.frame_idx - first_frame)\n        if untracked:\n            for j, inst in enumerate(lf.predicted_instances):\n                tracks[i, j] = inst.numpy(scores=return_confidence)\n        else:\n            tracked_instances = [\n                inst\n                for inst in lf.instances\n                if type(inst) == PredictedInstance and inst.track is not None\n            ]\n            for inst in tracked_instances:\n                j = self.tracks.index(inst.track)  # type: ignore[arg-type]\n                tracks[i, j] = inst.numpy(scores=return_confidence)\n\n    return tracks\n</code></pre>"},{"location":"reference/sleap_io/model/labels/#sleap_io.model.labels.Labels.remove_predictions","title":"<code>remove_predictions(clean=True)</code>","text":"<p>Remove all predicted instances from the labels.</p> <p>Parameters:</p> Name Type Description Default <code>clean</code> <code>bool</code> <p>If <code>True</code> (the default), also remove any empty frames and unused tracks and skeletons. It does NOT remove videos that have no labeled frames or instances with no visible points.</p> <code>True</code> <p>See also: <code>Labels.clean</code></p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def remove_predictions(self, clean: bool = True):\n    \"\"\"Remove all predicted instances from the labels.\n\n    Args:\n        clean: If `True` (the default), also remove any empty frames and unused\n            tracks and skeletons. It does NOT remove videos that have no labeled\n            frames or instances with no visible points.\n\n    See also: `Labels.clean`\n    \"\"\"\n    for lf in self.labeled_frames:\n        lf.remove_predictions()\n\n    if clean:\n        self.clean(\n            frames=True,\n            empty_instances=False,\n            skeletons=True,\n            tracks=True,\n            videos=False,\n        )\n</code></pre>"},{"location":"reference/sleap_io/model/labels/#sleap_io.model.labels.Labels.replace_filenames","title":"<code>replace_filenames(new_filenames=None, filename_map=None, prefix_map=None)</code>","text":"<p>Replace video filenames.</p> <p>Parameters:</p> Name Type Description Default <code>new_filenames</code> <code>list[str | Path] | None</code> <p>List of new filenames. Must have the same length as the number of videos in the labels.</p> <code>None</code> <code>filename_map</code> <code>dict[str | Path, str | Path] | None</code> <p>Dictionary mapping old filenames (keys) to new filenames (values).</p> <code>None</code> <code>prefix_map</code> <code>dict[str | Path, str | Path] | None</code> <p>Dictonary mapping old prefixes (keys) to new prefixes (values).</p> <code>None</code> Notes <p>Only one of the argument types can be provided.</p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def replace_filenames(\n    self,\n    new_filenames: list[str | Path] | None = None,\n    filename_map: dict[str | Path, str | Path] | None = None,\n    prefix_map: dict[str | Path, str | Path] | None = None,\n):\n    \"\"\"Replace video filenames.\n\n    Args:\n        new_filenames: List of new filenames. Must have the same length as the\n            number of videos in the labels.\n        filename_map: Dictionary mapping old filenames (keys) to new filenames\n            (values).\n        prefix_map: Dictonary mapping old prefixes (keys) to new prefixes (values).\n\n    Notes:\n        Only one of the argument types can be provided.\n    \"\"\"\n    n = 0\n    if new_filenames is not None:\n        n += 1\n    if filename_map is not None:\n        n += 1\n    if prefix_map is not None:\n        n += 1\n    if n != 1:\n        raise ValueError(\n            \"Exactly one input method must be provided to replace filenames.\"\n        )\n\n    if new_filenames is not None:\n        if len(self.videos) != len(new_filenames):\n            raise ValueError(\n                f\"Number of new filenames ({len(new_filenames)}) does not match \"\n                f\"the number of videos ({len(self.videos)}).\"\n            )\n\n        for video, new_filename in zip(self.videos, new_filenames):\n            video.replace_filename(new_filename)\n\n    elif filename_map is not None:\n        for video in self.videos:\n            for old_fn, new_fn in filename_map.items():\n                if type(video.filename) == list:\n                    new_fns = []\n                    for fn in video.filename:\n                        if Path(fn) == Path(old_fn):\n                            new_fns.append(new_fn)\n                        else:\n                            new_fns.append(fn)\n                    video.replace_filename(new_fns)\n                else:\n                    if Path(video.filename) == Path(old_fn):\n                        video.replace_filename(new_fn)\n\n    elif prefix_map is not None:\n        for video in self.videos:\n            for old_prefix, new_prefix in prefix_map.items():\n                old_prefix, new_prefix = Path(old_prefix), Path(new_prefix)\n\n                if type(video.filename) == list:\n                    new_fns = []\n                    for fn in video.filename:\n                        fn = Path(fn)\n                        if fn.as_posix().startswith(old_prefix.as_posix()):\n                            new_fns.append(new_prefix / fn.relative_to(old_prefix))\n                        else:\n                            new_fns.append(fn)\n                    video.replace_filename(new_fns)\n                else:\n                    fn = Path(video.filename)\n                    if fn.as_posix().startswith(old_prefix.as_posix()):\n                        video.replace_filename(\n                            new_prefix / fn.relative_to(old_prefix)\n                        )\n</code></pre>"},{"location":"reference/sleap_io/model/labels/#sleap_io.model.labels.Labels.replace_videos","title":"<code>replace_videos(old_videos=None, new_videos=None, video_map=None)</code>","text":"<p>Replace videos and update all references.</p> <p>Parameters:</p> Name Type Description Default <code>old_videos</code> <code>list[Video] | None</code> <p>List of videos to be replaced.</p> <code>None</code> <code>new_videos</code> <code>list[Video] | None</code> <p>List of videos to replace with.</p> <code>None</code> <code>video_map</code> <code>dict[Video, Video] | None</code> <p>Alternative input of dictionary where keys are the old videos and values are the new videos.</p> <code>None</code> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def replace_videos(\n    self,\n    old_videos: list[Video] | None = None,\n    new_videos: list[Video] | None = None,\n    video_map: dict[Video, Video] | None = None,\n):\n    \"\"\"Replace videos and update all references.\n\n    Args:\n        old_videos: List of videos to be replaced.\n        new_videos: List of videos to replace with.\n        video_map: Alternative input of dictionary where keys are the old videos and\n            values are the new videos.\n    \"\"\"\n    if video_map is None:\n        video_map = {o: n for o, n in zip(old_videos, new_videos)}\n\n    # Update the labeled frames with the new videos.\n    for lf in self.labeled_frames:\n        if lf.video in video_map:\n            lf.video = video_map[lf.video]\n\n    # Update suggestions with the new videos.\n    for sf in self.suggestions:\n        if sf.video in video_map:\n            sf.video = video_map[sf.video]\n</code></pre>"},{"location":"reference/sleap_io/model/labels/#sleap_io.model.labels.Labels.save","title":"<code>save(filename, format=None, embed=None, **kwargs)</code>","text":"<p>Save labels to file in specified format.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>Path to save labels to.</p> required <code>format</code> <code>Optional[str]</code> <p>The format to save the labels in. If <code>None</code>, the format will be inferred from the file extension. Available formats are <code>\"slp\"</code>, <code>\"nwb\"</code>, <code>\"labelstudio\"</code>, and <code>\"jabs\"</code>.</p> <code>None</code> <code>embed</code> <code>bool | str | list[tuple[Video, int]] | None</code> <p>Frames to embed in the saved labels file. One of <code>None</code>, <code>True</code>, <code>\"all\"</code>, <code>\"user\"</code>, <code>\"suggestions\"</code>, <code>\"user+suggestions\"</code>, <code>\"source\"</code> or list of tuples of <code>(video, frame_idx)</code>.</p> <p>If <code>None</code> is specified (the default) and the labels contains embedded frames, those embedded frames will be re-saved to the new file.</p> <p>If <code>True</code> or <code>\"all\"</code>, all labeled frames and suggested frames will be embedded.</p> <p>If <code>\"source\"</code> is specified, no images will be embedded and the source video will be restored if available.</p> <p>This argument is only valid for the SLP backend.</p> <code>None</code> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def save(\n    self,\n    filename: str,\n    format: Optional[str] = None,\n    embed: bool | str | list[tuple[Video, int]] | None = None,\n    **kwargs,\n):\n    \"\"\"Save labels to file in specified format.\n\n    Args:\n        filename: Path to save labels to.\n        format: The format to save the labels in. If `None`, the format will be\n            inferred from the file extension. Available formats are `\"slp\"`,\n            `\"nwb\"`, `\"labelstudio\"`, and `\"jabs\"`.\n        embed: Frames to embed in the saved labels file. One of `None`, `True`,\n            `\"all\"`, `\"user\"`, `\"suggestions\"`, `\"user+suggestions\"`, `\"source\"` or\n            list of tuples of `(video, frame_idx)`.\n\n            If `None` is specified (the default) and the labels contains embedded\n            frames, those embedded frames will be re-saved to the new file.\n\n            If `True` or `\"all\"`, all labeled frames and suggested frames will be\n            embedded.\n\n            If `\"source\"` is specified, no images will be embedded and the source\n            video will be restored if available.\n\n            This argument is only valid for the SLP backend.\n    \"\"\"\n    from sleap_io import save_file\n\n    save_file(self, filename, format=format, embed=embed, **kwargs)\n</code></pre>"},{"location":"reference/sleap_io/model/labels/#sleap_io.model.labels.Labels.split","title":"<code>split(n, seed=None)</code>","text":"<p>Separate the labels into random splits.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int | float</code> <p>Size of the first split. If integer &gt;= 1, assumes that this is the number of labeled frames in the first split. If &lt; 1.0, this will be treated as a fraction of the total labeled frames.</p> required <code>seed</code> <code>int | None</code> <p>Optional integer seed to use for reproducibility.</p> <code>None</code> <p>Returns:</p> Type Description <code>tuple[Labels, Labels]</code> <p>A tuple of <code>split1, split2</code>.</p> <p>If an integer was specified, <code>len(split1) == n</code>.</p> <p>If a fraction was specified, <code>len(split1) == int(n * len(labels))</code>.</p> <p>The second split contains the remainder, i.e., <code>len(split2) == len(labels) - len(split1)</code>.</p> <p>If there are too few frames, a minimum of 1 frame will be kept in the second split.</p> <p>If there is exactly 1 labeled frame in the labels, the same frame will be assigned to both splits.</p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def split(self, n: int | float, seed: int | None = None) -&gt; tuple[Labels, Labels]:\n    \"\"\"Separate the labels into random splits.\n\n    Args:\n        n: Size of the first split. If integer &gt;= 1, assumes that this is the number\n            of labeled frames in the first split. If &lt; 1.0, this will be treated as\n            a fraction of the total labeled frames.\n        seed: Optional integer seed to use for reproducibility.\n\n    Returns:\n        A tuple of `split1, split2`.\n\n        If an integer was specified, `len(split1) == n`.\n\n        If a fraction was specified, `len(split1) == int(n * len(labels))`.\n\n        The second split contains the remainder, i.e.,\n        `len(split2) == len(labels) - len(split1)`.\n\n        If there are too few frames, a minimum of 1 frame will be kept in the second\n        split.\n\n        If there is exactly 1 labeled frame in the labels, the same frame will be\n        assigned to both splits.\n    \"\"\"\n    n0 = len(self)\n    if n0 == 0:\n        return self, self\n    n1 = n\n    if n &lt; 1.0:\n        n1 = max(int(n0 * float(n)), 1)\n    n2 = max(n0 - n1, 1)\n    n1, n2 = int(n1), int(n2)\n\n    rng = np.random.default_rng(seed=seed)\n    inds1 = rng.choice(n0, size=(n1,), replace=False)\n\n    if n0 == 1:\n        inds2 = np.array([0])\n    else:\n        inds2 = np.setdiff1d(np.arange(n0), inds1)\n\n    split1, split2 = self[inds1], self[inds2]\n    split1, split2 = deepcopy(split1), deepcopy(split2)\n    split1, split2 = Labels(split1), Labels(split2)\n\n    split1.provenance = self.provenance\n    split2.provenance = self.provenance\n    split1.provenance[\"source_labels\"] = self.provenance.get(\"filename\", None)\n    split2.provenance[\"source_labels\"] = self.provenance.get(\"filename\", None)\n\n    return split1, split2\n</code></pre>"},{"location":"reference/sleap_io/model/labels/#sleap_io.model.labels.Labels.update","title":"<code>update()</code>","text":"<p>Update data structures based on contents.</p> <p>This function will update the list of skeletons, videos and tracks from the labeled frames, instances and suggestions.</p> Source code in <code>sleap_io/model/labels.py</code> <pre><code>def update(self):\n    \"\"\"Update data structures based on contents.\n\n    This function will update the list of skeletons, videos and tracks from the\n    labeled frames, instances and suggestions.\n    \"\"\"\n    for lf in self.labeled_frames:\n        if lf.video not in self.videos:\n            self.videos.append(lf.video)\n\n        for inst in lf:\n            if inst.skeleton not in self.skeletons:\n                self.skeletons.append(inst.skeleton)\n\n            if inst.track is not None and inst.track not in self.tracks:\n                self.tracks.append(inst.track)\n\n    for sf in self.suggestions:\n        if sf.video not in self.videos:\n            self.videos.append(sf.video)\n</code></pre>"},{"location":"reference/sleap_io/model/skeleton/","title":"skeleton","text":""},{"location":"reference/sleap_io/model/skeleton/#sleap_io.model.skeleton","title":"<code>sleap_io.model.skeleton</code>","text":"<p>Data model for skeletons.</p> <p>Skeletons are collections of nodes and edges which describe the landmarks associated with a pose model. The edges represent the connections between them and may be used differently depending on the underlying pose model.</p>"},{"location":"reference/sleap_io/model/skeleton/#sleap_io.model.skeleton.Edge","title":"<code>Edge</code>","text":"<p>A connection between two <code>Node</code> objects within a <code>Skeleton</code>.</p> <p>This is a directed edge, representing the ordering of <code>Node</code>s in the <code>Skeleton</code> tree.</p> <p>Attributes:</p> Name Type Description <code>source</code> <code>Node</code> <p>The origin <code>Node</code>.</p> <code>destination</code> <code>Node</code> <p>The destination <code>Node</code>.</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>@define(frozen=True)\nclass Edge:\n    \"\"\"A connection between two `Node` objects within a `Skeleton`.\n\n    This is a directed edge, representing the ordering of `Node`s in the `Skeleton`\n    tree.\n\n    Attributes:\n        source: The origin `Node`.\n        destination: The destination `Node`.\n    \"\"\"\n\n    source: Node\n    destination: Node\n\n    def __getitem__(self, idx) -&gt; Node:\n        \"\"\"Return the source `Node` (`idx` is 0) or destination `Node` (`idx` is 1).\"\"\"\n        if idx == 0:\n            return self.source\n        elif idx == 1:\n            return self.destination\n        else:\n            raise IndexError(\"Edge only has 2 nodes (source and destination).\")\n</code></pre>"},{"location":"reference/sleap_io/model/skeleton/#sleap_io.model.skeleton.Edge.__getitem__","title":"<code>__getitem__(idx)</code>","text":"<p>Return the source <code>Node</code> (<code>idx</code> is 0) or destination <code>Node</code> (<code>idx</code> is 1).</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def __getitem__(self, idx) -&gt; Node:\n    \"\"\"Return the source `Node` (`idx` is 0) or destination `Node` (`idx` is 1).\"\"\"\n    if idx == 0:\n        return self.source\n    elif idx == 1:\n        return self.destination\n    else:\n        raise IndexError(\"Edge only has 2 nodes (source and destination).\")\n</code></pre>"},{"location":"reference/sleap_io/model/skeleton/#sleap_io.model.skeleton.Node","title":"<code>Node</code>","text":"<p>A landmark type within a <code>Skeleton</code>.</p> <p>This typically corresponds to a unique landmark within a skeleton, such as the \"left eye\".</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>Descriptive label for the landmark.</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>@define(frozen=True, cache_hash=True)\nclass Node:\n    \"\"\"A landmark type within a `Skeleton`.\n\n    This typically corresponds to a unique landmark within a skeleton, such as the \"left\n    eye\".\n\n    Attributes:\n        name: Descriptive label for the landmark.\n    \"\"\"\n\n    name: str\n</code></pre>"},{"location":"reference/sleap_io/model/skeleton/#sleap_io.model.skeleton.Skeleton","title":"<code>Skeleton</code>","text":"<p>A description of a set of landmark types and connections between them.</p> <p>Skeletons are represented by a directed graph composed of a set of <code>Node</code>s (landmark types such as body parts) and <code>Edge</code>s (connections between parts).</p> <p>Attributes:</p> Name Type Description <code>nodes</code> <code>list[Node]</code> <p>A list of <code>Node</code>s. May be specified as a list of strings to create new nodes from their names.</p> <code>edges</code> <code>list[Edge]</code> <p>A list of <code>Edge</code>s. May be specified as a list of 2-tuples of string names or integer indices of <code>nodes</code>. Each edge corresponds to a pair of source and destination nodes forming a directed edge.</p> <code>symmetries</code> <code>list[Symmetry]</code> <p>A list of <code>Symmetry</code>s. Each symmetry corresponds to symmetric body parts, such as <code>\"left eye\", \"right eye\"</code>. This is used when applying flip (reflection) augmentation to images in order to appropriately swap the indices of symmetric landmarks.</p> <code>name</code> <code>Optional[str]</code> <p>A descriptive name for the <code>Skeleton</code>.</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>@define\nclass Skeleton:\n    \"\"\"A description of a set of landmark types and connections between them.\n\n    Skeletons are represented by a directed graph composed of a set of `Node`s (landmark\n    types such as body parts) and `Edge`s (connections between parts).\n\n    Attributes:\n        nodes: A list of `Node`s. May be specified as a list of strings to create new\n            nodes from their names.\n        edges: A list of `Edge`s. May be specified as a list of 2-tuples of string names\n            or integer indices of `nodes`. Each edge corresponds to a pair of source and\n            destination nodes forming a directed edge.\n        symmetries: A list of `Symmetry`s. Each symmetry corresponds to symmetric body\n            parts, such as `\"left eye\", \"right eye\"`. This is used when applying flip\n            (reflection) augmentation to images in order to appropriately swap the\n            indices of symmetric landmarks.\n        name: A descriptive name for the `Skeleton`.\n    \"\"\"\n\n    def _update_node_map(self, attr, nodes):\n        \"\"\"Callback for maintaining node name/index to `Node` map.\"\"\"\n        self._node_name_map = {node.name: node for node in nodes}\n        self._node_ind_map = {node: i for i, node in enumerate(nodes)}\n\n    nodes: list[Node] = field(factory=list, on_setattr=_update_node_map)\n    edges: list[Edge] = field(factory=list)\n    symmetries: list[Symmetry] = field(factory=list)\n    name: Optional[str] = None\n    _node_name_map: dict[str, Node] = field(init=False, repr=False, eq=False)\n    _node_ind_map: dict[Node, int] = field(init=False, repr=False, eq=False)\n\n    def __attrs_post_init__(self):\n        \"\"\"Ensure nodes are `Node`s, edges are `Edge`s, and `Node` map is updated.\"\"\"\n        self._convert_nodes()\n        self._convert_edges()\n        self._update_node_map(None, self.nodes)\n\n    def _convert_nodes(self):\n        \"\"\"Convert nodes to `Node` objects if needed.\"\"\"\n        if isinstance(self.nodes, np.ndarray):\n            object.__setattr__(self, \"nodes\", self.nodes.tolist())\n        for i, node in enumerate(self.nodes):\n            if type(node) == str:\n                self.nodes[i] = Node(node)\n\n    def _convert_edges(self):\n        \"\"\"Convert list of edge names or integers to `Edge` objects if needed.\"\"\"\n        if isinstance(self.edges, np.ndarray):\n            self.edges = self.edges.tolist()\n        node_names = self.node_names\n        for i, edge in enumerate(self.edges):\n            if type(edge) == Edge:\n                continue\n            src, dst = edge\n            if type(src) == str:\n                try:\n                    src = node_names.index(src)\n                except ValueError:\n                    raise ValueError(\n                        f\"Node '{src}' specified in the edge list is not in the nodes.\"\n                    )\n            if type(src) == int or (\n                np.isscalar(src) and np.issubdtype(src.dtype, np.integer)\n            ):\n                src = self.nodes[src]\n\n            if type(dst) == str:\n                try:\n                    dst = node_names.index(dst)\n                except ValueError:\n                    raise ValueError(\n                        f\"Node '{dst}' specified in the edge list is not in the nodes.\"\n                    )\n            if type(dst) == int or (\n                np.isscalar(dst) and np.issubdtype(dst.dtype, np.integer)\n            ):\n                dst = self.nodes[dst]\n\n            self.edges[i] = Edge(src, dst)\n\n    @property\n    def node_names(self) -&gt; list[str]:\n        \"\"\"Names of the nodes associated with this skeleton as a list of strings.\"\"\"\n        return [node.name for node in self.nodes]\n\n    @property\n    def edge_inds(self) -&gt; list[Tuple[int, int]]:\n        \"\"\"Edges indices as a list of 2-tuples.\"\"\"\n        return [\n            (self.nodes.index(edge.source), self.nodes.index(edge.destination))\n            for edge in self.edges\n        ]\n\n    @property\n    def edge_names(self) -&gt; list[str, str]:\n        \"\"\"Edge names as a list of 2-tuples with string node names.\"\"\"\n        return [(edge.source.name, edge.destination.name) for edge in self.edges]\n\n    @property\n    def flipped_node_inds(self) -&gt; list[int]:\n        \"\"\"Returns node indices that should be switched when horizontally flipping.\"\"\"\n        flip_idx = np.arange(len(self.nodes))\n        if len(self.symmetries) &gt; 0:\n            symmetry_inds = np.array(\n                [(self.index(a), self.index(b)) for a, b in self.symmetries]\n            )\n            flip_idx[symmetry_inds[:, 0]] = symmetry_inds[:, 1]\n            flip_idx[symmetry_inds[:, 1]] = symmetry_inds[:, 0]\n\n        flip_idx = flip_idx.tolist()\n        return flip_idx\n\n    def __len__(self) -&gt; int:\n        \"\"\"Return the number of nodes in the skeleton.\"\"\"\n        return len(self.nodes)\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return a readable representation of the skeleton.\"\"\"\n        nodes = \", \".join([f'\"{node}\"' for node in self.node_names])\n        return \"Skeleton(\" f\"nodes=[{nodes}], \" f\"edges={self.edge_inds}\" \")\"\n\n    def index(self, node: Node | str) -&gt; int:\n        \"\"\"Return the index of a node specified as a `Node` or string name.\"\"\"\n        if type(node) == str:\n            return self.index(self._node_name_map[node])\n        elif type(node) == Node:\n            return self._node_ind_map[node]\n        else:\n            raise IndexError(f\"Invalid indexing argument for skeleton: {node}\")\n\n    def __getitem__(self, idx: int | str) -&gt; Node:\n        \"\"\"Return a `Node` when indexing by name or integer.\"\"\"\n        if type(idx) == int:\n            return self.nodes[idx]\n        elif type(idx) == str:\n            return self._node_name_map[idx]\n        else:\n            raise IndexError(f\"Invalid indexing argument for skeleton: {idx}\")\n\n    def add_node(self, node: Node | str):\n        \"\"\"Add a `Node` to the skeleton.\n\n        Args:\n            node: A `Node` object or a string name to create a new node.\n        \"\"\"\n        if type(node) == str:\n            node = Node(node)\n        if node not in self.nodes:\n            self.nodes.append(node)\n            self._update_node_map(None, self.nodes)\n\n    def add_edge(self, src: Edge | Node | str = None, dst: Node | str = None):\n        \"\"\"Add an `Edge` to the skeleton.\n\n        Args:\n            src: The source `Node` or name of the source node.\n            dst: The destination `Node` or name of the destination node.\n        \"\"\"\n        if type(src) == Edge:\n            edge = src\n            if edge not in self.edges:\n                self.edges.append(edge)\n            if edge.source not in self.nodes:\n                self.add_node(edge.source)\n            if edge.destination not in self.nodes:\n                self.add_node(edge.destination)\n            return\n\n        if type(src) == str or type(src) == Node:\n            try:\n                src = self.index(src)\n            except KeyError:\n                self.add_node(src)\n                src = self.index(src)\n\n        if type(dst) == str or type(dst) == Node:\n            try:\n                dst = self.index(dst)\n            except KeyError:\n                self.add_node(dst)\n                dst = self.index(dst)\n\n        edge = Edge(self.nodes[src], self.nodes[dst])\n        if edge not in self.edges:\n            self.edges.append(edge)\n\n    def add_symmetry(\n        self, node1: Symmetry | Node | str = None, node2: Node | str = None\n    ):\n        \"\"\"Add a symmetry relationship to the skeleton.\n\n        Args:\n            node1: The first `Node` or name of the first node.\n            node2: The second `Node` or name of the second node.\n        \"\"\"\n        if type(node1) == Symmetry:\n            if node1 not in self.symmetries:\n                self.symmetries.append(node1)\n                for node in node1.nodes:\n                    if node not in self.nodes:\n                        self.add_node(node)\n            return\n\n        if type(node1) == str or type(node1) == Node:\n            try:\n                node1 = self.index(node1)\n            except KeyError:\n                self.add_node(node1)\n                node1 = self.index(node1)\n\n        if type(node2) == str or type(node2) == Node:\n            try:\n                node2 = self.index(node2)\n            except KeyError:\n                self.add_node(node2)\n                node2 = self.index(node2)\n\n        symmetry = Symmetry({self.nodes[node1], self.nodes[node2]})\n        if symmetry not in self.symmetries:\n            self.symmetries.append(symmetry)\n</code></pre>"},{"location":"reference/sleap_io/model/skeleton/#sleap_io.model.skeleton.Skeleton.edge_inds","title":"<code>edge_inds: list[Tuple[int, int]]</code>  <code>property</code>","text":"<p>Edges indices as a list of 2-tuples.</p>"},{"location":"reference/sleap_io/model/skeleton/#sleap_io.model.skeleton.Skeleton.edge_names","title":"<code>edge_names: list[str, str]</code>  <code>property</code>","text":"<p>Edge names as a list of 2-tuples with string node names.</p>"},{"location":"reference/sleap_io/model/skeleton/#sleap_io.model.skeleton.Skeleton.flipped_node_inds","title":"<code>flipped_node_inds: list[int]</code>  <code>property</code>","text":"<p>Returns node indices that should be switched when horizontally flipping.</p>"},{"location":"reference/sleap_io/model/skeleton/#sleap_io.model.skeleton.Skeleton.node_names","title":"<code>node_names: list[str]</code>  <code>property</code>","text":"<p>Names of the nodes associated with this skeleton as a list of strings.</p>"},{"location":"reference/sleap_io/model/skeleton/#sleap_io.model.skeleton.Skeleton.__attrs_post_init__","title":"<code>__attrs_post_init__()</code>","text":"<p>Ensure nodes are <code>Node</code>s, edges are <code>Edge</code>s, and <code>Node</code> map is updated.</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def __attrs_post_init__(self):\n    \"\"\"Ensure nodes are `Node`s, edges are `Edge`s, and `Node` map is updated.\"\"\"\n    self._convert_nodes()\n    self._convert_edges()\n    self._update_node_map(None, self.nodes)\n</code></pre>"},{"location":"reference/sleap_io/model/skeleton/#sleap_io.model.skeleton.Skeleton.__getitem__","title":"<code>__getitem__(idx)</code>","text":"<p>Return a <code>Node</code> when indexing by name or integer.</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def __getitem__(self, idx: int | str) -&gt; Node:\n    \"\"\"Return a `Node` when indexing by name or integer.\"\"\"\n    if type(idx) == int:\n        return self.nodes[idx]\n    elif type(idx) == str:\n        return self._node_name_map[idx]\n    else:\n        raise IndexError(f\"Invalid indexing argument for skeleton: {idx}\")\n</code></pre>"},{"location":"reference/sleap_io/model/skeleton/#sleap_io.model.skeleton.Skeleton.__len__","title":"<code>__len__()</code>","text":"<p>Return the number of nodes in the skeleton.</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"Return the number of nodes in the skeleton.\"\"\"\n    return len(self.nodes)\n</code></pre>"},{"location":"reference/sleap_io/model/skeleton/#sleap_io.model.skeleton.Skeleton.__repr__","title":"<code>__repr__()</code>","text":"<p>Return a readable representation of the skeleton.</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Return a readable representation of the skeleton.\"\"\"\n    nodes = \", \".join([f'\"{node}\"' for node in self.node_names])\n    return \"Skeleton(\" f\"nodes=[{nodes}], \" f\"edges={self.edge_inds}\" \")\"\n</code></pre>"},{"location":"reference/sleap_io/model/skeleton/#sleap_io.model.skeleton.Skeleton.add_edge","title":"<code>add_edge(src=None, dst=None)</code>","text":"<p>Add an <code>Edge</code> to the skeleton.</p> <p>Parameters:</p> Name Type Description Default <code>src</code> <code>Edge | Node | str</code> <p>The source <code>Node</code> or name of the source node.</p> <code>None</code> <code>dst</code> <code>Node | str</code> <p>The destination <code>Node</code> or name of the destination node.</p> <code>None</code> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def add_edge(self, src: Edge | Node | str = None, dst: Node | str = None):\n    \"\"\"Add an `Edge` to the skeleton.\n\n    Args:\n        src: The source `Node` or name of the source node.\n        dst: The destination `Node` or name of the destination node.\n    \"\"\"\n    if type(src) == Edge:\n        edge = src\n        if edge not in self.edges:\n            self.edges.append(edge)\n        if edge.source not in self.nodes:\n            self.add_node(edge.source)\n        if edge.destination not in self.nodes:\n            self.add_node(edge.destination)\n        return\n\n    if type(src) == str or type(src) == Node:\n        try:\n            src = self.index(src)\n        except KeyError:\n            self.add_node(src)\n            src = self.index(src)\n\n    if type(dst) == str or type(dst) == Node:\n        try:\n            dst = self.index(dst)\n        except KeyError:\n            self.add_node(dst)\n            dst = self.index(dst)\n\n    edge = Edge(self.nodes[src], self.nodes[dst])\n    if edge not in self.edges:\n        self.edges.append(edge)\n</code></pre>"},{"location":"reference/sleap_io/model/skeleton/#sleap_io.model.skeleton.Skeleton.add_node","title":"<code>add_node(node)</code>","text":"<p>Add a <code>Node</code> to the skeleton.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>Node | str</code> <p>A <code>Node</code> object or a string name to create a new node.</p> required Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def add_node(self, node: Node | str):\n    \"\"\"Add a `Node` to the skeleton.\n\n    Args:\n        node: A `Node` object or a string name to create a new node.\n    \"\"\"\n    if type(node) == str:\n        node = Node(node)\n    if node not in self.nodes:\n        self.nodes.append(node)\n        self._update_node_map(None, self.nodes)\n</code></pre>"},{"location":"reference/sleap_io/model/skeleton/#sleap_io.model.skeleton.Skeleton.add_symmetry","title":"<code>add_symmetry(node1=None, node2=None)</code>","text":"<p>Add a symmetry relationship to the skeleton.</p> <p>Parameters:</p> Name Type Description Default <code>node1</code> <code>Symmetry | Node | str</code> <p>The first <code>Node</code> or name of the first node.</p> <code>None</code> <code>node2</code> <code>Node | str</code> <p>The second <code>Node</code> or name of the second node.</p> <code>None</code> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def add_symmetry(\n    self, node1: Symmetry | Node | str = None, node2: Node | str = None\n):\n    \"\"\"Add a symmetry relationship to the skeleton.\n\n    Args:\n        node1: The first `Node` or name of the first node.\n        node2: The second `Node` or name of the second node.\n    \"\"\"\n    if type(node1) == Symmetry:\n        if node1 not in self.symmetries:\n            self.symmetries.append(node1)\n            for node in node1.nodes:\n                if node not in self.nodes:\n                    self.add_node(node)\n        return\n\n    if type(node1) == str or type(node1) == Node:\n        try:\n            node1 = self.index(node1)\n        except KeyError:\n            self.add_node(node1)\n            node1 = self.index(node1)\n\n    if type(node2) == str or type(node2) == Node:\n        try:\n            node2 = self.index(node2)\n        except KeyError:\n            self.add_node(node2)\n            node2 = self.index(node2)\n\n    symmetry = Symmetry({self.nodes[node1], self.nodes[node2]})\n    if symmetry not in self.symmetries:\n        self.symmetries.append(symmetry)\n</code></pre>"},{"location":"reference/sleap_io/model/skeleton/#sleap_io.model.skeleton.Skeleton.index","title":"<code>index(node)</code>","text":"<p>Return the index of a node specified as a <code>Node</code> or string name.</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def index(self, node: Node | str) -&gt; int:\n    \"\"\"Return the index of a node specified as a `Node` or string name.\"\"\"\n    if type(node) == str:\n        return self.index(self._node_name_map[node])\n    elif type(node) == Node:\n        return self._node_ind_map[node]\n    else:\n        raise IndexError(f\"Invalid indexing argument for skeleton: {node}\")\n</code></pre>"},{"location":"reference/sleap_io/model/skeleton/#sleap_io.model.skeleton.Symmetry","title":"<code>Symmetry</code>","text":"<p>A relationship between a pair of nodes denoting their left/right pairing.</p> <p>Attributes:</p> Name Type Description <code>nodes</code> <code>set[Node]</code> <p>A set of two <code>Node</code>s.</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>@define\nclass Symmetry:\n    \"\"\"A relationship between a pair of nodes denoting their left/right pairing.\n\n    Attributes:\n        nodes: A set of two `Node`s.\n    \"\"\"\n\n    nodes: set[Node] = field(converter=set, validator=lambda _, __, val: len(val) == 2)\n\n    def __iter__(self):\n        \"\"\"Iterate over the symmetric nodes.\"\"\"\n        return iter(self.nodes)\n\n    def __getitem__(self, idx) -&gt; Node:\n        \"\"\"Return the first node.\"\"\"\n        for i, node in enumerate(self.nodes):\n            if i == idx:\n                return node\n</code></pre>"},{"location":"reference/sleap_io/model/skeleton/#sleap_io.model.skeleton.Symmetry.__getitem__","title":"<code>__getitem__(idx)</code>","text":"<p>Return the first node.</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def __getitem__(self, idx) -&gt; Node:\n    \"\"\"Return the first node.\"\"\"\n    for i, node in enumerate(self.nodes):\n        if i == idx:\n            return node\n</code></pre>"},{"location":"reference/sleap_io/model/skeleton/#sleap_io.model.skeleton.Symmetry.__iter__","title":"<code>__iter__()</code>","text":"<p>Iterate over the symmetric nodes.</p> Source code in <code>sleap_io/model/skeleton.py</code> <pre><code>def __iter__(self):\n    \"\"\"Iterate over the symmetric nodes.\"\"\"\n    return iter(self.nodes)\n</code></pre>"},{"location":"reference/sleap_io/model/suggestions/","title":"suggestions","text":""},{"location":"reference/sleap_io/model/suggestions/#sleap_io.model.suggestions","title":"<code>sleap_io.model.suggestions</code>","text":"<p>Data module for suggestions.</p>"},{"location":"reference/sleap_io/model/suggestions/#sleap_io.model.suggestions.SuggestionFrame","title":"<code>SuggestionFrame</code>","text":"<p>Data structure for a single frame of suggestions.</p> <p>Attributes:</p> Name Type Description <code>video</code> <code>Video</code> <p>The video associated with the frame.</p> <code>frame_idx</code> <code>int</code> <p>The index of the frame in the video.</p> Source code in <code>sleap_io/model/suggestions.py</code> <pre><code>@attrs.define(auto_attribs=True)\nclass SuggestionFrame:\n    \"\"\"Data structure for a single frame of suggestions.\n\n    Attributes:\n        video: The video associated with the frame.\n        frame_idx: The index of the frame in the video.\n    \"\"\"\n\n    video: Video\n    frame_idx: int\n</code></pre>"},{"location":"reference/sleap_io/model/video/","title":"video","text":""},{"location":"reference/sleap_io/model/video/#sleap_io.model.video","title":"<code>sleap_io.model.video</code>","text":"<p>Data model for videos.</p> <p>The <code>Video</code> class is a SLEAP data structure that stores information regarding a video and its components used in SLEAP.</p>"},{"location":"reference/sleap_io/model/video/#sleap_io.model.video.Video","title":"<code>Video</code>","text":"<p><code>Video</code> class used by sleap to represent videos and data associated with them.</p> <p>This class is used to store information regarding a video and its components. It is used to store the video's <code>filename</code>, <code>shape</code>, and the video's <code>backend</code>.</p> <p>To create a <code>Video</code> object, use the <code>from_filename</code> method which will select the backend appropriately.</p> <p>Attributes:</p> Name Type Description <code>filename</code> <code>str | list[str]</code> <p>The filename(s) of the video. Supported extensions: \"mp4\", \"avi\", \"mov\", \"mj2\", \"mkv\", \"h5\", \"hdf5\", \"slp\", \"png\", \"jpg\", \"jpeg\", \"tif\", \"tiff\", \"bmp\". If the filename is a list, a list of image filenames are expected. If filename is a folder, it will be searched for images.</p> <code>backend</code> <code>Optional[VideoBackend]</code> <p>An object that implements the basic methods for reading and manipulating frames of a specific video type.</p> <code>backend_metadata</code> <code>dict[str, any]</code> <p>A dictionary of metadata specific to the backend. This is useful for storing metadata that requires an open backend (e.g., shape information) without having access to the video file itself.</p> <code>source_video</code> <code>Optional[Video]</code> <p>The source video object if this is a proxy video. This is present when the video contains an embedded subset of frames from another video.</p> Notes <p>Instances of this class are hashed by identity, not by value. This means that two <code>Video</code> instances with the same attributes will NOT be considered equal in a set or dict.</p> <p>See also: VideoBackend</p> Source code in <code>sleap_io/model/video.py</code> <pre><code>@attrs.define(eq=False)\nclass Video:\n    \"\"\"`Video` class used by sleap to represent videos and data associated with them.\n\n    This class is used to store information regarding a video and its components.\n    It is used to store the video's `filename`, `shape`, and the video's `backend`.\n\n    To create a `Video` object, use the `from_filename` method which will select the\n    backend appropriately.\n\n    Attributes:\n        filename: The filename(s) of the video. Supported extensions: \"mp4\", \"avi\",\n            \"mov\", \"mj2\", \"mkv\", \"h5\", \"hdf5\", \"slp\", \"png\", \"jpg\", \"jpeg\", \"tif\",\n            \"tiff\", \"bmp\". If the filename is a list, a list of image filenames are\n            expected. If filename is a folder, it will be searched for images.\n        backend: An object that implements the basic methods for reading and\n            manipulating frames of a specific video type.\n        backend_metadata: A dictionary of metadata specific to the backend. This is\n            useful for storing metadata that requires an open backend (e.g., shape\n            information) without having access to the video file itself.\n        source_video: The source video object if this is a proxy video. This is present\n            when the video contains an embedded subset of frames from another video.\n\n    Notes:\n        Instances of this class are hashed by identity, not by value. This means that\n        two `Video` instances with the same attributes will NOT be considered equal in a\n        set or dict.\n\n    See also: VideoBackend\n    \"\"\"\n\n    filename: str | list[str]\n    backend: Optional[VideoBackend] = None\n    backend_metadata: dict[str, any] = attrs.field(factory=dict)\n    source_video: Optional[Video] = None\n\n    EXTS = MediaVideo.EXTS + HDF5Video.EXTS + ImageVideo.EXTS\n\n    def __attrs_post_init__(self):\n        \"\"\"Post init syntactic sugar.\"\"\"\n        if self.backend is None and self.exists():\n            self.open()\n\n    @classmethod\n    def from_filename(\n        cls,\n        filename: str | list[str],\n        dataset: Optional[str] = None,\n        grayscale: Optional[bool] = None,\n        keep_open: bool = True,\n        source_video: Optional[Video] = None,\n        **kwargs,\n    ) -&gt; VideoBackend:\n        \"\"\"Create a Video from a filename.\n\n        Args:\n            filename: The filename(s) of the video. Supported extensions: \"mp4\", \"avi\",\n                \"mov\", \"mj2\", \"mkv\", \"h5\", \"hdf5\", \"slp\", \"png\", \"jpg\", \"jpeg\", \"tif\",\n                \"tiff\", \"bmp\". If the filename is a list, a list of image filenames are\n                expected. If filename is a folder, it will be searched for images.\n            dataset: Name of dataset in HDF5 file.\n            grayscale: Whether to force grayscale. If None, autodetect on first frame\n                load.\n            keep_open: Whether to keep the video reader open between calls to read\n                frames. If False, will close the reader after each call. If True (the\n                default), it will keep the reader open and cache it for subsequent calls\n                which may enhance the performance of reading multiple frames.\n            source_video: The source video object if this is a proxy video. This is\n                present when the video contains an embedded subset of frames from\n                another video.\n\n        Returns:\n            Video instance with the appropriate backend instantiated.\n        \"\"\"\n        return cls(\n            filename=filename,\n            backend=VideoBackend.from_filename(\n                filename,\n                dataset=dataset,\n                grayscale=grayscale,\n                keep_open=keep_open,\n                **kwargs,\n            ),\n            source_video=source_video,\n        )\n\n    @property\n    def shape(self) -&gt; Tuple[int, int, int, int] | None:\n        \"\"\"Return the shape of the video as (num_frames, height, width, channels).\n\n        If the video backend is not set or it cannot determine the shape of the video,\n        this will return None.\n        \"\"\"\n        return self._get_shape()\n\n    def _get_shape(self) -&gt; Tuple[int, int, int, int] | None:\n        \"\"\"Return the shape of the video as (num_frames, height, width, channels).\n\n        This suppresses errors related to querying the backend for the video shape, such\n        as when it has not been set or when the video file is not found.\n        \"\"\"\n        try:\n            return self.backend.shape\n        except:\n            if \"shape\" in self.backend_metadata:\n                return self.backend_metadata[\"shape\"]\n            return None\n\n    @property\n    def grayscale(self) -&gt; bool | None:\n        \"\"\"Return whether the video is grayscale.\n\n        If the video backend is not set or it cannot determine whether the video is\n        grayscale, this will return None.\n        \"\"\"\n        shape = self.shape\n        if shape is not None:\n            return shape[-1] == 1\n        else:\n            if \"grayscale\" in self.backend_metadata:\n                return self.backend_metadata[\"grayscale\"]\n            return None\n\n    def __len__(self) -&gt; int:\n        \"\"\"Return the length of the video as the number of frames.\"\"\"\n        shape = self.shape\n        return 0 if shape is None else shape[0]\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Informal string representation (for print or format).\"\"\"\n        dataset = (\n            f\"dataset={self.backend.dataset}, \"\n            if getattr(self.backend, \"dataset\", \"\")\n            else \"\"\n        )\n        return (\n            \"Video(\"\n            f'filename=\"{self.filename}\", '\n            f\"shape={self.shape}, \"\n            f\"{dataset}\"\n            f\"backend={type(self.backend).__name__}\"\n            \")\"\n        )\n\n    def __str__(self) -&gt; str:\n        \"\"\"Informal string representation (for print or format).\"\"\"\n        return self.__repr__()\n\n    def __getitem__(self, inds: int | list[int] | slice) -&gt; np.ndarray:\n        \"\"\"Return the frames of the video at the given indices.\n\n        Args:\n            inds: Index or list of indices of frames to read.\n\n        Returns:\n            Frame or frames as a numpy array of shape `(height, width, channels)` if a\n            scalar index is provided, or `(frames, height, width, channels)` if a list\n            of indices is provided.\n\n        See also: VideoBackend.get_frame, VideoBackend.get_frames\n        \"\"\"\n        if not self.is_open:\n            self.open()\n        return self.backend[inds]\n\n    def exists(self, check_all: bool = False) -&gt; bool:\n        \"\"\"Check if the video file exists.\n\n        Args:\n            check_all: If `True`, check that all filenames in a list exist. If `False`\n                (the default), check that the first filename exists.\n        \"\"\"\n        if isinstance(self.filename, list):\n            if check_all:\n                for f in self.filename:\n                    if not Path(f).exists():\n                        return False\n                return True\n            else:\n                return Path(self.filename[0]).exists()\n        return Path(self.filename).exists()\n\n    @property\n    def is_open(self) -&gt; bool:\n        \"\"\"Check if the video backend is open.\"\"\"\n        return self.exists() and self.backend is not None\n\n    def open(\n        self,\n        dataset: Optional[str] = None,\n        grayscale: Optional[str] = None,\n        keep_open: bool = True,\n    ):\n        \"\"\"Open the video backend for reading.\n\n        Args:\n            dataset: Name of dataset in HDF5 file.\n            grayscale: Whether to force grayscale. If None, autodetect on first frame\n                load.\n            keep_open: Whether to keep the video reader open between calls to read\n                frames. If False, will close the reader after each call. If True (the\n                default), it will keep the reader open and cache it for subsequent calls\n                which may enhance the performance of reading multiple frames.\n\n        Notes:\n            This is useful for opening the video backend to read frames and then closing\n            it after reading all the necessary frames.\n\n            If the backend was already open, it will be closed before opening a new one.\n            Values for the HDF5 dataset and grayscale will be remembered if not\n            specified.\n        \"\"\"\n        if not self.exists():\n            raise FileNotFoundError(f\"Video file not found: {self.filename}\")\n\n        # Try to remember values from previous backend if available and not specified.\n        if self.backend is not None:\n            if dataset is None:\n                dataset = getattr(self.backend, \"dataset\", None)\n            if grayscale is None:\n                grayscale = getattr(self.backend, \"grayscale\", None)\n\n        else:\n            if dataset is None and \"dataset\" in self.backend_metadata:\n                dataset = self.backend_metadata[\"dataset\"]\n            if grayscale is None and \"grayscale\" in self.backend_metadata:\n                grayscale = self.backend_metadata[\"grayscale\"]\n\n        # Close previous backend if open.\n        self.close()\n\n        # Create new backend.\n        self.backend = VideoBackend.from_filename(\n            self.filename,\n            dataset=dataset,\n            grayscale=grayscale,\n            keep_open=keep_open,\n        )\n\n    def close(self):\n        \"\"\"Close the video backend.\"\"\"\n        if self.backend is not None:\n            del self.backend\n            self.backend = None\n\n    def replace_filename(\n        self, new_filename: str | Path | list[str] | list[Path], open: bool = True\n    ):\n        \"\"\"Update the filename of the video, optionally opening the backend.\n\n        Args:\n            new_filename: New filename to set for the video.\n            open: If `True` (the default), open the backend with the new filename. If\n                the new filename does not exist, no error is raised.\n        \"\"\"\n        if isinstance(new_filename, Path):\n            new_filename = new_filename.as_posix()\n\n        if isinstance(new_filename, list):\n            new_filename = [\n                p.as_posix() if isinstance(p, Path) else p for p in new_filename\n            ]\n\n        self.filename = new_filename\n\n        if open:\n            if self.exists():\n                self.open()\n            else:\n                self.close()\n</code></pre>"},{"location":"reference/sleap_io/model/video/#sleap_io.model.video.Video.grayscale","title":"<code>grayscale: bool | None</code>  <code>property</code>","text":"<p>Return whether the video is grayscale.</p> <p>If the video backend is not set or it cannot determine whether the video is grayscale, this will return None.</p>"},{"location":"reference/sleap_io/model/video/#sleap_io.model.video.Video.is_open","title":"<code>is_open: bool</code>  <code>property</code>","text":"<p>Check if the video backend is open.</p>"},{"location":"reference/sleap_io/model/video/#sleap_io.model.video.Video.shape","title":"<code>shape: Tuple[int, int, int, int] | None</code>  <code>property</code>","text":"<p>Return the shape of the video as (num_frames, height, width, channels).</p> <p>If the video backend is not set or it cannot determine the shape of the video, this will return None.</p>"},{"location":"reference/sleap_io/model/video/#sleap_io.model.video.Video.__attrs_post_init__","title":"<code>__attrs_post_init__()</code>","text":"<p>Post init syntactic sugar.</p> Source code in <code>sleap_io/model/video.py</code> <pre><code>def __attrs_post_init__(self):\n    \"\"\"Post init syntactic sugar.\"\"\"\n    if self.backend is None and self.exists():\n        self.open()\n</code></pre>"},{"location":"reference/sleap_io/model/video/#sleap_io.model.video.Video.__getitem__","title":"<code>__getitem__(inds)</code>","text":"<p>Return the frames of the video at the given indices.</p> <p>Parameters:</p> Name Type Description Default <code>inds</code> <code>int | list[int] | slice</code> <p>Index or list of indices of frames to read.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Frame or frames as a numpy array of shape <code>(height, width, channels)</code> if a scalar index is provided, or <code>(frames, height, width, channels)</code> if a list of indices is provided.</p> <p>See also: VideoBackend.get_frame, VideoBackend.get_frames</p> Source code in <code>sleap_io/model/video.py</code> <pre><code>def __getitem__(self, inds: int | list[int] | slice) -&gt; np.ndarray:\n    \"\"\"Return the frames of the video at the given indices.\n\n    Args:\n        inds: Index or list of indices of frames to read.\n\n    Returns:\n        Frame or frames as a numpy array of shape `(height, width, channels)` if a\n        scalar index is provided, or `(frames, height, width, channels)` if a list\n        of indices is provided.\n\n    See also: VideoBackend.get_frame, VideoBackend.get_frames\n    \"\"\"\n    if not self.is_open:\n        self.open()\n    return self.backend[inds]\n</code></pre>"},{"location":"reference/sleap_io/model/video/#sleap_io.model.video.Video.__len__","title":"<code>__len__()</code>","text":"<p>Return the length of the video as the number of frames.</p> Source code in <code>sleap_io/model/video.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"Return the length of the video as the number of frames.\"\"\"\n    shape = self.shape\n    return 0 if shape is None else shape[0]\n</code></pre>"},{"location":"reference/sleap_io/model/video/#sleap_io.model.video.Video.__repr__","title":"<code>__repr__()</code>","text":"<p>Informal string representation (for print or format).</p> Source code in <code>sleap_io/model/video.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Informal string representation (for print or format).\"\"\"\n    dataset = (\n        f\"dataset={self.backend.dataset}, \"\n        if getattr(self.backend, \"dataset\", \"\")\n        else \"\"\n    )\n    return (\n        \"Video(\"\n        f'filename=\"{self.filename}\", '\n        f\"shape={self.shape}, \"\n        f\"{dataset}\"\n        f\"backend={type(self.backend).__name__}\"\n        \")\"\n    )\n</code></pre>"},{"location":"reference/sleap_io/model/video/#sleap_io.model.video.Video.__str__","title":"<code>__str__()</code>","text":"<p>Informal string representation (for print or format).</p> Source code in <code>sleap_io/model/video.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Informal string representation (for print or format).\"\"\"\n    return self.__repr__()\n</code></pre>"},{"location":"reference/sleap_io/model/video/#sleap_io.model.video.Video.close","title":"<code>close()</code>","text":"<p>Close the video backend.</p> Source code in <code>sleap_io/model/video.py</code> <pre><code>def close(self):\n    \"\"\"Close the video backend.\"\"\"\n    if self.backend is not None:\n        del self.backend\n        self.backend = None\n</code></pre>"},{"location":"reference/sleap_io/model/video/#sleap_io.model.video.Video.exists","title":"<code>exists(check_all=False)</code>","text":"<p>Check if the video file exists.</p> <p>Parameters:</p> Name Type Description Default <code>check_all</code> <code>bool</code> <p>If <code>True</code>, check that all filenames in a list exist. If <code>False</code> (the default), check that the first filename exists.</p> <code>False</code> Source code in <code>sleap_io/model/video.py</code> <pre><code>def exists(self, check_all: bool = False) -&gt; bool:\n    \"\"\"Check if the video file exists.\n\n    Args:\n        check_all: If `True`, check that all filenames in a list exist. If `False`\n            (the default), check that the first filename exists.\n    \"\"\"\n    if isinstance(self.filename, list):\n        if check_all:\n            for f in self.filename:\n                if not Path(f).exists():\n                    return False\n            return True\n        else:\n            return Path(self.filename[0]).exists()\n    return Path(self.filename).exists()\n</code></pre>"},{"location":"reference/sleap_io/model/video/#sleap_io.model.video.Video.from_filename","title":"<code>from_filename(filename, dataset=None, grayscale=None, keep_open=True, source_video=None, **kwargs)</code>  <code>classmethod</code>","text":"<p>Create a Video from a filename.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str | list[str]</code> <p>The filename(s) of the video. Supported extensions: \"mp4\", \"avi\", \"mov\", \"mj2\", \"mkv\", \"h5\", \"hdf5\", \"slp\", \"png\", \"jpg\", \"jpeg\", \"tif\", \"tiff\", \"bmp\". If the filename is a list, a list of image filenames are expected. If filename is a folder, it will be searched for images.</p> required <code>dataset</code> <code>Optional[str]</code> <p>Name of dataset in HDF5 file.</p> <code>None</code> <code>grayscale</code> <code>Optional[bool]</code> <p>Whether to force grayscale. If None, autodetect on first frame load.</p> <code>None</code> <code>keep_open</code> <code>bool</code> <p>Whether to keep the video reader open between calls to read frames. If False, will close the reader after each call. If True (the default), it will keep the reader open and cache it for subsequent calls which may enhance the performance of reading multiple frames.</p> <code>True</code> <code>source_video</code> <code>Optional[Video]</code> <p>The source video object if this is a proxy video. This is present when the video contains an embedded subset of frames from another video.</p> <code>None</code> <p>Returns:</p> Type Description <code>VideoBackend</code> <p>Video instance with the appropriate backend instantiated.</p> Source code in <code>sleap_io/model/video.py</code> <pre><code>@classmethod\ndef from_filename(\n    cls,\n    filename: str | list[str],\n    dataset: Optional[str] = None,\n    grayscale: Optional[bool] = None,\n    keep_open: bool = True,\n    source_video: Optional[Video] = None,\n    **kwargs,\n) -&gt; VideoBackend:\n    \"\"\"Create a Video from a filename.\n\n    Args:\n        filename: The filename(s) of the video. Supported extensions: \"mp4\", \"avi\",\n            \"mov\", \"mj2\", \"mkv\", \"h5\", \"hdf5\", \"slp\", \"png\", \"jpg\", \"jpeg\", \"tif\",\n            \"tiff\", \"bmp\". If the filename is a list, a list of image filenames are\n            expected. If filename is a folder, it will be searched for images.\n        dataset: Name of dataset in HDF5 file.\n        grayscale: Whether to force grayscale. If None, autodetect on first frame\n            load.\n        keep_open: Whether to keep the video reader open between calls to read\n            frames. If False, will close the reader after each call. If True (the\n            default), it will keep the reader open and cache it for subsequent calls\n            which may enhance the performance of reading multiple frames.\n        source_video: The source video object if this is a proxy video. This is\n            present when the video contains an embedded subset of frames from\n            another video.\n\n    Returns:\n        Video instance with the appropriate backend instantiated.\n    \"\"\"\n    return cls(\n        filename=filename,\n        backend=VideoBackend.from_filename(\n            filename,\n            dataset=dataset,\n            grayscale=grayscale,\n            keep_open=keep_open,\n            **kwargs,\n        ),\n        source_video=source_video,\n    )\n</code></pre>"},{"location":"reference/sleap_io/model/video/#sleap_io.model.video.Video.open","title":"<code>open(dataset=None, grayscale=None, keep_open=True)</code>","text":"<p>Open the video backend for reading.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>Optional[str]</code> <p>Name of dataset in HDF5 file.</p> <code>None</code> <code>grayscale</code> <code>Optional[str]</code> <p>Whether to force grayscale. If None, autodetect on first frame load.</p> <code>None</code> <code>keep_open</code> <code>bool</code> <p>Whether to keep the video reader open between calls to read frames. If False, will close the reader after each call. If True (the default), it will keep the reader open and cache it for subsequent calls which may enhance the performance of reading multiple frames.</p> <code>True</code> Notes <p>This is useful for opening the video backend to read frames and then closing it after reading all the necessary frames.</p> <p>If the backend was already open, it will be closed before opening a new one. Values for the HDF5 dataset and grayscale will be remembered if not specified.</p> Source code in <code>sleap_io/model/video.py</code> <pre><code>def open(\n    self,\n    dataset: Optional[str] = None,\n    grayscale: Optional[str] = None,\n    keep_open: bool = True,\n):\n    \"\"\"Open the video backend for reading.\n\n    Args:\n        dataset: Name of dataset in HDF5 file.\n        grayscale: Whether to force grayscale. If None, autodetect on first frame\n            load.\n        keep_open: Whether to keep the video reader open between calls to read\n            frames. If False, will close the reader after each call. If True (the\n            default), it will keep the reader open and cache it for subsequent calls\n            which may enhance the performance of reading multiple frames.\n\n    Notes:\n        This is useful for opening the video backend to read frames and then closing\n        it after reading all the necessary frames.\n\n        If the backend was already open, it will be closed before opening a new one.\n        Values for the HDF5 dataset and grayscale will be remembered if not\n        specified.\n    \"\"\"\n    if not self.exists():\n        raise FileNotFoundError(f\"Video file not found: {self.filename}\")\n\n    # Try to remember values from previous backend if available and not specified.\n    if self.backend is not None:\n        if dataset is None:\n            dataset = getattr(self.backend, \"dataset\", None)\n        if grayscale is None:\n            grayscale = getattr(self.backend, \"grayscale\", None)\n\n    else:\n        if dataset is None and \"dataset\" in self.backend_metadata:\n            dataset = self.backend_metadata[\"dataset\"]\n        if grayscale is None and \"grayscale\" in self.backend_metadata:\n            grayscale = self.backend_metadata[\"grayscale\"]\n\n    # Close previous backend if open.\n    self.close()\n\n    # Create new backend.\n    self.backend = VideoBackend.from_filename(\n        self.filename,\n        dataset=dataset,\n        grayscale=grayscale,\n        keep_open=keep_open,\n    )\n</code></pre>"},{"location":"reference/sleap_io/model/video/#sleap_io.model.video.Video.replace_filename","title":"<code>replace_filename(new_filename, open=True)</code>","text":"<p>Update the filename of the video, optionally opening the backend.</p> <p>Parameters:</p> Name Type Description Default <code>new_filename</code> <code>str | Path | list[str] | list[Path]</code> <p>New filename to set for the video.</p> required <code>open</code> <code>bool</code> <p>If <code>True</code> (the default), open the backend with the new filename. If the new filename does not exist, no error is raised.</p> <code>True</code> Source code in <code>sleap_io/model/video.py</code> <pre><code>def replace_filename(\n    self, new_filename: str | Path | list[str] | list[Path], open: bool = True\n):\n    \"\"\"Update the filename of the video, optionally opening the backend.\n\n    Args:\n        new_filename: New filename to set for the video.\n        open: If `True` (the default), open the backend with the new filename. If\n            the new filename does not exist, no error is raised.\n    \"\"\"\n    if isinstance(new_filename, Path):\n        new_filename = new_filename.as_posix()\n\n    if isinstance(new_filename, list):\n        new_filename = [\n            p.as_posix() if isinstance(p, Path) else p for p in new_filename\n        ]\n\n    self.filename = new_filename\n\n    if open:\n        if self.exists():\n            self.open()\n        else:\n            self.close()\n</code></pre>"}]}